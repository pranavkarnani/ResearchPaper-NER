module,parameter
"ALBERT
	",vocab_size
"ALBERT
	",embedding_size
"ALBERT
	",hidden_size
"ALBERT
	",num_hidden_layers
"ALBERT
	",num_hidden_groups
"ALBERT
	",num_attention_heads
"ALBERT
	",intermediate_size
"ALBERT
	",inner_group_num
"ALBERT
	",hidden_act
"ALBERT
	",hidden_dropout_prob
"ALBERT
	",attention_probs_dropout_prob
"ALBERT
	",max_position_embeddings
"ALBERT
	",type_vocab_size
"ALBERT
	",initializer_range
"ALBERT
	",layer_norm_eps
"ALBERT
	",classifier_dropout_prob
"ALBERT
	",position_embedding_type
"ALBERT
	",vocab_file
"ALBERT
	",do_lower_case
"ALBERT
	",remove_space
"ALBERT
	",keep_accents
"ALBERT
	",bos_token
"ALBERT
	",eos_token
"ALBERT
	",unk_token
"ALBERT
	",sep_token
"ALBERT
	",pad_token
"ALBERT
	",cls_token
"ALBERT
	",mask_token
"ALBERT
	",sp_model_kwargs
"ALBERT
	",sp_model
"ALBERT
	",token_ids_0
"ALBERT
	",token_ids_1
"ALBERT
	",token_ids_0
"ALBERT
	",token_ids_1
"ALBERT
	",already_has_special_tokens
"ALBERT
	",token_ids_0
"ALBERT
	",token_ids_1
"ALBERT
	",vocab_file
"ALBERT
	",do_lower_case
"ALBERT
	",remove_space
"ALBERT
	",keep_accents
"ALBERT
	",bos_token
"ALBERT
	",eos_token
"ALBERT
	",unk_token
"ALBERT
	",sep_token
"ALBERT
	",pad_token
"ALBERT
	",cls_token
"ALBERT
	",mask_token
"ALBERT
	",token_ids_0
"ALBERT
	",token_ids_1
"ALBERT
	",token_ids_0
"ALBERT
	",token_ids_1
"ALBERT
	",loss
"ALBERT
	",prediction_logits
"ALBERT
	",sop_logits
"ALBERT
	",hidden_states
"ALBERT
	",attentions
"ALBERT
	",prediction_logits
"ALBERT
	",sop_logits
"ALBERT
	",hidden_states
"ALBERT
	",attentions
"ALBERT
	",config
"ALBERT
	",input_ids
"ALBERT
	",attention_mask
"ALBERT
	",token_type_ids
"ALBERT
	",position_ids
"ALBERT
	",head_mask
"ALBERT
	",inputs_embeds
"ALBERT
	",output_attentions
"ALBERT
	",output_hidden_states
"ALBERT
	",return_dict
"ALBERT
	",config
"ALBERT
	",input_ids
"ALBERT
	",attention_mask
"ALBERT
	",token_type_ids
"ALBERT
	",position_ids
"ALBERT
	",head_mask
"ALBERT
	",inputs_embeds
"ALBERT
	",output_attentions
"ALBERT
	",output_hidden_states
"ALBERT
	",return_dict
"ALBERT
	",labels
"ALBERT
	",sentence_order_label
"ALBERT
	",config
"ALBERT
	",input_ids
"ALBERT
	",attention_mask
"ALBERT
	",token_type_ids
"ALBERT
	",position_ids
"ALBERT
	",head_mask
"ALBERT
	",inputs_embeds
"ALBERT
	",output_attentions
"ALBERT
	",output_hidden_states
"ALBERT
	",return_dict
"ALBERT
	",labels
"ALBERT
	",config
"ALBERT
	",input_ids
"ALBERT
	",attention_mask
"ALBERT
	",token_type_ids
"ALBERT
	",position_ids
"ALBERT
	",head_mask
"ALBERT
	",inputs_embeds
"ALBERT
	",output_attentions
"ALBERT
	",output_hidden_states
"ALBERT
	",return_dict
"ALBERT
	",labels
"ALBERT
	",config
"ALBERT
	",input_ids
"ALBERT
	",attention_mask
"ALBERT
	",token_type_ids
"ALBERT
	",position_ids
"ALBERT
	",head_mask
"ALBERT
	",inputs_embeds
"ALBERT
	",output_attentions
"ALBERT
	",output_hidden_states
"ALBERT
	",return_dict
"ALBERT
	",labels
"ALBERT
	",config
"ALBERT
	",input_ids
"ALBERT
	",attention_mask
"ALBERT
	",token_type_ids
"ALBERT
	",position_ids
"ALBERT
	",head_mask
"ALBERT
	",inputs_embeds
"ALBERT
	",output_attentions
"ALBERT
	",output_hidden_states
"ALBERT
	",return_dict
"ALBERT
	",labels
"ALBERT
	",config
"ALBERT
	",input_ids
"ALBERT
	",attention_mask
"ALBERT
	",token_type_ids
"ALBERT
	",position_ids
"ALBERT
	",head_mask
"ALBERT
	",inputs_embeds
"ALBERT
	",output_attentions
"ALBERT
	",output_hidden_states
"ALBERT
	",return_dict
"ALBERT
	",start_positions
"ALBERT
	",end_positions
"ALBERT
	",config
"ALBERT
	",input_ids
"ALBERT
	",attention_mask
"ALBERT
	",token_type_ids
"ALBERT
	",position_ids
"ALBERT
	",head_mask
"ALBERT
	",inputs_embeds
"ALBERT
	",output_attentions
"ALBERT
	",output_hidden_states
"ALBERT
	",return_dict
"ALBERT
	",training
"ALBERT
	",config
"ALBERT
	",input_ids
"ALBERT
	",attention_mask
"ALBERT
	",token_type_ids
"ALBERT
	",position_ids
"ALBERT
	",head_mask
"ALBERT
	",inputs_embeds
"ALBERT
	",output_attentions
"ALBERT
	",output_hidden_states
"ALBERT
	",return_dict
"ALBERT
	",training
"ALBERT
	",config
"ALBERT
	",input_ids
"ALBERT
	",attention_mask
"ALBERT
	",token_type_ids
"ALBERT
	",position_ids
"ALBERT
	",head_mask
"ALBERT
	",inputs_embeds
"ALBERT
	",output_attentions
"ALBERT
	",output_hidden_states
"ALBERT
	",return_dict
"ALBERT
	",training
"ALBERT
	",labels
"ALBERT
	",config
"ALBERT
	",input_ids
"ALBERT
	",attention_mask
"ALBERT
	",token_type_ids
"ALBERT
	",position_ids
"ALBERT
	",head_mask
"ALBERT
	",inputs_embeds
"ALBERT
	",output_attentions
"ALBERT
	",output_hidden_states
"ALBERT
	",return_dict
"ALBERT
	",training
"ALBERT
	",labels
"ALBERT
	",config
"ALBERT
	",input_ids
"ALBERT
	",attention_mask
"ALBERT
	",token_type_ids
"ALBERT
	",position_ids
"ALBERT
	",head_mask
"ALBERT
	",inputs_embeds
"ALBERT
	",output_attentions
"ALBERT
	",output_hidden_states
"ALBERT
	",return_dict
"ALBERT
	",training
"ALBERT
	",labels
"ALBERT
	",config
"ALBERT
	",input_ids
"ALBERT
	",attention_mask
"ALBERT
	",token_type_ids
"ALBERT
	",position_ids
"ALBERT
	",head_mask
"ALBERT
	",inputs_embeds
"ALBERT
	",output_attentions
"ALBERT
	",output_hidden_states
"ALBERT
	",return_dict
"ALBERT
	",training
"ALBERT
	",labels
"ALBERT
	",config
"ALBERT
	",input_ids
"ALBERT
	",attention_mask
"ALBERT
	",token_type_ids
"ALBERT
	",position_ids
"ALBERT
	",head_mask
"ALBERT
	",inputs_embeds
"ALBERT
	",output_attentions
"ALBERT
	",output_hidden_states
"ALBERT
	",return_dict
"ALBERT
	",training
"ALBERT
	",start_positions
"ALBERT
	",end_positions
"ALBERT
	",config
"ALBERT
	",dtype
"ALBERT
	",input_ids
"ALBERT
	",attention_mask
"ALBERT
	",token_type_ids
"ALBERT
	",position_ids
"ALBERT
	",return_dict
"ALBERT
	",config
"ALBERT
	",dtype
"ALBERT
	",input_ids
"ALBERT
	",attention_mask
"ALBERT
	",token_type_ids
"ALBERT
	",position_ids
"ALBERT
	",return_dict
"ALBERT
	",config
"ALBERT
	",dtype
"ALBERT
	",input_ids
"ALBERT
	",attention_mask
"ALBERT
	",token_type_ids
"ALBERT
	",position_ids
"ALBERT
	",return_dict
"ALBERT
	",config
"ALBERT
	",dtype
"ALBERT
	",input_ids
"ALBERT
	",attention_mask
"ALBERT
	",token_type_ids
"ALBERT
	",position_ids
"ALBERT
	",return_dict
"ALBERT
	",config
"ALBERT
	",dtype
"ALBERT
	",input_ids
"ALBERT
	",attention_mask
"ALBERT
	",token_type_ids
"ALBERT
	",position_ids
"ALBERT
	",return_dict
"ALBERT
	",config
"ALBERT
	",dtype
"ALBERT
	",input_ids
"ALBERT
	",attention_mask
"ALBERT
	",token_type_ids
"ALBERT
	",position_ids
"ALBERT
	",return_dict
"ALBERT
	",config
"ALBERT
	",dtype
"ALBERT
	",input_ids
"ALBERT
	",attention_mask
"ALBERT
	",token_type_ids
"ALBERT
	",position_ids
"ALBERT
	",return_dict
"T5
	",vocab_size
"T5
	",d_model
"T5
	",d_kv
"T5
	",d_ff
"T5
	",num_layers
"T5
	",num_decoder_layers
"T5
	",num_heads
"T5
	",relative_attention_num_buckets
"T5
	",relative_attention_max_distance
"T5
	",dropout_rate
"T5
	",layer_norm_eps
"T5
	",initializer_factor
"T5
	",feed_forward_proj
"T5
	",use_cache
"T5
	",vocab_file
"T5
	",eos_token
"T5
	",unk_token
"T5
	",pad_token
"T5
	",extra_ids
"T5
	",additional_special_tokens
"T5
	",sp_model_kwargs
"T5
	",sp_model
"T5
	",token_ids_0
"T5
	",token_ids_1
"T5
	",token_ids_0
"T5
	",token_ids_1
"T5
	",already_has_special_tokens
"T5
	",token_ids_0
"T5
	",token_ids_1
"T5
	",vocab_file
"T5
	",eos_token
"T5
	",unk_token
"T5
	",pad_token
"T5
	",extra_ids
"T5
	",additional_special_tokens
"T5
	",token_ids_0
"T5
	",token_ids_1
"T5
	",token_ids_0
"T5
	",token_ids_1
"T5
	",config
"T5
	",input_ids
"T5
	",attention_mask
"T5
	",decoder_input_ids
"T5
	",decoder_attention_mask
"T5
	",head_mask
"T5
	",decoder_head_mask
"T5
	",cross_attn_head_mask
"T5
	",encoder_outputs
"T5
	",past_key_values
"T5
	",inputs_embeds
"T5
	",decoder_inputs_embeds
"T5
	",use_cache
"T5
	",output_attentions
"T5
	",output_hidden_states
"T5
	",return_dict
"T5
	",device_map
"T5
	",config
"T5
	",input_ids
"T5
	",attention_mask
"T5
	",decoder_input_ids
"T5
	",decoder_attention_mask
"T5
	",head_mask
"T5
	",decoder_head_mask
"T5
	",cross_attn_head_mask
"T5
	",encoder_outputs
"T5
	",past_key_values
"T5
	",inputs_embeds
"T5
	",decoder_inputs_embeds
"T5
	",use_cache
"T5
	",output_attentions
"T5
	",output_hidden_states
"T5
	",return_dict
"T5
	",labels
"T5
	",device_map
"T5
	",config
"T5
	",input_ids
"T5
	",attention_mask
"T5
	",head_mask
"T5
	",inputs_embeds
"T5
	",output_attentions
"T5
	",output_hidden_states
"T5
	",return_dict
"T5
	",device_map
"T5
	",config
"T5
	",input_ids
"T5
	",decoder_input_ids
"T5
	",attention_mask
"T5
	",decoder_attention_mask
"T5
	",head_mask
"T5
	",decoder_head_mask
"T5
	",encoder_outputs
"T5
	",past_key_values
"T5
	",inputs_embeds
"T5
	",decoder_inputs_embeds
"T5
	",use_cache
"T5
	",output_attentions
"T5
	",output_hidden_states
"T5
	",return_dict
"T5
	",training
"T5
	",config
"T5
	",input_ids
"T5
	",decoder_input_ids
"T5
	",attention_mask
"T5
	",decoder_attention_mask
"T5
	",head_mask
"T5
	",decoder_head_mask
"T5
	",encoder_outputs
"T5
	",past_key_values
"T5
	",inputs_embeds
"T5
	",decoder_inputs_embeds
"T5
	",use_cache
"T5
	",output_attentions
"T5
	",output_hidden_states
"T5
	",return_dict
"T5
	",training
"T5
	",labels
"T5
	",config
"T5
	",inputs
"T5
	",attention_mask
"T5
	",inputs_embeds
"T5
	",head_mask
"T5
	",output_attentions
"T5
	",output_hidden_states
"T5
	",return_dict
"T5
	",training
"T5
	",input_ids
"T5
	",attention_mask
"T5
	",decoder_input_ids
"T5
	",decoder_attention_mask
"T5
	",encoder_outputs
"T5
	",past_key_values
"T5
	",input_ids
"T5
	",attention_mask
"T5
	",output_attentions
"T5
	",output_hidden_states
"T5
	",return_dict
"T5
	",decoder_input_ids
"T5
	",encoder_outputs
"T5
	",encoder_attention_mask
"T5
	",decoder_attention_mask
"T5
	",past_key_values
"T5
	",output_attentions
"T5
	",output_hidden_states
"T5
	",return_dict
"T5
	",input_ids
"T5
	",attention_mask
"T5
	",decoder_input_ids
"T5
	",decoder_attention_mask
"T5
	",encoder_outputs
"T5
	",past_key_values
"T5
	",input_ids
"T5
	",attention_mask
"T5
	",output_attentions
"T5
	",output_hidden_states
"T5
	",return_dict
"T5
	",decoder_input_ids
"T5
	",encoder_outputs
"T5
	",encoder_attention_mask
"T5
	",decoder_attention_mask
"T5
	",past_key_values
"T5
	",output_attentions
"T5
	",output_hidden_states
"T5
	",return_dict
"T5
	",input_ids
"T5
	",attention_mask
"T5
	",output_attentions
"T5
	",output_hidden_states
"T5
	",return_dict
"SqueezeBERT
	",vocab_size
"SqueezeBERT
	",hidden_size
"SqueezeBERT
	",num_hidden_layers
"SqueezeBERT
	",num_attention_heads
"SqueezeBERT
	",intermediate_size
"SqueezeBERT
	",hidden_act
"SqueezeBERT
	",hidden_dropout_prob
"SqueezeBERT
	",attention_probs_dropout_prob
"SqueezeBERT
	",max_position_embeddings
"SqueezeBERT
	",type_vocab_size
"SqueezeBERT
	",initializer_range
"SqueezeBERT
	",layer_norm_eps
"SqueezeBERT
	",pad_token_id
"SqueezeBERT
	",embedding_size
"SqueezeBERT
	",q_groups
"SqueezeBERT
	",k_groups
"SqueezeBERT
	",v_groups
"SqueezeBERT
	",post_attention_groups
"SqueezeBERT
	",intermediate_groups
"SqueezeBERT
	",output_groups
"SqueezeBERT
	",vocab_file
"SqueezeBERT
	",do_lower_case
"SqueezeBERT
	",do_basic_tokenize
"SqueezeBERT
	",never_split
"SqueezeBERT
	",unk_token
"SqueezeBERT
	",sep_token
"SqueezeBERT
	",pad_token
"SqueezeBERT
	",cls_token
"SqueezeBERT
	",mask_token
"SqueezeBERT
	",tokenize_chinese_chars
"SqueezeBERT
	",strip_accents
"SqueezeBERT
	",token_ids_0
"SqueezeBERT
	",token_ids_1
"SqueezeBERT
	",token_ids_0
"SqueezeBERT
	",token_ids_1
"SqueezeBERT
	",already_has_special_tokens
"SqueezeBERT
	",token_ids_0
"SqueezeBERT
	",token_ids_1
"SqueezeBERT
	",vocab_file
"SqueezeBERT
	",do_lower_case
"SqueezeBERT
	",unk_token
"SqueezeBERT
	",sep_token
"SqueezeBERT
	",pad_token
"SqueezeBERT
	",cls_token
"SqueezeBERT
	",mask_token
"SqueezeBERT
	",clean_text
"SqueezeBERT
	",tokenize_chinese_chars
"SqueezeBERT
	",strip_accents
"SqueezeBERT
	",wordpieces_prefix
"SqueezeBERT
	",token_ids_0
"SqueezeBERT
	",token_ids_1
"SqueezeBERT
	",token_ids_0
"SqueezeBERT
	",token_ids_1
"SqueezeBERT
	",config
"SqueezeBERT
	",input_ids
"SqueezeBERT
	",attention_mask
"SqueezeBERT
	",token_type_ids
"SqueezeBERT
	",position_ids
"SqueezeBERT
	",head_mask
"SqueezeBERT
	",inputs_embeds
"SqueezeBERT
	",output_attentions
"SqueezeBERT
	",output_hidden_states
"SqueezeBERT
	",return_dict
"SqueezeBERT
	",config
"SqueezeBERT
	",input_ids
"SqueezeBERT
	",attention_mask
"SqueezeBERT
	",token_type_ids
"SqueezeBERT
	",position_ids
"SqueezeBERT
	",head_mask
"SqueezeBERT
	",inputs_embeds
"SqueezeBERT
	",output_attentions
"SqueezeBERT
	",output_hidden_states
"SqueezeBERT
	",return_dict
"SqueezeBERT
	",labels
"SqueezeBERT
	",config
"SqueezeBERT
	",input_ids
"SqueezeBERT
	",attention_mask
"SqueezeBERT
	",token_type_ids
"SqueezeBERT
	",position_ids
"SqueezeBERT
	",head_mask
"SqueezeBERT
	",inputs_embeds
"SqueezeBERT
	",output_attentions
"SqueezeBERT
	",output_hidden_states
"SqueezeBERT
	",return_dict
"SqueezeBERT
	",labels
"SqueezeBERT
	",config
"SqueezeBERT
	",input_ids
"SqueezeBERT
	",attention_mask
"SqueezeBERT
	",token_type_ids
"SqueezeBERT
	",position_ids
"SqueezeBERT
	",head_mask
"SqueezeBERT
	",inputs_embeds
"SqueezeBERT
	",output_attentions
"SqueezeBERT
	",output_hidden_states
"SqueezeBERT
	",return_dict
"SqueezeBERT
	",labels
"SqueezeBERT
	",config
"SqueezeBERT
	",input_ids
"SqueezeBERT
	",attention_mask
"SqueezeBERT
	",token_type_ids
"SqueezeBERT
	",position_ids
"SqueezeBERT
	",head_mask
"SqueezeBERT
	",inputs_embeds
"SqueezeBERT
	",output_attentions
"SqueezeBERT
	",output_hidden_states
"SqueezeBERT
	",return_dict
"SqueezeBERT
	",labels
"SqueezeBERT
	",config
"SqueezeBERT
	",input_ids
"SqueezeBERT
	",attention_mask
"SqueezeBERT
	",token_type_ids
"SqueezeBERT
	",position_ids
"SqueezeBERT
	",head_mask
"SqueezeBERT
	",inputs_embeds
"SqueezeBERT
	",output_attentions
"SqueezeBERT
	",output_hidden_states
"SqueezeBERT
	",return_dict
"SqueezeBERT
	",start_positions
"SqueezeBERT
	",end_positions
"Splinter
	",vocab_size
"Splinter
	",hidden_size
"Splinter
	",num_hidden_layers
"Splinter
	",num_attention_heads
"Splinter
	",intermediate_size
"Splinter
	",hidden_act
"Splinter
	",hidden_dropout_prob
"Splinter
	",attention_probs_dropout_prob
"Splinter
	",max_position_embeddings
"Splinter
	",type_vocab_size
"Splinter
	",initializer_range
"Splinter
	",layer_norm_eps
"Splinter
	",use_cache
"Splinter
	",question_token_id
"Splinter
	",vocab_file
"Splinter
	",do_lower_case
"Splinter
	",do_basic_tokenize
"Splinter
	",never_split
"Splinter
	",unk_token
"Splinter
	",sep_token
"Splinter
	",pad_token
"Splinter
	",cls_token
"Splinter
	",mask_token
"Splinter
	",question_token
"Splinter
	",tokenize_chinese_chars
"Splinter
	",strip_accents
"Splinter
	",token_ids_0
"Splinter
	",token_ids_1
"Splinter
	",token_ids_0
"Splinter
	",token_ids_1
"Splinter
	",already_has_special_tokens
"Splinter
	",token_ids_0
"Splinter
	",token_ids_1
"Splinter
	",vocab_file
"Splinter
	",do_lower_case
"Splinter
	",unk_token
"Splinter
	",sep_token
"Splinter
	",pad_token
"Splinter
	",cls_token
"Splinter
	",mask_token
"Splinter
	",question_token
"Splinter
	",clean_text
"Splinter
	",tokenize_chinese_chars
"Splinter
	",strip_accents
"Splinter
	",wordpieces_prefix
"Splinter
	",token_ids_0
"Splinter
	",token_ids_1
"Splinter
	",config
"Splinter
	",input_ids
"Splinter
	",attention_mask
"Splinter
	",token_type_ids
"Splinter
	",position_ids
"Splinter
	",head_mask
"Splinter
	",inputs_embeds
"Splinter
	",output_attentions
"Splinter
	",output_hidden_states
"Splinter
	",return_dict
"Splinter
	",encoder_hidden_states
"Splinter
	",encoder_attention_mask
"Splinter
	",past_key_values
"Splinter
	",use_cache
"Splinter
	",config
"Splinter
	",input_ids
"Splinter
	",attention_mask
"Splinter
	",token_type_ids
"Splinter
	",position_ids
"Splinter
	",head_mask
"Splinter
	",inputs_embeds
"Splinter
	",output_attentions
"Splinter
	",output_hidden_states
"Splinter
	",return_dict
"Splinter
	",start_positions
"Splinter
	",end_positions
"Splinter
	",question_positions
"Splinter
	",config
"Splinter
	",input_ids
"Splinter
	",attention_mask
"Splinter
	",token_type_ids
"Splinter
	",position_ids
"Splinter
	",head_mask
"Splinter
	",inputs_embeds
"Splinter
	",output_attentions
"Splinter
	",output_hidden_states
"Splinter
	",return_dict
"Splinter
	",start_positions
"Splinter
	",end_positions
"Splinter
	",question_positions
"RoFormer
	",vocab_size
"RoFormer
	",embedding_size
"RoFormer
	",hidden_size
"RoFormer
	",num_hidden_layers
"RoFormer
	",num_attention_heads
"RoFormer
	",intermediate_size
"RoFormer
	",hidden_act
"RoFormer
	",hidden_dropout_prob
"RoFormer
	",attention_probs_dropout_prob
"RoFormer
	",max_position_embeddings
"RoFormer
	",type_vocab_size
"RoFormer
	",initializer_range
"RoFormer
	",layer_norm_eps
"RoFormer
	",use_cache
"RoFormer
	",rotary_value
"RoFormer
	",vocab_file
"RoFormer
	",do_lower_case
"RoFormer
	",do_basic_tokenize
"RoFormer
	",never_split
"RoFormer
	",unk_token
"RoFormer
	",sep_token
"RoFormer
	",pad_token
"RoFormer
	",cls_token
"RoFormer
	",mask_token
"RoFormer
	",tokenize_chinese_chars
"RoFormer
	",strip_accents
"RoFormer
	",token_ids_0
"RoFormer
	",token_ids_1
"RoFormer
	",token_ids_0
"RoFormer
	",token_ids_1
"RoFormer
	",already_has_special_tokens
"RoFormer
	",token_ids_0
"RoFormer
	",token_ids_1
"RoFormer
	",token_ids_0
"RoFormer
	",token_ids_1
"RoFormer
	",config
"RoFormer
	",input_ids
"RoFormer
	",attention_mask
"RoFormer
	",token_type_ids
"RoFormer
	",head_mask
"RoFormer
	",inputs_embeds
"RoFormer
	",output_attentions
"RoFormer
	",output_hidden_states
"RoFormer
	",return_dict
"RoFormer
	",encoder_hidden_states
"RoFormer
	",encoder_attention_mask
"RoFormer
	",past_key_values
"RoFormer
	",use_cache
"RoFormer
	",config
"RoFormer
	",input_ids
"RoFormer
	",attention_mask
"RoFormer
	",token_type_ids
"RoFormer
	",head_mask
"RoFormer
	",inputs_embeds
"RoFormer
	",output_attentions
"RoFormer
	",output_hidden_states
"RoFormer
	",return_dict
"RoFormer
	",encoder_hidden_states
"RoFormer
	",encoder_attention_mask
"RoFormer
	",past_key_values
"RoFormer
	",labels
"RoFormer
	",use_cache
"RoFormer
	",config
"RoFormer
	",input_ids
"RoFormer
	",attention_mask
"RoFormer
	",token_type_ids
"RoFormer
	",head_mask
"RoFormer
	",inputs_embeds
"RoFormer
	",output_attentions
"RoFormer
	",output_hidden_states
"RoFormer
	",return_dict
"RoFormer
	",labels
"RoFormer
	",config
"RoFormer
	",input_ids
"RoFormer
	",attention_mask
"RoFormer
	",token_type_ids
"RoFormer
	",head_mask
"RoFormer
	",inputs_embeds
"RoFormer
	",output_attentions
"RoFormer
	",output_hidden_states
"RoFormer
	",return_dict
"RoFormer
	",labels
"RoFormer
	",config
"RoFormer
	",input_ids
"RoFormer
	",attention_mask
"RoFormer
	",token_type_ids
"RoFormer
	",head_mask
"RoFormer
	",inputs_embeds
"RoFormer
	",output_attentions
"RoFormer
	",output_hidden_states
"RoFormer
	",return_dict
"RoFormer
	",labels
"RoFormer
	",config
"RoFormer
	",input_ids
"RoFormer
	",attention_mask
"RoFormer
	",token_type_ids
"RoFormer
	",head_mask
"RoFormer
	",inputs_embeds
"RoFormer
	",output_attentions
"RoFormer
	",output_hidden_states
"RoFormer
	",return_dict
"RoFormer
	",labels
"RoFormer
	",config
"RoFormer
	",input_ids
"RoFormer
	",attention_mask
"RoFormer
	",token_type_ids
"RoFormer
	",head_mask
"RoFormer
	",inputs_embeds
"RoFormer
	",output_attentions
"RoFormer
	",output_hidden_states
"RoFormer
	",return_dict
"RoFormer
	",start_positions
"RoFormer
	",end_positions
"RoFormer
	",config
"RoFormer
	",input_ids
"RoFormer
	",attention_mask
"RoFormer
	",token_type_ids
"RoFormer
	",head_mask
"RoFormer
	",inputs_embeds
"RoFormer
	",output_attentions
"RoFormer
	",output_hidden_states
"RoFormer
	",return_dict
"RoFormer
	",training
"RoFormer
	",config
"RoFormer
	",input_ids
"RoFormer
	",attention_mask
"RoFormer
	",token_type_ids
"RoFormer
	",head_mask
"RoFormer
	",inputs_embeds
"RoFormer
	",output_attentions
"RoFormer
	",output_hidden_states
"RoFormer
	",return_dict
"RoFormer
	",training
"RoFormer
	",labels
"RoFormer
	",config
"RoFormer
	",config
"RoFormer
	",input_ids
"RoFormer
	",attention_mask
"RoFormer
	",token_type_ids
"RoFormer
	",head_mask
"RoFormer
	",inputs_embeds
"RoFormer
	",output_attentions
"RoFormer
	",output_hidden_states
"RoFormer
	",return_dict
"RoFormer
	",training
"RoFormer
	",labels
"RoFormer
	",config
"RoFormer
	",input_ids
"RoFormer
	",attention_mask
"RoFormer
	",token_type_ids
"RoFormer
	",head_mask
"RoFormer
	",inputs_embeds
"RoFormer
	",output_attentions
"RoFormer
	",output_hidden_states
"RoFormer
	",return_dict
"RoFormer
	",training
"RoFormer
	",labels
"RoFormer
	",config
"RoFormer
	",input_ids
"RoFormer
	",attention_mask
"RoFormer
	",token_type_ids
"RoFormer
	",head_mask
"RoFormer
	",inputs_embeds
"RoFormer
	",output_attentions
"RoFormer
	",output_hidden_states
"RoFormer
	",return_dict
"RoFormer
	",training
"RoFormer
	",labels
"RoFormer
	",config
"RoFormer
	",input_ids
"RoFormer
	",attention_mask
"RoFormer
	",token_type_ids
"RoFormer
	",head_mask
"RoFormer
	",inputs_embeds
"RoFormer
	",output_attentions
"RoFormer
	",output_hidden_states
"RoFormer
	",return_dict
"RoFormer
	",training
"RoFormer
	",start_positions
"RoFormer
	",end_positions
"RoFormer
	",config
"RoFormer
	",dtype
"RoFormer
	",input_ids
"RoFormer
	",attention_mask
"RoFormer
	",token_type_ids
"RoFormer
	",position_ids
"RoFormer
	",head_mask
"RoFormer
	",return_dict
"RoFormer
	",config
"RoFormer
	",dtype
"RoFormer
	",input_ids
"RoFormer
	",attention_mask
"RoFormer
	",token_type_ids
"RoFormer
	",position_ids
"RoFormer
	",head_mask
"RoFormer
	",return_dict
"RoFormer
	",config
"RoFormer
	",dtype
"RoFormer
	",input_ids
"RoFormer
	",attention_mask
"RoFormer
	",token_type_ids
"RoFormer
	",position_ids
"RoFormer
	",head_mask
"RoFormer
	",return_dict
"RoFormer
	",config
"RoFormer
	",dtype
"RoFormer
	",input_ids
"RoFormer
	",attention_mask
"RoFormer
	",token_type_ids
"RoFormer
	",position_ids
"RoFormer
	",head_mask
"RoFormer
	",return_dict
"RoFormer
	",config
"RoFormer
	",dtype
"RoFormer
	",input_ids
"RoFormer
	",attention_mask
"RoFormer
	",token_type_ids
"RoFormer
	",position_ids
"RoFormer
	",head_mask
"RoFormer
	",return_dict
"RoFormer
	",config
"RoFormer
	",dtype
"RoFormer
	",input_ids
"RoFormer
	",attention_mask
"RoFormer
	",token_type_ids
"RoFormer
	",position_ids
"RoFormer
	",head_mask
"RoFormer
	",return_dict
"RoBERTa
	",vocab_file
"RoBERTa
	",merges_file
"RoBERTa
	",errors
"RoBERTa
	",bos_token
"RoBERTa
	",eos_token
"RoBERTa
	",sep_token
"RoBERTa
	",cls_token
"RoBERTa
	",unk_token
"RoBERTa
	",pad_token
"RoBERTa
	",mask_token
"RoBERTa
	",add_prefix_space
"RoBERTa
	",token_ids_0
"RoBERTa
	",token_ids_1
"RoBERTa
	",token_ids_0
"RoBERTa
	",token_ids_1
"RoBERTa
	",already_has_special_tokens
"RoBERTa
	",token_ids_0
"RoBERTa
	",token_ids_1
"RoBERTa
	",vocab_file
"RoBERTa
	",merges_file
"RoBERTa
	",errors
"RoBERTa
	",bos_token
"RoBERTa
	",eos_token
"RoBERTa
	",sep_token
"RoBERTa
	",cls_token
"RoBERTa
	",unk_token
"RoBERTa
	",pad_token
"RoBERTa
	",mask_token
"RoBERTa
	",add_prefix_space
"RoBERTa
	",trim_offsets
"RoBERTa
	",config
"RoBERTa
	",input_ids
"RoBERTa
	",attention_mask
"RoBERTa
	",token_type_ids
"RoBERTa
	",position_ids
"RoBERTa
	",head_mask
"RoBERTa
	",inputs_embeds
"RoBERTa
	",output_attentions
"RoBERTa
	",output_hidden_states
"RoBERTa
	",return_dict
"RoBERTa
	",encoder_hidden_states
"RoBERTa
	",encoder_attention_mask
"RoBERTa
	",past_key_values
"RoBERTa
	",use_cache
"RoBERTa
	",config
"RoBERTa
	",input_ids
"RoBERTa
	",attention_mask
"RoBERTa
	",token_type_ids
"RoBERTa
	",position_ids
"RoBERTa
	",head_mask
"RoBERTa
	",inputs_embeds
"RoBERTa
	",output_attentions
"RoBERTa
	",output_hidden_states
"RoBERTa
	",return_dict
"RoBERTa
	",encoder_hidden_states
"RoBERTa
	",encoder_attention_mask
"RoBERTa
	",labels
"RoBERTa
	",past_key_values
"RoBERTa
	",use_cache
"RoBERTa
	",config
"RoBERTa
	",input_ids
"RoBERTa
	",attention_mask
"RoBERTa
	",token_type_ids
"RoBERTa
	",position_ids
"RoBERTa
	",head_mask
"RoBERTa
	",inputs_embeds
"RoBERTa
	",output_attentions
"RoBERTa
	",output_hidden_states
"RoBERTa
	",return_dict
"RoBERTa
	",labels
"RoBERTa
	",kwargs
"RoBERTa
	",config
"RoBERTa
	",input_ids
"RoBERTa
	",attention_mask
"RoBERTa
	",token_type_ids
"RoBERTa
	",position_ids
"RoBERTa
	",head_mask
"RoBERTa
	",inputs_embeds
"RoBERTa
	",output_attentions
"RoBERTa
	",output_hidden_states
"RoBERTa
	",return_dict
"RoBERTa
	",labels
"RoBERTa
	",config
"RoBERTa
	",input_ids
"RoBERTa
	",attention_mask
"RoBERTa
	",token_type_ids
"RoBERTa
	",position_ids
"RoBERTa
	",head_mask
"RoBERTa
	",inputs_embeds
"RoBERTa
	",output_attentions
"RoBERTa
	",output_hidden_states
"RoBERTa
	",return_dict
"RoBERTa
	",labels
"RoBERTa
	",config
"RoBERTa
	",input_ids
"RoBERTa
	",attention_mask
"RoBERTa
	",token_type_ids
"RoBERTa
	",position_ids
"RoBERTa
	",head_mask
"RoBERTa
	",inputs_embeds
"RoBERTa
	",output_attentions
"RoBERTa
	",output_hidden_states
"RoBERTa
	",return_dict
"RoBERTa
	",labels
"RoBERTa
	",config
"RoBERTa
	",input_ids
"RoBERTa
	",attention_mask
"RoBERTa
	",token_type_ids
"RoBERTa
	",position_ids
"RoBERTa
	",head_mask
"RoBERTa
	",inputs_embeds
"RoBERTa
	",output_attentions
"RoBERTa
	",output_hidden_states
"RoBERTa
	",return_dict
"RoBERTa
	",start_positions
"RoBERTa
	",end_positions
"RoBERTa
	",config
"RoBERTa
	",input_ids
"RoBERTa
	",attention_mask
"RoBERTa
	",token_type_ids
"RoBERTa
	",position_ids
"RoBERTa
	",head_mask
"RoBERTa
	",inputs_embeds
"RoBERTa
	",output_attentions
"RoBERTa
	",output_hidden_states
"RoBERTa
	",return_dict
"RoBERTa
	",training
"RoBERTa
	",encoder_hidden_states
"RoBERTa
	",encoder_attention_mask
"RoBERTa
	",past_key_values
"RoBERTa
	",use_cache
"RoBERTa
	",input_ids
"RoBERTa
	",attention_mask
"RoBERTa
	",token_type_ids
"RoBERTa
	",position_ids
"RoBERTa
	",head_mask
"RoBERTa
	",inputs_embeds
"RoBERTa
	",output_attentions
"RoBERTa
	",output_hidden_states
"RoBERTa
	",return_dict
"RoBERTa
	",training
"RoBERTa
	",encoder_hidden_states
"RoBERTa
	",encoder_attention_mask
"RoBERTa
	",past_key_values
"RoBERTa
	",use_cache
"RoBERTa
	",labels
"RoBERTa
	",config
"RoBERTa
	",input_ids
"RoBERTa
	",attention_mask
"RoBERTa
	",token_type_ids
"RoBERTa
	",position_ids
"RoBERTa
	",head_mask
"RoBERTa
	",inputs_embeds
"RoBERTa
	",output_attentions
"RoBERTa
	",output_hidden_states
"RoBERTa
	",return_dict
"RoBERTa
	",training
"RoBERTa
	",labels
"RoBERTa
	",config
"RoBERTa
	",input_ids
"RoBERTa
	",attention_mask
"RoBERTa
	",token_type_ids
"RoBERTa
	",position_ids
"RoBERTa
	",head_mask
"RoBERTa
	",inputs_embeds
"RoBERTa
	",output_attentions
"RoBERTa
	",output_hidden_states
"RoBERTa
	",return_dict
"RoBERTa
	",training
"RoBERTa
	",labels
"RoBERTa
	",config
"RoBERTa
	",input_ids
"RoBERTa
	",attention_mask
"RoBERTa
	",token_type_ids
"RoBERTa
	",position_ids
"RoBERTa
	",head_mask
"RoBERTa
	",inputs_embeds
"RoBERTa
	",output_attentions
"RoBERTa
	",output_hidden_states
"RoBERTa
	",return_dict
"RoBERTa
	",training
"RoBERTa
	",labels
"RoBERTa
	",config
"RoBERTa
	",input_ids
"RoBERTa
	",attention_mask
"RoBERTa
	",token_type_ids
"RoBERTa
	",position_ids
"RoBERTa
	",head_mask
"RoBERTa
	",inputs_embeds
"RoBERTa
	",output_attentions
"RoBERTa
	",output_hidden_states
"RoBERTa
	",return_dict
"RoBERTa
	",training
"RoBERTa
	",labels
"RoBERTa
	",config
"RoBERTa
	",input_ids
"RoBERTa
	",attention_mask
"RoBERTa
	",token_type_ids
"RoBERTa
	",position_ids
"RoBERTa
	",head_mask
"RoBERTa
	",inputs_embeds
"RoBERTa
	",output_attentions
"RoBERTa
	",output_hidden_states
"RoBERTa
	",return_dict
"RoBERTa
	",training
"RoBERTa
	",start_positions
"RoBERTa
	",end_positions
"RoBERTa
	",config
"RoBERTa
	",input_ids
"RoBERTa
	",attention_mask
"RoBERTa
	",token_type_ids
"RoBERTa
	",position_ids
"RoBERTa
	",head_mask
"RoBERTa
	",return_dict
"RoBERTa
	",config
"RoBERTa
	",input_ids
"RoBERTa
	",attention_mask
"RoBERTa
	",token_type_ids
"RoBERTa
	",position_ids
"RoBERTa
	",head_mask
"RoBERTa
	",return_dict
"RoBERTa
	",config
"RoBERTa
	",input_ids
"RoBERTa
	",attention_mask
"RoBERTa
	",token_type_ids
"RoBERTa
	",position_ids
"RoBERTa
	",head_mask
"RoBERTa
	",return_dict
"RoBERTa
	",config
"RoBERTa
	",input_ids
"RoBERTa
	",attention_mask
"RoBERTa
	",token_type_ids
"RoBERTa
	",position_ids
"RoBERTa
	",head_mask
"RoBERTa
	",return_dict
"RoBERTa
	",config
"RoBERTa
	",input_ids
"RoBERTa
	",attention_mask
"RoBERTa
	",token_type_ids
"RoBERTa
	",position_ids
"RoBERTa
	",head_mask
"RoBERTa
	",return_dict
"RoBERTa
	",config
"RoBERTa
	",input_ids
"RoBERTa
	",attention_mask
"RoBERTa
	",token_type_ids
"RoBERTa
	",position_ids
"RoBERTa
	",head_mask
"RoBERTa
	",return_dict
"RoBERTa
	",config
"RoBERTa
	",input_ids
"RoBERTa
	",attention_mask
"RoBERTa
	",token_type_ids
"RoBERTa
	",position_ids
"RoBERTa
	",head_mask
"RoBERTa
	",return_dict
"RetriBERT
	",vocab_size
"RetriBERT
	",hidden_size
"RetriBERT
	",num_hidden_layers
"RetriBERT
	",num_attention_heads
"RetriBERT
	",intermediate_size
"RetriBERT
	",hidden_act
"RetriBERT
	",hidden_dropout_prob
"RetriBERT
	",attention_probs_dropout_prob
"RetriBERT
	",max_position_embeddings
"RetriBERT
	",type_vocab_size
"RetriBERT
	",initializer_range
"RetriBERT
	",layer_norm_eps
"RetriBERT
	",share_encoders
"RetriBERT
	",projection_dim
"RetriBERT
	",vocab_file
"RetriBERT
	",do_lower_case
"RetriBERT
	",do_basic_tokenize
"RetriBERT
	",never_split
"RetriBERT
	",unk_token
"RetriBERT
	",sep_token
"RetriBERT
	",pad_token
"RetriBERT
	",cls_token
"RetriBERT
	",mask_token
"RetriBERT
	",tokenize_chinese_chars
"RetriBERT
	",strip_accents
"RetriBERT
	",token_ids_0
"RetriBERT
	",token_ids_1
"RetriBERT
	",token_ids_0
"RetriBERT
	",token_ids_1
"RetriBERT
	",token_ids_0
"RetriBERT
	",token_ids_1
"RetriBERT
	",already_has_special_tokens
"RetriBERT
	",vocab_file
"RetriBERT
	",do_lower_case
"RetriBERT
	",unk_token
"RetriBERT
	",sep_token
"RetriBERT
	",pad_token
"RetriBERT
	",cls_token
"RetriBERT
	",mask_token
"RetriBERT
	",clean_text
"RetriBERT
	",tokenize_chinese_chars
"RetriBERT
	",strip_accents
"RetriBERT
	",wordpieces_prefix
"RetriBERT
	",token_ids_0
"RetriBERT
	",token_ids_1
"RetriBERT
	",token_ids_0
"RetriBERT
	",token_ids_1
"RetriBERT
	",config
"RetriBERT
	",input_ids_query
"RetriBERT
	",attention_mask_query
"RetriBERT
	",input_ids_doc
"RetriBERT
	",attention_mask_doc
"RetriBERT
	",checkpoint_batch_size
"RemBERT
	",vocab_size
"RemBERT
	",hidden_size
"RemBERT
	",num_hidden_layers
"RemBERT
	",num_attention_heads
"RemBERT
	",input_embedding_size
"RemBERT
	",output_embedding_size
"RemBERT
	",intermediate_size
"RemBERT
	",hidden_act
"RemBERT
	",hidden_dropout_prob
"RemBERT
	",attention_probs_dropout_prob
"RemBERT
	",classifier_dropout_prob
"RemBERT
	",max_position_embeddings
"RemBERT
	",type_vocab_size
"RemBERT
	",initializer_range
"RemBERT
	",layer_norm_eps
"RemBERT
	",use_cache
"RemBERT
	",vocab_file
"RemBERT
	",bos_token
"RemBERT
	",eos_token
"RemBERT
	",unk_token
"RemBERT
	",sep_token
"RemBERT
	",pad_token
"RemBERT
	",cls_token
"RemBERT
	",mask_token
"RemBERT
	",sp_model
"RemBERT
	",token_ids_0
"RemBERT
	",token_ids_1
"RemBERT
	",token_ids_0
"RemBERT
	",token_ids_1
"RemBERT
	",already_has_special_tokens
"RemBERT
	",token_ids_0
"RemBERT
	",token_ids_1
"RemBERT
	",vocab_file
"RemBERT
	",do_lower_case
"RemBERT
	",remove_space
"RemBERT
	",keep_accents
"RemBERT
	",bos_token
"RemBERT
	",eos_token
"RemBERT
	",unk_token
"RemBERT
	",sep_token
"RemBERT
	",pad_token
"RemBERT
	",cls_token
"RemBERT
	",mask_token
"RemBERT
	",token_ids_0
"RemBERT
	",token_ids_1
"RemBERT
	",token_ids_0
"RemBERT
	",token_ids_1
"RemBERT
	",already_has_special_tokens
"RemBERT
	",token_ids_0
"RemBERT
	",token_ids_1
"RemBERT
	",config
"RemBERT
	",input_ids
"RemBERT
	",attention_mask
"RemBERT
	",token_type_ids
"RemBERT
	",position_ids
"RemBERT
	",head_mask
"RemBERT
	",inputs_embeds
"RemBERT
	",output_attentions
"RemBERT
	",output_hidden_states
"RemBERT
	",return_dict
"RemBERT
	",encoder_hidden_states
"RemBERT
	",encoder_attention_mask
"RemBERT
	",past_key_values
"RemBERT
	",use_cache
"RemBERT
	",config
"RemBERT
	",input_ids
"RemBERT
	",attention_mask
"RemBERT
	",token_type_ids
"RemBERT
	",position_ids
"RemBERT
	",head_mask
"RemBERT
	",inputs_embeds
"RemBERT
	",output_attentions
"RemBERT
	",output_hidden_states
"RemBERT
	",return_dict
"RemBERT
	",encoder_hidden_states
"RemBERT
	",encoder_attention_mask
"RemBERT
	",past_key_values
"RemBERT
	",labels
"RemBERT
	",use_cache
"RemBERT
	",config
"RemBERT
	",input_ids
"RemBERT
	",attention_mask
"RemBERT
	",token_type_ids
"RemBERT
	",position_ids
"RemBERT
	",head_mask
"RemBERT
	",inputs_embeds
"RemBERT
	",output_attentions
"RemBERT
	",output_hidden_states
"RemBERT
	",return_dict
"RemBERT
	",labels
"RemBERT
	",config
"RemBERT
	",input_ids
"RemBERT
	",attention_mask
"RemBERT
	",token_type_ids
"RemBERT
	",position_ids
"RemBERT
	",head_mask
"RemBERT
	",inputs_embeds
"RemBERT
	",output_attentions
"RemBERT
	",output_hidden_states
"RemBERT
	",return_dict
"RemBERT
	",labels
"RemBERT
	",config
"RemBERT
	",input_ids
"RemBERT
	",attention_mask
"RemBERT
	",token_type_ids
"RemBERT
	",position_ids
"RemBERT
	",head_mask
"RemBERT
	",inputs_embeds
"RemBERT
	",output_attentions
"RemBERT
	",output_hidden_states
"RemBERT
	",return_dict
"RemBERT
	",labels
"RemBERT
	",config
"RemBERT
	",input_ids
"RemBERT
	",attention_mask
"RemBERT
	",token_type_ids
"RemBERT
	",position_ids
"RemBERT
	",head_mask
"RemBERT
	",inputs_embeds
"RemBERT
	",output_attentions
"RemBERT
	",output_hidden_states
"RemBERT
	",return_dict
"RemBERT
	",labels
"RemBERT
	",config
"RemBERT
	",input_ids
"RemBERT
	",attention_mask
"RemBERT
	",token_type_ids
"RemBERT
	",position_ids
"RemBERT
	",head_mask
"RemBERT
	",inputs_embeds
"RemBERT
	",output_attentions
"RemBERT
	",output_hidden_states
"RemBERT
	",return_dict
"RemBERT
	",start_positions
"RemBERT
	",end_positions
"RemBERT
	",config
"RemBERT
	",input_ids
"RemBERT
	",attention_mask
"RemBERT
	",token_type_ids
"RemBERT
	",position_ids
"RemBERT
	",head_mask
"RemBERT
	",inputs_embeds
"RemBERT
	",output_attentions
"RemBERT
	",output_hidden_states
"RemBERT
	",return_dict
"RemBERT
	",training
"RemBERT
	",encoder_hidden_states
"RemBERT
	",encoder_attention_mask
"RemBERT
	",past_key_values
"RemBERT
	",use_cache
"RemBERT
	",config
"RemBERT
	",input_ids
"RemBERT
	",attention_mask
"RemBERT
	",token_type_ids
"RemBERT
	",position_ids
"RemBERT
	",head_mask
"RemBERT
	",inputs_embeds
"RemBERT
	",output_attentions
"RemBERT
	",output_hidden_states
"RemBERT
	",return_dict
"RemBERT
	",training
"RemBERT
	",labels
"RemBERT
	",config
"RemBERT
	",config
"RemBERT
	",input_ids
"RemBERT
	",attention_mask
"RemBERT
	",token_type_ids
"RemBERT
	",position_ids
"RemBERT
	",head_mask
"RemBERT
	",inputs_embeds
"RemBERT
	",output_attentions
"RemBERT
	",output_hidden_states
"RemBERT
	",return_dict
"RemBERT
	",training
"RemBERT
	",labels
"RemBERT
	",config
"RemBERT
	",input_ids
"RemBERT
	",attention_mask
"RemBERT
	",token_type_ids
"RemBERT
	",position_ids
"RemBERT
	",head_mask
"RemBERT
	",inputs_embeds
"RemBERT
	",output_attentions
"RemBERT
	",output_hidden_states
"RemBERT
	",return_dict
"RemBERT
	",training
"RemBERT
	",labels
"RemBERT
	",config
"RemBERT
	",input_ids
"RemBERT
	",attention_mask
"RemBERT
	",token_type_ids
"RemBERT
	",position_ids
"RemBERT
	",head_mask
"RemBERT
	",inputs_embeds
"RemBERT
	",output_attentions
"RemBERT
	",output_hidden_states
"RemBERT
	",return_dict
"RemBERT
	",training
"RemBERT
	",labels
"RemBERT
	",config
"RemBERT
	",input_ids
"RemBERT
	",attention_mask
"RemBERT
	",token_type_ids
"RemBERT
	",position_ids
"RemBERT
	",head_mask
"RemBERT
	",inputs_embeds
"RemBERT
	",output_attentions
"RemBERT
	",output_hidden_states
"RemBERT
	",return_dict
"RemBERT
	",training
"RemBERT
	",start_positions
"RemBERT
	",end_positions
"Reformer
	",attention_head_size
"Reformer
	",attn_layers
"Reformer
	",axial_pos_embds
"Reformer
	",axial_norm_std
"Reformer
	",axial_pos_shape
"Reformer
	",axial_pos_embds_dim
"Reformer
	",chunk_size_lm_head
"Reformer
	",eos_token_id
"Reformer
	",feed_forward_size
"Reformer
	",hash_seed
"Reformer
	",hidden_act
"Reformer
	",hidden_dropout_prob
"Reformer
	",hidden_size
"Reformer
	",initializer_range
"Reformer
	",is_decoder
"Reformer
	",layer_norm_eps
"Reformer
	",local_chunk_length
"Reformer
	",local_num_chunks_before
"Reformer
	",local_num_chunks_after
"Reformer
	",local_attention_probs_dropout_prob
"Reformer
	",lsh_attn_chunk_length
"Reformer
	",lsh_num_chunks_before
"Reformer
	",lsh_num_chunks_after
"Reformer
	",lsh_attention_probs_dropout_prob
"Reformer
	",max_position_embeddings
"Reformer
	",num_attention_heads
"Reformer
	",num_buckets
"Reformer
	",num_hashes
"Reformer
	",pad_token_id
"Reformer
	",vocab_size
"Reformer
	",tie_word_embeddings
"Reformer
	",use_cache
"Reformer
	",classifier_dropout
"Reformer
	",vocab_file
"Reformer
	",eos_token
"Reformer
	",unk_token
"Reformer
	",pad_token
"Reformer
	",additional_special_tokens
"Reformer
	",sp_model_kwargs
"Reformer
	",vocab_file
"Reformer
	",eos_token
"Reformer
	",unk_token
"Reformer
	",pad_token
"Reformer
	",additional_special_tokens
"Reformer
	",config
"Reformer
	",input_ids
"Reformer
	",attention_mask
"Reformer
	",position_ids
"Reformer
	",head_mask
"Reformer
	",inputs_embeds
"Reformer
	",num_hashes
"Reformer
	",past_buckets_states
"Reformer
	",use_cache
"Reformer
	",output_attentions
"Reformer
	",output_hidden_states
"Reformer
	",return_dict
"Reformer
	",config
"Reformer
	",input_ids
"Reformer
	",attention_mask
"Reformer
	",position_ids
"Reformer
	",head_mask
"Reformer
	",inputs_embeds
"Reformer
	",num_hashes
"Reformer
	",past_buckets_states
"Reformer
	",use_cache
"Reformer
	",output_attentions
"Reformer
	",output_hidden_states
"Reformer
	",return_dict
"Reformer
	",labels
"Reformer
	",config
"Reformer
	",input_ids
"Reformer
	",attention_mask
"Reformer
	",position_ids
"Reformer
	",head_mask
"Reformer
	",inputs_embeds
"Reformer
	",num_hashes
"Reformer
	",past_buckets_states
"Reformer
	",use_cache
"Reformer
	",output_attentions
"Reformer
	",output_hidden_states
"Reformer
	",return_dict
"Reformer
	",labels
"Reformer
	",config
"Reformer
	",input_ids
"Reformer
	",attention_mask
"Reformer
	",position_ids
"Reformer
	",head_mask
"Reformer
	",inputs_embeds
"Reformer
	",num_hashes
"Reformer
	",past_buckets_states
"Reformer
	",use_cache
"Reformer
	",output_attentions
"Reformer
	",output_hidden_states
"Reformer
	",return_dict
"Reformer
	",labels
"Reformer
	",config
"Reformer
	",input_ids
"Reformer
	",attention_mask
"Reformer
	",position_ids
"Reformer
	",head_mask
"Reformer
	",inputs_embeds
"Reformer
	",num_hashes
"Reformer
	",past_buckets_states
"Reformer
	",use_cache
"Reformer
	",output_attentions
"Reformer
	",output_hidden_states
"Reformer
	",return_dict
"Reformer
	",start_positions
"Reformer
	",end_positions
"REALM
	",vocab_size
"REALM
	",hidden_size
"REALM
	",retriever_proj_size
"REALM
	",num_hidden_layers
"REALM
	",num_attention_heads
"REALM
	",num_candidates
"REALM
	",intermediate_size
"REALM
	",hidden_act
"REALM
	",hidden_dropout_prob
"REALM
	",attention_probs_dropout_prob
"REALM
	",max_position_embeddings
"REALM
	",type_vocab_size
"REALM
	",initializer_range
"REALM
	",layer_norm_eps
"REALM
	",span_hidden_size
"REALM
	",max_span_width
"REALM
	",reader_layer_norm_eps
"REALM
	",reader_beam_size
"REALM
	",reader_seq_len
"REALM
	",num_block_records
"REALM
	",searcher_beam_size
"REALM
	",searcher_seq_len
"REALM
	",vocab_file
"REALM
	",do_lower_case
"REALM
	",do_basic_tokenize
"REALM
	",never_split
"REALM
	",unk_token
"REALM
	",sep_token
"REALM
	",pad_token
"REALM
	",cls_token
"REALM
	",mask_token
"REALM
	",tokenize_chinese_chars
"REALM
	",strip_accents
"REALM
	",token_ids_0
"REALM
	",token_ids_1
"REALM
	",token_ids_0
"REALM
	",token_ids_1
"REALM
	",already_has_special_tokens
"REALM
	",token_ids_0
"REALM
	",token_ids_1
"REALM
	",text
"REALM
	",text_pair
"REALM
	",call
"REALM
	",vocab_file
"REALM
	",do_lower_case
"REALM
	",unk_token
"REALM
	",sep_token
"REALM
	",pad_token
"REALM
	",cls_token
"REALM
	",mask_token
"REALM
	",clean_text
"REALM
	",tokenize_chinese_chars
"REALM
	",strip_accents
"REALM
	",wordpieces_prefix
"REALM
	",text
"REALM
	",text_pair
"REALM
	",call
"REALM
	",block_records
"REALM
	",tokenizer
"REALM
	",config
"REALM
	",input_ids
"REALM
	",attention_mask
"REALM
	",token_type_ids
"REALM
	",position_ids
"REALM
	",head_mask
"REALM
	",inputs_embeds
"REALM
	",output_attentions
"REALM
	",output_hidden_states
"REALM
	",return_dict
"REALM
	",config
"REALM
	",query_embedder
"REALM
	",input_ids
"REALM
	",attention_mask
"REALM
	",token_type_ids
"REALM
	",position_ids
"REALM
	",head_mask
"REALM
	",inputs_embeds
"REALM
	",output_attentions
"REALM
	",output_hidden_states
"REALM
	",return_dict
"REALM
	",candidate_input_ids
"REALM
	",candidate_attention_mask
"REALM
	",candidate_token_type_ids
"REALM
	",candidate_inputs_embeds
"REALM
	",config
"REALM
	",input_ids
"REALM
	",attention_mask
"REALM
	",token_type_ids
"REALM
	",position_ids
"REALM
	",head_mask
"REALM
	",inputs_embeds
"REALM
	",output_attentions
"REALM
	",output_hidden_states
"REALM
	",return_dict
"REALM
	",relevance_score
"REALM
	",labels
"REALM
	",mlm_mask
"REALM
	",config
"REALM
	",input_ids
"REALM
	",attention_mask
"REALM
	",token_type_ids
"REALM
	",position_ids
"REALM
	",head_mask
"REALM
	",inputs_embeds
"REALM
	",output_attentions
"REALM
	",output_hidden_states
"REALM
	",return_dict
"REALM
	",relevance_score
"REALM
	",block_mask
"REALM
	",start_positions
"REALM
	",end_positions
"REALM
	",has_answers
"REALM
	",config
"REALM
	",device
"REALM
	",input_ids
"REALM
	",attention_mask
"REALM
	",token_type_ids
"REALM
	",answer_ids
"REALM
	",return_dict
"RAG
	",title_sep
"RAG
	",doc_sep
"RAG
	",n_docs
"RAG
	",max_combined_length
"RAG
	",retrieval_vector_size
"RAG
	",retrieval_batch_size
"RAG
	",dataset
"RAG
	",dataset_split
"RAG
	",index_name
"RAG
	",index_path
"RAG
	",passages_path
"RAG
	",use_dummy_dataset
"RAG
	",label_smoothing
"RAG
	",do_marginalize
"RAG
	",reduce_loss
"RAG
	",do_deduplication
"RAG
	",exclude_bos_score
"RAG
	",output_retrieved(
"RAG
	",","
"RAG
	",use_cache
"RAG
	",forced_eos_token_id
"RAG
	",loss
"RAG
	",logits
"RAG
	",doc_scores
"RAG
	",past_key_values
"RAG
	",retrieved_doc_embeds
"RAG
	",retrieved_doc_ids
"RAG
	",context_input_ids
"RAG
	",context_attention_mask
"RAG
	",question_encoder_last_hidden_state
"RAG
	",question_enc_hidden_states
"RAG
	",question_enc_attentions
"RAG
	",generator_enc_last_hidden_state
"RAG
	",generator_enc_hidden_states
"RAG
	",generator_enc_attentions
"RAG
	",generator_dec_hidden_states
"RAG
	",generator_dec_attentions
"RAG
	",generator_cross_attentions
"RAG
	",logits
"RAG
	",doc_scores
"RAG
	",past_key_values
"RAG
	",retrieved_doc_embeds
"RAG
	",retrieved_doc_ids
"RAG
	",context_input_ids
"RAG
	",context_attention_mask
"RAG
	",question_encoder_last_hidden_state
"RAG
	",question_enc_hidden_states
"RAG
	",question_enc_attentions
"RAG
	",generator_enc_last_hidden_state
"RAG
	",generator_enc_hidden_states
"RAG
	",generator_enc_attentions
"RAG
	",generator_dec_hidden_states
"RAG
	",generator_dec_attentions
"RAG
	",generator_cross_attentions
"RAG
	",config
"RAG
	",question_encoder_tokenizer
"RAG
	",generator_tokenizer
"RAG
	",index
"RAG
	",docs
"RAG
	",input_strings
"RAG
	",prefix
"RAG
	",question_hidden_states
"RAG
	",n_docs
"RAG
	",config
"RAG
	",question_encoder
"RAG
	",generator
"RAG
	",retriever
"RAG
	",input_ids
"RAG
	",attention_mask
"RAG
	",encoder_outputs
"RAG
	",decoder_input_ids
"RAG
	",decoder_attention_mask
"RAG
	",past_key_values
"RAG
	",doc_scores
"RAG
	",context_input_ids
"RAG
	",use_cache
"RAG
	",output_attentions
"RAG
	",output_hidden_states
"RAG
	",output_retrieved(
"RAG
	",","
"RAG
	",n_docs
"RAG
	",config
"RAG
	",question_encoder
"RAG
	",generator
"RAG
	",retriever
"RAG
	",input_ids
"RAG
	",attention_mask
"RAG
	",encoder_outputs
"RAG
	",decoder_input_ids
"RAG
	",decoder_attention_mask
"RAG
	",past_key_values
"RAG
	",doc_scores
"RAG
	",context_input_ids
"RAG
	",use_cache
"RAG
	",output_attentions
"RAG
	",output_hidden_states
"RAG
	",output_retrieved(
"RAG
	",","
"RAG
	",n_docs
"RAG
	",exclude_bos_score
"RAG
	",reduce_loss
"RAG
	",kwargs
"RAG
	",input_ids
"RAG
	",attention_mask
"RAG
	",context_input_ids
"RAG
	",context_attention_mask
"RAG
	",doc_scores
"RAG
	",do_deduplication
"RAG
	",num_return_sequences(
"RAG
	",","
"RAG
	",num_beams
"RAG
	",n_docs
"RAG
	",config
"RAG
	",question_encoder
"RAG
	",generator
"RAG
	",retriever
"RAG
	",input_ids
"RAG
	",attention_mask
"RAG
	",encoder_outputs
"RAG
	",decoder_input_ids
"RAG
	",decoder_attention_mask
"RAG
	",past_key_values
"RAG
	",doc_scores
"RAG
	",context_input_ids
"RAG
	",use_cache
"RAG
	",output_attentions
"RAG
	",output_hidden_states
"RAG
	",output_retrieved(
"RAG
	",","
"RAG
	",n_docs
"RAG
	",do_marginalize
"RAG
	",reduce_loss
"RAG
	",kwargs
"RAG
	",input_ids
"RAG
	",attention_mask
"RAG
	",context_input_ids
"RAG
	",context_attention_mask
"RAG
	",doc_scores
"RAG
	",max_length
"RAG
	",min_length
"RAG
	",early_stopping
"RAG
	",pad_token_id
"RAG
	",bos_token_id
"RAG
	",eos_token_id
"RAG
	",length_penalty
"RAG
	",no_repeat_ngram_size
"RAG
	",encoder_no_repeat_ngram_size
"RAG
	",bad_words_ids(
"RAG
	",","
"RAG
	",num_beams
"RAG
	",num_beam_groups
"RAG
	",diversity_penalty
"RAG
	",num_return_sequences(
"RAG
	",","
"RAG
	",n_docs
"RAG
	",logits_processor
"RAG
	",stopping_criteria
"RAG
	",forced_bos_token_id
"RAG
	",forced_eos_token_id
"RAG
	",remove_invalid_values
"RAG
	",config
"RAG
	",question_encoder
"RAG
	",generator
"RAG
	",retriever
"RAG
	",input_ids
"RAG
	",attention_mask
"RAG
	",encoder_outputs
"RAG
	",decoder_input_ids
"RAG
	",decoder_attention_mask
"RAG
	",past_key_values
"RAG
	",doc_scores
"RAG
	",context_input_ids
"RAG
	",use_cache
"RAG
	",output_attentions
"RAG
	",output_hidden_states
"RAG
	",output_retrieved(
"RAG
	",","
"RAG
	",return_dict
"RAG
	",n_docs
"RAG
	",config
"RAG
	",question_encoder
"RAG
	",generator
"RAG
	",retriever
"RAG
	",input_ids
"RAG
	",attention_mask
"RAG
	",encoder_outputs
"RAG
	",decoder_input_ids
"RAG
	",decoder_attention_mask
"RAG
	",past_key_values
"RAG
	",doc_scores
"RAG
	",context_input_ids
"RAG
	",use_cache
"RAG
	",output_attentions
"RAG
	",output_hidden_states
"RAG
	",output_retrieved(
"RAG
	",","
"RAG
	",return_dict
"RAG
	",n_docs
"RAG
	",exclude_bos_score
"RAG
	",labels
"RAG
	",reduce_loss
"RAG
	",kwargs
"RAG
	",input_ids
"RAG
	",attention_mask
"RAG
	",not masked
"RAG
	",masked
"RAG
	",context_input_ids
"RAG
	",context_attention_mask
"RAG
	",doc_scores
"RAG
	",do_deduplication
"RAG
	",num_return_sequences(
"RAG
	",","
"RAG
	",num_beams
"RAG
	",n_docs
"RAG
	",config
"RAG
	",question_encoder
"RAG
	",generator
"RAG
	",retriever
"RAG
	",input_ids
"RAG
	",attention_mask
"RAG
	",encoder_outputs
"RAG
	",decoder_input_ids
"RAG
	",decoder_attention_mask
"RAG
	",past_key_values
"RAG
	",doc_scores
"RAG
	",context_input_ids
"RAG
	",use_cache
"RAG
	",output_attentions
"RAG
	",output_hidden_states
"RAG
	",output_retrieved(
"RAG
	",","
"RAG
	",return_dict
"RAG
	",n_docs
"RAG
	",do_marginalize
"RAG
	",labels
"RAG
	",reduce_loss
"RAG
	",kwargs
"RAG
	",input_ids
"RAG
	",attention_mask
"RAG
	",context_input_ids
"RAG
	",context_attention_mask
"RAG
	",doc_scores
"RAG
	",max_length
"RAG
	",min_length
"RAG
	",early_stopping
"RAG
	",pad_token_id
"RAG
	",bos_token_id
"RAG
	",eos_token_id
"RAG
	",length_penalty
"RAG
	",no_repeat_ngram_size
"RAG
	",bad_words_ids(
"RAG
	",","
"RAG
	",num_beams
"RAG
	",num_return_sequences(
"RAG
	",","
"RAG
	",n_docs
"RAG
	",output_attentions
"RAG
	",output_hidden_states
"RAG
	",output_scores
"RAG
	",return_dict_in_generate
"QDQBERT
	",vocab_size
"QDQBERT
	",hidden_size
"QDQBERT
	",num_hidden_layers
"QDQBERT
	",num_attention_heads
"QDQBERT
	",intermediate_size
"QDQBERT
	",hidden_act
"QDQBERT
	",hidden_dropout_prob
"QDQBERT
	",attention_probs_dropout_prob
"QDQBERT
	",max_position_embeddings
"QDQBERT
	",type_vocab_size
"QDQBERT
	",initializer_range
"QDQBERT
	",layer_norm_eps
"QDQBERT
	",use_cache
"QDQBERT
	",config
"QDQBERT
	",input_ids
"QDQBERT
	",attention_mask
"QDQBERT
	",token_type_ids
"QDQBERT
	",position_ids
"QDQBERT
	",head_mask
"QDQBERT
	",inputs_embeds
"QDQBERT
	",output_attentions
"QDQBERT
	",output_hidden_states
"QDQBERT
	",return_dict
"QDQBERT
	",encoder_hidden_states
"QDQBERT
	",encoder_attention_mask
"QDQBERT
	",past_key_values
"QDQBERT
	",use_cache
"QDQBERT
	",config
"QDQBERT
	",input_ids
"QDQBERT
	",attention_mask
"QDQBERT
	",token_type_ids
"QDQBERT
	",position_ids
"QDQBERT
	",head_mask
"QDQBERT
	",inputs_embeds
"QDQBERT
	",output_attentions
"QDQBERT
	",output_hidden_states
"QDQBERT
	",return_dict
"QDQBERT
	",encoder_hidden_states
"QDQBERT
	",encoder_attention_mask
"QDQBERT
	",labels
"QDQBERT
	",past_key_values
"QDQBERT
	",use_cache
"QDQBERT
	",config
"QDQBERT
	",input_ids
"QDQBERT
	",attention_mask
"QDQBERT
	",token_type_ids
"QDQBERT
	",position_ids
"QDQBERT
	",head_mask
"QDQBERT
	",inputs_embeds
"QDQBERT
	",output_attentions
"QDQBERT
	",output_hidden_states
"QDQBERT
	",return_dict
"QDQBERT
	",labels
"QDQBERT
	",config
"QDQBERT
	",input_ids
"QDQBERT
	",attention_mask
"QDQBERT
	",token_type_ids
"QDQBERT
	",position_ids
"QDQBERT
	",head_mask
"QDQBERT
	",inputs_embeds
"QDQBERT
	",output_attentions
"QDQBERT
	",output_hidden_states
"QDQBERT
	",return_dict
"QDQBERT
	",labels
"QDQBERT
	",config
"QDQBERT
	",input_ids
"QDQBERT
	",attention_mask
"QDQBERT
	",token_type_ids
"QDQBERT
	",position_ids
"QDQBERT
	",head_mask
"QDQBERT
	",inputs_embeds
"QDQBERT
	",output_attentions
"QDQBERT
	",output_hidden_states
"QDQBERT
	",return_dict
"QDQBERT
	",labels
"QDQBERT
	",config
"QDQBERT
	",input_ids
"QDQBERT
	",attention_mask
"QDQBERT
	",token_type_ids
"QDQBERT
	",position_ids
"QDQBERT
	",head_mask
"QDQBERT
	",inputs_embeds
"QDQBERT
	",output_attentions
"QDQBERT
	",output_hidden_states
"QDQBERT
	",return_dict
"QDQBERT
	",labels
"QDQBERT
	",config
"QDQBERT
	",input_ids
"QDQBERT
	",attention_mask
"QDQBERT
	",token_type_ids
"QDQBERT
	",position_ids
"QDQBERT
	",head_mask
"QDQBERT
	",inputs_embeds
"QDQBERT
	",output_attentions
"QDQBERT
	",output_hidden_states
"QDQBERT
	",return_dict
"QDQBERT
	",labels
"QDQBERT
	",config
"QDQBERT
	",input_ids
"QDQBERT
	",attention_mask
"QDQBERT
	",token_type_ids
"QDQBERT
	",position_ids
"QDQBERT
	",head_mask
"QDQBERT
	",inputs_embeds
"QDQBERT
	",output_attentions
"QDQBERT
	",output_hidden_states
"QDQBERT
	",return_dict
"QDQBERT
	",start_positions
"QDQBERT
	",end_positions
"ProphetNet
	",activation_dropout
"ProphetNet
	",activation_function
"ProphetNet
	",vocab_size
"ProphetNet
	",hidden_size
"ProphetNet
	",encoder_ffn_dim
"ProphetNet
	",num_encoder_layers
"ProphetNet
	",num_encoder_attention_heads
"ProphetNet
	",decoder_ffn_dim
"ProphetNet
	",num_decoder_layers
"ProphetNet
	",num_decoder_attention_heads
"ProphetNet
	",attention_dropout
"ProphetNet
	",dropout
"ProphetNet
	",max_position_embeddings
"ProphetNet
	",init_std
"ProphetNet
	",add_cross_attention
"ProphetNet
	",is_encoder_decoder
"ProphetNet
	",pad_token_id
"ProphetNet
	",bos_token_id
"ProphetNet
	",eos_token_id
"ProphetNet
	",ngram
"ProphetNet
	",num_buckets
"ProphetNet
	",relative_max_distance
"ProphetNet
	",disable_ngram_loss
"ProphetNet
	",eps
"ProphetNet
	",use_cache
"ProphetNet
	",vocab_file
"ProphetNet
	",do_lower_case
"ProphetNet
	",do_basic_tokenize
"ProphetNet
	",never_split
"ProphetNet
	",unk_token
"ProphetNet
	",sep_token
"ProphetNet
	",x_sep_token
"ProphetNet
	",pad_token
"ProphetNet
	",cls_token
"ProphetNet
	",mask_token
"ProphetNet
	",tokenize_chinese_chars
"ProphetNet
	",strip_accents
"ProphetNet
	",token_ids_0
"ProphetNet
	",token_ids_1
"ProphetNet
	",token_ids_0
"ProphetNet
	",token_ids_1
"ProphetNet
	",token_ids_0
"ProphetNet
	",token_ids_1
"ProphetNet
	",already_has_special_tokens
"ProphetNet
	",loss
"ProphetNet
	",logits
"ProphetNet
	",logits_ngram
"ProphetNet
	",past_key_values
"ProphetNet
	",decoder_hidden_states
"ProphetNet
	",decoder_ngram_hidden_states
"ProphetNet
	",decoder_attentions
"ProphetNet
	",decoder_ngram_attentions
"ProphetNet
	",cross_attentions
"ProphetNet
	",encoder_last_hidden_state
"ProphetNet
	",encoder_hidden_states
"ProphetNet
	",encoder_attentions
"ProphetNet
	",last_hidden_state
"ProphetNet
	",last_hidden_state_ngram
"ProphetNet
	",past_key_values
"ProphetNet
	",decoder_hidden_states
"ProphetNet
	",decoder_ngram_hidden_states
"ProphetNet
	",decoder_attentions
"ProphetNet
	",decoder_ngram_attentions
"ProphetNet
	",cross_attentions
"ProphetNet
	",encoder_last_hidden_state
"ProphetNet
	",encoder_hidden_states
"ProphetNet
	",encoder_attentions
"ProphetNet
	",last_hidden_state
"ProphetNet
	",last_hidden_state_ngram
"ProphetNet
	",past_key_values
"ProphetNet
	",hidden_states
"ProphetNet
	",ngram_hidden_states
"ProphetNet
	",attentions
"ProphetNet
	",ngram_attentions
"ProphetNet
	",cross_attentions
"ProphetNet
	",loss
"ProphetNet
	",logits
"ProphetNet
	",logits_ngram
"ProphetNet
	",past_key_values
"ProphetNet
	",hidden_states
"ProphetNet
	",ngram_hidden_states
"ProphetNet
	",attentions
"ProphetNet
	",ngram_attentions
"ProphetNet
	",cross_attentions
"ProphetNet
	",config
"ProphetNet
	",input_ids
"ProphetNet
	",attention_mask
"ProphetNet
	",decoder_input_ids
"ProphetNet
	",decoder_attention_mask
"ProphetNet
	",head_mask
"ProphetNet
	",decoder_head_mask
"ProphetNet
	",cross_attn_head_mask
"ProphetNet
	",encoder_outputs
"ProphetNet
	",past_key_values
"ProphetNet
	",use_cache
"ProphetNet
	",output_attentions
"ProphetNet
	",output_hidden_states
"ProphetNet
	",return_dict
"ProphetNet
	",config
"ProphetNet
	",input_ids
"ProphetNet
	",attention_mask
"ProphetNet
	",head_mask
"ProphetNet
	",output_attentions
"ProphetNet
	",output_hidden_states
"ProphetNet
	",return_dict
"ProphetNet
	",config
"ProphetNet
	",input_ids
"ProphetNet
	",attention_mask
"ProphetNet
	",head_mask
"ProphetNet
	",output_attentions
"ProphetNet
	",output_hidden_states
"ProphetNet
	",return_dict
"ProphetNet
	",encoder_hidden_states
"ProphetNet
	",encoder_attention_mask
"ProphetNet
	",cross_attn_head_mask
"ProphetNet
	",past_key_values
"ProphetNet
	",use_cache
"ProphetNet
	",config
"ProphetNet
	",input_ids
"ProphetNet
	",attention_mask
"ProphetNet
	",decoder_input_ids
"ProphetNet
	",decoder_attention_mask
"ProphetNet
	",head_mask
"ProphetNet
	",decoder_head_mask
"ProphetNet
	",cross_attn_head_mask
"ProphetNet
	",encoder_outputs
"ProphetNet
	",past_key_values
"ProphetNet
	",use_cache
"ProphetNet
	",output_attentions
"ProphetNet
	",output_hidden_states
"ProphetNet
	",return_dict
"ProphetNet
	",labels
"ProphetNet
	",config
"ProphetNet
	",input_ids
"ProphetNet
	",attention_mask
"ProphetNet
	",head_mask
"ProphetNet
	",output_attentions
"ProphetNet
	",output_hidden_states
"ProphetNet
	",return_dict
"ProphetNet
	",encoder_hidden_states
"ProphetNet
	",encoder_attention_mask
"ProphetNet
	",cross_attn_head_mask
"ProphetNet
	",past_key_values
"ProphetNet
	",use_cache
"ProphetNet
	",labels
"PLBart
	",vocab_size
"PLBart
	",d_model
"PLBart
	",encoder_layers
"PLBart
	",decoder_layers
"PLBart
	",encoder_attention_heads
"PLBart
	",decoder_attention_heads
"PLBart
	",decoder_ffn_dim
"PLBart
	",encoder_ffn_dim
"PLBart
	",activation_function
"PLBart
	",dropout
"PLBart
	",attention_dropout
"PLBart
	",activation_dropout
"PLBart
	",classifier_dropout
"PLBart
	",max_position_embeddings
"PLBart
	",init_std
"PLBart
	",encoder_layerdrop
"PLBart
	",decoder_layerdrop
"PLBart
	",scale_embedding
"PLBart
	",use_cache
"PLBart
	",forced_eos_token_id
"PLBart
	",vocab_file
"PLBart
	",src_lang
"PLBart
	",tgt_lang
"PLBart
	",bos_token
"PLBart
	",eos_token
"PLBart
	",sep_token
"PLBart
	",cls_token
"PLBart
	",unk_token
"PLBart
	",pad_token
"PLBart
	",mask_token(
"PLBart
	",","
"PLBart
	",language_codes
"PLBart
	",sp_model_kwargs
"PLBart
	",token_ids_0
"PLBart
	",token_ids_1
"PLBart
	",config
"PLBart
	",input_ids
"PLBart
	",attention_mask
"PLBart
	",decoder_input_ids
"PLBart
	",decoder_attention_mask
"PLBart
	",head_mask
"PLBart
	",decoder_head_mask
"PLBart
	",cross_attn_head_mask
"PLBart
	",encoder_outputs
"PLBart
	",past_key_values
"PLBart
	",inputs_embeds
"PLBart
	",decoder_inputs_embeds
"PLBart
	",use_cache
"PLBart
	",output_attentions
"PLBart
	",output_hidden_states
"PLBart
	",return_dict
"PLBart
	",config
"PLBart
	",input_ids
"PLBart
	",attention_mask
"PLBart
	",decoder_input_ids
"PLBart
	",decoder_attention_mask
"PLBart
	",head_mask
"PLBart
	",decoder_head_mask
"PLBart
	",cross_attn_head_mask
"PLBart
	",encoder_outputs
"PLBart
	",past_key_values
"PLBart
	",inputs_embeds
"PLBart
	",decoder_inputs_embeds
"PLBart
	",use_cache
"PLBart
	",output_attentions
"PLBart
	",output_hidden_states
"PLBart
	",return_dict
"PLBart
	",labels
"PLBart
	",config
"PLBart
	",input_ids
"PLBart
	",attention_mask
"PLBart
	",decoder_input_ids
"PLBart
	",decoder_attention_mask
"PLBart
	",head_mask
"PLBart
	",decoder_head_mask
"PLBart
	",cross_attn_head_mask
"PLBart
	",encoder_outputs
"PLBart
	",past_key_values
"PLBart
	",inputs_embeds
"PLBart
	",decoder_inputs_embeds
"PLBart
	",use_cache
"PLBart
	",output_attentions
"PLBart
	",output_hidden_states
"PLBart
	",return_dict
"PLBart
	",labels
"PLBart
	",input_ids
"PLBart
	",attention_mask
"PLBart
	",encoder_hidden_states
"PLBart
	",encoder_attention_mask
"PLBart
	",head_mask
"PLBart
	",cross_attn_head_mask
"PLBart
	",past_key_values
"PLBart
	",labels
"PLBart
	",use_cache
"PLBart
	",output_attentions
"PLBart
	",output_hidden_states
"PLBart
	",return_dict
"PhoBERT
	",vocab_file
"PhoBERT
	",merges_file
"PhoBERT
	",bos_token
"PhoBERT
	",eos_token
"PhoBERT
	",sep_token
"PhoBERT
	",cls_token
"PhoBERT
	",unk_token
"PhoBERT
	",pad_token
"PhoBERT
	",mask_token
"PhoBERT
	",token_ids_0
"PhoBERT
	",token_ids_1
"PhoBERT
	",token_ids_0
"PhoBERT
	",token_ids_1
"PhoBERT
	",token_ids_0
"PhoBERT
	",token_ids_1
"PhoBERT
	",already_has_special_tokens
"PEGASUS-X
	",vocab_size
"PEGASUS-X
	",d_model
"PEGASUS-X
	",encoder_layers
"PEGASUS-X
	",decoder_layers
"PEGASUS-X
	",encoder_attention_heads
"PEGASUS-X
	",decoder_attention_heads
"PEGASUS-X
	",decoder_ffn_dim
"PEGASUS-X
	",encoder_ffn_dim
"PEGASUS-X
	",activation_function
"PEGASUS-X
	",dropout
"PEGASUS-X
	",attention_dropout
"PEGASUS-X
	",activation_dropout
"PEGASUS-X
	",classifier_dropout
"PEGASUS-X
	",max_position_embeddings
"PEGASUS-X
	",init_std
"PEGASUS-X
	",use_cache
"PEGASUS-X
	",forced_eos_token_id
"PEGASUS-X
	",num_global_tokens
"PEGASUS-X
	",block_size
"PEGASUS-X
	",stagger_local_block
"PEGASUS-X
	",config
"PEGASUS-X
	",input_ids
"PEGASUS-X
	",inputs_embeds
"PEGASUS-X
	",attention_mask
"PEGASUS-X
	",decoder_input_ids
"PEGASUS-X
	",decoder_attention_mask
"PEGASUS-X
	",encoder_outputs
"PEGASUS-X
	",past_key_values
"PEGASUS-X
	",decoder_inputs_embeds
"PEGASUS-X
	",use_cache
"PEGASUS-X
	",output_attentions
"PEGASUS-X
	",output_hidden_states
"PEGASUS-X
	",return_dict
"PEGASUS-X
	",config
"PEGASUS-X
	",input_ids
"PEGASUS-X
	",inputs_embeds
"PEGASUS-X
	",attention_mask
"PEGASUS-X
	",decoder_input_ids
"PEGASUS-X
	",decoder_attention_mask
"PEGASUS-X
	",encoder_outputs
"PEGASUS-X
	",past_key_values
"PEGASUS-X
	",decoder_inputs_embeds
"PEGASUS-X
	",use_cache
"PEGASUS-X
	",output_attentions
"PEGASUS-X
	",output_hidden_states
"PEGASUS-X
	",return_dict
"PEGASUS-X
	",labels
"YOSO
	",vocab_size
"YOSO
	",hidden_size
"YOSO
	",num_hidden_layers
"YOSO
	",num_attention_heads
"YOSO
	",intermediate_size
"YOSO
	",hidden_act
"YOSO
	",hidden_dropout_prob
"YOSO
	",attention_probs_dropout_prob
"YOSO
	",max_position_embeddings
"YOSO
	",type_vocab_size
"YOSO
	",initializer_range
"YOSO
	",layer_norm_eps
"YOSO
	",position_embedding_type
"YOSO
	",use_expectation
"YOSO
	",hash_code_len
"YOSO
	",num_hash
"YOSO
	",conv_window
"YOSO
	",use_fast_hash
"YOSO
	",lsh_backward
"YOSO
	",config
"YOSO
	",input_ids
"YOSO
	",attention_mask
"YOSO
	",token_type_ids
"YOSO
	",position_ids
"YOSO
	",head_mask
"YOSO
	",inputs_embeds
"YOSO
	",output_attentions
"YOSO
	",output_hidden_states
"YOSO
	",return_dict
"YOSO
	",config
"YOSO
	",input_ids
"YOSO
	",attention_mask
"YOSO
	",token_type_ids
"YOSO
	",position_ids
"YOSO
	",head_mask
"YOSO
	",inputs_embeds
"YOSO
	",output_attentions
"YOSO
	",output_hidden_states
"YOSO
	",return_dict
"YOSO
	",labels
"YOSO
	",config
"YOSO
	",input_ids
"YOSO
	",attention_mask
"YOSO
	",token_type_ids
"YOSO
	",position_ids
"YOSO
	",head_mask
"YOSO
	",inputs_embeds
"YOSO
	",output_attentions
"YOSO
	",output_hidden_states
"YOSO
	",return_dict
"YOSO
	",labels
"YOSO
	",config
"YOSO
	",input_ids
"YOSO
	",attention_mask
"YOSO
	",token_type_ids
"YOSO
	",position_ids
"YOSO
	",head_mask
"YOSO
	",inputs_embeds
"YOSO
	",output_attentions
"YOSO
	",output_hidden_states
"YOSO
	",return_dict
"YOSO
	",labels
"YOSO
	",config
"YOSO
	",input_ids
"YOSO
	",attention_mask
"YOSO
	",token_type_ids
"YOSO
	",position_ids
"YOSO
	",head_mask
"YOSO
	",inputs_embeds
"YOSO
	",output_attentions
"YOSO
	",output_hidden_states
"YOSO
	",return_dict
"YOSO
	",labels
"YOSO
	",config
"YOSO
	",input_ids
"YOSO
	",attention_mask
"YOSO
	",token_type_ids
"YOSO
	",position_ids
"YOSO
	",head_mask
"YOSO
	",inputs_embeds
"YOSO
	",output_attentions
"YOSO
	",output_hidden_states
"YOSO
	",return_dict
"YOSO
	",start_positions
"YOSO
	",end_positions
"XLNet
	",vocab_size
"XLNet
	",d_model
"XLNet
	",n_layer
"XLNet
	",n_head
"XLNet
	",d_inner
"XLNet
	",ff_activation
"XLNet
	",untie_r
"XLNet
	",attn_type
"XLNet
	",initializer_range
"XLNet
	",layer_norm_eps
"XLNet
	",dropout
"XLNet
	",mem_len
"XLNet
	",reuse_len
"XLNet
	",bi_data
"XLNet
	",clamp_len
"XLNet
	",same_length
"XLNet
	",summary_type
"XLNet
	",summary_use_proj
"XLNet
	",summary_activation
"XLNet
	",summary_proj_to_labels
"XLNet
	",summary_last_dropout
"XLNet
	",start_n_top
"XLNet
	",end_n_top
"XLNet
	",use_mems_eval
"XLNet
	",use_mems_train
"XLNet
	",vocab_file
"XLNet
	",do_lower_case
"XLNet
	",remove_space
"XLNet
	",keep_accents
"XLNet
	",bos_token
"XLNet
	",eos_token
"XLNet
	",unk_token
"XLNet
	",sep_token
"XLNet
	",pad_token
"XLNet
	",cls_token
"XLNet
	",mask_token
"XLNet
	",additional_special_tokens
"XLNet
	",sp_model_kwargs
"XLNet
	",sp_model
"XLNet
	",token_ids_0
"XLNet
	",token_ids_1
"XLNet
	",token_ids_0
"XLNet
	",token_ids_1
"XLNet
	",already_has_special_tokens
"XLNet
	",token_ids_0
"XLNet
	",token_ids_1
"XLNet
	",vocab_file
"XLNet
	",do_lower_case
"XLNet
	",remove_space
"XLNet
	",keep_accents
"XLNet
	",bos_token
"XLNet
	",eos_token
"XLNet
	",unk_token
"XLNet
	",sep_token
"XLNet
	",pad_token
"XLNet
	",cls_token
"XLNet
	",mask_token
"XLNet
	",additional_special_tokens
"XLNet
	",sp_model
"XLNet
	",token_ids_0
"XLNet
	",token_ids_1
"XLNet
	",token_ids_0
"XLNet
	",token_ids_1
"XLNet
	",last_hidden_state
"XLNet
	",mems
"XLNet
	",hidden_states
"XLNet
	",attentions
"XLNet
	",loss
"XLNet
	",logits
"XLNet
	",mems
"XLNet
	",hidden_states
"XLNet
	",attentions
"XLNet
	",loss
"XLNet
	",logits
"XLNet
	",mems
"XLNet
	",hidden_states
"XLNet
	",attentions
"XLNet
	",loss
"XLNet
	",logits
"XLNet
	",mems
"XLNet
	",hidden_states
"XLNet
	",attentions
"XLNet
	",loss
"XLNet
	",logits
"XLNet
	",mems
"XLNet
	",hidden_states
"XLNet
	",attentions
"XLNet
	",loss
"XLNet
	",start_logits
"XLNet
	",end_logits
"XLNet
	",mems
"XLNet
	",hidden_states
"XLNet
	",attentions
"XLNet
	",loss
"XLNet
	",start_top_log_probs
"XLNet
	",start_top_index
"XLNet
	",end_top_log_probs
"XLNet
	",end_top_index
"XLNet
	",cls_logits
"XLNet
	",mems
"XLNet
	",hidden_states
"XLNet
	",attentions
"XLNet
	",last_hidden_state
"XLNet
	",mems
"XLNet
	",hidden_states
"XLNet
	",attentions
"XLNet
	",loss
"XLNet
	",logits
"XLNet
	",mems
"XLNet
	",hidden_states
"XLNet
	",attentions
"XLNet
	",loss
"XLNet
	",logits
"XLNet
	",mems
"XLNet
	",hidden_states
"XLNet
	",attentions
"XLNet
	",loss
"XLNet
	",logits
"XLNet
	",mems
"XLNet
	",hidden_states
"XLNet
	",attentions
"XLNet
	",loss
"XLNet
	",logits
"XLNet
	",mems
"XLNet
	",hidden_states
"XLNet
	",attentions
"XLNet
	",loss
"XLNet
	",start_logits
"XLNet
	",end_logits
"XLNet
	",mems
"XLNet
	",hidden_states
"XLNet
	",attentions
"XLNet
	",config
"XLNet
	",input_ids
"XLNet
	",attention_mask
"XLNet
	",mems
"XLNet
	",perm_mask
"XLNet
	",target_mapping
"XLNet
	",token_type_ids
"XLNet
	",input_mask
"XLNet
	",head_mask
"XLNet
	",inputs_embeds
"XLNet
	",output_attentions
"XLNet
	",output_hidden_states
"XLNet
	",return_dict
"XLNet
	",config
"XLNet
	",input_ids
"XLNet
	",attention_mask
"XLNet
	",mems
"XLNet
	",perm_mask
"XLNet
	",target_mapping
"XLNet
	",token_type_ids
"XLNet
	",input_mask
"XLNet
	",head_mask
"XLNet
	",inputs_embeds
"XLNet
	",output_attentions
"XLNet
	",output_hidden_states
"XLNet
	",return_dict
"XLNet
	",labels
"XLNet
	",config
"XLNet
	",input_ids
"XLNet
	",attention_mask
"XLNet
	",mems
"XLNet
	",perm_mask
"XLNet
	",target_mapping
"XLNet
	",token_type_ids
"XLNet
	",input_mask
"XLNet
	",head_mask
"XLNet
	",inputs_embeds
"XLNet
	",output_attentions
"XLNet
	",output_hidden_states
"XLNet
	",return_dict
"XLNet
	",labels
"XLNet
	",config
"XLNet
	",input_ids
"XLNet
	",attention_mask
"XLNet
	",mems
"XLNet
	",perm_mask
"XLNet
	",target_mapping
"XLNet
	",token_type_ids
"XLNet
	",input_mask
"XLNet
	",head_mask
"XLNet
	",inputs_embeds
"XLNet
	",output_attentions
"XLNet
	",output_hidden_states
"XLNet
	",return_dict
"XLNet
	",labels
"XLNet
	",config
"XLNet
	",input_ids
"XLNet
	",attention_mask
"XLNet
	",mems
"XLNet
	",perm_mask
"XLNet
	",target_mapping
"XLNet
	",token_type_ids
"XLNet
	",input_mask
"XLNet
	",head_mask
"XLNet
	",inputs_embeds
"XLNet
	",output_attentions
"XLNet
	",output_hidden_states
"XLNet
	",return_dict
"XLNet
	",labels
"XLNet
	",config
"XLNet
	",input_ids
"XLNet
	",attention_mask
"XLNet
	",mems
"XLNet
	",perm_mask
"XLNet
	",target_mapping
"XLNet
	",token_type_ids
"XLNet
	",input_mask
"XLNet
	",head_mask
"XLNet
	",inputs_embeds
"XLNet
	",output_attentions
"XLNet
	",output_hidden_states
"XLNet
	",return_dict
"XLNet
	",start_positions
"XLNet
	",end_positions
"XLNet
	",config
"XLNet
	",input_ids
"XLNet
	",attention_mask
"XLNet
	",mems
"XLNet
	",perm_mask
"XLNet
	",target_mapping
"XLNet
	",token_type_ids
"XLNet
	",input_mask
"XLNet
	",head_mask
"XLNet
	",inputs_embeds
"XLNet
	",output_attentions
"XLNet
	",output_hidden_states
"XLNet
	",return_dict
"XLNet
	",start_positions
"XLNet
	",end_positions
"XLNet
	",is_impossible
"XLNet
	",cls_index
"XLNet
	",p_mask
"XLNet
	",config
"XLNet
	",input_ids
"XLNet
	",attention_mask
"XLNet
	",mems
"XLNet
	",perm_mask
"XLNet
	",target_mapping
"XLNet
	",token_type_ids
"XLNet
	",input_mask
"XLNet
	",head_mask
"XLNet
	",inputs_embeds
"XLNet
	",output_attentions
"XLNet
	",output_hidden_states
"XLNet
	",return_dict
"XLNet
	",config
"XLNet
	",input_ids
"XLNet
	",attention_mask
"XLNet
	",mems
"XLNet
	",perm_mask
"XLNet
	",target_mapping
"XLNet
	",token_type_ids
"XLNet
	",input_mask
"XLNet
	",head_mask
"XLNet
	",inputs_embeds
"XLNet
	",output_attentions
"XLNet
	",output_hidden_states
"XLNet
	",return_dict
"XLNet
	",labels
"XLNet
	",config
"XLNet
	",input_ids
"XLNet
	",attention_mask
"XLNet
	",mems
"XLNet
	",perm_mask
"XLNet
	",target_mapping
"XLNet
	",token_type_ids
"XLNet
	",input_mask
"XLNet
	",head_mask
"XLNet
	",inputs_embeds
"XLNet
	",output_attentions
"XLNet
	",output_hidden_states
"XLNet
	",return_dict
"XLNet
	",labels
"XLNet
	",config
"XLNet
	",input_ids
"XLNet
	",attention_mask
"XLNet
	",mems
"XLNet
	",perm_mask
"XLNet
	",target_mapping
"XLNet
	",token_type_ids
"XLNet
	",input_mask
"XLNet
	",head_mask
"XLNet
	",inputs_embeds
"XLNet
	",output_attentions
"XLNet
	",output_hidden_states
"XLNet
	",return_dict
"XLNet
	",labels
"XLNet
	",config
"XLNet
	",input_ids
"XLNet
	",attention_mask
"XLNet
	",mems
"XLNet
	",perm_mask
"XLNet
	",target_mapping
"XLNet
	",token_type_ids
"XLNet
	",input_mask
"XLNet
	",head_mask
"XLNet
	",inputs_embeds
"XLNet
	",output_attentions
"XLNet
	",output_hidden_states
"XLNet
	",return_dict
"XLNet
	",labels
"XLNet
	",config
"XLNet
	",input_ids
"XLNet
	",attention_mask
"XLNet
	",mems
"XLNet
	",perm_mask
"XLNet
	",target_mapping
"XLNet
	",token_type_ids
"XLNet
	",input_mask
"XLNet
	",head_mask
"XLNet
	",inputs_embeds
"XLNet
	",output_attentions
"XLNet
	",output_hidden_states
"XLNet
	",return_dict
"XLNet
	",start_positions
"XLNet
	",end_positions
"XLM-RoBERTa-XL
	",vocab_size
"XLM-RoBERTa-XL
	",hidden_size
"XLM-RoBERTa-XL
	",num_hidden_layers
"XLM-RoBERTa-XL
	",num_attention_heads
"XLM-RoBERTa-XL
	",intermediate_size
"XLM-RoBERTa-XL
	",hidden_act
"XLM-RoBERTa-XL
	",hidden_dropout_prob
"XLM-RoBERTa-XL
	",attention_probs_dropout_prob
"XLM-RoBERTa-XL
	",max_position_embeddings
"XLM-RoBERTa-XL
	",type_vocab_size
"XLM-RoBERTa-XL
	",initializer_range
"XLM-RoBERTa-XL
	",layer_norm_eps
"XLM-RoBERTa-XL
	",position_embedding_type
"XLM-RoBERTa-XL
	",use_cache
"XLM-RoBERTa-XL
	",classifier_dropout
"XLM-RoBERTa-XL
	",config
"XLM-RoBERTa-XL
	",input_ids
"XLM-RoBERTa-XL
	",attention_mask
"XLM-RoBERTa-XL
	",token_type_ids
"XLM-RoBERTa-XL
	",position_ids
"XLM-RoBERTa-XL
	",head_mask
"XLM-RoBERTa-XL
	",inputs_embeds
"XLM-RoBERTa-XL
	",output_attentions
"XLM-RoBERTa-XL
	",output_hidden_states
"XLM-RoBERTa-XL
	",return_dict
"XLM-RoBERTa-XL
	",encoder_hidden_states
"XLM-RoBERTa-XL
	",encoder_attention_mask
"XLM-RoBERTa-XL
	",past_key_values
"XLM-RoBERTa-XL
	",use_cache
"XLM-RoBERTa-XL
	",config
"XLM-RoBERTa-XL
	",input_ids
"XLM-RoBERTa-XL
	",attention_mask
"XLM-RoBERTa-XL
	",token_type_ids
"XLM-RoBERTa-XL
	",position_ids
"XLM-RoBERTa-XL
	",head_mask
"XLM-RoBERTa-XL
	",inputs_embeds
"XLM-RoBERTa-XL
	",output_attentions
"XLM-RoBERTa-XL
	",output_hidden_states
"XLM-RoBERTa-XL
	",return_dict
"XLM-RoBERTa-XL
	",encoder_hidden_states
"XLM-RoBERTa-XL
	",encoder_attention_mask
"XLM-RoBERTa-XL
	",labels
"XLM-RoBERTa-XL
	",past_key_values
"XLM-RoBERTa-XL
	",use_cache
"XLM-RoBERTa-XL
	",config
"XLM-RoBERTa-XL
	",input_ids
"XLM-RoBERTa-XL
	",attention_mask
"XLM-RoBERTa-XL
	",token_type_ids
"XLM-RoBERTa-XL
	",position_ids
"XLM-RoBERTa-XL
	",head_mask
"XLM-RoBERTa-XL
	",inputs_embeds
"XLM-RoBERTa-XL
	",output_attentions
"XLM-RoBERTa-XL
	",output_hidden_states
"XLM-RoBERTa-XL
	",return_dict
"XLM-RoBERTa-XL
	",labels
"XLM-RoBERTa-XL
	",kwargs
"XLM-RoBERTa-XL
	",config
"XLM-RoBERTa-XL
	",input_ids
"XLM-RoBERTa-XL
	",attention_mask
"XLM-RoBERTa-XL
	",token_type_ids
"XLM-RoBERTa-XL
	",position_ids
"XLM-RoBERTa-XL
	",head_mask
"XLM-RoBERTa-XL
	",inputs_embeds
"XLM-RoBERTa-XL
	",output_attentions
"XLM-RoBERTa-XL
	",output_hidden_states
"XLM-RoBERTa-XL
	",return_dict
"XLM-RoBERTa-XL
	",labels
"XLM-RoBERTa-XL
	",config
"XLM-RoBERTa-XL
	",input_ids
"XLM-RoBERTa-XL
	",attention_mask
"XLM-RoBERTa-XL
	",token_type_ids
"XLM-RoBERTa-XL
	",position_ids
"XLM-RoBERTa-XL
	",head_mask
"XLM-RoBERTa-XL
	",inputs_embeds
"XLM-RoBERTa-XL
	",output_attentions
"XLM-RoBERTa-XL
	",output_hidden_states
"XLM-RoBERTa-XL
	",return_dict
"XLM-RoBERTa-XL
	",labels
"XLM-RoBERTa-XL
	",config
"XLM-RoBERTa-XL
	",input_ids
"XLM-RoBERTa-XL
	",attention_mask
"XLM-RoBERTa-XL
	",token_type_ids
"XLM-RoBERTa-XL
	",position_ids
"XLM-RoBERTa-XL
	",head_mask
"XLM-RoBERTa-XL
	",inputs_embeds
"XLM-RoBERTa-XL
	",output_attentions
"XLM-RoBERTa-XL
	",output_hidden_states
"XLM-RoBERTa-XL
	",return_dict
"XLM-RoBERTa-XL
	",labels
"XLM-RoBERTa-XL
	",config
"XLM-RoBERTa-XL
	",input_ids
"XLM-RoBERTa-XL
	",attention_mask
"XLM-RoBERTa-XL
	",token_type_ids
"XLM-RoBERTa-XL
	",position_ids
"XLM-RoBERTa-XL
	",head_mask
"XLM-RoBERTa-XL
	",inputs_embeds
"XLM-RoBERTa-XL
	",output_attentions
"XLM-RoBERTa-XL
	",output_hidden_states
"XLM-RoBERTa-XL
	",return_dict
"XLM-RoBERTa-XL
	",start_positions
"XLM-RoBERTa-XL
	",end_positions
"XLM-RoBERTa
	",vocab_file
"XLM-RoBERTa
	",bos_token
"XLM-RoBERTa
	",eos_token
"XLM-RoBERTa
	",sep_token
"XLM-RoBERTa
	",cls_token
"XLM-RoBERTa
	",unk_token
"XLM-RoBERTa
	",pad_token
"XLM-RoBERTa
	",mask_token
"XLM-RoBERTa
	",additional_special_tokens
"XLM-RoBERTa
	",sp_model_kwargs
"XLM-RoBERTa
	",sp_model
"XLM-RoBERTa
	",token_ids_0
"XLM-RoBERTa
	",token_ids_1
"XLM-RoBERTa
	",token_ids_0
"XLM-RoBERTa
	",token_ids_1
"XLM-RoBERTa
	",already_has_special_tokens
"XLM-RoBERTa
	",token_ids_0
"XLM-RoBERTa
	",token_ids_1
"XLM-RoBERTa
	",vocab_file
"XLM-RoBERTa
	",bos_token
"XLM-RoBERTa
	",eos_token
"XLM-RoBERTa
	",sep_token
"XLM-RoBERTa
	",cls_token
"XLM-RoBERTa
	",unk_token
"XLM-RoBERTa
	",pad_token
"XLM-RoBERTa
	",mask_token
"XLM-RoBERTa
	",additional_special_tokens
"XLM-RoBERTa
	",token_ids_0
"XLM-RoBERTa
	",token_ids_1
"XLM-RoBERTa
	",token_ids_0
"XLM-RoBERTa
	",token_ids_1
"XLM-RoBERTa
	",config
"XLM-RoBERTa
	",input_ids
"XLM-RoBERTa
	",attention_mask
"XLM-RoBERTa
	",token_type_ids
"XLM-RoBERTa
	",position_ids
"XLM-RoBERTa
	",head_mask
"XLM-RoBERTa
	",inputs_embeds
"XLM-RoBERTa
	",output_attentions
"XLM-RoBERTa
	",output_hidden_states
"XLM-RoBERTa
	",return_dict
"XLM-RoBERTa
	",encoder_hidden_states
"XLM-RoBERTa
	",encoder_attention_mask
"XLM-RoBERTa
	",past_key_values
"XLM-RoBERTa
	",use_cache
"XLM-RoBERTa
	",config
"XLM-RoBERTa
	",input_ids
"XLM-RoBERTa
	",attention_mask
"XLM-RoBERTa
	",token_type_ids
"XLM-RoBERTa
	",position_ids
"XLM-RoBERTa
	",head_mask
"XLM-RoBERTa
	",inputs_embeds
"XLM-RoBERTa
	",output_attentions
"XLM-RoBERTa
	",output_hidden_states
"XLM-RoBERTa
	",return_dict
"XLM-RoBERTa
	",encoder_hidden_states
"XLM-RoBERTa
	",encoder_attention_mask
"XLM-RoBERTa
	",labels
"XLM-RoBERTa
	",past_key_values
"XLM-RoBERTa
	",use_cache
"XLM-RoBERTa
	",config
"XLM-RoBERTa
	",input_ids
"XLM-RoBERTa
	",attention_mask
"XLM-RoBERTa
	",token_type_ids
"XLM-RoBERTa
	",position_ids
"XLM-RoBERTa
	",head_mask
"XLM-RoBERTa
	",inputs_embeds
"XLM-RoBERTa
	",output_attentions
"XLM-RoBERTa
	",output_hidden_states
"XLM-RoBERTa
	",return_dict
"XLM-RoBERTa
	",labels
"XLM-RoBERTa
	",kwargs
"XLM-RoBERTa
	",config
"XLM-RoBERTa
	",input_ids
"XLM-RoBERTa
	",attention_mask
"XLM-RoBERTa
	",token_type_ids
"XLM-RoBERTa
	",position_ids
"XLM-RoBERTa
	",head_mask
"XLM-RoBERTa
	",inputs_embeds
"XLM-RoBERTa
	",output_attentions
"XLM-RoBERTa
	",output_hidden_states
"XLM-RoBERTa
	",return_dict
"XLM-RoBERTa
	",labels
"XLM-RoBERTa
	",config
"XLM-RoBERTa
	",input_ids
"XLM-RoBERTa
	",attention_mask
"XLM-RoBERTa
	",token_type_ids
"XLM-RoBERTa
	",position_ids
"XLM-RoBERTa
	",head_mask
"XLM-RoBERTa
	",inputs_embeds
"XLM-RoBERTa
	",output_attentions
"XLM-RoBERTa
	",output_hidden_states
"XLM-RoBERTa
	",return_dict
"XLM-RoBERTa
	",labels
"XLM-RoBERTa
	",config
"XLM-RoBERTa
	",input_ids
"XLM-RoBERTa
	",attention_mask
"XLM-RoBERTa
	",token_type_ids
"XLM-RoBERTa
	",position_ids
"XLM-RoBERTa
	",head_mask
"XLM-RoBERTa
	",inputs_embeds
"XLM-RoBERTa
	",output_attentions
"XLM-RoBERTa
	",output_hidden_states
"XLM-RoBERTa
	",return_dict
"XLM-RoBERTa
	",labels
"XLM-RoBERTa
	",config
"XLM-RoBERTa
	",input_ids
"XLM-RoBERTa
	",attention_mask
"XLM-RoBERTa
	",token_type_ids
"XLM-RoBERTa
	",position_ids
"XLM-RoBERTa
	",head_mask
"XLM-RoBERTa
	",inputs_embeds
"XLM-RoBERTa
	",output_attentions
"XLM-RoBERTa
	",output_hidden_states
"XLM-RoBERTa
	",return_dict
"XLM-RoBERTa
	",start_positions
"XLM-RoBERTa
	",end_positions
"XLM-RoBERTa
	",config
"XLM-RoBERTa
	",input_ids
"XLM-RoBERTa
	",attention_mask
"XLM-RoBERTa
	",token_type_ids
"XLM-RoBERTa
	",position_ids
"XLM-RoBERTa
	",head_mask
"XLM-RoBERTa
	",inputs_embeds
"XLM-RoBERTa
	",output_attentions
"XLM-RoBERTa
	",output_hidden_states
"XLM-RoBERTa
	",return_dict
"XLM-RoBERTa
	",training
"XLM-RoBERTa
	",encoder_hidden_states
"XLM-RoBERTa
	",encoder_attention_mask
"XLM-RoBERTa
	",past_key_values
"XLM-RoBERTa
	",use_cache
"XLM-RoBERTa
	",config
"XLM-RoBERTa
	",input_ids
"XLM-RoBERTa
	",attention_mask
"XLM-RoBERTa
	",token_type_ids
"XLM-RoBERTa
	",position_ids
"XLM-RoBERTa
	",head_mask
"XLM-RoBERTa
	",inputs_embeds
"XLM-RoBERTa
	",output_attentions
"XLM-RoBERTa
	",output_hidden_states
"XLM-RoBERTa
	",return_dict
"XLM-RoBERTa
	",training
"XLM-RoBERTa
	",labels
"XLM-RoBERTa
	",config
"XLM-RoBERTa
	",input_ids
"XLM-RoBERTa
	",attention_mask
"XLM-RoBERTa
	",token_type_ids
"XLM-RoBERTa
	",position_ids
"XLM-RoBERTa
	",head_mask
"XLM-RoBERTa
	",inputs_embeds
"XLM-RoBERTa
	",output_attentions
"XLM-RoBERTa
	",output_hidden_states
"XLM-RoBERTa
	",return_dict
"XLM-RoBERTa
	",training
"XLM-RoBERTa
	",labels
"XLM-RoBERTa
	",config
"XLM-RoBERTa
	",input_ids
"XLM-RoBERTa
	",attention_mask
"XLM-RoBERTa
	",token_type_ids
"XLM-RoBERTa
	",position_ids
"XLM-RoBERTa
	",head_mask
"XLM-RoBERTa
	",inputs_embeds
"XLM-RoBERTa
	",output_attentions
"XLM-RoBERTa
	",output_hidden_states
"XLM-RoBERTa
	",return_dict
"XLM-RoBERTa
	",training
"XLM-RoBERTa
	",labels
"XLM-RoBERTa
	",config
"XLM-RoBERTa
	",input_ids
"XLM-RoBERTa
	",attention_mask
"XLM-RoBERTa
	",token_type_ids
"XLM-RoBERTa
	",position_ids
"XLM-RoBERTa
	",head_mask
"XLM-RoBERTa
	",inputs_embeds
"XLM-RoBERTa
	",output_attentions
"XLM-RoBERTa
	",output_hidden_states
"XLM-RoBERTa
	",return_dict
"XLM-RoBERTa
	",training
"XLM-RoBERTa
	",labels
"XLM-RoBERTa
	",config
"XLM-RoBERTa
	",input_ids
"XLM-RoBERTa
	",attention_mask
"XLM-RoBERTa
	",token_type_ids
"XLM-RoBERTa
	",position_ids
"XLM-RoBERTa
	",head_mask
"XLM-RoBERTa
	",inputs_embeds
"XLM-RoBERTa
	",output_attentions
"XLM-RoBERTa
	",output_hidden_states
"XLM-RoBERTa
	",return_dict
"XLM-RoBERTa
	",training
"XLM-RoBERTa
	",start_positions
"XLM-RoBERTa
	",end_positions
"XLM-RoBERTa
	",config
"XLM-RoBERTa
	",input_ids
"XLM-RoBERTa
	",attention_mask
"XLM-RoBERTa
	",token_type_ids
"XLM-RoBERTa
	",position_ids
"XLM-RoBERTa
	",head_mask
"XLM-RoBERTa
	",return_dict
"XLM-RoBERTa
	",config
"XLM-RoBERTa
	",input_ids
"XLM-RoBERTa
	",attention_mask
"XLM-RoBERTa
	",token_type_ids
"XLM-RoBERTa
	",position_ids
"XLM-RoBERTa
	",head_mask
"XLM-RoBERTa
	",return_dict
"XLM-RoBERTa
	",config
"XLM-RoBERTa
	",input_ids
"XLM-RoBERTa
	",attention_mask
"XLM-RoBERTa
	",token_type_ids
"XLM-RoBERTa
	",position_ids
"XLM-RoBERTa
	",head_mask
"XLM-RoBERTa
	",return_dict
"XLM-RoBERTa
	",config
"XLM-RoBERTa
	",input_ids
"XLM-RoBERTa
	",attention_mask
"XLM-RoBERTa
	",token_type_ids
"XLM-RoBERTa
	",position_ids
"XLM-RoBERTa
	",head_mask
"XLM-RoBERTa
	",return_dict
"XLM-RoBERTa
	",config
"XLM-RoBERTa
	",input_ids
"XLM-RoBERTa
	",attention_mask
"XLM-RoBERTa
	",token_type_ids
"XLM-RoBERTa
	",position_ids
"XLM-RoBERTa
	",head_mask
"XLM-RoBERTa
	",return_dict
"XLM-RoBERTa
	",config
"XLM-RoBERTa
	",input_ids
"XLM-RoBERTa
	",attention_mask
"XLM-RoBERTa
	",token_type_ids
"XLM-RoBERTa
	",position_ids
"XLM-RoBERTa
	",head_mask
"XLM-RoBERTa
	",return_dict
"XLM-ProphetNet
	",activation_dropout
"XLM-ProphetNet
	",activation_function
"XLM-ProphetNet
	",vocab_size
"XLM-ProphetNet
	",hidden_size
"XLM-ProphetNet
	",encoder_ffn_dim
"XLM-ProphetNet
	",num_encoder_layers
"XLM-ProphetNet
	",num_encoder_attention_heads
"XLM-ProphetNet
	",decoder_ffn_dim
"XLM-ProphetNet
	",num_decoder_layers
"XLM-ProphetNet
	",num_decoder_attention_heads
"XLM-ProphetNet
	",attention_dropout
"XLM-ProphetNet
	",dropout
"XLM-ProphetNet
	",max_position_embeddings
"XLM-ProphetNet
	",init_std
"XLM-ProphetNet
	",add_cross_attention
"XLM-ProphetNet
	",is_encoder_decoder
"XLM-ProphetNet
	",pad_token_id
"XLM-ProphetNet
	",bos_token_id
"XLM-ProphetNet
	",eos_token_id
"XLM-ProphetNet
	",ngram
"XLM-ProphetNet
	",num_buckets
"XLM-ProphetNet
	",relative_max_distance
"XLM-ProphetNet
	",disable_ngram_loss
"XLM-ProphetNet
	",eps
"XLM-ProphetNet
	",use_cache
"XLM-ProphetNet
	",vocab_file
"XLM-ProphetNet
	",bos_token
"XLM-ProphetNet
	",eos_token
"XLM-ProphetNet
	",sep_token
"XLM-ProphetNet
	",cls_token
"XLM-ProphetNet
	",unk_token
"XLM-ProphetNet
	",pad_token
"XLM-ProphetNet
	",mask_token
"XLM-ProphetNet
	",additional_special_tokens
"XLM-ProphetNet
	",sp_model_kwargs
"XLM-ProphetNet
	",sp_model
"XLM-ProphetNet
	",token_ids_0
"XLM-ProphetNet
	",token_ids_1
"XLM-ProphetNet
	",token_ids_0
"XLM-ProphetNet
	",token_ids_1
"XLM-ProphetNet
	",token_ids_0
"XLM-ProphetNet
	",token_ids_1
"XLM-ProphetNet
	",already_has_special_tokens
"XLM
	",vocab_size
"XLM
	",emb_dim
"XLM
	",n_layer
"XLM
	",n_head
"XLM
	",dropout
"XLM
	",attention_dropout
"XLM
	",gelu_activation
"XLM
	",sinusoidal_embeddings
"XLM
	",causal
"XLM
	",asm
"XLM
	",n_langs
"XLM
	",use_lang_emb
"XLM
	",max_position_embeddings
"XLM
	",embed_init_std
"XLM
	",init_std
"XLM
	",layer_norm_eps
"XLM
	",bos_index
"XLM
	",eos_index
"XLM
	",pad_index
"XLM
	",unk_index
"XLM
	",mask_index
"XLM
	",is_encoder(
"XLM
	",","
"XLM
	",summary_type
"XLM
	",summary_use_proj
"XLM
	",summary_activation
"XLM
	",summary_proj_to_labels
"XLM
	",summary_first_dropout
"XLM
	",start_n_top
"XLM
	",end_n_top
"XLM
	",mask_token_id
"XLM
	",lang_id
"XLM
	",vocab_file
"XLM
	",merges_file
"XLM
	",unk_token
"XLM
	",bos_token
"XLM
	",sep_token
"XLM
	",pad_token
"XLM
	",cls_token
"XLM
	",mask_token
"XLM
	",additional_special_tokens
"XLM
	",lang2id
"XLM
	",id2lang
"XLM
	",do_lowercase_and_remove_accent
"XLM
	",token_ids_0
"XLM
	",token_ids_1
"XLM
	",token_ids_0
"XLM
	",token_ids_1
"XLM
	",already_has_special_tokens
"XLM
	",token_ids_0
"XLM
	",token_ids_1
"XLM
	",loss
"XLM
	",start_top_log_probs
"XLM
	",start_top_index
"XLM
	",end_top_log_probs
"XLM
	",end_top_index
"XLM
	",cls_logits
"XLM
	",hidden_states
"XLM
	",attentions
"XLM
	",config
"XLM
	",input_ids
"XLM
	",attention_mask
"XLM
	",langs
"XLM
	",token_type_ids
"XLM
	",position_ids
"XLM
	",lengths
"XLM
	",cache
"XLM
	",head_mask
"XLM
	",inputs_embeds
"XLM
	",output_attentions
"XLM
	",output_hidden_states
"XLM
	",return_dict
"XLM
	",config
"XLM
	",input_ids
"XLM
	",attention_mask
"XLM
	",langs
"XLM
	",token_type_ids
"XLM
	",position_ids
"XLM
	",lengths
"XLM
	",cache
"XLM
	",head_mask
"XLM
	",inputs_embeds
"XLM
	",output_attentions
"XLM
	",output_hidden_states
"XLM
	",return_dict
"XLM
	",labels
"XLM
	",are shifted
"XLM
	",config
"XLM
	",input_ids
"XLM
	",attention_mask
"XLM
	",langs
"XLM
	",token_type_ids
"XLM
	",position_ids
"XLM
	",lengths
"XLM
	",cache
"XLM
	",head_mask
"XLM
	",inputs_embeds
"XLM
	",output_attentions
"XLM
	",output_hidden_states
"XLM
	",return_dict
"XLM
	",labels
"XLM
	",config
"XLM
	",input_ids
"XLM
	",attention_mask
"XLM
	",langs
"XLM
	",token_type_ids
"XLM
	",position_ids
"XLM
	",lengths
"XLM
	",cache
"XLM
	",head_mask
"XLM
	",inputs_embeds
"XLM
	",output_attentions
"XLM
	",output_hidden_states
"XLM
	",return_dict
"XLM
	",labels
"XLM
	",config
"XLM
	",input_ids
"XLM
	",attention_mask
"XLM
	",langs
"XLM
	",token_type_ids
"XLM
	",position_ids
"XLM
	",lengths
"XLM
	",cache
"XLM
	",head_mask
"XLM
	",inputs_embeds
"XLM
	",output_attentions
"XLM
	",output_hidden_states
"XLM
	",return_dict
"XLM
	",labels
"XLM
	",config
"XLM
	",input_ids
"XLM
	",attention_mask
"XLM
	",langs
"XLM
	",token_type_ids
"XLM
	",position_ids
"XLM
	",lengths
"XLM
	",cache
"XLM
	",head_mask
"XLM
	",inputs_embeds
"XLM
	",output_attentions
"XLM
	",output_hidden_states
"XLM
	",return_dict
"XLM
	",start_positions
"XLM
	",end_positions
"XLM
	",config
"XLM
	",input_ids
"XLM
	",attention_mask
"XLM
	",langs
"XLM
	",token_type_ids
"XLM
	",position_ids
"XLM
	",lengths
"XLM
	",cache
"XLM
	",head_mask
"XLM
	",inputs_embeds
"XLM
	",output_attentions
"XLM
	",output_hidden_states
"XLM
	",return_dict
"XLM
	",start_positions
"XLM
	",end_positions
"XLM
	",is_impossible
"XLM
	",cls_index
"XLM
	",p_mask
"XLM
	",config
"XLM
	",input_ids
"XLM
	",attention_mask
"XLM
	",langs
"XLM
	",token_type_ids
"XLM
	",position_ids
"XLM
	",lengths
"XLM
	",cache
"XLM
	",head_mask
"XLM
	",inputs_embeds
"XLM
	",output_attentions
"XLM
	",output_hidden_states
"XLM
	",return_dict
"XLM
	",training
"XLM
	",config
"XLM
	",input_ids
"XLM
	",attention_mask
"XLM
	",langs
"XLM
	",token_type_ids
"XLM
	",position_ids
"XLM
	",lengths
"XLM
	",cache
"XLM
	",head_mask
"XLM
	",inputs_embeds
"XLM
	",output_attentions
"XLM
	",output_hidden_states
"XLM
	",return_dict
"XLM
	",training
"XLM
	",config
"XLM
	",input_ids
"XLM
	",attention_mask
"XLM
	",langs
"XLM
	",token_type_ids
"XLM
	",position_ids
"XLM
	",lengths
"XLM
	",cache
"XLM
	",head_mask
"XLM
	",inputs_embeds
"XLM
	",output_attentions
"XLM
	",output_hidden_states
"XLM
	",return_dict
"XLM
	",training
"XLM
	",labels
"XLM
	",config
"XLM
	",input_ids
"XLM
	",attention_mask
"XLM
	",langs
"XLM
	",token_type_ids
"XLM
	",position_ids
"XLM
	",lengths
"XLM
	",cache
"XLM
	",head_mask
"XLM
	",inputs_embeds
"XLM
	",output_attentions
"XLM
	",output_hidden_states
"XLM
	",return_dict
"XLM
	",training
"XLM
	",config
"XLM
	",input_ids
"XLM
	",attention_mask
"XLM
	",langs
"XLM
	",token_type_ids
"XLM
	",position_ids
"XLM
	",lengths
"XLM
	",cache
"XLM
	",head_mask
"XLM
	",inputs_embeds
"XLM
	",output_attentions
"XLM
	",output_hidden_states
"XLM
	",return_dict
"XLM
	",training
"XLM
	",labels
"XLM
	",config
"XLM
	",input_ids
"XLM
	",attention_mask
"XLM
	",langs
"XLM
	",token_type_ids
"XLM
	",position_ids
"XLM
	",lengths
"XLM
	",cache
"XLM
	",head_mask
"XLM
	",inputs_embeds
"XLM
	",output_attentions
"XLM
	",output_hidden_states
"XLM
	",return_dict
"XLM
	",training
"XLM
	",start_positions
"XLM
	",end_positions
"XGLM
	",vocab_size
"XGLM
	",max_position_embeddings
"XGLM
	",d_model
"XGLM
	",ffn_dim
"XGLM
	",num_layers
"XGLM
	",attention_heads
"XGLM
	",activation_function
"XGLM
	",dropout
"XGLM
	",attention_dropout
"XGLM
	",activation_dropout
"XGLM
	",layerdrop
"XGLM
	",init_std
"XGLM
	",scale_embedding
"XGLM
	",use_cache
"XGLM
	",vocab_file
"XGLM
	",bos_token
"XGLM
	",eos_token
"XGLM
	",sep_token
"XGLM
	",cls_token
"XGLM
	",unk_token
"XGLM
	",pad_token
"XGLM
	",mask_token
"XGLM
	",additional_special_tokens
"XGLM
	",sp_model_kwargs
"XGLM
	",sp_model
"XGLM
	",token_ids_0
"XGLM
	",token_ids_1
"XGLM
	",token_ids_0
"XGLM
	",token_ids_1
"XGLM
	",already_has_special_tokens
"XGLM
	",token_ids_0
"XGLM
	",token_ids_1
"XGLM
	",vocab_file
"XGLM
	",bos_token
"XGLM
	",eos_token
"XGLM
	",sep_token
"XGLM
	",cls_token
"XGLM
	",unk_token
"XGLM
	",pad_token
"XGLM
	",additional_special_tokens
"XGLM
	",token_ids_0
"XGLM
	",token_ids_1
"XGLM
	",token_ids_0
"XGLM
	",token_ids_1
"XGLM
	",config
"XGLM
	",embed_tokens
"XGLM
	",input_ids
"XGLM
	",attention_mask
"XGLM
	",head_mask
"XGLM
	",past_key_values
"XGLM
	",inputs_embeds
"XGLM
	",use_cache
"XGLM
	",output_attentions
"XGLM
	",output_hidden_states
"XGLM
	",return_dict
"XGLM
	",config
"XGLM
	",input_ids
"XGLM
	",attention_mask
"XGLM
	",head_mask
"XGLM
	",past_key_values
"XGLM
	",inputs_embeds
"XGLM
	",use_cache
"XGLM
	",output_attentions
"XGLM
	",output_hidden_states
"XGLM
	",return_dict
"XGLM
	",labels
"XGLM
	",config
"XGLM
	",input_ids
"XGLM
	",attention_mask
"XGLM
	",encoder_hidden_states
"XGLM
	",encoder_attention_mask
"XGLM
	",head_mask
"XGLM
	",cross_attn_head_mask
"XGLM
	",past_key_values
"XGLM
	",inputs_embeds
"XGLM
	",use_cache
"XGLM
	",output_attentions
"XGLM
	",output_hidden_states
"XGLM
	",return_dict
"XGLM
	",training
"XGLM
	",config
"XGLM
	",input_ids
"XGLM
	",attention_mask
"XGLM
	",encoder_hidden_states
"XGLM
	",encoder_attention_mask
"XGLM
	",head_mask
"XGLM
	",cross_attn_head_mask
"XGLM
	",past_key_values
"XGLM
	",inputs_embeds
"XGLM
	",use_cache
"XGLM
	",output_attentions
"XGLM
	",output_hidden_states
"XGLM
	",return_dict
"XGLM
	",training
"XGLM
	",labels
"XGLM
	",are shifted
"XGLM
	",config
"XGLM
	",dtype
"XGLM
	",input_ids
"XGLM
	",attention_mask
"XGLM
	",position_ids
"XGLM
	",output_attentions
"XGLM
	",output_hidden_states
"XGLM
	",return_dict
"XGLM
	",config
"XGLM
	",dtype
"XGLM
	",input_ids
"XGLM
	",attention_mask
"XGLM
	",position_ids
"XGLM
	",output_attentions
"XGLM
	",output_hidden_states
"XGLM
	",return_dict
"Transformer XL
	",vocab_size
"Transformer XL
	",cutoffs
"Transformer XL
	",d_model
"Transformer XL
	",d_embed
"Transformer XL
	",n_head
"Transformer XL
	",d_head
"Transformer XL
	",d_inner
"Transformer XL
	",div_val
"Transformer XL
	",pre_lnorm
"Transformer XL
	",n_layer
"Transformer XL
	",mem_len
"Transformer XL
	",clamp_len
"Transformer XL
	",same_length
"Transformer XL
	",proj_share_all_but_first
"Transformer XL
	",attn_type
"Transformer XL
	",sample_softmax
"Transformer XL
	",adaptive
"Transformer XL
	",dropout
"Transformer XL
	",dropatt
"Transformer XL
	",untie_r
"Transformer XL
	",init
"Transformer XL
	",init_range
"Transformer XL
	",proj_init_std
"Transformer XL
	",init_std
"Transformer XL
	",layer_norm_epsilon
"Transformer XL
	",special
"Transformer XL
	",min_freq
"Transformer XL
	",max_size
"Transformer XL
	",lower_case
"Transformer XL
	",delimiter
"Transformer XL
	",vocab_file
"Transformer XL
	",pretrained_vocab_file
"Transformer XL
	",never_split
"Transformer XL
	",unk_token
"Transformer XL
	",eos_token
"Transformer XL
	",additional_special_tokens
"Transformer XL
	",language
"Transformer XL
	",last_hidden_state
"Transformer XL
	",mems
"Transformer XL
	",hidden_states
"Transformer XL
	",attentions
"Transformer XL
	",losses
"Transformer XL
	",prediction_scores
"Transformer XL
	",mems
"Transformer XL
	",hidden_states
"Transformer XL
	",attentions
"Transformer XL
	",loss
"Transformer XL
	",last_hidden_state
"Transformer XL
	",mems
"Transformer XL
	",hidden_states
"Transformer XL
	",attentions
"Transformer XL
	",losses
"Transformer XL
	",prediction_scores
"Transformer XL
	",mems
"Transformer XL
	",hidden_states
"Transformer XL
	",attentions
"Transformer XL
	",config
"Transformer XL
	",input_ids
"Transformer XL
	",mems
"Transformer XL
	",head_mask
"Transformer XL
	",inputs_embeds
"Transformer XL
	",output_attentions
"Transformer XL
	",output_hidden_states
"Transformer XL
	",return_dict
"Transformer XL
	",config
"Transformer XL
	",input_ids
"Transformer XL
	",mems
"Transformer XL
	",head_mask
"Transformer XL
	",inputs_embeds
"Transformer XL
	",output_attentions
"Transformer XL
	",output_hidden_states
"Transformer XL
	",return_dict
"Transformer XL
	",labels
"Transformer XL
	",are shifted
"Transformer XL
	",config
"Transformer XL
	",input_ids
"Transformer XL
	",mems
"Transformer XL
	",head_mask
"Transformer XL
	",inputs_embeds
"Transformer XL
	",output_attentions
"Transformer XL
	",output_hidden_states
"Transformer XL
	",return_dict
"Transformer XL
	",labels
"Transformer XL
	",config
"Transformer XL
	",input_ids
"Transformer XL
	",mems
"Transformer XL
	",head_mask
"Transformer XL
	",inputs_embeds
"Transformer XL
	",output_attentions
"Transformer XL
	",output_hidden_states
"Transformer XL
	",return_dict
"Transformer XL
	",training
"Transformer XL
	",config
"Transformer XL
	",input_ids
"Transformer XL
	",mems
"Transformer XL
	",head_mask
"Transformer XL
	",inputs_embeds
"Transformer XL
	",output_attentions
"Transformer XL
	",output_hidden_states
"Transformer XL
	",return_dict
"Transformer XL
	",training
"Transformer XL
	",config
"Transformer XL
	",input_ids
"Transformer XL
	",mems
"Transformer XL
	",head_mask
"Transformer XL
	",inputs_embeds
"Transformer XL
	",output_attentions
"Transformer XL
	",output_hidden_states
"Transformer XL
	",return_dict
"Transformer XL
	",training
"Transformer XL
	",labels
"TAPEX
	",vocab_file
"TAPEX
	",merges_file
"TAPEX
	",do_lower_case
"TAPEX
	",errors
"TAPEX
	",bos_token
"TAPEX
	",eos_token
"TAPEX
	",sep_token
"TAPEX
	",cls_token
"TAPEX
	",unk_token
"TAPEX
	",pad_token
"TAPEX
	",mask_token
"TAPEX
	",add_prefix_space
"TAPEX
	",max_cell_length
"TAPEX
	",table
"TAPEX
	",query
"TAPEX
	",answer
"TAPEX
	",add_special_tokens
"TAPEX
	",padding
"TAPEX
	",truncation
"TAPEX
	",max_length
"TAPEX
	",stride
"TAPEX
	",is_split_into_words
"TAPEX
	",pad_to_multiple_of
"TAPEX
	",return_tensors
"TAPEX
	",add_special_tokens
"TAPEX
	",padding
"TAPEX
	",truncation
"TAPEX
	",max_length
"TAPEX
	",stride
"TAPEX
	",pad_to_multiple_of
"TAPEX
	",return_tensors
"TAPAS
	",loss
"TAPAS
	",logits
"TAPAS
	",logits_aggregation
"TAPAS
	",hidden_states
"TAPAS
	",attentions
"TAPAS
	",vocab_size
"TAPAS
	",hidden_size
"TAPAS
	",num_hidden_layers
"TAPAS
	",num_attention_heads
"TAPAS
	",intermediate_size
"TAPAS
	",hidden_act
"TAPAS
	",hidden_dropout_prob
"TAPAS
	",attention_probs_dropout_prob
"TAPAS
	",max_position_embeddings
"TAPAS
	",type_vocab_sizes
"TAPAS
	",initializer_range
"TAPAS
	",layer_norm_eps
"TAPAS
	",positive_label_weight
"TAPAS
	",num_aggregation_labels
"TAPAS
	",aggregation_loss_weight
"TAPAS
	",use_answer_as_supervision
"TAPAS
	",answer_loss_importance
"TAPAS
	",use_normalized_answer_loss
"TAPAS
	",huber_loss_delta
"TAPAS
	",temperature
"TAPAS
	",aggregation_temperature
"TAPAS
	",use_gumbel_for_cells
"TAPAS
	",use_gumbel_for_aggregation
"TAPAS
	",average_approximation_function
"TAPAS
	",cell_selection_preference
"TAPAS
	",answer_loss_cutoff
"TAPAS
	",max_num_rows
"TAPAS
	",max_num_columns
"TAPAS
	",average_logits_per_cell
"TAPAS
	",select_one_column
"TAPAS
	",allow_empty_column_selection
"TAPAS
	",init_cell_selection_weights_to_zero
"TAPAS
	",reset_position_index_per_cell
"TAPAS
	",disable_per_token_loss
"TAPAS
	",aggregation_labels
"TAPAS
	",no_aggregation_label_index
"TAPAS
	",vocab_file
"TAPAS
	",do_lower_case
"TAPAS
	",do_basic_tokenize
"TAPAS
	",never_split
"TAPAS
	",unk_token
"TAPAS
	",sep_token
"TAPAS
	",pad_token
"TAPAS
	",cls_token
"TAPAS
	",mask_token
"TAPAS
	",empty_token
"TAPAS
	",tokenize_chinese_chars
"TAPAS
	",strip_accents
"TAPAS
	",cell_trim_length
"TAPAS
	",max_column_id
"TAPAS
	",max_row_id
"TAPAS
	",strip_column_names
"TAPAS
	",update_answer_coordinates
"TAPAS
	",min_question_length
"TAPAS
	",max_question_length
"TAPAS
	",table
"TAPAS
	",queries
"TAPAS
	",same
"TAPAS
	",answer_coordinates
"TAPAS
	",answer_text
"TAPAS
	",add_special_tokens
"TAPAS
	",padding
"TAPAS
	",truncation
"TAPAS
	",max_length
"TAPAS
	",is_split_into_words
"TAPAS
	",pad_to_multiple_of
"TAPAS
	",return_tensors
"TAPAS
	",data
"TAPAS
	",logits
"TAPAS
	",logits_agg
"TAPAS
	",cell_classification_threshold
"TAPAS
	",config
"TAPAS
	",input_ids
"TAPAS
	",attention_mask
"TAPAS
	",token_type_ids
"TAPAS
	",position_ids
"TAPAS
	",head_mask
"TAPAS
	",not masked
"TAPAS
	",masked
"TAPAS
	",inputs_embeds
"TAPAS
	",output_attentions
"TAPAS
	",output_hidden_states
"TAPAS
	",return_dict
"TAPAS
	",config
"TAPAS
	",input_ids
"TAPAS
	",attention_mask
"TAPAS
	",token_type_ids
"TAPAS
	",position_ids
"TAPAS
	",head_mask
"TAPAS
	",not masked
"TAPAS
	",masked
"TAPAS
	",inputs_embeds
"TAPAS
	",output_attentions
"TAPAS
	",output_hidden_states
"TAPAS
	",return_dict
"TAPAS
	",labels
"TAPAS
	",config
"TAPAS
	",input_ids
"TAPAS
	",attention_mask
"TAPAS
	",token_type_ids
"TAPAS
	",position_ids
"TAPAS
	",head_mask
"TAPAS
	",not masked
"TAPAS
	",masked
"TAPAS
	",inputs_embeds
"TAPAS
	",output_attentions
"TAPAS
	",output_hidden_states
"TAPAS
	",return_dict
"TAPAS
	",labels
"TAPAS
	",config
"TAPAS
	",input_ids
"TAPAS
	",attention_mask
"TAPAS
	",token_type_ids
"TAPAS
	",position_ids
"TAPAS
	",head_mask
"TAPAS
	",not masked
"TAPAS
	",masked
"TAPAS
	",inputs_embeds
"TAPAS
	",output_attentions
"TAPAS
	",output_hidden_states
"TAPAS
	",return_dict
"TAPAS
	",table_mask
"TAPAS
	",labels
"TAPAS
	",aggregation_labels
"TAPAS
	",float_answer
"TAPAS
	",numeric_values
"TAPAS
	",numeric_values_scale
"TAPAS
	",config
"TAPAS
	",input_ids
"TAPAS
	",attention_mask
"TAPAS
	",token_type_ids
"TAPAS
	",position_ids
"TAPAS
	",head_mask
"TAPAS
	",inputs_embeds
"TAPAS
	",output_attentions
"TAPAS
	",output_hidden_states
"TAPAS
	",return_dict
"TAPAS
	",training
"TAPAS
	",config
"TAPAS
	",input_ids
"TAPAS
	",attention_mask
"TAPAS
	",token_type_ids
"TAPAS
	",position_ids
"TAPAS
	",head_mask
"TAPAS
	",inputs_embeds
"TAPAS
	",output_attentions
"TAPAS
	",output_hidden_states
"TAPAS
	",return_dict
"TAPAS
	",training
"TAPAS
	",labels
"TAPAS
	",config
"TAPAS
	",input_ids
"TAPAS
	",attention_mask
"TAPAS
	",token_type_ids
"TAPAS
	",position_ids
"TAPAS
	",head_mask
"TAPAS
	",inputs_embeds
"TAPAS
	",output_attentions
"TAPAS
	",output_hidden_states
"TAPAS
	",return_dict
"TAPAS
	",training
"TAPAS
	",labels
"TAPAS
	",config
"TAPAS
	",input_ids
"TAPAS
	",attention_mask
"TAPAS
	",token_type_ids
"TAPAS
	",position_ids
"TAPAS
	",head_mask
"TAPAS
	",inputs_embeds
"TAPAS
	",output_attentions
"TAPAS
	",output_hidden_states
"TAPAS
	",return_dict
"TAPAS
	",training
"TAPAS
	",table_mask
"TAPAS
	",labels
"TAPAS
	",aggregation_labels
"TAPAS
	",float_answer
"TAPAS
	",numeric_values
"TAPAS
	",numeric_values_scale
"Pegasus
	",vocab_size
"Pegasus
	",d_model
"Pegasus
	",encoder_layers
"Pegasus
	",decoder_layers
"Pegasus
	",encoder_attention_heads
"Pegasus
	",decoder_attention_heads
"Pegasus
	",decoder_ffn_dim
"Pegasus
	",encoder_ffn_dim
"Pegasus
	",activation_function
"Pegasus
	",dropout
"Pegasus
	",attention_dropout
"Pegasus
	",activation_dropout
"Pegasus
	",classifier_dropout
"Pegasus
	",max_position_embeddings
"Pegasus
	",init_std
"Pegasus
	",encoder_layerdrop
"Pegasus
	",decoder_layerdrop
"Pegasus
	",scale_embedding
"Pegasus
	",use_cache
"Pegasus
	",forced_eos_token_id
"Pegasus
	",vocab_file
"Pegasus
	",pad_token
"Pegasus
	",eos_token
"Pegasus
	",unk_token
"Pegasus
	",mask_token
"Pegasus
	",mask_token_sent
"Pegasus
	",additional_special_tokens
"Pegasus
	",sp_model_kwargs
"Pegasus
	",token_ids_0
"Pegasus
	",token_ids_1
"Pegasus
	",vocab_file
"Pegasus
	",pad_token
"Pegasus
	",eos_token
"Pegasus
	",unk_token
"Pegasus
	",mask_token
"Pegasus
	",mask_token_sent
"Pegasus
	",additional_special_tokens
"Pegasus
	",token_ids_0
"Pegasus
	",token_ids_1
"Pegasus
	",config
"Pegasus
	",input_ids
"Pegasus
	",attention_mask
"Pegasus
	",decoder_input_ids
"Pegasus
	",decoder_attention_mask
"Pegasus
	",head_mask
"Pegasus
	",decoder_head_mask
"Pegasus
	",cross_attn_head_mask
"Pegasus
	",encoder_outputs
"Pegasus
	",past_key_values
"Pegasus
	",decoder_inputs_embeds
"Pegasus
	",use_cache
"Pegasus
	",output_attentions
"Pegasus
	",output_hidden_states
"Pegasus
	",return_dict
"Pegasus
	",config
"Pegasus
	",input_ids
"Pegasus
	",attention_mask
"Pegasus
	",decoder_input_ids
"Pegasus
	",decoder_attention_mask
"Pegasus
	",head_mask
"Pegasus
	",decoder_head_mask
"Pegasus
	",cross_attn_head_mask
"Pegasus
	",encoder_outputs
"Pegasus
	",past_key_values
"Pegasus
	",decoder_inputs_embeds
"Pegasus
	",use_cache
"Pegasus
	",output_attentions
"Pegasus
	",output_hidden_states
"Pegasus
	",return_dict
"Pegasus
	",labels
"Pegasus
	",input_ids
"Pegasus
	",attention_mask
"Pegasus
	",encoder_hidden_states
"Pegasus
	",encoder_attention_mask
"Pegasus
	",head_mask
"Pegasus
	",cross_attn_head_mask
"Pegasus
	",past_key_values
"Pegasus
	",labels
"Pegasus
	",use_cache
"Pegasus
	",output_attentions
"Pegasus
	",output_hidden_states
"Pegasus
	",return_dict
"Pegasus
	",config
"Pegasus
	",input_ids
"Pegasus
	",attention_mask
"Pegasus
	",decoder_input_ids
"Pegasus
	",decoder_attention_mask
"Pegasus
	",decoder_position_ids
"Pegasus
	",head_mask
"Pegasus
	",decoder_head_mask
"Pegasus
	",cross_attn_head_mask
"Pegasus
	",encoder_outputs
"Pegasus
	",past_key_values
"Pegasus
	",use_cache
"Pegasus
	",output_attentions
"Pegasus
	",output_hidden_states
"Pegasus
	",return_dict
"Pegasus
	",training
"Pegasus
	",config
"Pegasus
	",input_ids
"Pegasus
	",attention_mask
"Pegasus
	",decoder_input_ids
"Pegasus
	",decoder_attention_mask
"Pegasus
	",decoder_position_ids
"Pegasus
	",head_mask
"Pegasus
	",decoder_head_mask
"Pegasus
	",cross_attn_head_mask
"Pegasus
	",encoder_outputs
"Pegasus
	",past_key_values
"Pegasus
	",use_cache
"Pegasus
	",output_attentions
"Pegasus
	",output_hidden_states
"Pegasus
	",return_dict
"Pegasus
	",training
"Pegasus
	",labels
"Pegasus
	",config
"Pegasus
	",dtype
"Pegasus
	",input_ids
"Pegasus
	",attention_mask
"Pegasus
	",decoder_input_ids
"Pegasus
	",decoder_attention_mask
"Pegasus
	",position_ids
"Pegasus
	",decoder_position_ids
"Pegasus
	",output_attentions
"Pegasus
	",output_hidden_states
"Pegasus
	",return_dict
"Pegasus
	",input_ids
"Pegasus
	",attention_mask
"Pegasus
	",position_ids
"Pegasus
	",output_attentions
"Pegasus
	",output_hidden_states
"Pegasus
	",return_dict
"Pegasus
	",decoder_input_ids
"Pegasus
	",encoder_outputs
"Pegasus
	",encoder_attention_mask
"Pegasus
	",decoder_attention_mask
"Pegasus
	",decoder_position_ids
"Pegasus
	",past_key_values
"Pegasus
	",output_attentions
"Pegasus
	",output_hidden_states
"Pegasus
	",return_dict
"Pegasus
	",config
"Pegasus
	",dtype
"Pegasus
	",input_ids
"Pegasus
	",attention_mask
"Pegasus
	",decoder_input_ids
"Pegasus
	",decoder_attention_mask
"Pegasus
	",position_ids
"Pegasus
	",decoder_position_ids
"Pegasus
	",output_attentions
"Pegasus
	",output_hidden_states
"Pegasus
	",return_dict
"Pegasus
	",input_ids
"Pegasus
	",attention_mask
"Pegasus
	",position_ids
"Pegasus
	",output_attentions
"Pegasus
	",output_hidden_states
"Pegasus
	",return_dict
"Pegasus
	",decoder_input_ids
"Pegasus
	",encoder_outputs
"Pegasus
	",encoder_attention_mask
"Pegasus
	",decoder_attention_mask
"Pegasus
	",decoder_position_ids
"Pegasus
	",past_key_values
"Pegasus
	",output_attentions
"Pegasus
	",output_hidden_states
"Pegasus
	",return_dict
"OPT
	",vocab_size
"OPT
	",hidden_size
"OPT
	",num_hidden_layers
"OPT
	",ffn_dim
"OPT
	",num_attention_heads
"OPT
	",activation_function
"OPT
	",max_position_embeddings
"OPT
	",do_layer_norm_before
"OPT
	",word_embed_proj_dim
"OPT
	",dropout
"OPT
	",attention_dropout
"OPT
	",init_std
"OPT
	",use_cache
"OPT
	",config
"OPT
	",input_ids
"OPT
	",attention_mask
"OPT
	",head_mask
"OPT
	",past_key_values
"OPT
	",inputs_embeds
"OPT
	",use_cache
"OPT
	",output_attentions
"OPT
	",output_hidden_states
"OPT
	",return_dict
"OPT
	",input_ids
"OPT
	",attention_mask
"OPT
	",head_mask
"OPT
	",past_key_values
"OPT
	",inputs_embeds
"OPT
	",labels
"OPT
	",use_cache
"OPT
	",output_attentions
"OPT
	",output_hidden_states
"OPT
	",return_dict
"OPT
	",config
"OPT
	",input_ids
"OPT
	",attention_mask
"OPT
	",head_mask
"OPT
	",past_key_values
"OPT
	",use_cache
"OPT
	",output_attentions
"OPT
	",output_hidden_states
"OPT
	",return_dict
"OPT
	",training
"OPT
	",config
"OPT
	",input_ids
"OPT
	",attention_mask
"OPT
	",head_mask
"OPT
	",past_key_values
"OPT
	",inputs_embeds
"OPT
	",labels
"OPT
	",use_cache
"OPT
	",output_attentions
"OPT
	",output_hidden_states
"OPT
	",return_dict
"OPT
	",config
"OPT
	",input_ids
"OPT
	",attention_mask
"OPT
	",head_mask
"OPT
	",past_key_values
"OPT
	",inputs_embeds
"OPT
	",use_cache
"OPT
	",output_attentions
"OPT
	",output_hidden_states
"OPT
	",return_dict
"OPT
	",labels
"OPT
	",config
"OPT
	",input_ids
"OPT
	",attention_mask
"OPT
	",head_mask
"OPT
	",past_key_values
"OPT
	",inputs_embeds
"OPT
	",use_cache
"OPT
	",output_attentions
"OPT
	",output_hidden_states
"OPT
	",return_dict
"OPT
	",start_positions
"OPT
	",end_positions
"OPT
	",config
"OPT
	",dtype
"Nystrmformer
	",vocab_size
"Nystrmformer
	",hidden_size
"Nystrmformer
	",num_hidden_layers
"Nystrmformer
	",num_attention_heads
"Nystrmformer
	",intermediate_size
"Nystrmformer
	",hidden_act
"Nystrmformer
	",hidden_dropout_prob
"Nystrmformer
	",attention_probs_dropout_prob
"Nystrmformer
	",max_position_embeddings
"Nystrmformer
	",type_vocab_size
"Nystrmformer
	",segment_means_seq_len
"Nystrmformer
	",num_landmarks
"Nystrmformer
	",conv_kernel_size
"Nystrmformer
	",inv_coeff_init_option
"Nystrmformer
	",initializer_range
"Nystrmformer
	",layer_norm_eps
"Nystrmformer
	",config
"Nystrmformer
	",input_ids
"Nystrmformer
	",attention_mask
"Nystrmformer
	",token_type_ids
"Nystrmformer
	",position_ids
"Nystrmformer
	",head_mask
"Nystrmformer
	",inputs_embeds
"Nystrmformer
	",output_attentions
"Nystrmformer
	",output_hidden_states
"Nystrmformer
	",return_dict
"Nystrmformer
	",config
"Nystrmformer
	",input_ids
"Nystrmformer
	",attention_mask
"Nystrmformer
	",token_type_ids
"Nystrmformer
	",position_ids
"Nystrmformer
	",head_mask
"Nystrmformer
	",inputs_embeds
"Nystrmformer
	",output_attentions
"Nystrmformer
	",output_hidden_states
"Nystrmformer
	",return_dict
"Nystrmformer
	",labels
"Nystrmformer
	",config
"Nystrmformer
	",input_ids
"Nystrmformer
	",attention_mask
"Nystrmformer
	",token_type_ids
"Nystrmformer
	",position_ids
"Nystrmformer
	",head_mask
"Nystrmformer
	",inputs_embeds
"Nystrmformer
	",output_attentions
"Nystrmformer
	",output_hidden_states
"Nystrmformer
	",return_dict
"Nystrmformer
	",labels
"Nystrmformer
	",config
"Nystrmformer
	",input_ids
"Nystrmformer
	",attention_mask
"Nystrmformer
	",token_type_ids
"Nystrmformer
	",position_ids
"Nystrmformer
	",head_mask
"Nystrmformer
	",inputs_embeds
"Nystrmformer
	",output_attentions
"Nystrmformer
	",output_hidden_states
"Nystrmformer
	",return_dict
"Nystrmformer
	",labels
"Nystrmformer
	",config
"Nystrmformer
	",input_ids
"Nystrmformer
	",attention_mask
"Nystrmformer
	",token_type_ids
"Nystrmformer
	",position_ids
"Nystrmformer
	",head_mask
"Nystrmformer
	",inputs_embeds
"Nystrmformer
	",output_attentions
"Nystrmformer
	",output_hidden_states
"Nystrmformer
	",return_dict
"Nystrmformer
	",labels
"Nystrmformer
	",config
"Nystrmformer
	",input_ids
"Nystrmformer
	",attention_mask
"Nystrmformer
	",token_type_ids
"Nystrmformer
	",position_ids
"Nystrmformer
	",head_mask
"Nystrmformer
	",inputs_embeds
"Nystrmformer
	",output_attentions
"Nystrmformer
	",output_hidden_states
"Nystrmformer
	",return_dict
"Nystrmformer
	",start_positions
"Nystrmformer
	",end_positions
"NLLB
	",vocab_file
"NLLB
	",bos_token
"NLLB
	",eos_token
"NLLB
	",sep_token
"NLLB
	",cls_token
"NLLB
	",unk_token
"NLLB
	",pad_token
"NLLB
	",mask_token
"NLLB
	",tokenizer_file
"NLLB
	",src_lang
"NLLB
	",tgt_lang
"NLLB
	",sp_model_kwargs
"NLLB
	",token_ids_0
"NLLB
	",token_ids_1
"NLLB
	",vocab_file
"NLLB
	",bos_token
"NLLB
	",eos_token
"NLLB
	",sep_token
"NLLB
	",cls_token
"NLLB
	",unk_token
"NLLB
	",pad_token
"NLLB
	",mask_token
"NLLB
	",tokenizer_file
"NLLB
	",src_lang
"NLLB
	",tgt_lang
"NLLB
	",token_ids_0
"NLLB
	",token_ids_1
"NLLB
	",token_ids_0
"NLLB
	",token_ids_1
"Nezha
	",vocab_size
"Nezha
	",embedding_size
"Nezha
	",hidden_size
"Nezha
	",num_hidden_layers
"Nezha
	",num_attention_heads
"Nezha
	",intermediate_size
"Nezha
	",hidden_act
"Nezha
	",hidden_dropout_prob
"Nezha
	",attention_probs_dropout_prob
"Nezha
	",max_position_embeddings
"Nezha
	",type_vocab_size
"Nezha
	",initializer_range
"Nezha
	",layer_norm_eps
"Nezha
	",classifier_dropout
"Nezha
	",config
"Nezha
	",input_ids
"Nezha
	",attention_mask
"Nezha
	",token_type_ids
"Nezha
	",head_mask
"Nezha
	",inputs_embeds
"Nezha
	",output_attentions
"Nezha
	",output_hidden_states
"Nezha
	",return_dict
"Nezha
	",encoder_hidden_states
"Nezha
	",encoder_attention_mask
"Nezha
	",past_key_values
"Nezha
	",use_cache
"Nezha
	",config
"Nezha
	",input_ids
"Nezha
	",attention_mask
"Nezha
	",token_type_ids
"Nezha
	",head_mask
"Nezha
	",inputs_embeds
"Nezha
	",output_attentions
"Nezha
	",output_hidden_states
"Nezha
	",return_dict
"Nezha
	",config
"Nezha
	",input_ids
"Nezha
	",attention_mask
"Nezha
	",token_type_ids
"Nezha
	",head_mask
"Nezha
	",inputs_embeds
"Nezha
	",output_attentions
"Nezha
	",output_hidden_states
"Nezha
	",return_dict
"Nezha
	",labels
"Nezha
	",config
"Nezha
	",input_ids
"Nezha
	",attention_mask
"Nezha
	",token_type_ids
"Nezha
	",head_mask
"Nezha
	",inputs_embeds
"Nezha
	",output_attentions
"Nezha
	",output_hidden_states
"Nezha
	",return_dict
"Nezha
	",labels
"Nezha
	",config
"Nezha
	",input_ids
"Nezha
	",attention_mask
"Nezha
	",token_type_ids
"Nezha
	",head_mask
"Nezha
	",inputs_embeds
"Nezha
	",output_attentions
"Nezha
	",output_hidden_states
"Nezha
	",return_dict
"Nezha
	",labels
"Nezha
	",config
"Nezha
	",input_ids
"Nezha
	",attention_mask
"Nezha
	",token_type_ids
"Nezha
	",head_mask
"Nezha
	",inputs_embeds
"Nezha
	",output_attentions
"Nezha
	",output_hidden_states
"Nezha
	",return_dict
"Nezha
	",labels
"Nezha
	",config
"Nezha
	",input_ids
"Nezha
	",attention_mask
"Nezha
	",token_type_ids
"Nezha
	",head_mask
"Nezha
	",inputs_embeds
"Nezha
	",output_attentions
"Nezha
	",output_hidden_states
"Nezha
	",return_dict
"Nezha
	",labels
"Nezha
	",config
"Nezha
	",input_ids
"Nezha
	",attention_mask
"Nezha
	",token_type_ids
"Nezha
	",head_mask
"Nezha
	",inputs_embeds
"Nezha
	",output_attentions
"Nezha
	",output_hidden_states
"Nezha
	",return_dict
"Nezha
	",start_positions
"Nezha
	",end_positions
"MVP
	",vocab_size
"MVP
	",d_model
"MVP
	",encoder_layers
"MVP
	",decoder_layers
"MVP
	",encoder_attention_heads
"MVP
	",decoder_attention_heads
"MVP
	",decoder_ffn_dim
"MVP
	",encoder_ffn_dim
"MVP
	",activation_function
"MVP
	",dropout
"MVP
	",attention_dropout
"MVP
	",activation_dropout
"MVP
	",classifier_dropout
"MVP
	",max_position_embeddings
"MVP
	",init_std
"MVP
	",encoder_layerdrop
"MVP
	",decoder_layerdrop
"MVP
	",scale_embedding
"MVP
	",use_cache
"MVP
	",forced_eos_token_id
"MVP
	",use_prompt
"MVP
	",prompt_length
"MVP
	",prompt_mid_dim
"MVP
	",vocab_file
"MVP
	",merges_file
"MVP
	",errors
"MVP
	",bos_token
"MVP
	",eos_token
"MVP
	",sep_token
"MVP
	",cls_token
"MVP
	",unk_token
"MVP
	",pad_token
"MVP
	",mask_token
"MVP
	",add_prefix_space
"MVP
	",token_ids_0
"MVP
	",token_ids_1
"MVP
	",token_ids_0
"MVP
	",token_ids_1
"MVP
	",token_ids_0
"MVP
	",token_ids_1
"MVP
	",already_has_special_tokens
"MVP
	",vocab_file
"MVP
	",merges_file
"MVP
	",errors
"MVP
	",bos_token
"MVP
	",eos_token
"MVP
	",sep_token
"MVP
	",cls_token
"MVP
	",unk_token
"MVP
	",pad_token
"MVP
	",mask_token
"MVP
	",add_prefix_space
"MVP
	",trim_offsets
"MVP
	",token_ids_0
"MVP
	",token_ids_1
"MVP
	",config
"MVP
	",input_ids
"MVP
	",attention_mask
"MVP
	",decoder_input_ids
"MVP
	",decoder_attention_mask
"MVP
	",head_mask
"MVP
	",decoder_head_mask
"MVP
	",cross_attn_head_mask
"MVP
	",encoder_outputs
"MVP
	",past_key_values
"MVP
	",decoder_inputs_embeds
"MVP
	",use_cache
"MVP
	",output_attentions
"MVP
	",output_hidden_states
"MVP
	",return_dict
"MVP
	",config
"MVP
	",input_ids
"MVP
	",attention_mask
"MVP
	",decoder_input_ids
"MVP
	",decoder_attention_mask
"MVP
	",head_mask
"MVP
	",decoder_head_mask
"MVP
	",cross_attn_head_mask
"MVP
	",encoder_outputs
"MVP
	",past_key_values
"MVP
	",decoder_inputs_embeds
"MVP
	",use_cache
"MVP
	",output_attentions
"MVP
	",output_hidden_states
"MVP
	",return_dict
"MVP
	",labels
"MVP
	",config
"MVP
	",input_ids
"MVP
	",attention_mask
"MVP
	",decoder_input_ids
"MVP
	",decoder_attention_mask
"MVP
	",head_mask
"MVP
	",decoder_head_mask
"MVP
	",cross_attn_head_mask
"MVP
	",encoder_outputs
"MVP
	",past_key_values
"MVP
	",decoder_inputs_embeds
"MVP
	",use_cache
"MVP
	",output_attentions
"MVP
	",output_hidden_states
"MVP
	",return_dict
"MVP
	",labels
"MVP
	",config
"MVP
	",input_ids
"MVP
	",attention_mask
"MVP
	",decoder_input_ids
"MVP
	",decoder_attention_mask
"MVP
	",head_mask
"MVP
	",decoder_head_mask
"MVP
	",cross_attn_head_mask
"MVP
	",encoder_outputs
"MVP
	",past_key_values
"MVP
	",decoder_inputs_embeds
"MVP
	",use_cache
"MVP
	",output_attentions
"MVP
	",output_hidden_states
"MVP
	",return_dict
"MVP
	",start_positions
"MVP
	",end_positions
"MVP
	",input_ids
"MVP
	",attention_mask
"MVP
	",encoder_hidden_states
"MVP
	",encoder_attention_mask
"MVP
	",head_mask
"MVP
	",cross_attn_head_mask
"MVP
	",past_key_values
"MVP
	",labels
"MVP
	",use_cache
"MVP
	",output_attentions
"MVP
	",output_hidden_states
"MVP
	",return_dict
"mT5
	",vocab_size
"mT5
	",d_model
"mT5
	",d_kv
"mT5
	",d_ff
"mT5
	",num_layers
"mT5
	",num_decoder_layers
"mT5
	",num_heads
"mT5
	",relative_attention_num_buckets
"mT5
	",relative_attention_max_distance
"mT5
	",dropout_rate
"mT5
	",layer_norm_eps
"mT5
	",initializer_factor
"mT5
	",feed_forward_proj
"mT5
	",use_cache
"mT5
	",vocab_file
"mT5
	",eos_token
"mT5
	",unk_token
"mT5
	",pad_token
"mT5
	",extra_ids
"mT5
	",additional_special_tokens
"mT5
	",sp_model_kwargs
"mT5
	",sp_model
"mT5
	",token_ids_0
"mT5
	",token_ids_1
"mT5
	",token_ids_0
"mT5
	",token_ids_1
"mT5
	",token_ids_0
"mT5
	",token_ids_1
"mT5
	",already_has_special_tokens
"mT5
	",vocab_file
"mT5
	",eos_token
"mT5
	",unk_token
"mT5
	",pad_token
"mT5
	",extra_ids
"mT5
	",additional_special_tokens
"mT5
	",token_ids_0
"mT5
	",token_ids_1
"mT5
	",token_ids_0
"mT5
	",token_ids_1
"MPNet
	",vocab_size
"MPNet
	",hidden_size
"MPNet
	",num_hidden_layers
"MPNet
	",num_attention_heads
"MPNet
	",intermediate_size
"MPNet
	",hidden_act
"MPNet
	",hidden_dropout_prob
"MPNet
	",attention_probs_dropout_prob
"MPNet
	",max_position_embeddings
"MPNet
	",initializer_range
"MPNet
	",layer_norm_eps
"MPNet
	",relative_attention_num_buckets
"MPNet
	",vocab_file
"MPNet
	",do_lower_case
"MPNet
	",do_basic_tokenize
"MPNet
	",never_split
"MPNet
	",bos_token
"MPNet
	",eos_token
"MPNet
	",sep_token
"MPNet
	",cls_token
"MPNet
	",unk_token
"MPNet
	",pad_token
"MPNet
	",mask_token
"MPNet
	",tokenize_chinese_chars
"MPNet
	",token_ids_0
"MPNet
	",token_ids_1
"MPNet
	",token_ids_0
"MPNet
	",token_ids_1
"MPNet
	",already_has_special_tokens
"MPNet
	",token_ids_0
"MPNet
	",token_ids_1
"MPNet
	",vocab_file
"MPNet
	",do_lower_case
"MPNet
	",bos_token
"MPNet
	",eos_token
"MPNet
	",sep_token
"MPNet
	",cls_token
"MPNet
	",unk_token
"MPNet
	",pad_token
"MPNet
	",mask_token
"MPNet
	",tokenize_chinese_chars
"MPNet
	",token_ids_0
"MPNet
	",token_ids_1
"MPNet
	",config
"MPNet
	",input_ids
"MPNet
	",attention_mask
"MPNet
	",position_ids
"MPNet
	",head_mask
"MPNet
	",inputs_embeds
"MPNet
	",output_attentions
"MPNet
	",output_hidden_states
"MPNet
	",return_dict
"MPNet
	",input_ids
"MPNet
	",attention_mask
"MPNet
	",position_ids
"MPNet
	",head_mask
"MPNet
	",inputs_embeds
"MPNet
	",output_attentions
"MPNet
	",output_hidden_states
"MPNet
	",return_dict
"MPNet
	",labels
"MPNet
	",config
"MPNet
	",input_ids
"MPNet
	",attention_mask
"MPNet
	",position_ids
"MPNet
	",head_mask
"MPNet
	",inputs_embeds
"MPNet
	",output_attentions
"MPNet
	",output_hidden_states
"MPNet
	",return_dict
"MPNet
	",labels
"MPNet
	",config
"MPNet
	",input_ids
"MPNet
	",attention_mask
"MPNet
	",position_ids
"MPNet
	",head_mask
"MPNet
	",inputs_embeds
"MPNet
	",output_attentions
"MPNet
	",output_hidden_states
"MPNet
	",return_dict
"MPNet
	",labels
"MPNet
	",config
"MPNet
	",input_ids
"MPNet
	",attention_mask
"MPNet
	",position_ids
"MPNet
	",head_mask
"MPNet
	",inputs_embeds
"MPNet
	",output_attentions
"MPNet
	",output_hidden_states
"MPNet
	",return_dict
"MPNet
	",labels
"MPNet
	",config
"MPNet
	",input_ids
"MPNet
	",attention_mask
"MPNet
	",position_ids
"MPNet
	",head_mask
"MPNet
	",inputs_embeds
"MPNet
	",output_attentions
"MPNet
	",output_hidden_states
"MPNet
	",return_dict
"MPNet
	",start_positions
"MPNet
	",end_positions
"MPNet
	",config
"MPNet
	",input_ids
"MPNet
	",attention_mask
"MPNet
	",position_ids
"MPNet
	",head_mask
"MPNet
	",inputs_embeds
"MPNet
	",output_attentions
"MPNet
	",output_hidden_states
"MPNet
	",return_dict
"MPNet
	",training
"MPNet
	",config
"MPNet
	",input_ids
"MPNet
	",attention_mask
"MPNet
	",position_ids
"MPNet
	",head_mask
"MPNet
	",inputs_embeds
"MPNet
	",output_attentions
"MPNet
	",output_hidden_states
"MPNet
	",return_dict
"MPNet
	",training
"MPNet
	",labels
"MPNet
	",config
"MPNet
	",input_ids
"MPNet
	",attention_mask
"MPNet
	",position_ids
"MPNet
	",head_mask
"MPNet
	",inputs_embeds
"MPNet
	",output_attentions
"MPNet
	",output_hidden_states
"MPNet
	",return_dict
"MPNet
	",training
"MPNet
	",labels
"MPNet
	",config
"MPNet
	",input_ids
"MPNet
	",attention_mask
"MPNet
	",position_ids
"MPNet
	",head_mask
"MPNet
	",inputs_embeds
"MPNet
	",output_attentions
"MPNet
	",output_hidden_states
"MPNet
	",return_dict
"MPNet
	",training
"MPNet
	",labels
"MPNet
	",config
"MPNet
	",input_ids
"MPNet
	",attention_mask
"MPNet
	",position_ids
"MPNet
	",head_mask
"MPNet
	",inputs_embeds
"MPNet
	",output_attentions
"MPNet
	",output_hidden_states
"MPNet
	",return_dict
"MPNet
	",training
"MPNet
	",labels
"MPNet
	",config
"MPNet
	",input_ids
"MPNet
	",attention_mask
"MPNet
	",position_ids
"MPNet
	",head_mask
"MPNet
	",inputs_embeds
"MPNet
	",output_attentions
"MPNet
	",output_hidden_states
"MPNet
	",return_dict
"MPNet
	",training
"MPNet
	",start_positions
"MPNet
	",end_positions
"MobileBERT
	",vocab_size
"MobileBERT
	",hidden_size
"MobileBERT
	",num_hidden_layers
"MobileBERT
	",num_attention_heads
"MobileBERT
	",intermediate_size
"MobileBERT
	",hidden_act
"MobileBERT
	",hidden_dropout_prob
"MobileBERT
	",attention_probs_dropout_prob
"MobileBERT
	",max_position_embeddings
"MobileBERT
	",type_vocab_size
"MobileBERT
	",initializer_range
"MobileBERT
	",layer_norm_eps
"MobileBERT
	",pad_token_id
"MobileBERT
	",embedding_size
"MobileBERT
	",trigram_input
"MobileBERT
	",use_bottleneck
"MobileBERT
	",intra_bottleneck_size
"MobileBERT
	",use_bottleneck_attention
"MobileBERT
	",key_query_shared_bottleneck
"MobileBERT
	",num_feedforward_networks
"MobileBERT
	",normalization_type
"MobileBERT
	",classifier_dropout
"MobileBERT
	",loss
"MobileBERT
	",prediction_logits
"MobileBERT
	",seq_relationship_logits
"MobileBERT
	",hidden_states
"MobileBERT
	",attentions
"MobileBERT
	",prediction_logits
"MobileBERT
	",seq_relationship_logits
"MobileBERT
	",hidden_states
"MobileBERT
	",attentions
"MobileBERT
	",config
"MobileBERT
	",input_ids
"MobileBERT
	",attention_mask
"MobileBERT
	",token_type_ids
"MobileBERT
	",position_ids
"MobileBERT
	",head_mask
"MobileBERT
	",inputs_embeds
"MobileBERT
	",output_attentions
"MobileBERT
	",output_hidden_states
"MobileBERT
	",return_dict
"MobileBERT
	",config
"MobileBERT
	",input_ids
"MobileBERT
	",attention_mask
"MobileBERT
	",token_type_ids
"MobileBERT
	",position_ids
"MobileBERT
	",head_mask
"MobileBERT
	",inputs_embeds
"MobileBERT
	",output_attentions
"MobileBERT
	",output_hidden_states
"MobileBERT
	",return_dict
"MobileBERT
	",labels
"MobileBERT
	",next_sentence_label
"MobileBERT
	",config
"MobileBERT
	",input_ids
"MobileBERT
	",attention_mask
"MobileBERT
	",token_type_ids
"MobileBERT
	",position_ids
"MobileBERT
	",head_mask
"MobileBERT
	",inputs_embeds
"MobileBERT
	",output_attentions
"MobileBERT
	",output_hidden_states
"MobileBERT
	",return_dict
"MobileBERT
	",labels
"MobileBERT
	",config
"MobileBERT
	",input_ids
"MobileBERT
	",attention_mask
"MobileBERT
	",token_type_ids
"MobileBERT
	",position_ids
"MobileBERT
	",head_mask
"MobileBERT
	",inputs_embeds
"MobileBERT
	",output_attentions
"MobileBERT
	",output_hidden_states
"MobileBERT
	",return_dict
"MobileBERT
	",labels
"MobileBERT
	",config
"MobileBERT
	",input_ids
"MobileBERT
	",attention_mask
"MobileBERT
	",token_type_ids
"MobileBERT
	",position_ids
"MobileBERT
	",head_mask
"MobileBERT
	",inputs_embeds
"MobileBERT
	",output_attentions
"MobileBERT
	",output_hidden_states
"MobileBERT
	",return_dict
"MobileBERT
	",labels
"MobileBERT
	",config
"MobileBERT
	",input_ids
"MobileBERT
	",attention_mask
"MobileBERT
	",token_type_ids
"MobileBERT
	",position_ids
"MobileBERT
	",head_mask
"MobileBERT
	",inputs_embeds
"MobileBERT
	",output_attentions
"MobileBERT
	",output_hidden_states
"MobileBERT
	",return_dict
"MobileBERT
	",labels
"MobileBERT
	",config
"MobileBERT
	",input_ids
"MobileBERT
	",attention_mask
"MobileBERT
	",token_type_ids
"MobileBERT
	",position_ids
"MobileBERT
	",head_mask
"MobileBERT
	",inputs_embeds
"MobileBERT
	",output_attentions
"MobileBERT
	",output_hidden_states
"MobileBERT
	",return_dict
"MobileBERT
	",labels
"MobileBERT
	",config
"MobileBERT
	",input_ids
"MobileBERT
	",attention_mask
"MobileBERT
	",token_type_ids
"MobileBERT
	",position_ids
"MobileBERT
	",head_mask
"MobileBERT
	",inputs_embeds
"MobileBERT
	",output_attentions
"MobileBERT
	",output_hidden_states
"MobileBERT
	",return_dict
"MobileBERT
	",start_positions
"MobileBERT
	",end_positions
"MobileBERT
	",config
"MobileBERT
	",input_ids
"MobileBERT
	",attention_mask
"MobileBERT
	",token_type_ids
"MobileBERT
	",position_ids
"MobileBERT
	",head_mask
"MobileBERT
	",inputs_embeds
"MobileBERT
	",output_attentions
"MobileBERT
	",output_hidden_states
"MobileBERT
	",return_dict
"MobileBERT
	",training
"MobileBERT
	",config
"MobileBERT
	",input_ids
"MobileBERT
	",attention_mask
"MobileBERT
	",token_type_ids
"MobileBERT
	",position_ids
"MobileBERT
	",head_mask
"MobileBERT
	",inputs_embeds
"MobileBERT
	",output_attentions
"MobileBERT
	",output_hidden_states
"MobileBERT
	",return_dict
"MobileBERT
	",training
"MobileBERT
	",config
"MobileBERT
	",input_ids
"MobileBERT
	",attention_mask
"MobileBERT
	",token_type_ids
"MobileBERT
	",position_ids
"MobileBERT
	",head_mask
"MobileBERT
	",inputs_embeds
"MobileBERT
	",output_attentions
"MobileBERT
	",output_hidden_states
"MobileBERT
	",return_dict
"MobileBERT
	",training
"MobileBERT
	",labels
"MobileBERT
	",config
"MobileBERT
	",input_ids
"MobileBERT
	",attention_mask
"MobileBERT
	",token_type_ids
"MobileBERT
	",position_ids
"MobileBERT
	",head_mask
"MobileBERT
	",inputs_embeds
"MobileBERT
	",output_attentions
"MobileBERT
	",output_hidden_states
"MobileBERT
	",return_dict
"MobileBERT
	",training
"MobileBERT
	",config
"MobileBERT
	",input_ids
"MobileBERT
	",attention_mask
"MobileBERT
	",token_type_ids
"MobileBERT
	",position_ids
"MobileBERT
	",head_mask
"MobileBERT
	",inputs_embeds
"MobileBERT
	",output_attentions
"MobileBERT
	",output_hidden_states
"MobileBERT
	",return_dict
"MobileBERT
	",training
"MobileBERT
	",labels
"MobileBERT
	",config
"MobileBERT
	",input_ids
"MobileBERT
	",attention_mask
"MobileBERT
	",token_type_ids
"MobileBERT
	",position_ids
"MobileBERT
	",head_mask
"MobileBERT
	",inputs_embeds
"MobileBERT
	",output_attentions
"MobileBERT
	",output_hidden_states
"MobileBERT
	",return_dict
"MobileBERT
	",training
"MobileBERT
	",labels
"MobileBERT
	",config
"MobileBERT
	",input_ids
"MobileBERT
	",attention_mask
"MobileBERT
	",token_type_ids
"MobileBERT
	",position_ids
"MobileBERT
	",head_mask
"MobileBERT
	",inputs_embeds
"MobileBERT
	",output_attentions
"MobileBERT
	",output_hidden_states
"MobileBERT
	",return_dict
"MobileBERT
	",training
"MobileBERT
	",labels
"MobileBERT
	",config
"MobileBERT
	",input_ids
"MobileBERT
	",attention_mask
"MobileBERT
	",token_type_ids
"MobileBERT
	",position_ids
"MobileBERT
	",head_mask
"MobileBERT
	",inputs_embeds
"MobileBERT
	",output_attentions
"MobileBERT
	",output_hidden_states
"MobileBERT
	",return_dict
"MobileBERT
	",training
"MobileBERT
	",start_positions
"MobileBERT
	",end_positions
"mLUKE
	",vocab_file
"mLUKE
	",entity_vocab_file
"mLUKE
	",bos_token
"mLUKE
	",eos_token
"mLUKE
	",sep_token
"mLUKE
	",cls_token
"mLUKE
	",unk_token
"mLUKE
	",pad_token
"mLUKE
	",mask_token
"mLUKE
	",task
"mLUKE
	",max_entity_length
"mLUKE
	",max_mention_length
"mLUKE
	",entity_token_1
"mLUKE
	",entity_token_2
"mLUKE
	",additional_special_tokens
"mLUKE
	",sp_model_kwargs
"mLUKE
	",sp_model
"mLUKE
	",text
"mLUKE
	",text_pair
"mLUKE
	",entity_spans
"mLUKE
	",entity_spans_pair
"mLUKE
	",entities
"mLUKE
	",entities_pair
"mLUKE
	",max_entity_length
"mLUKE
	",add_special_tokens
"mLUKE
	",padding
"mLUKE
	",truncation
"mLUKE
	",max_length
"mLUKE
	",stride
"mLUKE
	",is_split_into_words
"mLUKE
	",pad_to_multiple_of
"mLUKE
	",return_tensors
"mLUKE
	",return_token_type_ids
"mLUKE
	",return_attention_mask
"mLUKE
	",return_overflowing_tokens
"mLUKE
	",return_special_tokens_mask
"mLUKE
	",return_offsets_mapping
"mLUKE
	",return_length
"mLUKE
	",verbose
"MegatronBERT
	",vocab_size
"MegatronBERT
	",hidden_size
"MegatronBERT
	",num_hidden_layers
"MegatronBERT
	",num_attention_heads
"MegatronBERT
	",intermediate_size
"MegatronBERT
	",hidden_act
"MegatronBERT
	",hidden_dropout_prob
"MegatronBERT
	",attention_probs_dropout_prob
"MegatronBERT
	",max_position_embeddings
"MegatronBERT
	",type_vocab_size
"MegatronBERT
	",initializer_range
"MegatronBERT
	",layer_norm_eps
"MegatronBERT
	",position_embedding_type
"MegatronBERT
	",use_cache
"MegatronBERT
	",config
"MegatronBERT
	",input_ids
"MegatronBERT
	",attention_mask
"MegatronBERT
	",token_type_ids
"MegatronBERT
	",position_ids
"MegatronBERT
	",head_mask
"MegatronBERT
	",inputs_embeds
"MegatronBERT
	",output_attentions
"MegatronBERT
	",output_hidden_states
"MegatronBERT
	",return_dict
"MegatronBERT
	",encoder_hidden_states
"MegatronBERT
	",encoder_attention_mask
"MegatronBERT
	",past_key_values
"MegatronBERT
	",use_cache
"MegatronBERT
	",config
"MegatronBERT
	",input_ids
"MegatronBERT
	",attention_mask
"MegatronBERT
	",token_type_ids
"MegatronBERT
	",position_ids
"MegatronBERT
	",head_mask
"MegatronBERT
	",inputs_embeds
"MegatronBERT
	",output_attentions
"MegatronBERT
	",output_hidden_states
"MegatronBERT
	",return_dict
"MegatronBERT
	",labels
"MegatronBERT
	",config
"MegatronBERT
	",input_ids
"MegatronBERT
	",attention_mask
"MegatronBERT
	",token_type_ids
"MegatronBERT
	",position_ids
"MegatronBERT
	",head_mask
"MegatronBERT
	",inputs_embeds
"MegatronBERT
	",output_attentions
"MegatronBERT
	",output_hidden_states
"MegatronBERT
	",return_dict
"MegatronBERT
	",encoder_hidden_states
"MegatronBERT
	",encoder_attention_mask
"MegatronBERT
	",labels
"MegatronBERT
	",past_key_values
"MegatronBERT
	",use_cache
"MegatronBERT
	",config
"MegatronBERT
	",input_ids
"MegatronBERT
	",attention_mask
"MegatronBERT
	",token_type_ids
"MegatronBERT
	",position_ids
"MegatronBERT
	",head_mask
"MegatronBERT
	",inputs_embeds
"MegatronBERT
	",output_attentions
"MegatronBERT
	",output_hidden_states
"MegatronBERT
	",return_dict
"MegatronBERT
	",labels
"MegatronBERT
	",config
"MegatronBERT
	",input_ids
"MegatronBERT
	",attention_mask
"MegatronBERT
	",token_type_ids
"MegatronBERT
	",position_ids
"MegatronBERT
	",head_mask
"MegatronBERT
	",inputs_embeds
"MegatronBERT
	",output_attentions
"MegatronBERT
	",output_hidden_states
"MegatronBERT
	",return_dict
"MegatronBERT
	",labels
"MegatronBERT
	",next_sentence_label
"MegatronBERT
	",kwargs
"MegatronBERT
	",config
"MegatronBERT
	",input_ids
"MegatronBERT
	",attention_mask
"MegatronBERT
	",token_type_ids
"MegatronBERT
	",position_ids
"MegatronBERT
	",head_mask
"MegatronBERT
	",inputs_embeds
"MegatronBERT
	",output_attentions
"MegatronBERT
	",output_hidden_states
"MegatronBERT
	",return_dict
"MegatronBERT
	",labels
"MegatronBERT
	",config
"MegatronBERT
	",input_ids
"MegatronBERT
	",attention_mask
"MegatronBERT
	",token_type_ids
"MegatronBERT
	",position_ids
"MegatronBERT
	",head_mask
"MegatronBERT
	",inputs_embeds
"MegatronBERT
	",output_attentions
"MegatronBERT
	",output_hidden_states
"MegatronBERT
	",return_dict
"MegatronBERT
	",labels
"MegatronBERT
	",config
"MegatronBERT
	",input_ids
"MegatronBERT
	",attention_mask
"MegatronBERT
	",token_type_ids
"MegatronBERT
	",position_ids
"MegatronBERT
	",head_mask
"MegatronBERT
	",inputs_embeds
"MegatronBERT
	",output_attentions
"MegatronBERT
	",output_hidden_states
"MegatronBERT
	",return_dict
"MegatronBERT
	",labels
"MegatronBERT
	",config
"MegatronBERT
	",input_ids
"MegatronBERT
	",attention_mask
"MegatronBERT
	",token_type_ids
"MegatronBERT
	",position_ids
"MegatronBERT
	",head_mask
"MegatronBERT
	",inputs_embeds
"MegatronBERT
	",output_attentions
"MegatronBERT
	",output_hidden_states
"MegatronBERT
	",return_dict
"MegatronBERT
	",start_positions
"MegatronBERT
	",end_positions
"MBart and MBart-50
	",vocab_size
"MBart and MBart-50
	",d_model
"MBart and MBart-50
	",encoder_layers
"MBart and MBart-50
	",decoder_layers
"MBart and MBart-50
	",encoder_attention_heads
"MBart and MBart-50
	",decoder_attention_heads
"MBart and MBart-50
	",decoder_ffn_dim
"MBart and MBart-50
	",encoder_ffn_dim
"MBart and MBart-50
	",activation_function
"MBart and MBart-50
	",dropout
"MBart and MBart-50
	",attention_dropout
"MBart and MBart-50
	",activation_dropout
"MBart and MBart-50
	",classifier_dropout
"MBart and MBart-50
	",max_position_embeddings
"MBart and MBart-50
	",init_std
"MBart and MBart-50
	",encoder_layerdrop
"MBart and MBart-50
	",decoder_layerdrop
"MBart and MBart-50
	",scale_embedding
"MBart and MBart-50
	",use_cache
"MBart and MBart-50
	",forced_eos_token_id
"MBart and MBart-50
	",token_ids_0
"MBart and MBart-50
	",token_ids_1
"MBart and MBart-50
	",token_ids_0
"MBart and MBart-50
	",token_ids_1
"MBart and MBart-50
	",token_ids_0
"MBart and MBart-50
	",token_ids_1
"MBart and MBart-50
	",vocab_file
"MBart and MBart-50
	",src_lang
"MBart and MBart-50
	",tgt_lang
"MBart and MBart-50
	",eos_token
"MBart and MBart-50
	",sep_token
"MBart and MBart-50
	",cls_token
"MBart and MBart-50
	",unk_token
"MBart and MBart-50
	",pad_token
"MBart and MBart-50
	",mask_token
"MBart and MBart-50
	",sp_model_kwargs
"MBart and MBart-50
	",token_ids_0
"MBart and MBart-50
	",token_ids_1
"MBart and MBart-50
	",token_ids_0
"MBart and MBart-50
	",token_ids_1
"MBart and MBart-50
	",already_has_special_tokens
"MBart and MBart-50
	",vocab_file
"MBart and MBart-50
	",src_lang
"MBart and MBart-50
	",tgt_lang
"MBart and MBart-50
	",eos_token
"MBart and MBart-50
	",sep_token
"MBart and MBart-50
	",cls_token
"MBart and MBart-50
	",unk_token
"MBart and MBart-50
	",pad_token
"MBart and MBart-50
	",mask_token
"MBart and MBart-50
	",token_ids_0
"MBart and MBart-50
	",token_ids_1
"MBart and MBart-50
	",config
"MBart and MBart-50
	",input_ids
"MBart and MBart-50
	",attention_mask
"MBart and MBart-50
	",decoder_input_ids
"MBart and MBart-50
	",decoder_attention_mask
"MBart and MBart-50
	",head_mask
"MBart and MBart-50
	",decoder_head_mask
"MBart and MBart-50
	",cross_attn_head_mask
"MBart and MBart-50
	",encoder_outputs
"MBart and MBart-50
	",past_key_values
"MBart and MBart-50
	",decoder_inputs_embeds
"MBart and MBart-50
	",use_cache
"MBart and MBart-50
	",output_attentions
"MBart and MBart-50
	",output_hidden_states
"MBart and MBart-50
	",return_dict
"MBart and MBart-50
	",config
"MBart and MBart-50
	",input_ids
"MBart and MBart-50
	",attention_mask
"MBart and MBart-50
	",decoder_input_ids
"MBart and MBart-50
	",decoder_attention_mask
"MBart and MBart-50
	",head_mask
"MBart and MBart-50
	",decoder_head_mask
"MBart and MBart-50
	",cross_attn_head_mask
"MBart and MBart-50
	",encoder_outputs
"MBart and MBart-50
	",past_key_values
"MBart and MBart-50
	",decoder_inputs_embeds
"MBart and MBart-50
	",use_cache
"MBart and MBart-50
	",output_attentions
"MBart and MBart-50
	",output_hidden_states
"MBart and MBart-50
	",return_dict
"MBart and MBart-50
	",labels
"MBart and MBart-50
	",config
"MBart and MBart-50
	",input_ids
"MBart and MBart-50
	",attention_mask
"MBart and MBart-50
	",decoder_input_ids
"MBart and MBart-50
	",decoder_attention_mask
"MBart and MBart-50
	",head_mask
"MBart and MBart-50
	",decoder_head_mask
"MBart and MBart-50
	",cross_attn_head_mask
"MBart and MBart-50
	",encoder_outputs
"MBart and MBart-50
	",past_key_values
"MBart and MBart-50
	",decoder_inputs_embeds
"MBart and MBart-50
	",use_cache
"MBart and MBart-50
	",output_attentions
"MBart and MBart-50
	",output_hidden_states
"MBart and MBart-50
	",return_dict
"MBart and MBart-50
	",start_positions
"MBart and MBart-50
	",end_positions
"MBart and MBart-50
	",config
"MBart and MBart-50
	",input_ids
"MBart and MBart-50
	",attention_mask
"MBart and MBart-50
	",decoder_input_ids
"MBart and MBart-50
	",decoder_attention_mask
"MBart and MBart-50
	",head_mask
"MBart and MBart-50
	",decoder_head_mask
"MBart and MBart-50
	",cross_attn_head_mask
"MBart and MBart-50
	",encoder_outputs
"MBart and MBart-50
	",past_key_values
"MBart and MBart-50
	",decoder_inputs_embeds
"MBart and MBart-50
	",use_cache
"MBart and MBart-50
	",output_attentions
"MBart and MBart-50
	",output_hidden_states
"MBart and MBart-50
	",return_dict
"MBart and MBart-50
	",labels
"MBart and MBart-50
	",input_ids
"MBart and MBart-50
	",attention_mask
"MBart and MBart-50
	",encoder_hidden_states
"MBart and MBart-50
	",encoder_attention_mask
"MBart and MBart-50
	",head_mask
"MBart and MBart-50
	",cross_attn_head_mask
"MBart and MBart-50
	",past_key_values
"MBart and MBart-50
	",labels
"MBart and MBart-50
	",use_cache
"MBart and MBart-50
	",output_attentions
"MBart and MBart-50
	",output_hidden_states
"MBart and MBart-50
	",return_dict
"MBart and MBart-50
	",config
"MBart and MBart-50
	",input_ids
"MBart and MBart-50
	",attention_mask
"MBart and MBart-50
	",decoder_input_ids
"MBart and MBart-50
	",decoder_attention_mask
"MBart and MBart-50
	",decoder_position_ids
"MBart and MBart-50
	",head_mask
"MBart and MBart-50
	",decoder_head_mask
"MBart and MBart-50
	",cross_attn_head_mask
"MBart and MBart-50
	",encoder_outputs
"MBart and MBart-50
	",past_key_values
"MBart and MBart-50
	",use_cache
"MBart and MBart-50
	",output_attentions
"MBart and MBart-50
	",output_hidden_states
"MBart and MBart-50
	",return_dict
"MBart and MBart-50
	",training
"MBart and MBart-50
	",config
"MBart and MBart-50
	",input_ids
"MBart and MBart-50
	",attention_mask
"MBart and MBart-50
	",decoder_input_ids
"MBart and MBart-50
	",decoder_attention_mask
"MBart and MBart-50
	",decoder_position_ids
"MBart and MBart-50
	",head_mask
"MBart and MBart-50
	",decoder_head_mask
"MBart and MBart-50
	",cross_attn_head_mask
"MBart and MBart-50
	",encoder_outputs
"MBart and MBart-50
	",past_key_values
"MBart and MBart-50
	",use_cache
"MBart and MBart-50
	",output_attentions
"MBart and MBart-50
	",output_hidden_states
"MBart and MBart-50
	",return_dict
"MBart and MBart-50
	",training
"MBart and MBart-50
	",labels
"MBart and MBart-50
	",config
"MBart and MBart-50
	",dtype
"MBart and MBart-50
	",input_ids
"MBart and MBart-50
	",attention_mask
"MBart and MBart-50
	",decoder_input_ids
"MBart and MBart-50
	",decoder_attention_mask
"MBart and MBart-50
	",position_ids
"MBart and MBart-50
	",decoder_position_ids
"MBart and MBart-50
	",output_attentions
"MBart and MBart-50
	",output_hidden_states
"MBart and MBart-50
	",return_dict
"MBart and MBart-50
	",input_ids
"MBart and MBart-50
	",attention_mask
"MBart and MBart-50
	",position_ids
"MBart and MBart-50
	",output_attentions
"MBart and MBart-50
	",output_hidden_states
"MBart and MBart-50
	",return_dict
"MBart and MBart-50
	",decoder_input_ids
"MBart and MBart-50
	",encoder_outputs
"MBart and MBart-50
	",encoder_attention_mask
"MBart and MBart-50
	",decoder_attention_mask
"MBart and MBart-50
	",decoder_position_ids
"MBart and MBart-50
	",past_key_values
"MBart and MBart-50
	",output_attentions
"MBart and MBart-50
	",output_hidden_states
"MBart and MBart-50
	",return_dict
"MBart and MBart-50
	",config
"MBart and MBart-50
	",dtype
"MBart and MBart-50
	",input_ids
"MBart and MBart-50
	",attention_mask
"MBart and MBart-50
	",decoder_input_ids
"MBart and MBart-50
	",decoder_attention_mask
"MBart and MBart-50
	",position_ids
"MBart and MBart-50
	",decoder_position_ids
"MBart and MBart-50
	",output_attentions
"MBart and MBart-50
	",output_hidden_states
"MBart and MBart-50
	",return_dict
"MBart and MBart-50
	",input_ids
"MBart and MBart-50
	",attention_mask
"MBart and MBart-50
	",position_ids
"MBart and MBart-50
	",output_attentions
"MBart and MBart-50
	",output_hidden_states
"MBart and MBart-50
	",return_dict
"MBart and MBart-50
	",decoder_input_ids
"MBart and MBart-50
	",encoder_outputs
"MBart and MBart-50
	",encoder_attention_mask
"MBart and MBart-50
	",decoder_attention_mask
"MBart and MBart-50
	",decoder_position_ids
"MBart and MBart-50
	",past_key_values
"MBart and MBart-50
	",output_attentions
"MBart and MBart-50
	",output_hidden_states
"MBart and MBart-50
	",return_dict
"MBart and MBart-50
	",config
"MBart and MBart-50
	",dtype
"MBart and MBart-50
	",input_ids
"MBart and MBart-50
	",attention_mask
"MBart and MBart-50
	",decoder_input_ids
"MBart and MBart-50
	",decoder_attention_mask
"MBart and MBart-50
	",position_ids
"MBart and MBart-50
	",decoder_position_ids
"MBart and MBart-50
	",output_attentions
"MBart and MBart-50
	",output_hidden_states
"MBart and MBart-50
	",return_dict
"MBart and MBart-50
	",input_ids
"MBart and MBart-50
	",attention_mask
"MBart and MBart-50
	",position_ids
"MBart and MBart-50
	",output_attentions
"MBart and MBart-50
	",output_hidden_states
"MBart and MBart-50
	",return_dict
"MBart and MBart-50
	",decoder_input_ids
"MBart and MBart-50
	",encoder_outputs
"MBart and MBart-50
	",encoder_attention_mask
"MBart and MBart-50
	",decoder_attention_mask
"MBart and MBart-50
	",decoder_position_ids
"MBart and MBart-50
	",past_key_values
"MBart and MBart-50
	",output_attentions
"MBart and MBart-50
	",output_hidden_states
"MBart and MBart-50
	",return_dict
"MBart and MBart-50
	",config
"MBart and MBart-50
	",dtype
"MBart and MBart-50
	",input_ids
"MBart and MBart-50
	",attention_mask
"MBart and MBart-50
	",decoder_input_ids
"MBart and MBart-50
	",decoder_attention_mask
"MBart and MBart-50
	",position_ids
"MBart and MBart-50
	",decoder_position_ids
"MBart and MBart-50
	",output_attentions
"MBart and MBart-50
	",output_hidden_states
"MBart and MBart-50
	",return_dict
"MBart and MBart-50
	",input_ids
"MBart and MBart-50
	",attention_mask
"MBart and MBart-50
	",position_ids
"MBart and MBart-50
	",output_attentions
"MBart and MBart-50
	",output_hidden_states
"MBart and MBart-50
	",return_dict
"MBart and MBart-50
	",decoder_input_ids
"MBart and MBart-50
	",encoder_outputs
"MBart and MBart-50
	",encoder_attention_mask
"MBart and MBart-50
	",decoder_attention_mask
"MBart and MBart-50
	",decoder_position_ids
"MBart and MBart-50
	",past_key_values
"MBart and MBart-50
	",output_attentions
"MBart and MBart-50
	",output_hidden_states
"MBart and MBart-50
	",return_dict
"MarkupLM
	",vocab_size
"MarkupLM
	",hidden_size
"MarkupLM
	",num_hidden_layers
"MarkupLM
	",num_attention_heads
"MarkupLM
	",intermediate_size
"MarkupLM
	",hidden_act
"MarkupLM
	",hidden_dropout_prob
"MarkupLM
	",attention_probs_dropout_prob
"MarkupLM
	",max_position_embeddings
"MarkupLM
	",type_vocab_size
"MarkupLM
	",initializer_range
"MarkupLM
	",layer_norm_eps
"MarkupLM
	",gradient_checkpointing
"MarkupLM
	",max_tree_id_unit_embeddings
"MarkupLM
	",max_xpath_tag_unit_embeddings
"MarkupLM
	",max_xpath_subs_unit_embeddings
"MarkupLM
	",tag_pad_id
"MarkupLM
	",subs_pad_id
"MarkupLM
	",xpath_tag_unit_hidden_size
"MarkupLM
	",max_depth
"MarkupLM
	",html_strings
"MarkupLM
	",vocab_file
"MarkupLM
	",merges_file
"MarkupLM
	",errors
"MarkupLM
	",bos_token
"MarkupLM
	",eos_token
"MarkupLM
	",sep_token
"MarkupLM
	",cls_token
"MarkupLM
	",unk_token
"MarkupLM
	",pad_token
"MarkupLM
	",mask_token
"MarkupLM
	",add_prefix_space
"MarkupLM
	",token_ids_0
"MarkupLM
	",token_ids_1
"MarkupLM
	",Retrieve
"MarkupLM
	",special
"MarkupLM
	",token_ids_0
"MarkupLM
	",token_ids_1
"MarkupLM
	",vocab_file
"MarkupLM
	",merges_file
"MarkupLM
	",errors
"MarkupLM
	",bos_token
"MarkupLM
	",eos_token
"MarkupLM
	",sep_token
"MarkupLM
	",cls_token
"MarkupLM
	",unk_token
"MarkupLM
	",pad_token
"MarkupLM
	",mask_token
"MarkupLM
	",add_prefix_space
"MarkupLM
	",token_ids_0
"MarkupLM
	",token_ids_1
"MarkupLM
	",token_ids_0
"MarkupLM
	",token_ids_1
"MarkupLM
	",text
"MarkupLM
	",text_pair
"MarkupLM
	",add_special_tokens
"MarkupLM
	",padding
"MarkupLM
	",truncation
"MarkupLM
	",max_length
"MarkupLM
	",stride
"MarkupLM
	",is_split_into_words
"MarkupLM
	",pad_to_multiple_of
"MarkupLM
	",return_tensors
"MarkupLM
	",add_special_tokens
"MarkupLM
	",padding
"MarkupLM
	",truncation
"MarkupLM
	",max_length
"MarkupLM
	",stride
"MarkupLM
	",pad_to_multiple_of
"MarkupLM
	",return_tensors
"MarkupLM
	",feature_extractor
"MarkupLM
	",tokenizer
"MarkupLM
	",parse_html
"MarkupLM
	",config
"MarkupLM
	",input_ids
"MarkupLM
	",xpath_tags_seq
"MarkupLM
	",xpath_subs_seq
"MarkupLM
	",attention_mask
"MarkupLM
	",token_type_ids
"MarkupLM
	",position_ids
"MarkupLM
	",head_mask
"MarkupLM
	",not masked
"MarkupLM
	",masked
"MarkupLM
	",inputs_embeds
"MarkupLM
	",output_attentions
"MarkupLM
	",output_hidden_states
"MarkupLM
	",return_dict
"MarkupLM
	",config
"MarkupLM
	",input_ids
"MarkupLM
	",xpath_tags_seq
"MarkupLM
	",xpath_subs_seq
"MarkupLM
	",attention_mask
"MarkupLM
	",token_type_ids
"MarkupLM
	",position_ids
"MarkupLM
	",head_mask
"MarkupLM
	",not masked
"MarkupLM
	",masked
"MarkupLM
	",inputs_embeds
"MarkupLM
	",output_attentions
"MarkupLM
	",output_hidden_states
"MarkupLM
	",return_dict
"MarkupLM
	",labels
"MarkupLM
	",config
"MarkupLM
	",input_ids
"MarkupLM
	",xpath_tags_seq
"MarkupLM
	",xpath_subs_seq
"MarkupLM
	",attention_mask
"MarkupLM
	",token_type_ids
"MarkupLM
	",position_ids
"MarkupLM
	",head_mask
"MarkupLM
	",not masked
"MarkupLM
	",masked
"MarkupLM
	",inputs_embeds
"MarkupLM
	",output_attentions
"MarkupLM
	",output_hidden_states
"MarkupLM
	",return_dict
"MarkupLM
	",labels
"MarkupLM
	",config
"MarkupLM
	",input_ids
"MarkupLM
	",xpath_tags_seq
"MarkupLM
	",xpath_subs_seq
"MarkupLM
	",attention_mask
"MarkupLM
	",token_type_ids
"MarkupLM
	",position_ids
"MarkupLM
	",head_mask
"MarkupLM
	",not masked
"MarkupLM
	",masked
"MarkupLM
	",inputs_embeds
"MarkupLM
	",output_attentions
"MarkupLM
	",output_hidden_states
"MarkupLM
	",return_dict
"MarkupLM
	",start_positions
"MarkupLM
	",end_positions
"MarianMT
	",vocab_size
"MarianMT
	",d_model
"MarianMT
	",encoder_layers
"MarianMT
	",decoder_layers
"MarianMT
	",encoder_attention_heads
"MarianMT
	",decoder_attention_heads
"MarianMT
	",decoder_ffn_dim
"MarianMT
	",encoder_ffn_dim
"MarianMT
	",activation_function
"MarianMT
	",dropout
"MarianMT
	",attention_dropout
"MarianMT
	",activation_dropout
"MarianMT
	",classifier_dropout
"MarianMT
	",max_position_embeddings
"MarianMT
	",init_std
"MarianMT
	",encoder_layerdrop
"MarianMT
	",decoder_layerdrop
"MarianMT
	",scale_embedding
"MarianMT
	",use_cache
"MarianMT
	",forced_eos_token_id
"MarianMT
	",source_spm
"MarianMT
	",target_spm
"MarianMT
	",source_lang
"MarianMT
	",target_lang
"MarianMT
	",unk_token
"MarianMT
	",eos_token
"MarianMT
	",pad_token
"MarianMT
	",model_max_length
"MarianMT
	",additional_special_tokens
"MarianMT
	",sp_model_kwargs
"MarianMT
	",config
"MarianMT
	",input_ids
"MarianMT
	",attention_mask
"MarianMT
	",decoder_input_ids
"MarianMT
	",decoder_attention_mask
"MarianMT
	",head_mask
"MarianMT
	",decoder_head_mask
"MarianMT
	",cross_attn_head_mask
"MarianMT
	",encoder_outputs
"MarianMT
	",past_key_values
"MarianMT
	",inputs_embeds
"MarianMT
	",decoder_inputs_embeds
"MarianMT
	",use_cache
"MarianMT
	",output_attentions
"MarianMT
	",output_hidden_states
"MarianMT
	",return_dict
"MarianMT
	",config
"MarianMT
	",input_ids
"MarianMT
	",attention_mask
"MarianMT
	",decoder_input_ids
"MarianMT
	",decoder_attention_mask
"MarianMT
	",head_mask
"MarianMT
	",decoder_head_mask
"MarianMT
	",cross_attn_head_mask
"MarianMT
	",encoder_outputs
"MarianMT
	",past_key_values
"MarianMT
	",inputs_embeds
"MarianMT
	",decoder_inputs_embeds
"MarianMT
	",use_cache
"MarianMT
	",output_attentions
"MarianMT
	",output_hidden_states
"MarianMT
	",return_dict
"MarianMT
	",labels
"MarianMT
	",input_ids
"MarianMT
	",attention_mask
"MarianMT
	",encoder_hidden_states
"MarianMT
	",encoder_attention_mask
"MarianMT
	",head_mask
"MarianMT
	",cross_attn_head_mask
"MarianMT
	",past_key_values
"MarianMT
	",labels
"MarianMT
	",use_cache
"MarianMT
	",output_attentions
"MarianMT
	",output_hidden_states
"MarianMT
	",return_dict
"MarianMT
	",config
"MarianMT
	",input_ids
"MarianMT
	",attention_mask
"MarianMT
	",decoder_input_ids
"MarianMT
	",decoder_attention_mask
"MarianMT
	",decoder_position_ids
"MarianMT
	",head_mask
"MarianMT
	",decoder_head_mask
"MarianMT
	",cross_attn_head_mask
"MarianMT
	",encoder_outputs
"MarianMT
	",past_key_values
"MarianMT
	",use_cache
"MarianMT
	",output_attentions
"MarianMT
	",output_hidden_states
"MarianMT
	",return_dict
"MarianMT
	",training
"MarianMT
	",config
"MarianMT
	",input_ids
"MarianMT
	",attention_mask
"MarianMT
	",decoder_input_ids
"MarianMT
	",decoder_attention_mask
"MarianMT
	",decoder_position_ids
"MarianMT
	",head_mask
"MarianMT
	",decoder_head_mask
"MarianMT
	",cross_attn_head_mask
"MarianMT
	",encoder_outputs
"MarianMT
	",past_key_values
"MarianMT
	",use_cache
"MarianMT
	",output_attentions
"MarianMT
	",output_hidden_states
"MarianMT
	",return_dict
"MarianMT
	",training
"MarianMT
	",labels
"MarianMT
	",config
"MarianMT
	",dtype
"MarianMT
	",input_ids
"MarianMT
	",attention_mask
"MarianMT
	",decoder_input_ids
"MarianMT
	",decoder_attention_mask
"MarianMT
	",position_ids
"MarianMT
	",decoder_position_ids
"MarianMT
	",output_attentions
"MarianMT
	",output_hidden_states
"MarianMT
	",return_dict
"MarianMT
	",config
"MarianMT
	",dtype
"MarianMT
	",input_ids
"MarianMT
	",attention_mask
"MarianMT
	",decoder_input_ids
"MarianMT
	",decoder_attention_mask
"MarianMT
	",position_ids
"MarianMT
	",decoder_position_ids
"MarianMT
	",output_attentions
"MarianMT
	",output_hidden_states
"MarianMT
	",return_dict
"M2M100
	",vocab_size
"M2M100
	",d_model
"M2M100
	",encoder_layers
"M2M100
	",decoder_layers
"M2M100
	",encoder_attention_heads
"M2M100
	",decoder_attention_heads
"M2M100
	",decoder_ffn_dim
"M2M100
	",encoder_ffn_dim
"M2M100
	",activation_function
"M2M100
	",dropout
"M2M100
	",attention_dropout
"M2M100
	",activation_dropout
"M2M100
	",classifier_dropout
"M2M100
	",max_position_embeddings
"M2M100
	",init_std
"M2M100
	",encoder_layerdrop
"M2M100
	",decoder_layerdrop
"M2M100
	",use_cache
"M2M100
	",vocab_file
"M2M100
	",spm_file
"M2M100
	",src_lang
"M2M100
	",tgt_lang
"M2M100
	",eos_token
"M2M100
	",sep_token
"M2M100
	",unk_token
"M2M100
	",pad_token
"M2M100
	",language_codes
"M2M100
	",sp_model_kwargs
"M2M100
	",token_ids_0
"M2M100
	",token_ids_1
"M2M100
	",token_ids_0
"M2M100
	",token_ids_1
"M2M100
	",already_has_special_tokens
"M2M100
	",token_ids_0
"M2M100
	",token_ids_1
"M2M100
	",config
"M2M100
	",input_ids
"M2M100
	",attention_mask
"M2M100
	",decoder_input_ids
"M2M100
	",decoder_attention_mask
"M2M100
	",head_mask
"M2M100
	",decoder_head_mask
"M2M100
	",cross_attn_head_mask
"M2M100
	",encoder_outputs
"M2M100
	",past_key_values
"M2M100
	",decoder_inputs_embeds
"M2M100
	",use_cache
"M2M100
	",output_attentions
"M2M100
	",output_hidden_states
"M2M100
	",return_dict
"M2M100
	",config
"M2M100
	",input_ids
"M2M100
	",attention_mask
"M2M100
	",decoder_input_ids
"M2M100
	",decoder_attention_mask
"M2M100
	",head_mask
"M2M100
	",decoder_head_mask
"M2M100
	",cross_attn_head_mask
"M2M100
	",encoder_outputs
"M2M100
	",past_key_values
"M2M100
	",decoder_inputs_embeds
"M2M100
	",use_cache
"M2M100
	",output_attentions
"M2M100
	",output_hidden_states
"M2M100
	",return_dict
"M2M100
	",labels
"LUKE
	",vocab_size
"LUKE
	",entity_vocab_size
"LUKE
	",hidden_size
"LUKE
	",entity_emb_size
"LUKE
	",num_hidden_layers
"LUKE
	",num_attention_heads
"LUKE
	",intermediate_size
"LUKE
	",hidden_act
"LUKE
	",hidden_dropout_prob
"LUKE
	",attention_probs_dropout_prob
"LUKE
	",max_position_embeddings
"LUKE
	",type_vocab_size
"LUKE
	",initializer_range
"LUKE
	",layer_norm_eps
"LUKE
	",use_entity_aware_attention
"LUKE
	",classifier_dropout
"LUKE
	",vocab_file
"LUKE
	",merges_file
"LUKE
	",entity_vocab_file
"LUKE
	",task
"LUKE
	",max_entity_length
"LUKE
	",max_mention_length
"LUKE
	",entity_token_1
"LUKE
	",entity_token_2
"LUKE
	",text
"LUKE
	",text_pair
"LUKE
	",entity_spans
"LUKE
	",entity_spans_pair
"LUKE
	",entities
"LUKE
	",entities_pair
"LUKE
	",max_entity_length
"LUKE
	",add_special_tokens
"LUKE
	",padding
"LUKE
	",truncation
"LUKE
	",max_length
"LUKE
	",stride
"LUKE
	",is_split_into_words
"LUKE
	",pad_to_multiple_of
"LUKE
	",return_tensors
"LUKE
	",return_token_type_ids
"LUKE
	",return_attention_mask
"LUKE
	",return_overflowing_tokens
"LUKE
	",return_special_tokens_mask
"LUKE
	",return_offsets_mapping
"LUKE
	",return_length
"LUKE
	",verbose
"LUKE
	",config
"LUKE
	",input_ids
"LUKE
	",attention_mask
"LUKE
	",token_type_ids
"LUKE
	",position_ids
"LUKE
	",entity_ids
"LUKE
	",entity_attention_mask
"LUKE
	",entity_token_type_ids
"LUKE
	",entity_position_ids
"LUKE
	",inputs_embeds
"LUKE
	",head_mask
"LUKE
	",output_attentions
"LUKE
	",output_hidden_states
"LUKE
	",return_dict
"LUKE
	",config
"LUKE
	",input_ids
"LUKE
	",attention_mask
"LUKE
	",token_type_ids
"LUKE
	",position_ids
"LUKE
	",entity_ids
"LUKE
	",entity_attention_mask
"LUKE
	",entity_token_type_ids
"LUKE
	",entity_position_ids
"LUKE
	",inputs_embeds
"LUKE
	",head_mask
"LUKE
	",output_attentions
"LUKE
	",output_hidden_states
"LUKE
	",return_dict
"LUKE
	",labels
"LUKE
	",entity_labels
"LUKE
	",config
"LUKE
	",input_ids
"LUKE
	",attention_mask
"LUKE
	",token_type_ids
"LUKE
	",position_ids
"LUKE
	",entity_ids
"LUKE
	",entity_attention_mask
"LUKE
	",entity_token_type_ids
"LUKE
	",entity_position_ids
"LUKE
	",inputs_embeds
"LUKE
	",head_mask
"LUKE
	",output_attentions
"LUKE
	",output_hidden_states
"LUKE
	",return_dict
"LUKE
	",labels
"LUKE
	",config
"LUKE
	",input_ids
"LUKE
	",attention_mask
"LUKE
	",token_type_ids
"LUKE
	",position_ids
"LUKE
	",entity_ids
"LUKE
	",entity_attention_mask
"LUKE
	",entity_token_type_ids
"LUKE
	",entity_position_ids
"LUKE
	",inputs_embeds
"LUKE
	",head_mask
"LUKE
	",output_attentions
"LUKE
	",output_hidden_states
"LUKE
	",return_dict
"LUKE
	",labels
"LUKE
	",config
"LUKE
	",input_ids
"LUKE
	",attention_mask
"LUKE
	",token_type_ids
"LUKE
	",position_ids
"LUKE
	",entity_ids
"LUKE
	",entity_attention_mask
"LUKE
	",entity_token_type_ids
"LUKE
	",entity_position_ids
"LUKE
	",inputs_embeds
"LUKE
	",head_mask
"LUKE
	",output_attentions
"LUKE
	",output_hidden_states
"LUKE
	",return_dict
"LUKE
	",entity_start_positions
"LUKE
	",entity_end_positions
"LUKE
	",labels
"LUKE
	",config
"LUKE
	",input_ids
"LUKE
	",attention_mask
"LUKE
	",token_type_ids
"LUKE
	",position_ids
"LUKE
	",entity_ids
"LUKE
	",entity_attention_mask
"LUKE
	",entity_token_type_ids
"LUKE
	",entity_position_ids
"LUKE
	",inputs_embeds
"LUKE
	",head_mask
"LUKE
	",output_attentions
"LUKE
	",output_hidden_states
"LUKE
	",return_dict
"LUKE
	",labels
"LUKE
	",config
"LUKE
	",input_ids
"LUKE
	",attention_mask
"LUKE
	",token_type_ids
"LUKE
	",position_ids
"LUKE
	",entity_ids
"LUKE
	",entity_attention_mask
"LUKE
	",entity_token_type_ids
"LUKE
	",entity_position_ids
"LUKE
	",inputs_embeds
"LUKE
	",head_mask
"LUKE
	",output_attentions
"LUKE
	",output_hidden_states
"LUKE
	",return_dict
"LUKE
	",labels
"LUKE
	",config
"LUKE
	",input_ids
"LUKE
	",attention_mask
"LUKE
	",token_type_ids
"LUKE
	",position_ids
"LUKE
	",entity_ids
"LUKE
	",entity_attention_mask
"LUKE
	",entity_token_type_ids
"LUKE
	",entity_position_ids
"LUKE
	",inputs_embeds
"LUKE
	",head_mask
"LUKE
	",output_attentions
"LUKE
	",output_hidden_states
"LUKE
	",return_dict
"LUKE
	",labels
"LUKE
	",config
"LUKE
	",input_ids
"LUKE
	",attention_mask
"LUKE
	",token_type_ids
"LUKE
	",position_ids
"LUKE
	",entity_ids
"LUKE
	",entity_attention_mask
"LUKE
	",entity_token_type_ids
"LUKE
	",entity_position_ids
"LUKE
	",inputs_embeds
"LUKE
	",head_mask
"LUKE
	",output_attentions
"LUKE
	",output_hidden_states
"LUKE
	",return_dict
"LUKE
	",start_positions
"LUKE
	",end_positions
"LongT5
	",vocab_size
"LongT5
	",d_model
"LongT5
	",d_kv
"LongT5
	",d_ff
"LongT5
	",num_layers
"LongT5
	",num_decoder_layers
"LongT5
	",num_heads
"LongT5
	",local_radius
"LongT5
	",global_block_size
"LongT5
	",relative_attention_num_buckets
"LongT5
	",relative_attention_max_distance
"LongT5
	",dropout_rate
"LongT5
	",layer_norm_eps
"LongT5
	",initializer_factor
"LongT5
	",feed_forward_proj
"LongT5
	",encoder_attention_type
"LongT5
	",use_cache
"LongT5
	",config
"LongT5
	",input_ids
"LongT5
	",attention_mask
"LongT5
	",decoder_input_ids
"LongT5
	",decoder_attention_mask
"LongT5
	",head_mask
"LongT5
	",decoder_head_mask
"LongT5
	",cross_attn_head_mask
"LongT5
	",encoder_outputs
"LongT5
	",past_key_values
"LongT5
	",inputs_embeds
"LongT5
	",decoder_inputs_embeds
"LongT5
	",use_cache
"LongT5
	",output_attentions
"LongT5
	",output_hidden_states
"LongT5
	",return_dict
"LongT5
	",config
"LongT5
	",input_ids
"LongT5
	",attention_mask
"LongT5
	",decoder_input_ids
"LongT5
	",decoder_attention_mask
"LongT5
	",head_mask
"LongT5
	",decoder_head_mask
"LongT5
	",cross_attn_head_mask
"LongT5
	",encoder_outputs
"LongT5
	",past_key_values
"LongT5
	",inputs_embeds
"LongT5
	",decoder_inputs_embeds
"LongT5
	",use_cache
"LongT5
	",output_attentions
"LongT5
	",output_hidden_states
"LongT5
	",return_dict
"LongT5
	",labels
"LongT5
	",config
"LongT5
	",input_ids
"LongT5
	",attention_mask
"LongT5
	",head_mask
"LongT5
	",inputs_embeds
"LongT5
	",output_attentions
"LongT5
	",output_hidden_states
"LongT5
	",return_dict
"LongT5
	",input_ids
"LongT5
	",attention_mask
"LongT5
	",decoder_input_ids
"LongT5
	",decoder_attention_mask
"LongT5
	",encoder_outputs
"LongT5
	",past_key_values
"LongT5
	",input_ids
"LongT5
	",attention_mask
"LongT5
	",output_attentions
"LongT5
	",output_hidden_states
"LongT5
	",return_dict
"LongT5
	",decoder_input_ids
"LongT5
	",encoder_outputs
"LongT5
	",encoder_attention_mask
"LongT5
	",decoder_attention_mask
"LongT5
	",past_key_values
"LongT5
	",output_attentions
"LongT5
	",output_hidden_states
"LongT5
	",return_dict
"LongT5
	",input_ids
"LongT5
	",attention_mask
"LongT5
	",decoder_input_ids
"LongT5
	",decoder_attention_mask
"LongT5
	",encoder_outputs
"LongT5
	",past_key_values
"LongT5
	",input_ids
"LongT5
	",attention_mask
"LongT5
	",output_attentions
"LongT5
	",output_hidden_states
"LongT5
	",return_dict
"LongT5
	",decoder_input_ids
"LongT5
	",encoder_outputs
"LongT5
	",encoder_attention_mask
"LongT5
	",decoder_attention_mask
"LongT5
	",past_key_values
"LongT5
	",output_attentions
"LongT5
	",output_hidden_states
"LongT5
	",return_dict
"Longformer
	",vocab_size
"Longformer
	",hidden_size
"Longformer
	",num_hidden_layers
"Longformer
	",num_attention_heads
"Longformer
	",intermediate_size
"Longformer
	",hidden_act
"Longformer
	",hidden_dropout_prob
"Longformer
	",attention_probs_dropout_prob
"Longformer
	",max_position_embeddings
"Longformer
	",type_vocab_size
"Longformer
	",initializer_range
"Longformer
	",layer_norm_eps
"Longformer
	",position_embedding_type
"Longformer
	",use_cache
"Longformer
	",classifier_dropout
"Longformer
	",attention_window
"Longformer
	",vocab_file
"Longformer
	",merges_file
"Longformer
	",errors
"Longformer
	",bos_token
"Longformer
	",eos_token
"Longformer
	",sep_token
"Longformer
	",cls_token
"Longformer
	",unk_token
"Longformer
	",pad_token
"Longformer
	",mask_token
"Longformer
	",add_prefix_space
"Longformer
	",token_ids_0
"Longformer
	",token_ids_1
"Longformer
	",token_ids_0
"Longformer
	",token_ids_1
"Longformer
	",token_ids_0
"Longformer
	",token_ids_1
"Longformer
	",already_has_special_tokens
"Longformer
	",last_hidden_state
"Longformer
	",hidden_states
"Longformer
	",attentions
"Longformer
	",global_attentions
"Longformer
	",last_hidden_state
"Longformer
	",pooler_output
"Longformer
	",hidden_states
"Longformer
	",attentions
"Longformer
	",global_attentions
"Longformer
	",loss
"Longformer
	",logits
"Longformer
	",hidden_states
"Longformer
	",attentions
"Longformer
	",global_attentions
"Longformer
	",loss
"Longformer
	",start_logits
"Longformer
	",end_logits
"Longformer
	",hidden_states
"Longformer
	",attentions
"Longformer
	",global_attentions
"Longformer
	",loss
"Longformer
	",logits
"Longformer
	",hidden_states
"Longformer
	",attentions
"Longformer
	",global_attentions
"Longformer
	",loss
"Longformer
	",logits
"Longformer
	",hidden_states
"Longformer
	",attentions
"Longformer
	",global_attentions
"Longformer
	",loss
"Longformer
	",logits
"Longformer
	",hidden_states
"Longformer
	",attentions
"Longformer
	",global_attentions
"Longformer
	",last_hidden_state
"Longformer
	",hidden_states
"Longformer
	",attentions
"Longformer
	",global_attentions
"Longformer
	",last_hidden_state
"Longformer
	",pooler_output
"Longformer
	",hidden_states
"Longformer
	",attentions
"Longformer
	",global_attentions
"Longformer
	",loss
"Longformer
	",logits
"Longformer
	",hidden_states
"Longformer
	",attentions
"Longformer
	",global_attentions
"Longformer
	",loss
"Longformer
	",start_logits
"Longformer
	",end_logits
"Longformer
	",hidden_states
"Longformer
	",attentions
"Longformer
	",global_attentions
"Longformer
	",loss
"Longformer
	",logits
"Longformer
	",hidden_states
"Longformer
	",attentions
"Longformer
	",global_attentions
"Longformer
	",loss
"Longformer
	",logits
"Longformer
	",hidden_states
"Longformer
	",attentions
"Longformer
	",global_attentions
"Longformer
	",loss
"Longformer
	",logits
"Longformer
	",hidden_states
"Longformer
	",attentions
"Longformer
	",global_attentions
"Longformer
	",config
"Longformer
	",input_ids
"Longformer
	",attention_mask
"Longformer
	",global_attention_mask
"Longformer
	",head_mask
"Longformer
	",decoder_head_mask
"Longformer
	",token_type_ids
"Longformer
	",position_ids
"Longformer
	",inputs_embeds
"Longformer
	",output_attentions
"Longformer
	",output_hidden_states
"Longformer
	",return_dict
"Longformer
	",config
"Longformer
	",input_ids
"Longformer
	",attention_mask
"Longformer
	",global_attention_mask
"Longformer
	",head_mask
"Longformer
	",decoder_head_mask
"Longformer
	",token_type_ids
"Longformer
	",position_ids
"Longformer
	",inputs_embeds
"Longformer
	",output_attentions
"Longformer
	",output_hidden_states
"Longformer
	",return_dict
"Longformer
	",labels
"Longformer
	",kwargs
"Longformer
	",config
"Longformer
	",input_ids
"Longformer
	",attention_mask
"Longformer
	",global_attention_mask
"Longformer
	",head_mask
"Longformer
	",decoder_head_mask
"Longformer
	",token_type_ids
"Longformer
	",position_ids
"Longformer
	",inputs_embeds
"Longformer
	",output_attentions
"Longformer
	",output_hidden_states
"Longformer
	",return_dict
"Longformer
	",labels
"Longformer
	",config
"Longformer
	",input_ids
"Longformer
	",attention_mask
"Longformer
	",global_attention_mask
"Longformer
	",head_mask
"Longformer
	",decoder_head_mask
"Longformer
	",token_type_ids
"Longformer
	",position_ids
"Longformer
	",inputs_embeds
"Longformer
	",output_attentions
"Longformer
	",output_hidden_states
"Longformer
	",return_dict
"Longformer
	",labels
"Longformer
	",config
"Longformer
	",input_ids
"Longformer
	",attention_mask
"Longformer
	",global_attention_mask
"Longformer
	",head_mask
"Longformer
	",decoder_head_mask
"Longformer
	",token_type_ids
"Longformer
	",position_ids
"Longformer
	",inputs_embeds
"Longformer
	",output_attentions
"Longformer
	",output_hidden_states
"Longformer
	",return_dict
"Longformer
	",labels
"Longformer
	",config
"Longformer
	",input_ids
"Longformer
	",attention_mask
"Longformer
	",global_attention_mask
"Longformer
	",head_mask
"Longformer
	",decoder_head_mask
"Longformer
	",token_type_ids
"Longformer
	",position_ids
"Longformer
	",inputs_embeds
"Longformer
	",output_attentions
"Longformer
	",output_hidden_states
"Longformer
	",return_dict
"Longformer
	",start_positions
"Longformer
	",end_positions
"Longformer
	",config
"Longformer
	",input_ids
"Longformer
	",attention_mask
"Longformer
	",head_mask
"Longformer
	",global_attention_mask
"Longformer
	",token_type_ids
"Longformer
	",position_ids
"Longformer
	",inputs_embeds
"Longformer
	",output_attentions
"Longformer
	",output_hidden_states
"Longformer
	",return_dict
"Longformer
	",training
"Longformer
	",config
"Longformer
	",input_ids
"Longformer
	",attention_mask
"Longformer
	",head_mask
"Longformer
	",global_attention_mask
"Longformer
	",token_type_ids
"Longformer
	",position_ids
"Longformer
	",inputs_embeds
"Longformer
	",output_attentions
"Longformer
	",output_hidden_states
"Longformer
	",return_dict
"Longformer
	",training
"Longformer
	",labels
"Longformer
	",config
"Longformer
	",input_ids
"Longformer
	",attention_mask
"Longformer
	",head_mask
"Longformer
	",global_attention_mask
"Longformer
	",token_type_ids
"Longformer
	",position_ids
"Longformer
	",inputs_embeds
"Longformer
	",output_attentions
"Longformer
	",output_hidden_states
"Longformer
	",return_dict
"Longformer
	",training
"Longformer
	",start_positions
"Longformer
	",end_positions
"Longformer
	",config
"Longformer
	",input_ids
"Longformer
	",attention_mask
"Longformer
	",head_mask
"Longformer
	",global_attention_mask
"Longformer
	",token_type_ids
"Longformer
	",position_ids
"Longformer
	",inputs_embeds
"Longformer
	",output_attentions
"Longformer
	",output_hidden_states
"Longformer
	",return_dict
"Longformer
	",training
"Longformer
	",config
"Longformer
	",input_ids
"Longformer
	",attention_mask
"Longformer
	",head_mask
"Longformer
	",global_attention_mask
"Longformer
	",token_type_ids
"Longformer
	",position_ids
"Longformer
	",inputs_embeds
"Longformer
	",output_attentions
"Longformer
	",output_hidden_states
"Longformer
	",return_dict
"Longformer
	",training
"Longformer
	",labels
"Longformer
	",config
"Longformer
	",input_ids
"Longformer
	",attention_mask
"Longformer
	",head_mask
"Longformer
	",global_attention_mask
"Longformer
	",token_type_ids
"Longformer
	",position_ids
"Longformer
	",inputs_embeds
"Longformer
	",output_attentions
"Longformer
	",output_hidden_states
"Longformer
	",return_dict
"Longformer
	",training
"Longformer
	",labels
"LED
	",vocab_size
"LED
	",d_model
"LED
	",encoder_layers
"LED
	",decoder_layers
"LED
	",encoder_attention_heads
"LED
	",decoder_attention_heads
"LED
	",decoder_ffn_dim
"LED
	",encoder_ffn_dim
"LED
	",activation_function
"LED
	",dropout
"LED
	",attention_dropout
"LED
	",activation_dropout
"LED
	",classifier_dropout
"LED
	",max_encoder_position_embeddings
"LED
	",max_decoder_position_embeddings
"LED
	",init_std
"LED
	",encoder_layerdrop
"LED
	",decoder_layerdrop
"LED
	",use_cache
"LED
	",vocab_file
"LED
	",merges_file
"LED
	",errors
"LED
	",bos_token
"LED
	",eos_token
"LED
	",sep_token
"LED
	",cls_token
"LED
	",unk_token
"LED
	",pad_token
"LED
	",mask_token
"LED
	",add_prefix_space
"LED
	",token_ids_0
"LED
	",token_ids_1
"LED
	",token_ids_0
"LED
	",token_ids_1
"LED
	",already_has_special_tokens
"LED
	",token_ids_0
"LED
	",token_ids_1
"LED
	",vocab_file
"LED
	",merges_file
"LED
	",errors
"LED
	",bos_token
"LED
	",eos_token
"LED
	",sep_token
"LED
	",cls_token
"LED
	",unk_token
"LED
	",pad_token
"LED
	",mask_token
"LED
	",add_prefix_space
"LED
	",trim_offsets
"LED
	",token_ids_0
"LED
	",token_ids_1
"LED
	",last_hidden_state
"LED
	",hidden_states
"LED
	",attentions
"LED
	",global_attentions
"LED
	",last_hidden_state
"LED
	",past_key_values
"LED
	",decoder_hidden_states
"LED
	",decoder_attentions
"LED
	",cross_attentions
"LED
	",encoder_last_hidden_state
"LED
	",encoder_hidden_states
"LED
	",encoder_attentions
"LED
	",encoder_global_attentions
"LED
	",loss
"LED
	",logits
"LED
	",past_key_values
"LED
	",decoder_hidden_states
"LED
	",decoder_attentions
"LED
	",cross_attentions
"LED
	",encoder_last_hidden_state
"LED
	",encoder_hidden_states
"LED
	",encoder_attentions
"LED
	",encoder_global_attentions
"LED
	",loss
"LED
	",logits
"LED
	",past_key_values
"LED
	",decoder_hidden_states
"LED
	",decoder_attentions
"LED
	",cross_attentions
"LED
	",encoder_last_hidden_state
"LED
	",encoder_hidden_states
"LED
	",encoder_attentions
"LED
	",encoder_global_attentions
"LED
	",loss
"LED
	",start_logits
"LED
	",end_logits
"LED
	",past_key_values
"LED
	",decoder_hidden_states
"LED
	",decoder_attentions
"LED
	",cross_attentions
"LED
	",encoder_last_hidden_state
"LED
	",encoder_hidden_states
"LED
	",encoder_attentions
"LED
	",encoder_global_attentions
"LED
	",last_hidden_state
"LED
	",hidden_states
"LED
	",attentions
"LED
	",global_attentions
"LED
	",last_hidden_state
"LED
	",past_key_values
"LED
	",decoder_hidden_states
"LED
	",decoder_attentions
"LED
	",cross_attentions
"LED
	",encoder_last_hidden_state
"LED
	",encoder_hidden_states
"LED
	",encoder_attentions
"LED
	",encoder_global_attentions
"LED
	",loss
"LED
	",logits
"LED
	",past_key_values
"LED
	",decoder_hidden_states
"LED
	",decoder_attentions
"LED
	",cross_attentions
"LED
	",encoder_last_hidden_state
"LED
	",encoder_hidden_states
"LED
	",encoder_attentions
"LED
	",encoder_global_attentions
"LED
	",config
"LED
	",input_ids
"LED
	",attention_mask
"LED
	",decoder_input_ids
"LED
	",decoder_attention_mask
"LED
	",global_attention_mask
"LED
	",head_mask
"LED
	",decoder_head_mask
"LED
	",cross_attn_head_mask
"LED
	",encoder_outputs
"LED
	",past_key_values
"LED
	",inputs_embeds
"LED
	",decoder_inputs_embeds
"LED
	",use_cache
"LED
	",output_attentions
"LED
	",output_hidden_states
"LED
	",return_dict
"LED
	",config
"LED
	",input_ids
"LED
	",attention_mask
"LED
	",decoder_input_ids
"LED
	",decoder_attention_mask
"LED
	",global_attention_mask
"LED
	",head_mask
"LED
	",decoder_head_mask
"LED
	",cross_attn_head_mask
"LED
	",encoder_outputs
"LED
	",past_key_values
"LED
	",inputs_embeds
"LED
	",decoder_inputs_embeds
"LED
	",use_cache
"LED
	",output_attentions
"LED
	",output_hidden_states
"LED
	",return_dict
"LED
	",labels
"LED
	",config
"LED
	",input_ids
"LED
	",attention_mask
"LED
	",decoder_input_ids
"LED
	",decoder_attention_mask
"LED
	",global_attention_mask
"LED
	",head_mask
"LED
	",decoder_head_mask
"LED
	",cross_attn_head_mask
"LED
	",encoder_outputs
"LED
	",past_key_values
"LED
	",inputs_embeds
"LED
	",decoder_inputs_embeds
"LED
	",use_cache
"LED
	",output_attentions
"LED
	",output_hidden_states
"LED
	",return_dict
"LED
	",labels
"LED
	",config
"LED
	",input_ids
"LED
	",attention_mask
"LED
	",decoder_input_ids
"LED
	",decoder_attention_mask
"LED
	",global_attention_mask
"LED
	",head_mask
"LED
	",decoder_head_mask
"LED
	",cross_attn_head_mask
"LED
	",encoder_outputs
"LED
	",past_key_values
"LED
	",inputs_embeds
"LED
	",decoder_inputs_embeds
"LED
	",use_cache
"LED
	",output_attentions
"LED
	",output_hidden_states
"LED
	",return_dict
"LED
	",start_positions
"LED
	",end_positions
"LED
	",config
"LED
	",input_ids
"LED
	",attention_mask
"LED
	",decoder_input_ids
"LED
	",decoder_attention_mask
"LED
	",head_mask
"LED
	",decoder_head_mask
"LED
	",encoder_outputs
"LED
	",past_key_values
"LED
	",use_cache
"LED
	",output_attentions
"LED
	",output_hidden_states
"LED
	",return_dict
"LED
	",training
"LED
	",config
"LED
	",input_ids
"LED
	",attention_mask
"LED
	",decoder_input_ids
"LED
	",decoder_attention_mask
"LED
	",head_mask
"LED
	",decoder_head_mask
"LED
	",encoder_outputs
"LED
	",past_key_values
"LED
	",use_cache
"LED
	",output_attentions
"LED
	",output_hidden_states
"LED
	",return_dict
"LED
	",training
"LayoutLM
	",vocab_size
"LayoutLM
	",hidden_size
"LayoutLM
	",num_hidden_layers
"LayoutLM
	",num_attention_heads
"LayoutLM
	",intermediate_size
"LayoutLM
	",hidden_act
"LayoutLM
	",hidden_dropout_prob
"LayoutLM
	",attention_probs_dropout_prob
"LayoutLM
	",max_position_embeddings
"LayoutLM
	",type_vocab_size
"LayoutLM
	",initializer_range
"LayoutLM
	",layer_norm_eps
"LayoutLM
	",max_2d_position_embeddings
"LayoutLM
	",config
"LayoutLM
	",input_ids
"LayoutLM
	",bbox
"LayoutLM
	",attention_mask
"LayoutLM
	",token_type_ids
"LayoutLM
	",position_ids
"LayoutLM
	",head_mask
"LayoutLM
	",not masked
"LayoutLM
	",masked
"LayoutLM
	",inputs_embeds
"LayoutLM
	",output_attentions
"LayoutLM
	",output_hidden_states
"LayoutLM
	",return_dict
"LayoutLM
	",config
"LayoutLM
	",input_ids
"LayoutLM
	",bbox
"LayoutLM
	",attention_mask
"LayoutLM
	",token_type_ids
"LayoutLM
	",position_ids
"LayoutLM
	",head_mask
"LayoutLM
	",not masked
"LayoutLM
	",masked
"LayoutLM
	",inputs_embeds
"LayoutLM
	",output_attentions
"LayoutLM
	",output_hidden_states
"LayoutLM
	",return_dict
"LayoutLM
	",labels
"LayoutLM
	",config
"LayoutLM
	",input_ids
"LayoutLM
	",bbox
"LayoutLM
	",attention_mask
"LayoutLM
	",token_type_ids
"LayoutLM
	",position_ids
"LayoutLM
	",head_mask
"LayoutLM
	",not masked
"LayoutLM
	",masked
"LayoutLM
	",inputs_embeds
"LayoutLM
	",output_attentions
"LayoutLM
	",output_hidden_states
"LayoutLM
	",return_dict
"LayoutLM
	",labels
"LayoutLM
	",config
"LayoutLM
	",input_ids
"LayoutLM
	",bbox
"LayoutLM
	",attention_mask
"LayoutLM
	",token_type_ids
"LayoutLM
	",position_ids
"LayoutLM
	",head_mask
"LayoutLM
	",not masked
"LayoutLM
	",masked
"LayoutLM
	",inputs_embeds
"LayoutLM
	",output_attentions
"LayoutLM
	",output_hidden_states
"LayoutLM
	",return_dict
"LayoutLM
	",labels
"LayoutLM
	",config
"LayoutLM
	",config
"LayoutLM
	",input_ids
"LayoutLM
	",bbox
"LayoutLM
	",attention_mask
"LayoutLM
	",token_type_ids
"LayoutLM
	",position_ids
"LayoutLM
	",head_mask
"LayoutLM
	",inputs_embeds
"LayoutLM
	",output_attentions
"LayoutLM
	",output_hidden_states
"LayoutLM
	",return_dict
"LayoutLM
	",training
"LayoutLM
	",config
"LayoutLM
	",input_ids
"LayoutLM
	",bbox
"LayoutLM
	",attention_mask
"LayoutLM
	",token_type_ids
"LayoutLM
	",position_ids
"LayoutLM
	",head_mask
"LayoutLM
	",inputs_embeds
"LayoutLM
	",output_attentions
"LayoutLM
	",output_hidden_states
"LayoutLM
	",return_dict
"LayoutLM
	",training
"LayoutLM
	",labels
"LayoutLM
	",config
"LayoutLM
	",input_ids
"LayoutLM
	",bbox
"LayoutLM
	",attention_mask
"LayoutLM
	",token_type_ids
"LayoutLM
	",position_ids
"LayoutLM
	",head_mask
"LayoutLM
	",inputs_embeds
"LayoutLM
	",output_attentions
"LayoutLM
	",output_hidden_states
"LayoutLM
	",return_dict
"LayoutLM
	",training
"LayoutLM
	",labels
"LayoutLM
	",config
"LayoutLM
	",input_ids
"LayoutLM
	",bbox
"LayoutLM
	",attention_mask
"LayoutLM
	",token_type_ids
"LayoutLM
	",position_ids
"LayoutLM
	",head_mask
"LayoutLM
	",inputs_embeds
"LayoutLM
	",output_attentions
"LayoutLM
	",output_hidden_states
"LayoutLM
	",return_dict
"LayoutLM
	",training
"LayoutLM
	",labels
"LayoutLM
	",config
"LayoutLM
	",input_ids
"LayoutLM
	",bbox
"LayoutLM
	",attention_mask
"LayoutLM
	",token_type_ids
"LayoutLM
	",position_ids
"LayoutLM
	",head_mask
"LayoutLM
	",inputs_embeds
"LayoutLM
	",output_attentions
"LayoutLM
	",output_hidden_states
"LayoutLM
	",return_dict
"LayoutLM
	",training
"LayoutLM
	",start_positions
"LayoutLM
	",end_positions
"I-BERT
	",vocab_size
"I-BERT
	",hidden_size
"I-BERT
	",num_hidden_layers
"I-BERT
	",num_attention_heads
"I-BERT
	",intermediate_size
"I-BERT
	",hidden_act
"I-BERT
	",hidden_dropout_prob
"I-BERT
	",attention_probs_dropout_prob
"I-BERT
	",max_position_embeddings
"I-BERT
	",type_vocab_size
"I-BERT
	",initializer_range
"I-BERT
	",layer_norm_eps
"I-BERT
	",position_embedding_type
"I-BERT
	",quant_mode
"I-BERT
	",force_dequant
"I-BERT
	",config
"I-BERT
	",input_ids
"I-BERT
	",attention_mask
"I-BERT
	",token_type_ids
"I-BERT
	",position_ids
"I-BERT
	",head_mask
"I-BERT
	",inputs_embeds
"I-BERT
	",output_attentions
"I-BERT
	",output_hidden_states
"I-BERT
	",return_dict
"I-BERT
	",config
"I-BERT
	",input_ids
"I-BERT
	",attention_mask
"I-BERT
	",token_type_ids
"I-BERT
	",position_ids
"I-BERT
	",head_mask
"I-BERT
	",inputs_embeds
"I-BERT
	",output_attentions
"I-BERT
	",output_hidden_states
"I-BERT
	",return_dict
"I-BERT
	",labels
"I-BERT
	",kwargs
"I-BERT
	",config
"I-BERT
	",input_ids
"I-BERT
	",attention_mask
"I-BERT
	",token_type_ids
"I-BERT
	",position_ids
"I-BERT
	",head_mask
"I-BERT
	",inputs_embeds
"I-BERT
	",output_attentions
"I-BERT
	",output_hidden_states
"I-BERT
	",return_dict
"I-BERT
	",labels
"I-BERT
	",config
"I-BERT
	",input_ids
"I-BERT
	",attention_mask
"I-BERT
	",token_type_ids
"I-BERT
	",position_ids
"I-BERT
	",head_mask
"I-BERT
	",inputs_embeds
"I-BERT
	",output_attentions
"I-BERT
	",output_hidden_states
"I-BERT
	",return_dict
"I-BERT
	",labels
"I-BERT
	",config
"I-BERT
	",input_ids
"I-BERT
	",attention_mask
"I-BERT
	",token_type_ids
"I-BERT
	",position_ids
"I-BERT
	",head_mask
"I-BERT
	",inputs_embeds
"I-BERT
	",output_attentions
"I-BERT
	",output_hidden_states
"I-BERT
	",return_dict
"I-BERT
	",labels
"I-BERT
	",config
"I-BERT
	",input_ids
"I-BERT
	",attention_mask
"I-BERT
	",token_type_ids
"I-BERT
	",position_ids
"I-BERT
	",head_mask
"I-BERT
	",inputs_embeds
"I-BERT
	",output_attentions
"I-BERT
	",output_hidden_states
"I-BERT
	",return_dict
"I-BERT
	",start_positions
"I-BERT
	",end_positions
"HerBERT
	",token_ids_0
"HerBERT
	",token_ids_1
"HerBERT
	",token_ids_0
"HerBERT
	",token_ids_1
"HerBERT
	",token_ids_0
"HerBERT
	",token_ids_1
"HerBERT
	",already_has_special_tokens
"HerBERT
	",vocab_file
"HerBERT
	",merges_file
"HerBERT
	",token_ids_0
"HerBERT
	",token_ids_1
"HerBERT
	",token_ids_0
"HerBERT
	",token_ids_1
"HerBERT
	",token_ids_0
"HerBERT
	",token_ids_1
"HerBERT
	",already_has_special_tokens
"GPT-J
	",vocab_size
"GPT-J
	",n_positions
"GPT-J
	",n_embd
"GPT-J
	",n_layer
"GPT-J
	",n_head
"GPT-J
	",rotary_dim
"GPT-J
	",n_inner
"GPT-J
	",activation_function
"GPT-J
	",resid_pdrop
"GPT-J
	",embd_pdrop
"GPT-J
	",attn_pdrop
"GPT-J
	",layer_norm_epsilon
"GPT-J
	",initializer_range
"GPT-J
	",scale_attn_weights
"GPT-J
	",use_cache
"GPT-J
	",config
"GPT-J
	",input_ids
"GPT-J
	",attention_mask
"GPT-J
	",token_type_ids
"GPT-J
	",position_ids
"GPT-J
	",head_mask
"GPT-J
	",inputs_embeds
"GPT-J
	",output_attentions
"GPT-J
	",output_hidden_states
"GPT-J
	",return_dict
"GPT-J
	",config
"GPT-J
	",input_ids
"GPT-J
	",attention_mask
"GPT-J
	",token_type_ids
"GPT-J
	",position_ids
"GPT-J
	",head_mask
"GPT-J
	",inputs_embeds
"GPT-J
	",output_attentions
"GPT-J
	",output_hidden_states
"GPT-J
	",return_dict
"GPT-J
	",labels
"GPT-J
	",are shifted
"GPT-J
	",config
"GPT-J
	",input_ids
"GPT-J
	",attention_mask
"GPT-J
	",token_type_ids
"GPT-J
	",position_ids
"GPT-J
	",head_mask
"GPT-J
	",inputs_embeds
"GPT-J
	",output_attentions
"GPT-J
	",output_hidden_states
"GPT-J
	",return_dict
"GPT-J
	",labels
"GPT-J
	",config
"GPT-J
	",input_ids
"GPT-J
	",attention_mask
"GPT-J
	",token_type_ids
"GPT-J
	",position_ids
"GPT-J
	",head_mask
"GPT-J
	",inputs_embeds
"GPT-J
	",output_attentions
"GPT-J
	",output_hidden_states
"GPT-J
	",return_dict
"GPT-J
	",start_positions
"GPT-J
	",end_positions
"GPT-J
	",config
"GPT-J
	",input_ids
"GPT-J
	",past_key_values
"GPT-J
	",attention_mask
"GPT-J
	",token_type_ids
"GPT-J
	",position_ids
"GPT-J
	",head_mask
"GPT-J
	",inputs_embeds
"GPT-J
	",output_attentions
"GPT-J
	",output_hidden_states
"GPT-J
	",return_dict
"GPT-J
	",training
"GPT-J
	",use_cache
"GPT-J
	",config
"GPT-J
	",input_ids
"GPT-J
	",past_key_values
"GPT-J
	",attention_mask
"GPT-J
	",token_type_ids
"GPT-J
	",position_ids
"GPT-J
	",head_mask
"GPT-J
	",inputs_embeds
"GPT-J
	",output_attentions
"GPT-J
	",output_hidden_states
"GPT-J
	",return_dict
"GPT-J
	",training
"GPT-J
	",labels
"GPT-J
	",are shifted
"GPT-J
	",config
"GPT-J
	",input_ids
"GPT-J
	",past_key_values
"GPT-J
	",attention_mask
"GPT-J
	",token_type_ids
"GPT-J
	",position_ids
"GPT-J
	",head_mask
"GPT-J
	",inputs_embeds
"GPT-J
	",output_attentions
"GPT-J
	",output_hidden_states
"GPT-J
	",return_dict
"GPT-J
	",training
"GPT-J
	",labels
"GPT-J
	",config
"GPT-J
	",input_ids
"GPT-J
	",past_key_values
"GPT-J
	",attention_mask
"GPT-J
	",token_type_ids
"GPT-J
	",position_ids
"GPT-J
	",head_mask
"GPT-J
	",inputs_embeds
"GPT-J
	",output_attentions
"GPT-J
	",output_hidden_states
"GPT-J
	",return_dict
"GPT-J
	",training
"GPT-J
	",start_positions
"GPT-J
	",end_positions
"GPT-J
	",config
"GPT-J
	",dtype
"GPT-J
	",input_ids
"GPT-J
	",attention_mask
"GPT-J
	",position_ids
"GPT-J
	",past_key_values
"GPT-J
	",output_attentions
"GPT-J
	",output_hidden_states
"GPT-J
	",return_dict
"GPT-J
	",config
"GPT-J
	",dtype
"GPT-J
	",input_ids
"GPT-J
	",attention_mask
"GPT-J
	",position_ids
"GPT-J
	",past_key_values
"GPT-J
	",output_attentions
"GPT-J
	",output_hidden_states
"GPT-J
	",return_dict
"GPT-NeoX-Japanese
	",vocab_size
"GPT-NeoX-Japanese
	",hidden_size
"GPT-NeoX-Japanese
	",num_hidden_layers
"GPT-NeoX-Japanese
	",num_attention_heads
"GPT-NeoX-Japanese
	",intermediate_multiple_size
"GPT-NeoX-Japanese
	",hidden_act
"GPT-NeoX-Japanese
	",rotary_pct
"GPT-NeoX-Japanese
	",rotary_emb_base
"GPT-NeoX-Japanese
	",max_position_embeddings
"GPT-NeoX-Japanese
	",initializer_range
"GPT-NeoX-Japanese
	",layer_norm_eps
"GPT-NeoX-Japanese
	",use_cache
"GPT-NeoX-Japanese
	",weight_tying
"GPT-NeoX-Japanese
	",attention_dropout
"GPT-NeoX-Japanese
	",hidden_dropout
"GPT-NeoX-Japanese
	",vocab_file
"GPT-NeoX-Japanese
	",emoji_file
"GPT-NeoX-Japanese
	",unk_token
"GPT-NeoX-Japanese
	",pad_token
"GPT-NeoX-Japanese
	",bos_token
"GPT-NeoX-Japanese
	",eos_token
"GPT-NeoX-Japanese
	",do_clean_text
"GPT-NeoX-Japanese
	",config
"GPT-NeoX-Japanese
	",input_ids
"GPT-NeoX-Japanese
	",attention_mask
"GPT-NeoX-Japanese
	",token_type_ids
"GPT-NeoX-Japanese
	",position_ids
"GPT-NeoX-Japanese
	",head_mask
"GPT-NeoX-Japanese
	",inputs_embeds
"GPT-NeoX-Japanese
	",output_attentions
"GPT-NeoX-Japanese
	",output_hidden_states
"GPT-NeoX-Japanese
	",return_dict
"GPT-NeoX-Japanese
	",past_key_values
"GPT-NeoX-Japanese
	",use_cache
"GPT-NeoX-Japanese
	",config
"GPT-NeoX-Japanese
	",input_ids
"GPT-NeoX-Japanese
	",attention_mask
"GPT-NeoX-Japanese
	",token_type_ids
"GPT-NeoX-Japanese
	",position_ids
"GPT-NeoX-Japanese
	",head_mask
"GPT-NeoX-Japanese
	",inputs_embeds
"GPT-NeoX-Japanese
	",output_attentions
"GPT-NeoX-Japanese
	",output_hidden_states
"GPT-NeoX-Japanese
	",return_dict
"GPT-NeoX-Japanese
	",past_key_values
"GPT-NeoX-Japanese
	",labels
"GPT-NeoX-Japanese
	",use_cache
"GPT-NeoX
	",vocab_size
"GPT-NeoX
	",hidden_size
"GPT-NeoX
	",num_hidden_layers
"GPT-NeoX
	",num_attention_heads
"GPT-NeoX
	",intermediate_size
"GPT-NeoX
	",hidden_act
"GPT-NeoX
	",rotary_pct
"GPT-NeoX
	",rotary_emb_base
"GPT-NeoX
	",max_position_embeddings
"GPT-NeoX
	",initializer_range
"GPT-NeoX
	",layer_norm_eps
"GPT-NeoX
	",use_cache
"GPT-NeoX
	",use_parallel_residual
"GPT-NeoX
	",vocab_file
"GPT-NeoX
	",merges_file
"GPT-NeoX
	",errors
"GPT-NeoX
	",unk_token
"GPT-NeoX
	",bos_token
"GPT-NeoX
	",eos_token
"GPT-NeoX
	",add_prefix_space
"GPT-NeoX
	",trim_offsets
"GPT-NeoX
	",config
"GPT-NeoX
	",input_ids
"GPT-NeoX
	",attention_mask
"GPT-NeoX
	",token_type_ids
"GPT-NeoX
	",position_ids
"GPT-NeoX
	",head_mask
"GPT-NeoX
	",inputs_embeds
"GPT-NeoX
	",output_attentions
"GPT-NeoX
	",output_hidden_states
"GPT-NeoX
	",return_dict
"GPT-NeoX
	",past_key_values
"GPT-NeoX
	",use_cache
"GPT-NeoX
	",config
"GPT-NeoX
	",input_ids
"GPT-NeoX
	",attention_mask
"GPT-NeoX
	",token_type_ids
"GPT-NeoX
	",position_ids
"GPT-NeoX
	",head_mask
"GPT-NeoX
	",inputs_embeds
"GPT-NeoX
	",output_attentions
"GPT-NeoX
	",output_hidden_states
"GPT-NeoX
	",return_dict
"GPT-NeoX
	",past_key_values
"GPT-NeoX
	",labels
"GPT-NeoX
	",use_cache
"GPT Neo
	",vocab_size
"GPT Neo
	",attention_types
"GPT Neo
	",hidden_size
"GPT Neo
	",num_layers
"GPT Neo
	",num_heads
"GPT Neo
	",intermediate_size
"GPT Neo
	",activation_function
"GPT Neo
	",embed_dropout
"GPT Neo
	",attention_dropout
"GPT Neo
	",max_position_embeddings
"GPT Neo
	",type_vocab_size
"GPT Neo
	",initializer_range
"GPT Neo
	",layer_norm_epsilon
"GPT Neo
	",use_cache
"GPT Neo
	",config
"GPT Neo
	",input_ids
"GPT Neo
	",past_key_values
"GPT Neo
	",attention_mask
"GPT Neo
	",token_type_ids
"GPT Neo
	",position_ids
"GPT Neo
	",head_mask
"GPT Neo
	",inputs_embeds
"GPT Neo
	",use_cache
"GPT Neo
	",output_attentions
"GPT Neo
	",output_hidden_states
"GPT Neo
	",return_dict
"GPT Neo
	",config
"GPT Neo
	",input_ids
"GPT Neo
	",past_key_values
"GPT Neo
	",attention_mask
"GPT Neo
	",token_type_ids
"GPT Neo
	",position_ids
"GPT Neo
	",head_mask
"GPT Neo
	",inputs_embeds
"GPT Neo
	",use_cache
"GPT Neo
	",output_attentions
"GPT Neo
	",output_hidden_states
"GPT Neo
	",return_dict
"GPT Neo
	",labels
"GPT Neo
	",are shifted
"GPT Neo
	",config
"GPT Neo
	",input_ids
"GPT Neo
	",past_key_values
"GPT Neo
	",attention_mask
"GPT Neo
	",token_type_ids
"GPT Neo
	",position_ids
"GPT Neo
	",head_mask
"GPT Neo
	",inputs_embeds
"GPT Neo
	",use_cache
"GPT Neo
	",output_attentions
"GPT Neo
	",output_hidden_states
"GPT Neo
	",return_dict
"GPT Neo
	",labels
"GPT Neo
	",config
"GPT Neo
	",dtype
"GPT Neo
	",input_ids
"GPT Neo
	",attention_mask
"GPT Neo
	",position_ids
"GPT Neo
	",past_key_values
"GPT Neo
	",output_attentions
"GPT Neo
	",output_hidden_states
"GPT Neo
	",return_dict
"GPT Neo
	",config
"GPT Neo
	",dtype
"GPT Neo
	",input_ids
"GPT Neo
	",attention_mask
"GPT Neo
	",position_ids
"GPT Neo
	",past_key_values
"GPT Neo
	",output_attentions
"GPT Neo
	",output_hidden_states
"GPT Neo
	",return_dict
"OpenAI GPT
	",vocab_size
"OpenAI GPT
	",n_positions
"OpenAI GPT
	",n_embd
"OpenAI GPT
	",n_layer
"OpenAI GPT
	",n_head
"OpenAI GPT
	",afn
"OpenAI GPT
	",resid_pdrop
"OpenAI GPT
	",embd_pdrop
"OpenAI GPT
	",attn_pdrop
"OpenAI GPT
	",layer_norm_epsilon
"OpenAI GPT
	",initializer_range
"OpenAI GPT
	",predict_special_tokens
"OpenAI GPT
	",summary_type
"OpenAI GPT
	",summary_use_proj
"OpenAI GPT
	",summary_activation
"OpenAI GPT
	",summary_proj_to_labels
"OpenAI GPT
	",summary_first_dropout
"OpenAI GPT
	",use_cache
"OpenAI GPT
	",vocab_file
"OpenAI GPT
	",merges_file
"OpenAI GPT
	",unk_token
"OpenAI GPT
	",vocab_file
"OpenAI GPT
	",merges_file
"OpenAI GPT
	",unk_token
"OpenAI GPT
	",loss
"OpenAI GPT
	",mc_loss
"OpenAI GPT
	",logits
"OpenAI GPT
	",mc_logits
"OpenAI GPT
	",hidden_states
"OpenAI GPT
	",attentions
"OpenAI GPT
	",logits
"OpenAI GPT
	",mc_logits
"OpenAI GPT
	",hidden_states
"OpenAI GPT
	",attentions
"OpenAI GPT
	",config
"OpenAI GPT
	",input_ids
"OpenAI GPT
	",attention_mask
"OpenAI GPT
	",token_type_ids
"OpenAI GPT
	",position_ids
"OpenAI GPT
	",head_mask
"OpenAI GPT
	",inputs_embeds
"OpenAI GPT
	",output_attentions
"OpenAI GPT
	",output_hidden_states
"OpenAI GPT
	",return_dict
"OpenAI GPT
	",config
"OpenAI GPT
	",input_ids
"OpenAI GPT
	",attention_mask
"OpenAI GPT
	",token_type_ids
"OpenAI GPT
	",position_ids
"OpenAI GPT
	",head_mask
"OpenAI GPT
	",inputs_embeds
"OpenAI GPT
	",output_attentions
"OpenAI GPT
	",output_hidden_states
"OpenAI GPT
	",return_dict
"OpenAI GPT
	",labels
"OpenAI GPT
	",are shifted
"OpenAI GPT
	",config
"OpenAI GPT
	",input_ids
"OpenAI GPT
	",attention_mask
"OpenAI GPT
	",token_type_ids
"OpenAI GPT
	",position_ids
"OpenAI GPT
	",head_mask
"OpenAI GPT
	",inputs_embeds
"OpenAI GPT
	",output_attentions
"OpenAI GPT
	",output_hidden_states
"OpenAI GPT
	",return_dict
"OpenAI GPT
	",mc_token_ids
"OpenAI GPT
	",labels
"OpenAI GPT
	",are shifted
"OpenAI GPT
	",mc_labels
"OpenAI GPT
	",config
"OpenAI GPT
	",input_ids
"OpenAI GPT
	",attention_mask
"OpenAI GPT
	",token_type_ids
"OpenAI GPT
	",position_ids
"OpenAI GPT
	",head_mask
"OpenAI GPT
	",inputs_embeds
"OpenAI GPT
	",output_attentions
"OpenAI GPT
	",output_hidden_states
"OpenAI GPT
	",return_dict
"OpenAI GPT
	",labels
"OpenAI GPT
	",config
"OpenAI GPT
	",input_ids
"OpenAI GPT
	",attention_mask
"OpenAI GPT
	",token_type_ids
"OpenAI GPT
	",position_ids
"OpenAI GPT
	",head_mask
"OpenAI GPT
	",inputs_embeds
"OpenAI GPT
	",output_attentions
"OpenAI GPT
	",output_hidden_states
"OpenAI GPT
	",return_dict
"OpenAI GPT
	",training
"OpenAI GPT
	",config
"OpenAI GPT
	",input_ids
"OpenAI GPT
	",attention_mask
"OpenAI GPT
	",token_type_ids
"OpenAI GPT
	",position_ids
"OpenAI GPT
	",head_mask
"OpenAI GPT
	",inputs_embeds
"OpenAI GPT
	",output_attentions
"OpenAI GPT
	",output_hidden_states
"OpenAI GPT
	",return_dict
"OpenAI GPT
	",training
"OpenAI GPT
	",labels
"OpenAI GPT
	",config
"OpenAI GPT
	",input_ids
"OpenAI GPT
	",attention_mask
"OpenAI GPT
	",token_type_ids
"OpenAI GPT
	",position_ids
"OpenAI GPT
	",head_mask
"OpenAI GPT
	",inputs_embeds
"OpenAI GPT
	",output_attentions
"OpenAI GPT
	",output_hidden_states
"OpenAI GPT
	",return_dict
"OpenAI GPT
	",training
"OpenAI GPT
	",mc_token_ids
"OpenAI GPT
	",config
"OpenAI GPT
	",input_ids
"OpenAI GPT
	",attention_mask
"OpenAI GPT
	",token_type_ids
"OpenAI GPT
	",position_ids
"OpenAI GPT
	",head_mask
"OpenAI GPT
	",inputs_embeds
"OpenAI GPT
	",output_attentions
"OpenAI GPT
	",output_hidden_states
"OpenAI GPT
	",return_dict
"OpenAI GPT
	",training
"OpenAI GPT
	",labels
"Funnel Transformer
	",vocab_size
"Funnel Transformer
	",block_sizes
"Funnel Transformer
	",block_repeats
"Funnel Transformer
	",num_decoder_layers
"Funnel Transformer
	",d_model
"Funnel Transformer
	",n_head
"Funnel Transformer
	",d_head
"Funnel Transformer
	",d_inner
"Funnel Transformer
	",hidden_act
"Funnel Transformer
	",hidden_dropout
"Funnel Transformer
	",attention_dropout
"Funnel Transformer
	",activation_dropout
"Funnel Transformer
	",max_position_embeddings
"Funnel Transformer
	",type_vocab_size
"Funnel Transformer
	",initializer_range
"Funnel Transformer
	",initializer_std
"Funnel Transformer
	",layer_norm_eps
"Funnel Transformer
	",pooling_type
"Funnel Transformer
	",attention_type
"Funnel Transformer
	",separate_cls
"Funnel Transformer
	",truncate_seq
"Funnel Transformer
	",pool_q_only
"Funnel Transformer
	",token_ids_0
"Funnel Transformer
	",token_ids_1
"Funnel Transformer
	",token_ids_0
"Funnel Transformer
	",token_ids_1
"Funnel Transformer
	",already_has_special_tokens
"Funnel Transformer
	",token_ids_0
"Funnel Transformer
	",token_ids_1
"Funnel Transformer
	",token_ids_0
"Funnel Transformer
	",token_ids_1
"Funnel Transformer
	",loss
"Funnel Transformer
	",logits
"Funnel Transformer
	",hidden_states
"Funnel Transformer
	",attentions
"Funnel Transformer
	",logits
"Funnel Transformer
	",hidden_states
"Funnel Transformer
	",attentions
"Funnel Transformer
	",config
"Funnel Transformer
	",input_ids
"Funnel Transformer
	",attention_mask
"Funnel Transformer
	",token_type_ids
"Funnel Transformer
	",inputs_embeds
"Funnel Transformer
	",output_attentions
"Funnel Transformer
	",output_hidden_states
"Funnel Transformer
	",return_dict
"Funnel Transformer
	",config
"Funnel Transformer
	",input_ids
"Funnel Transformer
	",attention_mask
"Funnel Transformer
	",token_type_ids
"Funnel Transformer
	",inputs_embeds
"Funnel Transformer
	",output_attentions
"Funnel Transformer
	",output_hidden_states
"Funnel Transformer
	",return_dict
"Funnel Transformer
	",input_ids
"Funnel Transformer
	",attention_mask
"Funnel Transformer
	",token_type_ids
"Funnel Transformer
	",inputs_embeds
"Funnel Transformer
	",output_attentions
"Funnel Transformer
	",output_hidden_states
"Funnel Transformer
	",return_dict
"Funnel Transformer
	",labels
"Funnel Transformer
	",config
"Funnel Transformer
	",input_ids
"Funnel Transformer
	",attention_mask
"Funnel Transformer
	",token_type_ids
"Funnel Transformer
	",inputs_embeds
"Funnel Transformer
	",output_attentions
"Funnel Transformer
	",output_hidden_states
"Funnel Transformer
	",return_dict
"Funnel Transformer
	",labels
"Funnel Transformer
	",config
"Funnel Transformer
	",input_ids
"Funnel Transformer
	",attention_mask
"Funnel Transformer
	",token_type_ids
"Funnel Transformer
	",inputs_embeds
"Funnel Transformer
	",output_attentions
"Funnel Transformer
	",output_hidden_states
"Funnel Transformer
	",return_dict
"Funnel Transformer
	",labels
"Funnel Transformer
	",config
"Funnel Transformer
	",input_ids
"Funnel Transformer
	",attention_mask
"Funnel Transformer
	",token_type_ids
"Funnel Transformer
	",inputs_embeds
"Funnel Transformer
	",output_attentions
"Funnel Transformer
	",output_hidden_states
"Funnel Transformer
	",return_dict
"Funnel Transformer
	",labels
"Funnel Transformer
	",config
"Funnel Transformer
	",input_ids
"Funnel Transformer
	",attention_mask
"Funnel Transformer
	",token_type_ids
"Funnel Transformer
	",inputs_embeds
"Funnel Transformer
	",output_attentions
"Funnel Transformer
	",output_hidden_states
"Funnel Transformer
	",return_dict
"Funnel Transformer
	",labels
"Funnel Transformer
	",config
"Funnel Transformer
	",input_ids
"Funnel Transformer
	",attention_mask
"Funnel Transformer
	",token_type_ids
"Funnel Transformer
	",inputs_embeds
"Funnel Transformer
	",output_attentions
"Funnel Transformer
	",output_hidden_states
"Funnel Transformer
	",return_dict
"Funnel Transformer
	",start_positions
"Funnel Transformer
	",end_positions
"Funnel Transformer
	",config
"Funnel Transformer
	",input_ids
"Funnel Transformer
	",attention_mask
"Funnel Transformer
	",token_type_ids
"Funnel Transformer
	",inputs_embeds
"Funnel Transformer
	",output_attentions
"Funnel Transformer
	",output_hidden_states
"Funnel Transformer
	",return_dict
"Funnel Transformer
	",training
"Funnel Transformer
	",config
"Funnel Transformer
	",input_ids
"Funnel Transformer
	",attention_mask
"Funnel Transformer
	",token_type_ids
"Funnel Transformer
	",inputs_embeds
"Funnel Transformer
	",output_attentions
"Funnel Transformer
	",output_hidden_states
"Funnel Transformer
	",return_dict
"Funnel Transformer
	",training
"Funnel Transformer
	",config
"Funnel Transformer
	",input_ids
"Funnel Transformer
	",attention_mask
"Funnel Transformer
	",token_type_ids
"Funnel Transformer
	",inputs_embeds
"Funnel Transformer
	",output_attentions
"Funnel Transformer
	",output_hidden_states
"Funnel Transformer
	",return_dict
"Funnel Transformer
	",training
"Funnel Transformer
	",config
"Funnel Transformer
	",input_ids
"Funnel Transformer
	",attention_mask
"Funnel Transformer
	",token_type_ids
"Funnel Transformer
	",inputs_embeds
"Funnel Transformer
	",output_attentions
"Funnel Transformer
	",output_hidden_states
"Funnel Transformer
	",return_dict
"Funnel Transformer
	",training
"Funnel Transformer
	",labels
"Funnel Transformer
	",config
"Funnel Transformer
	",input_ids
"Funnel Transformer
	",attention_mask
"Funnel Transformer
	",token_type_ids
"Funnel Transformer
	",inputs_embeds
"Funnel Transformer
	",output_attentions
"Funnel Transformer
	",output_hidden_states
"Funnel Transformer
	",return_dict
"Funnel Transformer
	",training
"Funnel Transformer
	",labels
"Funnel Transformer
	",config
"Funnel Transformer
	",input_ids
"Funnel Transformer
	",attention_mask
"Funnel Transformer
	",token_type_ids
"Funnel Transformer
	",inputs_embeds
"Funnel Transformer
	",output_attentions
"Funnel Transformer
	",output_hidden_states
"Funnel Transformer
	",return_dict
"Funnel Transformer
	",training
"Funnel Transformer
	",labels
"Funnel Transformer
	",config
"Funnel Transformer
	",input_ids
"Funnel Transformer
	",attention_mask
"Funnel Transformer
	",token_type_ids
"Funnel Transformer
	",inputs_embeds
"Funnel Transformer
	",output_attentions
"Funnel Transformer
	",output_hidden_states
"Funnel Transformer
	",return_dict
"Funnel Transformer
	",training
"Funnel Transformer
	",labels
"Funnel Transformer
	",config
"Funnel Transformer
	",input_ids
"Funnel Transformer
	",attention_mask
"Funnel Transformer
	",token_type_ids
"Funnel Transformer
	",inputs_embeds
"Funnel Transformer
	",output_attentions
"Funnel Transformer
	",output_hidden_states
"Funnel Transformer
	",return_dict
"Funnel Transformer
	",training
"Funnel Transformer
	",start_positions
"Funnel Transformer
	",end_positions
"FSMT
	",langs
"FSMT
	",src_vocab_size
"FSMT
	",tgt_vocab_size
"FSMT
	",d_model
"FSMT
	",encoder_layers
"FSMT
	",decoder_layers
"FSMT
	",encoder_attention_heads
"FSMT
	",decoder_attention_heads
"FSMT
	",decoder_ffn_dim
"FSMT
	",encoder_ffn_dim
"FSMT
	",activation_function
"FSMT
	",dropout
"FSMT
	",attention_dropout
"FSMT
	",activation_dropout
"FSMT
	",max_position_embeddings
"FSMT
	",init_std
"FSMT
	",scale_embedding
"FSMT
	",bos_token_id
"FSMT
	",pad_token_id
"FSMT
	",eos_token_id
"FSMT
	",decoder_start_token_id
"FSMT
	",encoder_layerdrop
"FSMT
	",decoder_layerdrop
"FSMT
	",is_encoder_decoder
"FSMT
	",tie_word_embeddings
"FSMT
	",num_beams
"FSMT
	",length_penalty
"FSMT
	",early_stopping
"FSMT
	",use_cache
"FSMT
	",forced_eos_token_id
"FSMT
	",langs
"FSMT
	",src_vocab_file
"FSMT
	",tgt_vocab_file
"FSMT
	",merges_file
"FSMT
	",do_lower_case
"FSMT
	",unk_token
"FSMT
	",bos_token
"FSMT
	",sep_token
"FSMT
	",pad_token
"FSMT
	",token_ids_0
"FSMT
	",token_ids_1
"FSMT
	",token_ids_0
"FSMT
	",token_ids_1
"FSMT
	",already_has_special_tokens
"FSMT
	",token_ids_0
"FSMT
	",token_ids_1
"FSMT
	",config
"FSMT
	",input_ids
"FSMT
	",attention_mask
"FSMT
	",decoder_input_ids
"FSMT
	",decoder_attention_mask
"FSMT
	",head_mask
"FSMT
	",decoder_head_mask
"FSMT
	",cross_attn_head_mask
"FSMT
	",encoder_outputs
"FSMT
	",past_key_values
"FSMT
	",use_cache
"FSMT
	",output_attentions
"FSMT
	",output_hidden_states
"FSMT
	",return_dict
"FSMT
	",config
"FSMT
	",input_ids
"FSMT
	",attention_mask
"FSMT
	",decoder_input_ids
"FSMT
	",decoder_attention_mask
"FSMT
	",head_mask
"FSMT
	",decoder_head_mask
"FSMT
	",cross_attn_head_mask
"FSMT
	",encoder_outputs
"FSMT
	",past_key_values
"FSMT
	",use_cache
"FSMT
	",output_attentions
"FSMT
	",output_hidden_states
"FSMT
	",return_dict
"FSMT
	",labels
"FNet
	",vocab_size
"FNet
	",hidden_size
"FNet
	",num_hidden_layers
"FNet
	",intermediate_size
"FNet
	",hidden_act
"FNet
	",hidden_dropout_prob
"FNet
	",max_position_embeddings
"FNet
	",type_vocab_size
"FNet
	",initializer_range
"FNet
	",layer_norm_eps
"FNet
	",use_tpu_fourier_optimizations
"FNet
	",tpu_short_seq_length
"FNet
	",vocab_file
"FNet
	",do_lower_case
"FNet
	",remove_space
"FNet
	",keep_accents
"FNet
	",unk_token
"FNet
	",sep_token
"FNet
	",pad_token
"FNet
	",cls_token
"FNet
	",mask_token
"FNet
	",sp_model_kwargs
"FNet
	",sp_model
"FNet
	",token_ids_0
"FNet
	",token_ids_1
"FNet
	",token_ids_0
"FNet
	",token_ids_1
"FNet
	",already_has_special_tokens
"FNet
	",token_ids_0
"FNet
	",token_ids_1
"FNet
	",vocab_file
"FNet
	",do_lower_case
"FNet
	",remove_space
"FNet
	",keep_accents
"FNet
	",unk_token
"FNet
	",sep_token
"FNet
	",pad_token
"FNet
	",cls_token
"FNet
	",mask_token
"FNet
	",token_ids_0
"FNet
	",token_ids_1
"FNet
	",token_ids_0
"FNet
	",token_ids_1
"FNet
	",config
"FNet
	",input_ids
"FNet
	",token_type_ids
"FNet
	",position_ids
"FNet
	",inputs_embeds
"FNet
	",output_hidden_states
"FNet
	",return_dict
"FNet
	",config
"FNet
	",input_ids
"FNet
	",token_type_ids
"FNet
	",position_ids
"FNet
	",inputs_embeds
"FNet
	",output_hidden_states
"FNet
	",return_dict
"FNet
	",labels
"FNet
	",next_sentence_label
"FNet
	",kwargs
"FNet
	",config
"FNet
	",input_ids
"FNet
	",token_type_ids
"FNet
	",position_ids
"FNet
	",inputs_embeds
"FNet
	",output_hidden_states
"FNet
	",return_dict
"FNet
	",labels
"FNet
	",config
"FNet
	",input_ids
"FNet
	",token_type_ids
"FNet
	",position_ids
"FNet
	",inputs_embeds
"FNet
	",output_hidden_states
"FNet
	",return_dict
"FNet
	",labels
"FNet
	",config
"FNet
	",input_ids
"FNet
	",token_type_ids
"FNet
	",position_ids
"FNet
	",inputs_embeds
"FNet
	",output_hidden_states
"FNet
	",return_dict
"FNet
	",labels
"FNet
	",config
"FNet
	",input_ids
"FNet
	",token_type_ids
"FNet
	",position_ids
"FNet
	",inputs_embeds
"FNet
	",output_hidden_states
"FNet
	",return_dict
"FNet
	",labels
"FNet
	",config
"FNet
	",input_ids
"FNet
	",token_type_ids
"FNet
	",position_ids
"FNet
	",inputs_embeds
"FNet
	",output_hidden_states
"FNet
	",return_dict
"FNet
	",labels
"FNet
	",config
"FNet
	",input_ids
"FNet
	",token_type_ids
"FNet
	",position_ids
"FNet
	",inputs_embeds
"FNet
	",output_hidden_states
"FNet
	",return_dict
"FNet
	",start_positions
"FNet
	",end_positions
"FlauBERT
	",pre_norm
"FlauBERT
	",layerdrop
"FlauBERT
	",vocab_size
"FlauBERT
	",emb_dim
"FlauBERT
	",n_layer
"FlauBERT
	",n_head
"FlauBERT
	",dropout
"FlauBERT
	",attention_dropout
"FlauBERT
	",gelu_activation
"FlauBERT
	",sinusoidal_embeddings
"FlauBERT
	",causal
"FlauBERT
	",asm
"FlauBERT
	",n_langs
"FlauBERT
	",use_lang_emb
"FlauBERT
	",max_position_embeddings
"FlauBERT
	",embed_init_std
"FlauBERT
	",init_std
"FlauBERT
	",layer_norm_eps
"FlauBERT
	",bos_index
"FlauBERT
	",eos_index
"FlauBERT
	",pad_index
"FlauBERT
	",unk_index
"FlauBERT
	",mask_index
"FlauBERT
	",is_encoder(
"FlauBERT
	",","
"FlauBERT
	",summary_type
"FlauBERT
	",summary_use_proj
"FlauBERT
	",summary_activation
"FlauBERT
	",summary_proj_to_labels
"FlauBERT
	",summary_first_dropout
"FlauBERT
	",start_n_top
"FlauBERT
	",end_n_top
"FlauBERT
	",mask_token_id
"FlauBERT
	",lang_id
"FlauBERT
	",vocab_file
"FlauBERT
	",merges_file
"FlauBERT
	",do_lowercase
"FlauBERT
	",unk_token
"FlauBERT
	",bos_token
"FlauBERT
	",sep_token
"FlauBERT
	",pad_token
"FlauBERT
	",cls_token
"FlauBERT
	",mask_token
"FlauBERT
	",additional_special_tokens
"FlauBERT
	",lang2id
"FlauBERT
	",id2lang
"FlauBERT
	",do_lowercase_and_remove_accent
"FlauBERT
	",token_ids_0
"FlauBERT
	",token_ids_1
"FlauBERT
	",token_ids_0
"FlauBERT
	",token_ids_1
"FlauBERT
	",token_ids_0
"FlauBERT
	",token_ids_1
"FlauBERT
	",already_has_special_tokens
"FlauBERT
	",config
"FlauBERT
	",input_ids
"FlauBERT
	",attention_mask
"FlauBERT
	",token_type_ids
"FlauBERT
	",position_ids
"FlauBERT
	",lengths
"FlauBERT
	",cache
"FlauBERT
	",head_mask
"FlauBERT
	",inputs_embeds
"FlauBERT
	",output_attentions
"FlauBERT
	",output_hidden_states
"FlauBERT
	",return_dict
"FlauBERT
	",config
"FlauBERT
	",input_ids
"FlauBERT
	",attention_mask
"FlauBERT
	",langs
"FlauBERT
	",token_type_ids
"FlauBERT
	",position_ids
"FlauBERT
	",lengths
"FlauBERT
	",cache
"FlauBERT
	",head_mask
"FlauBERT
	",inputs_embeds
"FlauBERT
	",output_attentions
"FlauBERT
	",output_hidden_states
"FlauBERT
	",return_dict
"FlauBERT
	",labels
"FlauBERT
	",are shifted
"FlauBERT
	",config
"FlauBERT
	",input_ids
"FlauBERT
	",attention_mask
"FlauBERT
	",langs
"FlauBERT
	",token_type_ids
"FlauBERT
	",position_ids
"FlauBERT
	",lengths
"FlauBERT
	",cache
"FlauBERT
	",head_mask
"FlauBERT
	",inputs_embeds
"FlauBERT
	",output_attentions
"FlauBERT
	",output_hidden_states
"FlauBERT
	",return_dict
"FlauBERT
	",labels
"FlauBERT
	",config
"FlauBERT
	",input_ids
"FlauBERT
	",attention_mask
"FlauBERT
	",langs
"FlauBERT
	",token_type_ids
"FlauBERT
	",position_ids
"FlauBERT
	",lengths
"FlauBERT
	",cache
"FlauBERT
	",head_mask
"FlauBERT
	",inputs_embeds
"FlauBERT
	",output_attentions
"FlauBERT
	",output_hidden_states
"FlauBERT
	",return_dict
"FlauBERT
	",labels
"FlauBERT
	",config
"FlauBERT
	",input_ids
"FlauBERT
	",attention_mask
"FlauBERT
	",langs
"FlauBERT
	",token_type_ids
"FlauBERT
	",position_ids
"FlauBERT
	",lengths
"FlauBERT
	",cache
"FlauBERT
	",head_mask
"FlauBERT
	",inputs_embeds
"FlauBERT
	",output_attentions
"FlauBERT
	",output_hidden_states
"FlauBERT
	",return_dict
"FlauBERT
	",labels
"FlauBERT
	",config
"FlauBERT
	",input_ids
"FlauBERT
	",attention_mask
"FlauBERT
	",langs
"FlauBERT
	",token_type_ids
"FlauBERT
	",position_ids
"FlauBERT
	",lengths
"FlauBERT
	",cache
"FlauBERT
	",head_mask
"FlauBERT
	",inputs_embeds
"FlauBERT
	",output_attentions
"FlauBERT
	",output_hidden_states
"FlauBERT
	",return_dict
"FlauBERT
	",start_positions
"FlauBERT
	",end_positions
"FlauBERT
	",config
"FlauBERT
	",input_ids
"FlauBERT
	",attention_mask
"FlauBERT
	",langs
"FlauBERT
	",token_type_ids
"FlauBERT
	",position_ids
"FlauBERT
	",lengths
"FlauBERT
	",cache
"FlauBERT
	",head_mask
"FlauBERT
	",inputs_embeds
"FlauBERT
	",output_attentions
"FlauBERT
	",output_hidden_states
"FlauBERT
	",return_dict
"FlauBERT
	",start_positions
"FlauBERT
	",end_positions
"FlauBERT
	",is_impossible
"FlauBERT
	",cls_index
"FlauBERT
	",p_mask
"FlauBERT
	",config
"FlauBERT
	",input_ids
"FlauBERT
	",attention_mask
"FlauBERT
	",langs
"FlauBERT
	",token_type_ids
"FlauBERT
	",position_ids
"FlauBERT
	",lengths
"FlauBERT
	",cache
"FlauBERT
	",head_mask
"FlauBERT
	",inputs_embeds
"FlauBERT
	",output_attentions
"FlauBERT
	",output_hidden_states
"FlauBERT
	",return_dict
"FlauBERT
	",training
"FlauBERT
	",config
"FlauBERT
	",input_ids
"FlauBERT
	",attention_mask
"FlauBERT
	",langs
"FlauBERT
	",token_type_ids
"FlauBERT
	",position_ids
"FlauBERT
	",lengths
"FlauBERT
	",cache
"FlauBERT
	",head_mask
"FlauBERT
	",inputs_embeds
"FlauBERT
	",output_attentions
"FlauBERT
	",output_hidden_states
"FlauBERT
	",return_dict
"FlauBERT
	",training
"FlauBERT
	",config
"FlauBERT
	",input_ids
"FlauBERT
	",attention_mask
"FlauBERT
	",langs
"FlauBERT
	",token_type_ids
"FlauBERT
	",position_ids
"FlauBERT
	",lengths
"FlauBERT
	",cache
"FlauBERT
	",head_mask
"FlauBERT
	",inputs_embeds
"FlauBERT
	",output_attentions
"FlauBERT
	",output_hidden_states
"FlauBERT
	",return_dict
"FlauBERT
	",training
"FlauBERT
	",labels
"FlauBERT
	",config
"FlauBERT
	",input_ids
"FlauBERT
	",attention_mask
"FlauBERT
	",langs
"FlauBERT
	",token_type_ids
"FlauBERT
	",position_ids
"FlauBERT
	",lengths
"FlauBERT
	",cache
"FlauBERT
	",head_mask
"FlauBERT
	",inputs_embeds
"FlauBERT
	",output_attentions
"FlauBERT
	",output_hidden_states
"FlauBERT
	",return_dict
"FlauBERT
	",training
"FlauBERT
	",config
"FlauBERT
	",input_ids
"FlauBERT
	",attention_mask
"FlauBERT
	",langs
"FlauBERT
	",token_type_ids
"FlauBERT
	",position_ids
"FlauBERT
	",lengths
"FlauBERT
	",cache
"FlauBERT
	",head_mask
"FlauBERT
	",inputs_embeds
"FlauBERT
	",output_attentions
"FlauBERT
	",output_hidden_states
"FlauBERT
	",return_dict
"FlauBERT
	",training
"FlauBERT
	",labels
"FlauBERT
	",config
"FlauBERT
	",input_ids
"FlauBERT
	",attention_mask
"FlauBERT
	",langs
"FlauBERT
	",token_type_ids
"FlauBERT
	",position_ids
"FlauBERT
	",lengths
"FlauBERT
	",cache
"FlauBERT
	",head_mask
"FlauBERT
	",inputs_embeds
"FlauBERT
	",output_attentions
"FlauBERT
	",output_hidden_states
"FlauBERT
	",return_dict
"FlauBERT
	",training
"FlauBERT
	",start_positions
"FlauBERT
	",end_positions
"ESM
	",vocab_size
"ESM
	",mask_token_id
"ESM
	",pad_token_id
"ESM
	",hidden_size
"ESM
	",num_hidden_layers
"ESM
	",num_attention_heads
"ESM
	",intermediate_size
"ESM
	",hidden_act
"ESM
	",hidden_dropout_prob
"ESM
	",attention_probs_dropout_prob
"ESM
	",max_position_embeddings
"ESM
	",initializer_range
"ESM
	",layer_norm_eps
"ESM
	",position_embedding_type
"ESM
	",use_cache
"ESM
	",classifier_dropout
"ESM
	",emb_layer_norm_before
"ESM
	",token_dropout
"ESM
	",token_ids_0
"ESM
	",token_ids_1
"ESM
	",already_has_special_tokens
"ESM
	",token_ids_0
"ESM
	",token_ids_1
"ESM
	",config
"ESM
	",input_ids
"ESM
	",attention_mask
"ESM
	",position_ids
"ESM
	",head_mask
"ESM
	",inputs_embeds
"ESM
	",output_attentions
"ESM
	",output_hidden_states
"ESM
	",return_dict
"ESM
	",encoder_hidden_states
"ESM
	",encoder_attention_mask
"ESM
	",past_key_values
"ESM
	",use_cache
"ESM
	",config
"ESM
	",input_ids
"ESM
	",attention_mask
"ESM
	",position_ids
"ESM
	",head_mask
"ESM
	",inputs_embeds
"ESM
	",output_attentions
"ESM
	",output_hidden_states
"ESM
	",return_dict
"ESM
	",labels
"ESM
	",kwargs
"ESM
	",config
"ESM
	",input_ids
"ESM
	",attention_mask
"ESM
	",position_ids
"ESM
	",head_mask
"ESM
	",inputs_embeds
"ESM
	",output_attentions
"ESM
	",output_hidden_states
"ESM
	",return_dict
"ESM
	",labels
"ESM
	",config
"ESM
	",input_ids
"ESM
	",attention_mask
"ESM
	",position_ids
"ESM
	",head_mask
"ESM
	",inputs_embeds
"ESM
	",output_attentions
"ESM
	",output_hidden_states
"ESM
	",return_dict
"ESM
	",labels
"ERNIE
	",vocab_size
"ERNIE
	",hidden_size
"ERNIE
	",num_hidden_layers
"ERNIE
	",num_attention_heads
"ERNIE
	",intermediate_size
"ERNIE
	",hidden_act
"ERNIE
	",hidden_dropout_prob
"ERNIE
	",attention_probs_dropout_prob
"ERNIE
	",max_position_embeddings
"ERNIE
	",type_vocab_size
"ERNIE
	",task_type_vocab_size
"ERNIE
	",use_task_id
"ERNIE
	",initializer_range
"ERNIE
	",layer_norm_eps
"ERNIE
	",position_embedding_type
"ERNIE
	",use_cache
"ERNIE
	",classifier_dropout
"ERNIE
	",loss
"ERNIE
	",prediction_logits
"ERNIE
	",seq_relationship_logits
"ERNIE
	",hidden_states
"ERNIE
	",attentions
"ERNIE
	",config
"ERNIE
	",input_ids
"ERNIE
	",attention_mask
"ERNIE
	",token_type_ids
"ERNIE
	",task_type_ids
"ERNIE
	",position_ids
"ERNIE
	",head_mask
"ERNIE
	",inputs_embeds
"ERNIE
	",output_attentions
"ERNIE
	",output_hidden_states
"ERNIE
	",return_dict
"ERNIE
	",encoder_hidden_states
"ERNIE
	",encoder_attention_mask
"ERNIE
	",past_key_values
"ERNIE
	",use_cache
"ERNIE
	",config
"ERNIE
	",input_ids
"ERNIE
	",attention_mask
"ERNIE
	",token_type_ids
"ERNIE
	",task_type_ids
"ERNIE
	",position_ids
"ERNIE
	",head_mask
"ERNIE
	",inputs_embeds
"ERNIE
	",output_attentions
"ERNIE
	",output_hidden_states
"ERNIE
	",return_dict
"ERNIE
	",config
"ERNIE
	",input_ids
"ERNIE
	",attention_mask
"ERNIE
	",token_type_ids
"ERNIE
	",task_type_ids
"ERNIE
	",position_ids
"ERNIE
	",head_mask
"ERNIE
	",inputs_embeds
"ERNIE
	",output_attentions
"ERNIE
	",output_hidden_states
"ERNIE
	",return_dict
"ERNIE
	",encoder_hidden_states
"ERNIE
	",encoder_attention_mask
"ERNIE
	",labels
"ERNIE
	",past_key_values
"ERNIE
	",use_cache
"ERNIE
	",config
"ERNIE
	",input_ids
"ERNIE
	",attention_mask
"ERNIE
	",token_type_ids
"ERNIE
	",task_type_ids
"ERNIE
	",position_ids
"ERNIE
	",head_mask
"ERNIE
	",inputs_embeds
"ERNIE
	",output_attentions
"ERNIE
	",output_hidden_states
"ERNIE
	",return_dict
"ERNIE
	",labels
"ERNIE
	",config
"ERNIE
	",input_ids
"ERNIE
	",attention_mask
"ERNIE
	",token_type_ids
"ERNIE
	",task_type_ids
"ERNIE
	",position_ids
"ERNIE
	",head_mask
"ERNIE
	",inputs_embeds
"ERNIE
	",output_attentions
"ERNIE
	",output_hidden_states
"ERNIE
	",return_dict
"ERNIE
	",labels
"ERNIE
	",config
"ERNIE
	",input_ids
"ERNIE
	",attention_mask
"ERNIE
	",token_type_ids
"ERNIE
	",task_type_ids
"ERNIE
	",position_ids
"ERNIE
	",head_mask
"ERNIE
	",inputs_embeds
"ERNIE
	",output_attentions
"ERNIE
	",output_hidden_states
"ERNIE
	",return_dict
"ERNIE
	",labels
"ERNIE
	",config
"ERNIE
	",input_ids
"ERNIE
	",attention_mask
"ERNIE
	",token_type_ids
"ERNIE
	",task_type_ids
"ERNIE
	",position_ids
"ERNIE
	",head_mask
"ERNIE
	",inputs_embeds
"ERNIE
	",output_attentions
"ERNIE
	",output_hidden_states
"ERNIE
	",return_dict
"ERNIE
	",labels
"ERNIE
	",config
"ERNIE
	",input_ids
"ERNIE
	",attention_mask
"ERNIE
	",token_type_ids
"ERNIE
	",task_type_ids
"ERNIE
	",position_ids
"ERNIE
	",head_mask
"ERNIE
	",inputs_embeds
"ERNIE
	",output_attentions
"ERNIE
	",output_hidden_states
"ERNIE
	",return_dict
"ERNIE
	",labels
"ERNIE
	",config
"ERNIE
	",input_ids
"ERNIE
	",attention_mask
"ERNIE
	",token_type_ids
"ERNIE
	",task_type_ids
"ERNIE
	",position_ids
"ERNIE
	",head_mask
"ERNIE
	",inputs_embeds
"ERNIE
	",output_attentions
"ERNIE
	",output_hidden_states
"ERNIE
	",return_dict
"ERNIE
	",start_positions
"ERNIE
	",end_positions
"Encoder Decoder Models
	",kwargs
"Encoder Decoder Models
	",config
"Encoder Decoder Models
	",input_ids
"Encoder Decoder Models
	",attention_mask
"Encoder Decoder Models
	",decoder_input_ids
"Encoder Decoder Models
	",decoder_attention_mask
"Encoder Decoder Models
	",encoder_outputs
"Encoder Decoder Models
	",past_key_values
"Encoder Decoder Models
	",inputs_embeds
"Encoder Decoder Models
	",decoder_inputs_embeds
"Encoder Decoder Models
	",labels
"Encoder Decoder Models
	",use_cache
"Encoder Decoder Models
	",output_attentions
"Encoder Decoder Models
	",output_hidden_states
"Encoder Decoder Models
	",return_dict
"Encoder Decoder Models
	",kwargs
"Encoder Decoder Models
	",encoder_pretrained_model_name_or_path
"Encoder Decoder Models
	",decoder_pretrained_model_name_or_path
"Encoder Decoder Models
	",model_args
"Encoder Decoder Models
	",kwargs
"Encoder Decoder Models
	",config
"Encoder Decoder Models
	",input_ids
"Encoder Decoder Models
	",attention_mask
"Encoder Decoder Models
	",decoder_input_ids
"Encoder Decoder Models
	",decoder_attention_mask
"Encoder Decoder Models
	",encoder_outputs
"Encoder Decoder Models
	",past_key_values
"Encoder Decoder Models
	",inputs_embeds
"Encoder Decoder Models
	",decoder_inputs_embeds
"Encoder Decoder Models
	",labels
"Encoder Decoder Models
	",use_cache
"Encoder Decoder Models
	",output_attentions
"Encoder Decoder Models
	",output_hidden_states
"Encoder Decoder Models
	",return_dict
"Encoder Decoder Models
	",training
"Encoder Decoder Models
	",kwargs
"Encoder Decoder Models
	",encoder_pretrained_model_name_or_path
"Encoder Decoder Models
	",decoder_pretrained_model_name_or_path
"Encoder Decoder Models
	",model_args
"Encoder Decoder Models
	",kwargs
"Encoder Decoder Models
	",config
"Encoder Decoder Models
	",dtype
"Encoder Decoder Models
	",input_ids
"Encoder Decoder Models
	",attention_mask
"Encoder Decoder Models
	",decoder_input_ids
"Encoder Decoder Models
	",decoder_attention_mask
"Encoder Decoder Models
	",position_ids
"Encoder Decoder Models
	",decoder_position_ids
"Encoder Decoder Models
	",output_attentions
"Encoder Decoder Models
	",output_hidden_states
"Encoder Decoder Models
	",return_dict
"Encoder Decoder Models
	",encoder_pretrained_model_name_or_path
"Encoder Decoder Models
	",decoder_pretrained_model_name_or_path
"Encoder Decoder Models
	",model_args
"Encoder Decoder Models
	",kwargs
"ELECTRA
	",vocab_size
"ELECTRA
	",embedding_size
"ELECTRA
	",hidden_size
"ELECTRA
	",num_hidden_layers
"ELECTRA
	",num_attention_heads
"ELECTRA
	",intermediate_size
"ELECTRA
	",hidden_act
"ELECTRA
	",hidden_dropout_prob
"ELECTRA
	",attention_probs_dropout_prob
"ELECTRA
	",max_position_embeddings
"ELECTRA
	",type_vocab_size
"ELECTRA
	",initializer_range
"ELECTRA
	",layer_norm_eps
"ELECTRA
	",summary_type
"ELECTRA
	",summary_use_proj
"ELECTRA
	",summary_activation
"ELECTRA
	",summary_last_dropout
"ELECTRA
	",position_embedding_type
"ELECTRA
	",use_cache
"ELECTRA
	",classifier_dropout
"ELECTRA
	",vocab_file
"ELECTRA
	",do_lower_case
"ELECTRA
	",do_basic_tokenize
"ELECTRA
	",never_split
"ELECTRA
	",unk_token
"ELECTRA
	",sep_token
"ELECTRA
	",pad_token
"ELECTRA
	",cls_token
"ELECTRA
	",mask_token
"ELECTRA
	",tokenize_chinese_chars
"ELECTRA
	",strip_accents
"ELECTRA
	",token_ids_0
"ELECTRA
	",token_ids_1
"ELECTRA
	",token_ids_0
"ELECTRA
	",token_ids_1
"ELECTRA
	",token_ids_0
"ELECTRA
	",token_ids_1
"ELECTRA
	",already_has_special_tokens
"ELECTRA
	",loss
"ELECTRA
	",logits
"ELECTRA
	",hidden_states
"ELECTRA
	",attentions
"ELECTRA
	",loss
"ELECTRA
	",logits
"ELECTRA
	",hidden_states
"ELECTRA
	",attentions
"ELECTRA
	",config
"ELECTRA
	",input_ids
"ELECTRA
	",attention_mask
"ELECTRA
	",token_type_ids
"ELECTRA
	",position_ids
"ELECTRA
	",head_mask
"ELECTRA
	",inputs_embeds
"ELECTRA
	",encoder_hidden_states
"ELECTRA
	",encoder_attention_mask
"ELECTRA
	",output_attentions
"ELECTRA
	",output_hidden_states
"ELECTRA
	",return_dict
"ELECTRA
	",config
"ELECTRA
	",input_ids
"ELECTRA
	",attention_mask
"ELECTRA
	",token_type_ids
"ELECTRA
	",position_ids
"ELECTRA
	",head_mask
"ELECTRA
	",inputs_embeds
"ELECTRA
	",encoder_hidden_states
"ELECTRA
	",encoder_attention_mask
"ELECTRA
	",output_attentions
"ELECTRA
	",output_hidden_states
"ELECTRA
	",return_dict
"ELECTRA
	",labels
"ELECTRA
	",config
"ELECTRA
	",input_ids
"ELECTRA
	",attention_mask
"ELECTRA
	",token_type_ids
"ELECTRA
	",position_ids
"ELECTRA
	",head_mask
"ELECTRA
	",inputs_embeds
"ELECTRA
	",encoder_hidden_states
"ELECTRA
	",encoder_attention_mask
"ELECTRA
	",output_attentions
"ELECTRA
	",output_hidden_states
"ELECTRA
	",return_dict
"ELECTRA
	",encoder_hidden_states
"ELECTRA
	",encoder_attention_mask
"ELECTRA
	",labels
"ELECTRA
	",past_key_values
"ELECTRA
	",use_cache
"ELECTRA
	",config
"ELECTRA
	",input_ids
"ELECTRA
	",attention_mask
"ELECTRA
	",token_type_ids
"ELECTRA
	",position_ids
"ELECTRA
	",head_mask
"ELECTRA
	",inputs_embeds
"ELECTRA
	",encoder_hidden_states
"ELECTRA
	",encoder_attention_mask
"ELECTRA
	",output_attentions
"ELECTRA
	",output_hidden_states
"ELECTRA
	",return_dict
"ELECTRA
	",labels
"ELECTRA
	",config
"ELECTRA
	",input_ids
"ELECTRA
	",attention_mask
"ELECTRA
	",token_type_ids
"ELECTRA
	",position_ids
"ELECTRA
	",head_mask
"ELECTRA
	",inputs_embeds
"ELECTRA
	",encoder_hidden_states
"ELECTRA
	",encoder_attention_mask
"ELECTRA
	",output_attentions
"ELECTRA
	",output_hidden_states
"ELECTRA
	",return_dict
"ELECTRA
	",labels
"ELECTRA
	",config
"ELECTRA
	",input_ids
"ELECTRA
	",attention_mask
"ELECTRA
	",token_type_ids
"ELECTRA
	",position_ids
"ELECTRA
	",head_mask
"ELECTRA
	",inputs_embeds
"ELECTRA
	",encoder_hidden_states
"ELECTRA
	",encoder_attention_mask
"ELECTRA
	",output_attentions
"ELECTRA
	",output_hidden_states
"ELECTRA
	",return_dict
"ELECTRA
	",labels
"ELECTRA
	",config
"ELECTRA
	",input_ids
"ELECTRA
	",attention_mask
"ELECTRA
	",token_type_ids
"ELECTRA
	",position_ids
"ELECTRA
	",head_mask
"ELECTRA
	",inputs_embeds
"ELECTRA
	",encoder_hidden_states
"ELECTRA
	",encoder_attention_mask
"ELECTRA
	",output_attentions
"ELECTRA
	",output_hidden_states
"ELECTRA
	",return_dict
"ELECTRA
	",labels
"ELECTRA
	",config
"ELECTRA
	",input_ids
"ELECTRA
	",attention_mask
"ELECTRA
	",token_type_ids
"ELECTRA
	",position_ids
"ELECTRA
	",head_mask
"ELECTRA
	",inputs_embeds
"ELECTRA
	",encoder_hidden_states
"ELECTRA
	",encoder_attention_mask
"ELECTRA
	",output_attentions
"ELECTRA
	",output_hidden_states
"ELECTRA
	",return_dict
"ELECTRA
	",start_positions
"ELECTRA
	",end_positions
"ELECTRA
	",config
"ELECTRA
	",input_ids
"ELECTRA
	",attention_mask
"ELECTRA
	",position_ids
"ELECTRA
	",head_mask
"ELECTRA
	",inputs_embeds
"ELECTRA
	",output_attentions
"ELECTRA
	",output_hidden_states
"ELECTRA
	",return_dict
"ELECTRA
	",training
"ELECTRA
	",encoder_hidden_states
"ELECTRA
	",encoder_attention_mask
"ELECTRA
	",past_key_values
"ELECTRA
	",use_cache
"ELECTRA
	",config
"ELECTRA
	",input_ids
"ELECTRA
	",attention_mask
"ELECTRA
	",position_ids
"ELECTRA
	",head_mask
"ELECTRA
	",inputs_embeds
"ELECTRA
	",output_attentions
"ELECTRA
	",output_hidden_states
"ELECTRA
	",return_dict
"ELECTRA
	",training
"ELECTRA
	",config
"ELECTRA
	",input_ids
"ELECTRA
	",attention_mask
"ELECTRA
	",position_ids
"ELECTRA
	",head_mask
"ELECTRA
	",inputs_embeds
"ELECTRA
	",output_attentions
"ELECTRA
	",output_hidden_states
"ELECTRA
	",return_dict
"ELECTRA
	",training
"ELECTRA
	",labels
"ELECTRA
	",config
"ELECTRA
	",input_ids
"ELECTRA
	",attention_mask
"ELECTRA
	",position_ids
"ELECTRA
	",head_mask
"ELECTRA
	",inputs_embeds
"ELECTRA
	",output_attentions
"ELECTRA
	",output_hidden_states
"ELECTRA
	",return_dict
"ELECTRA
	",training
"ELECTRA
	",labels
"ELECTRA
	",config
"ELECTRA
	",input_ids
"ELECTRA
	",attention_mask
"ELECTRA
	",position_ids
"ELECTRA
	",head_mask
"ELECTRA
	",inputs_embeds
"ELECTRA
	",output_attentions
"ELECTRA
	",output_hidden_states
"ELECTRA
	",return_dict
"ELECTRA
	",training
"ELECTRA
	",labels
"ELECTRA
	",config
"ELECTRA
	",input_ids
"ELECTRA
	",attention_mask
"ELECTRA
	",position_ids
"ELECTRA
	",head_mask
"ELECTRA
	",inputs_embeds
"ELECTRA
	",output_attentions
"ELECTRA
	",output_hidden_states
"ELECTRA
	",return_dict
"ELECTRA
	",training
"ELECTRA
	",labels
"ELECTRA
	",config
"ELECTRA
	",input_ids
"ELECTRA
	",attention_mask
"ELECTRA
	",position_ids
"ELECTRA
	",head_mask
"ELECTRA
	",inputs_embeds
"ELECTRA
	",output_attentions
"ELECTRA
	",output_hidden_states
"ELECTRA
	",return_dict
"ELECTRA
	",training
"ELECTRA
	",start_positions
"ELECTRA
	",end_positions
"ELECTRA
	",config
"ELECTRA
	",input_ids
"ELECTRA
	",attention_mask
"ELECTRA
	",token_type_ids
"ELECTRA
	",position_ids
"ELECTRA
	",head_mask
"ELECTRA
	",return_dict
"ELECTRA
	",config
"ELECTRA
	",input_ids
"ELECTRA
	",attention_mask
"ELECTRA
	",token_type_ids
"ELECTRA
	",position_ids
"ELECTRA
	",head_mask
"ELECTRA
	",return_dict
"ELECTRA
	",config
"ELECTRA
	",input_ids
"ELECTRA
	",attention_mask
"ELECTRA
	",token_type_ids
"ELECTRA
	",position_ids
"ELECTRA
	",head_mask
"ELECTRA
	",return_dict
"ELECTRA
	",config
"ELECTRA
	",input_ids
"ELECTRA
	",attention_mask
"ELECTRA
	",token_type_ids
"ELECTRA
	",position_ids
"ELECTRA
	",head_mask
"ELECTRA
	",return_dict
"ELECTRA
	",config
"ELECTRA
	",input_ids
"ELECTRA
	",attention_mask
"ELECTRA
	",token_type_ids
"ELECTRA
	",position_ids
"ELECTRA
	",head_mask
"ELECTRA
	",return_dict
"ELECTRA
	",config
"ELECTRA
	",input_ids
"ELECTRA
	",attention_mask
"ELECTRA
	",token_type_ids
"ELECTRA
	",position_ids
"ELECTRA
	",head_mask
"ELECTRA
	",return_dict
"ELECTRA
	",config
"ELECTRA
	",input_ids
"ELECTRA
	",attention_mask
"ELECTRA
	",token_type_ids
"ELECTRA
	",position_ids
"ELECTRA
	",head_mask
"ELECTRA
	",return_dict
"ELECTRA
	",config
"ELECTRA
	",input_ids
"ELECTRA
	",attention_mask
"ELECTRA
	",token_type_ids
"ELECTRA
	",position_ids
"ELECTRA
	",head_mask
"ELECTRA
	",return_dict
"DPR
	",vocab_size
"DPR
	",hidden_size
"DPR
	",num_hidden_layers
"DPR
	",num_attention_heads
"DPR
	",intermediate_size
"DPR
	",hidden_act
"DPR
	",hidden_dropout_prob
"DPR
	",attention_probs_dropout_prob
"DPR
	",max_position_embeddings
"DPR
	",type_vocab_size
"DPR
	",initializer_range
"DPR
	",layer_norm_eps
"DPR
	",position_embedding_type
"DPR
	",projection_dim
"DPR
	",questions
"DPR
	",titles
"DPR
	",texts
"DPR
	",padding
"DPR
	",truncation
"DPR
	",max_length
"DPR
	",return_tensors
"DPR
	",return_attention_mask
"DPR
	",questions
"DPR
	",titles
"DPR
	",texts
"DPR
	",padding
"DPR
	",truncation
"DPR
	",max_length
"DPR
	",return_tensors
"DPR
	",return_attention_mask
"DPR
	",pooler_output
"DPR
	",hidden_states
"DPR
	",attentions
"DPR
	",pooler_output
"DPR
	",hidden_states
"DPR
	",attentions
"DPR
	",start_logits
"DPR
	",end_logits
"DPR
	",relevance_logits
"DPR
	",hidden_states
"DPR
	",attentions
"DPR
	",config
"DPR
	",input_ids
"DPR
	",config
"DPR
	",input_ids
"DPR
	",config
"DPR
	",input_ids
"DPR
	",attention_mask
"DPR
	",inputs_embeds
"DPR
	",output_attentions
"DPR
	",output_hidden_states
"DPR
	",return_dict
"DPR
	",config
"DPR
	",input_ids
"DPR
	",config
"DPR
	",input_ids
"DPR
	",config
"DPR
	",input_ids
"DPR
	",attention_mask
"DPR
	",inputs_embeds
"DPR
	",output_hidden_states
"DPR
	",return_dict
"DPR
	",training
"DistilBERT
	",vocab_size
"DistilBERT
	",max_position_embeddings
"DistilBERT
	",sinusoidal_pos_embds
"DistilBERT
	",n_layers
"DistilBERT
	",n_heads
"DistilBERT
	",dim
"DistilBERT
	",hidden_dim
"DistilBERT
	",dropout
"DistilBERT
	",attention_dropout
"DistilBERT
	",activation
"DistilBERT
	",initializer_range
"DistilBERT
	",qa_dropout
"DistilBERT
	",seq_classif_dropout
"DistilBERT
	",config
"DistilBERT
	",input_ids
"DistilBERT
	",attention_mask
"DistilBERT
	",head_mask
"DistilBERT
	",inputs_embeds
"DistilBERT
	",output_attentions
"DistilBERT
	",output_hidden_states
"DistilBERT
	",return_dict
"DistilBERT
	",config
"DistilBERT
	",input_ids
"DistilBERT
	",attention_mask
"DistilBERT
	",head_mask
"DistilBERT
	",inputs_embeds
"DistilBERT
	",output_attentions
"DistilBERT
	",output_hidden_states
"DistilBERT
	",return_dict
"DistilBERT
	",labels
"DistilBERT
	",config
"DistilBERT
	",input_ids
"DistilBERT
	",attention_mask
"DistilBERT
	",head_mask
"DistilBERT
	",inputs_embeds
"DistilBERT
	",output_attentions
"DistilBERT
	",output_hidden_states
"DistilBERT
	",return_dict
"DistilBERT
	",labels
"DistilBERT
	",config
"DistilBERT
	",input_ids
"DistilBERT
	",attention_mask
"DistilBERT
	",head_mask
"DistilBERT
	",inputs_embeds
"DistilBERT
	",output_attentions
"DistilBERT
	",output_hidden_states
"DistilBERT
	",return_dict
"DistilBERT
	",labels
"DistilBERT
	",config
"DistilBERT
	",input_ids
"DistilBERT
	",attention_mask
"DistilBERT
	",head_mask
"DistilBERT
	",inputs_embeds
"DistilBERT
	",output_attentions
"DistilBERT
	",output_hidden_states
"DistilBERT
	",return_dict
"DistilBERT
	",labels
"DistilBERT
	",config
"DistilBERT
	",input_ids
"DistilBERT
	",attention_mask
"DistilBERT
	",head_mask
"DistilBERT
	",inputs_embeds
"DistilBERT
	",output_attentions
"DistilBERT
	",output_hidden_states
"DistilBERT
	",return_dict
"DistilBERT
	",start_positions
"DistilBERT
	",end_positions
"DistilBERT
	",config
"DistilBERT
	",input_ids
"DistilBERT
	",attention_mask
"DistilBERT
	",head_mask
"DistilBERT
	",inputs_embeds
"DistilBERT
	",output_attentions
"DistilBERT
	",output_hidden_states
"DistilBERT
	",return_dict
"DistilBERT
	",training
"DistilBERT
	",config
"DistilBERT
	",input_ids
"DistilBERT
	",attention_mask
"DistilBERT
	",head_mask
"DistilBERT
	",inputs_embeds
"DistilBERT
	",output_attentions
"DistilBERT
	",output_hidden_states
"DistilBERT
	",return_dict
"DistilBERT
	",training
"DistilBERT
	",labels
"DistilBERT
	",config
"DistilBERT
	",input_ids
"DistilBERT
	",attention_mask
"DistilBERT
	",head_mask
"DistilBERT
	",inputs_embeds
"DistilBERT
	",output_attentions
"DistilBERT
	",output_hidden_states
"DistilBERT
	",return_dict
"DistilBERT
	",training
"DistilBERT
	",labels
"DistilBERT
	",config
"DistilBERT
	",input_ids
"DistilBERT
	",attention_mask
"DistilBERT
	",head_mask
"DistilBERT
	",inputs_embeds
"DistilBERT
	",output_attentions
"DistilBERT
	",output_hidden_states
"DistilBERT
	",return_dict
"DistilBERT
	",training
"DistilBERT
	",labels
"DistilBERT
	",config
"DistilBERT
	",input_ids
"DistilBERT
	",attention_mask
"DistilBERT
	",head_mask
"DistilBERT
	",inputs_embeds
"DistilBERT
	",output_attentions
"DistilBERT
	",output_hidden_states
"DistilBERT
	",return_dict
"DistilBERT
	",training
"DistilBERT
	",labels
"DistilBERT
	",config
"DistilBERT
	",input_ids
"DistilBERT
	",attention_mask
"DistilBERT
	",head_mask
"DistilBERT
	",inputs_embeds
"DistilBERT
	",output_attentions
"DistilBERT
	",output_hidden_states
"DistilBERT
	",return_dict
"DistilBERT
	",training
"DistilBERT
	",start_positions
"DistilBERT
	",end_positions
"DistilBERT
	",config
"DistilBERT
	",input_ids
"DistilBERT
	",attention_mask
"DistilBERT
	",output_attentions
"DistilBERT
	",output_hidden_states
"DistilBERT
	",return_dict
"DistilBERT
	",config
"DistilBERT
	",input_ids
"DistilBERT
	",attention_mask
"DistilBERT
	",output_attentions
"DistilBERT
	",output_hidden_states
"DistilBERT
	",return_dict
"DistilBERT
	",config
"DistilBERT
	",input_ids
"DistilBERT
	",attention_mask
"DistilBERT
	",output_attentions
"DistilBERT
	",output_hidden_states
"DistilBERT
	",return_dict
"DistilBERT
	",config
"DistilBERT
	",input_ids
"DistilBERT
	",attention_mask
"DistilBERT
	",output_attentions
"DistilBERT
	",output_hidden_states
"DistilBERT
	",return_dict
"DistilBERT
	",config
"DistilBERT
	",input_ids
"DistilBERT
	",attention_mask
"DistilBERT
	",output_attentions
"DistilBERT
	",output_hidden_states
"DistilBERT
	",return_dict
"DistilBERT
	",config
"DistilBERT
	",input_ids
"DistilBERT
	",attention_mask
"DistilBERT
	",output_attentions
"DistilBERT
	",output_hidden_states
"DistilBERT
	",return_dict
"DeBERTa-v2
	",vocab_size
"DeBERTa-v2
	",hidden_size
"DeBERTa-v2
	",num_hidden_layers
"DeBERTa-v2
	",num_attention_heads
"DeBERTa-v2
	",intermediate_size
"DeBERTa-v2
	",hidden_act
"DeBERTa-v2
	",hidden_dropout_prob
"DeBERTa-v2
	",attention_probs_dropout_prob
"DeBERTa-v2
	",max_position_embeddings
"DeBERTa-v2
	",type_vocab_size
"DeBERTa-v2
	",initializer_range
"DeBERTa-v2
	",layer_norm_eps
"DeBERTa-v2
	",relative_attention
"DeBERTa-v2
	",max_relative_positions
"DeBERTa-v2
	",pad_token_id
"DeBERTa-v2
	",position_biased_input
"DeBERTa-v2
	",pos_att_type
"DeBERTa-v2
	",layer_norm_eps
"DeBERTa-v2
	",vocab_file
"DeBERTa-v2
	",do_lower_case
"DeBERTa-v2
	",bos_token
"DeBERTa-v2
	",eos_token
"DeBERTa-v2
	",unk_token
"DeBERTa-v2
	",sep_token
"DeBERTa-v2
	",pad_token
"DeBERTa-v2
	",cls_token
"DeBERTa-v2
	",mask_token
"DeBERTa-v2
	",sp_model_kwargs
"DeBERTa-v2
	",token_ids_0
"DeBERTa-v2
	",token_ids_1
"DeBERTa-v2
	",token_ids_0
"DeBERTa-v2
	",token_ids_1
"DeBERTa-v2
	",already_has_special_tokens
"DeBERTa-v2
	",token_ids_0
"DeBERTa-v2
	",token_ids_1
"DeBERTa-v2
	",vocab_file
"DeBERTa-v2
	",do_lower_case
"DeBERTa-v2
	",bos_token
"DeBERTa-v2
	",eos_token
"DeBERTa-v2
	",unk_token
"DeBERTa-v2
	",sep_token
"DeBERTa-v2
	",pad_token
"DeBERTa-v2
	",cls_token
"DeBERTa-v2
	",mask_token
"DeBERTa-v2
	",sp_model_kwargs
"DeBERTa-v2
	",token_ids_0
"DeBERTa-v2
	",token_ids_1
"DeBERTa-v2
	",token_ids_0
"DeBERTa-v2
	",token_ids_1
"DeBERTa-v2
	",config
"DeBERTa-v2
	",input_ids
"DeBERTa-v2
	",attention_mask
"DeBERTa-v2
	",token_type_ids
"DeBERTa-v2
	",position_ids
"DeBERTa-v2
	",inputs_embeds
"DeBERTa-v2
	",output_attentions
"DeBERTa-v2
	",output_hidden_states
"DeBERTa-v2
	",return_dict
"DeBERTa-v2
	",config
"DeBERTa-v2
	",input_ids
"DeBERTa-v2
	",attention_mask
"DeBERTa-v2
	",token_type_ids
"DeBERTa-v2
	",position_ids
"DeBERTa-v2
	",inputs_embeds
"DeBERTa-v2
	",output_attentions
"DeBERTa-v2
	",output_hidden_states
"DeBERTa-v2
	",return_dict
"DeBERTa-v2
	",labels
"DeBERTa-v2
	",config
"DeBERTa-v2
	",input_ids
"DeBERTa-v2
	",attention_mask
"DeBERTa-v2
	",token_type_ids
"DeBERTa-v2
	",position_ids
"DeBERTa-v2
	",inputs_embeds
"DeBERTa-v2
	",output_attentions
"DeBERTa-v2
	",output_hidden_states
"DeBERTa-v2
	",return_dict
"DeBERTa-v2
	",labels
"DeBERTa-v2
	",config
"DeBERTa-v2
	",input_ids
"DeBERTa-v2
	",attention_mask
"DeBERTa-v2
	",token_type_ids
"DeBERTa-v2
	",position_ids
"DeBERTa-v2
	",inputs_embeds
"DeBERTa-v2
	",output_attentions
"DeBERTa-v2
	",output_hidden_states
"DeBERTa-v2
	",return_dict
"DeBERTa-v2
	",labels
"DeBERTa-v2
	",config
"DeBERTa-v2
	",input_ids
"DeBERTa-v2
	",attention_mask
"DeBERTa-v2
	",token_type_ids
"DeBERTa-v2
	",position_ids
"DeBERTa-v2
	",inputs_embeds
"DeBERTa-v2
	",output_attentions
"DeBERTa-v2
	",output_hidden_states
"DeBERTa-v2
	",return_dict
"DeBERTa-v2
	",start_positions
"DeBERTa-v2
	",end_positions
"DeBERTa-v2
	",config
"DeBERTa-v2
	",input_ids
"DeBERTa-v2
	",attention_mask
"DeBERTa-v2
	",token_type_ids
"DeBERTa-v2
	",position_ids
"DeBERTa-v2
	",inputs_embeds
"DeBERTa-v2
	",output_attentions
"DeBERTa-v2
	",output_hidden_states
"DeBERTa-v2
	",return_dict
"DeBERTa-v2
	",labels
"DeBERTa-v2
	",config
"DeBERTa-v2
	",input_ids
"DeBERTa-v2
	",attention_mask
"DeBERTa-v2
	",token_type_ids
"DeBERTa-v2
	",position_ids
"DeBERTa-v2
	",inputs_embeds
"DeBERTa-v2
	",output_attentions
"DeBERTa-v2
	",output_hidden_states
"DeBERTa-v2
	",return_dict
"DeBERTa-v2
	",config
"DeBERTa-v2
	",input_ids
"DeBERTa-v2
	",attention_mask
"DeBERTa-v2
	",token_type_ids
"DeBERTa-v2
	",position_ids
"DeBERTa-v2
	",inputs_embeds
"DeBERTa-v2
	",output_attentions
"DeBERTa-v2
	",output_hidden_states
"DeBERTa-v2
	",return_dict
"DeBERTa-v2
	",labels
"DeBERTa-v2
	",config
"DeBERTa-v2
	",input_ids
"DeBERTa-v2
	",attention_mask
"DeBERTa-v2
	",token_type_ids
"DeBERTa-v2
	",position_ids
"DeBERTa-v2
	",inputs_embeds
"DeBERTa-v2
	",output_attentions
"DeBERTa-v2
	",output_hidden_states
"DeBERTa-v2
	",return_dict
"DeBERTa-v2
	",labels
"DeBERTa-v2
	",config
"DeBERTa-v2
	",input_ids
"DeBERTa-v2
	",attention_mask
"DeBERTa-v2
	",token_type_ids
"DeBERTa-v2
	",position_ids
"DeBERTa-v2
	",inputs_embeds
"DeBERTa-v2
	",output_attentions
"DeBERTa-v2
	",output_hidden_states
"DeBERTa-v2
	",return_dict
"DeBERTa-v2
	",labels
"DeBERTa-v2
	",config
"DeBERTa-v2
	",input_ids
"DeBERTa-v2
	",attention_mask
"DeBERTa-v2
	",token_type_ids
"DeBERTa-v2
	",position_ids
"DeBERTa-v2
	",inputs_embeds
"DeBERTa-v2
	",output_attentions
"DeBERTa-v2
	",output_hidden_states
"DeBERTa-v2
	",return_dict
"DeBERTa-v2
	",start_positions
"DeBERTa-v2
	",end_positions
"DeBERTa
	",vocab_size
"DeBERTa
	",hidden_size
"DeBERTa
	",num_hidden_layers
"DeBERTa
	",num_attention_heads
"DeBERTa
	",intermediate_size
"DeBERTa
	",hidden_act
"DeBERTa
	",hidden_dropout_prob
"DeBERTa
	",attention_probs_dropout_prob
"DeBERTa
	",max_position_embeddings
"DeBERTa
	",type_vocab_size
"DeBERTa
	",initializer_range
"DeBERTa
	",layer_norm_eps
"DeBERTa
	",relative_attention
"DeBERTa
	",max_relative_positions
"DeBERTa
	",pad_token_id
"DeBERTa
	",position_biased_input
"DeBERTa
	",pos_att_type
"DeBERTa
	",layer_norm_eps
"DeBERTa
	",vocab_file
"DeBERTa
	",do_lower_case
"DeBERTa
	",unk_token
"DeBERTa
	",sep_token
"DeBERTa
	",pad_token
"DeBERTa
	",cls_token
"DeBERTa
	",mask_token
"DeBERTa
	",token_ids_0
"DeBERTa
	",token_ids_1
"DeBERTa
	",token_ids_0
"DeBERTa
	",token_ids_1
"DeBERTa
	",already_has_special_tokens
"DeBERTa
	",token_ids_0
"DeBERTa
	",token_ids_1
"DeBERTa
	",vocab_file
"DeBERTa
	",do_lower_case
"DeBERTa
	",unk_token
"DeBERTa
	",sep_token
"DeBERTa
	",pad_token
"DeBERTa
	",cls_token
"DeBERTa
	",mask_token
"DeBERTa
	",token_ids_0
"DeBERTa
	",token_ids_1
"DeBERTa
	",token_ids_0
"DeBERTa
	",token_ids_1
"DeBERTa
	",config
"DeBERTa
	",input_ids
"DeBERTa
	",attention_mask
"DeBERTa
	",token_type_ids
"DeBERTa
	",position_ids
"DeBERTa
	",inputs_embeds
"DeBERTa
	",output_attentions
"DeBERTa
	",output_hidden_states
"DeBERTa
	",return_dict
"DeBERTa
	",config
"DeBERTa
	",input_ids
"DeBERTa
	",attention_mask
"DeBERTa
	",token_type_ids
"DeBERTa
	",position_ids
"DeBERTa
	",inputs_embeds
"DeBERTa
	",output_attentions
"DeBERTa
	",output_hidden_states
"DeBERTa
	",return_dict
"DeBERTa
	",labels
"DeBERTa
	",config
"DeBERTa
	",input_ids
"DeBERTa
	",attention_mask
"DeBERTa
	",token_type_ids
"DeBERTa
	",position_ids
"DeBERTa
	",inputs_embeds
"DeBERTa
	",output_attentions
"DeBERTa
	",output_hidden_states
"DeBERTa
	",return_dict
"DeBERTa
	",labels
"DeBERTa
	",config
"DeBERTa
	",input_ids
"DeBERTa
	",attention_mask
"DeBERTa
	",token_type_ids
"DeBERTa
	",position_ids
"DeBERTa
	",inputs_embeds
"DeBERTa
	",output_attentions
"DeBERTa
	",output_hidden_states
"DeBERTa
	",return_dict
"DeBERTa
	",labels
"DeBERTa
	",config
"DeBERTa
	",input_ids
"DeBERTa
	",attention_mask
"DeBERTa
	",token_type_ids
"DeBERTa
	",position_ids
"DeBERTa
	",inputs_embeds
"DeBERTa
	",output_attentions
"DeBERTa
	",output_hidden_states
"DeBERTa
	",return_dict
"DeBERTa
	",start_positions
"DeBERTa
	",end_positions
"DeBERTa
	",config
"DeBERTa
	",input_ids
"DeBERTa
	",attention_mask
"DeBERTa
	",token_type_ids
"DeBERTa
	",position_ids
"DeBERTa
	",inputs_embeds
"DeBERTa
	",output_attentions
"DeBERTa
	",output_hidden_states
"DeBERTa
	",return_dict
"DeBERTa
	",config
"DeBERTa
	",input_ids
"DeBERTa
	",attention_mask
"DeBERTa
	",token_type_ids
"DeBERTa
	",position_ids
"DeBERTa
	",inputs_embeds
"DeBERTa
	",output_attentions
"DeBERTa
	",output_hidden_states
"DeBERTa
	",return_dict
"DeBERTa
	",labels
"DeBERTa
	",config
"DeBERTa
	",input_ids
"DeBERTa
	",attention_mask
"DeBERTa
	",token_type_ids
"DeBERTa
	",position_ids
"DeBERTa
	",inputs_embeds
"DeBERTa
	",output_attentions
"DeBERTa
	",output_hidden_states
"DeBERTa
	",return_dict
"DeBERTa
	",labels
"DeBERTa
	",config
"DeBERTa
	",input_ids
"DeBERTa
	",attention_mask
"DeBERTa
	",token_type_ids
"DeBERTa
	",position_ids
"DeBERTa
	",inputs_embeds
"DeBERTa
	",output_attentions
"DeBERTa
	",output_hidden_states
"DeBERTa
	",return_dict
"DeBERTa
	",labels
"DeBERTa
	",config
"DeBERTa
	",input_ids
"DeBERTa
	",attention_mask
"DeBERTa
	",token_type_ids
"DeBERTa
	",position_ids
"DeBERTa
	",inputs_embeds
"DeBERTa
	",output_attentions
"DeBERTa
	",output_hidden_states
"DeBERTa
	",return_dict
"DeBERTa
	",start_positions
"DeBERTa
	",end_positions
"CTRL
	",vocab_size
"CTRL
	",n_positions
"CTRL
	",n_embd
"CTRL
	",dff
"CTRL
	",n_layer
"CTRL
	",n_head
"CTRL
	",resid_pdrop
"CTRL
	",embd_pdrop
"CTRL
	",attn_pdrop
"CTRL
	",layer_norm_epsilon
"CTRL
	",initializer_range
"CTRL
	",use_cache
"CTRL
	",vocab_file
"CTRL
	",merges_file
"CTRL
	",unk_token
"CTRL
	",config
"CTRL
	",input_ids
"CTRL
	",past_key_values
"CTRL
	",attention_mask
"CTRL
	",token_type_ids
"CTRL
	",position_ids
"CTRL
	",head_mask
"CTRL
	",inputs_embeds
"CTRL
	",use_cache
"CTRL
	",output_attentions
"CTRL
	",output_hidden_states
"CTRL
	",return_dict
"CTRL
	",config
"CTRL
	",input_ids
"CTRL
	",past_key_values
"CTRL
	",attention_mask
"CTRL
	",token_type_ids
"CTRL
	",position_ids
"CTRL
	",head_mask
"CTRL
	",inputs_embeds
"CTRL
	",use_cache
"CTRL
	",output_attentions
"CTRL
	",output_hidden_states
"CTRL
	",return_dict
"CTRL
	",labels
"CTRL
	",are shifted
"CTRL
	",config
"CTRL
	",input_ids
"CTRL
	",past_key_values
"CTRL
	",attention_mask
"CTRL
	",token_type_ids
"CTRL
	",position_ids
"CTRL
	",head_mask
"CTRL
	",inputs_embeds
"CTRL
	",use_cache
"CTRL
	",output_attentions
"CTRL
	",output_hidden_states
"CTRL
	",return_dict
"CTRL
	",labels
"CTRL
	",config
"CTRL
	",input_ids
"CTRL
	",past
"CTRL
	",attention_mask
"CTRL
	",token_type_ids
"CTRL
	",position_ids
"CTRL
	",head_mask
"CTRL
	",inputs_embeds
"CTRL
	",use_cache
"CTRL
	",output_attentions
"CTRL
	",output_hidden_states
"CTRL
	",return_dict
"CTRL
	",training
"CTRL
	",config
"CTRL
	",input_ids
"CTRL
	",past
"CTRL
	",attention_mask
"CTRL
	",token_type_ids
"CTRL
	",position_ids
"CTRL
	",head_mask
"CTRL
	",inputs_embeds
"CTRL
	",use_cache
"CTRL
	",output_attentions
"CTRL
	",output_hidden_states
"CTRL
	",return_dict
"CTRL
	",training
"CTRL
	",labels
"CTRL
	",config
"CTRL
	",input_ids
"CTRL
	",past
"CTRL
	",attention_mask
"CTRL
	",token_type_ids
"CTRL
	",position_ids
"CTRL
	",head_mask
"CTRL
	",inputs_embeds
"CTRL
	",use_cache
"CTRL
	",output_attentions
"CTRL
	",output_hidden_states
"CTRL
	",return_dict
"CTRL
	",training
"CTRL
	",labels
"ConvBERT
	",vocab_size
"ConvBERT
	",hidden_size
"ConvBERT
	",num_hidden_layers
"ConvBERT
	",num_attention_heads
"ConvBERT
	",intermediate_size
"ConvBERT
	",hidden_act
"ConvBERT
	",hidden_dropout_prob
"ConvBERT
	",attention_probs_dropout_prob
"ConvBERT
	",max_position_embeddings
"ConvBERT
	",type_vocab_size
"ConvBERT
	",initializer_range
"ConvBERT
	",layer_norm_eps
"ConvBERT
	",head_ratio
"ConvBERT
	",num_groups
"ConvBERT
	",conv_kernel_size
"ConvBERT
	",classifier_dropout
"ConvBERT
	",vocab_file
"ConvBERT
	",do_lower_case
"ConvBERT
	",do_basic_tokenize
"ConvBERT
	",never_split
"ConvBERT
	",unk_token
"ConvBERT
	",sep_token
"ConvBERT
	",pad_token
"ConvBERT
	",cls_token
"ConvBERT
	",mask_token
"ConvBERT
	",tokenize_chinese_chars
"ConvBERT
	",strip_accents
"ConvBERT
	",token_ids_0
"ConvBERT
	",token_ids_1
"ConvBERT
	",token_ids_0
"ConvBERT
	",token_ids_1
"ConvBERT
	",already_has_special_tokens
"ConvBERT
	",token_ids_0
"ConvBERT
	",token_ids_1
"ConvBERT
	",vocab_file
"ConvBERT
	",do_lower_case
"ConvBERT
	",unk_token
"ConvBERT
	",sep_token
"ConvBERT
	",pad_token
"ConvBERT
	",cls_token
"ConvBERT
	",mask_token
"ConvBERT
	",clean_text
"ConvBERT
	",tokenize_chinese_chars
"ConvBERT
	",strip_accents
"ConvBERT
	",wordpieces_prefix
"ConvBERT
	",token_ids_0
"ConvBERT
	",token_ids_1
"ConvBERT
	",token_ids_0
"ConvBERT
	",token_ids_1
"ConvBERT
	",config
"ConvBERT
	",input_ids
"ConvBERT
	",attention_mask
"ConvBERT
	",config
"ConvBERT
	",input_ids
"ConvBERT
	",attention_mask
"ConvBERT
	",config
"ConvBERT
	",input_ids
"ConvBERT
	",attention_mask
"ConvBERT
	",config
"ConvBERT
	",input_ids
"ConvBERT
	",attention_mask
"ConvBERT
	",config
"ConvBERT
	",input_ids
"ConvBERT
	",attention_mask
"ConvBERT
	",config
"ConvBERT
	",input_ids
"ConvBERT
	",attention_mask
"ConvBERT
	",config
"ConvBERT
	",input_ids
"ConvBERT
	",attention_mask
"ConvBERT
	",token_type_ids
"ConvBERT
	",position_ids
"ConvBERT
	",head_mask
"ConvBERT
	",inputs_embeds
"ConvBERT
	",output_attentions
"ConvBERT
	",output_hidden_states
"ConvBERT
	",return_dict
"ConvBERT
	",training
"ConvBERT
	",config
"ConvBERT
	",input_ids
"ConvBERT
	",attention_mask
"ConvBERT
	",token_type_ids
"ConvBERT
	",position_ids
"ConvBERT
	",head_mask
"ConvBERT
	",inputs_embeds
"ConvBERT
	",output_attentions
"ConvBERT
	",output_hidden_states
"ConvBERT
	",return_dict
"ConvBERT
	",training
"ConvBERT
	",labels
"ConvBERT
	",config
"ConvBERT
	",input_ids
"ConvBERT
	",attention_mask
"ConvBERT
	",token_type_ids
"ConvBERT
	",position_ids
"ConvBERT
	",head_mask
"ConvBERT
	",inputs_embeds
"ConvBERT
	",output_attentions
"ConvBERT
	",output_hidden_states
"ConvBERT
	",return_dict
"ConvBERT
	",training
"ConvBERT
	",labels
"ConvBERT
	",config
"ConvBERT
	",input_ids
"ConvBERT
	",attention_mask
"ConvBERT
	",token_type_ids
"ConvBERT
	",position_ids
"ConvBERT
	",head_mask
"ConvBERT
	",inputs_embeds
"ConvBERT
	",output_attentions
"ConvBERT
	",output_hidden_states
"ConvBERT
	",return_dict
"ConvBERT
	",training
"ConvBERT
	",labels
"ConvBERT
	",config
"ConvBERT
	",input_ids
"ConvBERT
	",attention_mask
"ConvBERT
	",token_type_ids
"ConvBERT
	",position_ids
"ConvBERT
	",head_mask
"ConvBERT
	",inputs_embeds
"ConvBERT
	",output_attentions
"ConvBERT
	",output_hidden_states
"ConvBERT
	",return_dict
"ConvBERT
	",training
"ConvBERT
	",labels
"ConvBERT
	",config
"ConvBERT
	",input_ids
"ConvBERT
	",attention_mask
"ConvBERT
	",token_type_ids
"ConvBERT
	",position_ids
"ConvBERT
	",head_mask
"ConvBERT
	",inputs_embeds
"ConvBERT
	",output_attentions
"ConvBERT
	",output_hidden_states
"ConvBERT
	",return_dict
"ConvBERT
	",training
"ConvBERT
	",start_positions
"ConvBERT
	",end_positions
"CodeGen
	",vocab_size
"CodeGen
	",n_positions
"CodeGen
	",n_embd
"CodeGen
	",n_layer
"CodeGen
	",n_head
"CodeGen
	",rotary_dim
"CodeGen
	",n_inner
"CodeGen
	",activation_function
"CodeGen
	",resid_pdrop
"CodeGen
	",embd_pdrop
"CodeGen
	",attn_pdrop
"CodeGen
	",layer_norm_epsilon
"CodeGen
	",initializer_range
"CodeGen
	",scale_attn_weights
"CodeGen
	",use_cache
"CodeGen
	",vocab_file
"CodeGen
	",merges_file
"CodeGen
	",errors
"CodeGen
	",unk_token
"CodeGen
	",bos_token
"CodeGen
	",eos_token
"CodeGen
	",add_prefix_space
"CodeGen
	",vocab_file
"CodeGen
	",merges_file
"CodeGen
	",errors
"CodeGen
	",unk_token
"CodeGen
	",bos_token
"CodeGen
	",eos_token
"CodeGen
	",add_prefix_space
"CodeGen
	",trim_offsets
"CodeGen
	",token_ids
"CodeGen
	",skip_special_tokens
"CodeGen
	",clean_up_tokenization_spaces
"CodeGen
	",truncate_before_pattern
"CodeGen
	",config
"CodeGen
	",input_ids
"CodeGen
	",attention_mask
"CodeGen
	",token_type_ids
"CodeGen
	",position_ids
"CodeGen
	",head_mask
"CodeGen
	",inputs_embeds
"CodeGen
	",output_attentions
"CodeGen
	",output_hidden_states
"CodeGen
	",return_dict
"CodeGen
	",config
"CodeGen
	",input_ids
"CodeGen
	",attention_mask
"CodeGen
	",token_type_ids
"CodeGen
	",position_ids
"CodeGen
	",head_mask
"CodeGen
	",inputs_embeds
"CodeGen
	",output_attentions
"CodeGen
	",output_hidden_states
"CodeGen
	",return_dict
"CodeGen
	",labels
"CodeGen
	",are shifted
"CANINE
	",last_hidden_state
"CANINE
	",pooler_output
"CANINE
	",hidden_states
"CANINE
	",attentions
"CANINE
	",hidden_size
"CANINE
	",num_hidden_layers
"CANINE
	",num_attention_heads
"CANINE
	",intermediate_size
"CANINE
	",hidden_act
"CANINE
	",hidden_dropout_prob
"CANINE
	",attention_probs_dropout_prob
"CANINE
	",max_position_embeddings
"CANINE
	",type_vocab_size
"CANINE
	",initializer_range
"CANINE
	",layer_norm_eps
"CANINE
	",downsampling_rate
"CANINE
	",upsampling_kernel_size
"CANINE
	",num_hash_functions
"CANINE
	",num_hash_buckets
"CANINE
	",local_transformer_stride
"CANINE
	",model_max_length
"CANINE
	",token_ids_0
"CANINE
	",token_ids_1
"CANINE
	",token_ids_0
"CANINE
	",token_ids_1
"CANINE
	",already_has_special_tokens
"CANINE
	",token_ids_0
"CANINE
	",token_ids_1
"CANINE
	",config
"CANINE
	",input_ids
"CANINE
	",attention_mask
"CANINE
	",token_type_ids
"CANINE
	",position_ids
"CANINE
	",head_mask
"CANINE
	",inputs_embeds
"CANINE
	",output_attentions
"CANINE
	",output_hidden_states
"CANINE
	",return_dict
"CANINE
	",config
"CANINE
	",input_ids
"CANINE
	",attention_mask
"CANINE
	",token_type_ids
"CANINE
	",position_ids
"CANINE
	",head_mask
"CANINE
	",inputs_embeds
"CANINE
	",output_attentions
"CANINE
	",output_hidden_states
"CANINE
	",return_dict
"CANINE
	",labels
"CANINE
	",config
"CANINE
	",input_ids
"CANINE
	",attention_mask
"CANINE
	",token_type_ids
"CANINE
	",position_ids
"CANINE
	",head_mask
"CANINE
	",inputs_embeds
"CANINE
	",output_attentions
"CANINE
	",output_hidden_states
"CANINE
	",return_dict
"CANINE
	",labels
"CANINE
	",config
"CANINE
	",input_ids
"CANINE
	",attention_mask
"CANINE
	",token_type_ids
"CANINE
	",position_ids
"CANINE
	",head_mask
"CANINE
	",inputs_embeds
"CANINE
	",output_attentions
"CANINE
	",output_hidden_states
"CANINE
	",return_dict
"CANINE
	",labels
"CANINE
	",config
"CANINE
	",input_ids
"CANINE
	",attention_mask
"CANINE
	",token_type_ids
"CANINE
	",position_ids
"CANINE
	",head_mask
"CANINE
	",inputs_embeds
"CANINE
	",output_attentions
"CANINE
	",output_hidden_states
"CANINE
	",return_dict
"CANINE
	",start_positions
"CANINE
	",end_positions
"CamemBERT
	",vocab_file
"CamemBERT
	",bos_token
"CamemBERT
	",eos_token
"CamemBERT
	",sep_token
"CamemBERT
	",cls_token
"CamemBERT
	",unk_token
"CamemBERT
	",pad_token
"CamemBERT
	",mask_token
"CamemBERT
	",additional_special_tokens
"CamemBERT
	",sp_model_kwargs
"CamemBERT
	",sp_model
"CamemBERT
	",token_ids_0
"CamemBERT
	",token_ids_1
"CamemBERT
	",token_ids_0
"CamemBERT
	",token_ids_1
"CamemBERT
	",already_has_special_tokens
"CamemBERT
	",token_ids_0
"CamemBERT
	",token_ids_1
"CamemBERT
	",vocab_file
"CamemBERT
	",bos_token
"CamemBERT
	",eos_token
"CamemBERT
	",sep_token
"CamemBERT
	",cls_token
"CamemBERT
	",unk_token
"CamemBERT
	",pad_token
"CamemBERT
	",mask_token
"CamemBERT
	",additional_special_tokens
"CamemBERT
	",token_ids_0
"CamemBERT
	",token_ids_1
"CamemBERT
	",token_ids_0
"CamemBERT
	",token_ids_1
"CamemBERT
	",config
"CamemBERT
	",input_ids
"CamemBERT
	",attention_mask
"CamemBERT
	",token_type_ids
"CamemBERT
	",position_ids
"CamemBERT
	",head_mask
"CamemBERT
	",inputs_embeds
"CamemBERT
	",output_attentions
"CamemBERT
	",output_hidden_states
"CamemBERT
	",return_dict
"CamemBERT
	",encoder_hidden_states
"CamemBERT
	",encoder_attention_mask
"CamemBERT
	",past_key_values
"CamemBERT
	",use_cache
"CamemBERT
	",config
"CamemBERT
	",input_ids
"CamemBERT
	",attention_mask
"CamemBERT
	",token_type_ids
"CamemBERT
	",position_ids
"CamemBERT
	",head_mask
"CamemBERT
	",inputs_embeds
"CamemBERT
	",output_attentions
"CamemBERT
	",output_hidden_states
"CamemBERT
	",return_dict
"CamemBERT
	",encoder_hidden_states
"CamemBERT
	",encoder_attention_mask
"CamemBERT
	",labels
"CamemBERT
	",past_key_values
"CamemBERT
	",use_cache
"CamemBERT
	",config
"CamemBERT
	",input_ids
"CamemBERT
	",attention_mask
"CamemBERT
	",token_type_ids
"CamemBERT
	",position_ids
"CamemBERT
	",head_mask
"CamemBERT
	",inputs_embeds
"CamemBERT
	",output_attentions
"CamemBERT
	",output_hidden_states
"CamemBERT
	",return_dict
"CamemBERT
	",labels
"CamemBERT
	",kwargs
"CamemBERT
	",config
"CamemBERT
	",input_ids
"CamemBERT
	",attention_mask
"CamemBERT
	",token_type_ids
"CamemBERT
	",position_ids
"CamemBERT
	",head_mask
"CamemBERT
	",inputs_embeds
"CamemBERT
	",output_attentions
"CamemBERT
	",output_hidden_states
"CamemBERT
	",return_dict
"CamemBERT
	",labels
"CamemBERT
	",config
"CamemBERT
	",input_ids
"CamemBERT
	",attention_mask
"CamemBERT
	",token_type_ids
"CamemBERT
	",position_ids
"CamemBERT
	",head_mask
"CamemBERT
	",inputs_embeds
"CamemBERT
	",output_attentions
"CamemBERT
	",output_hidden_states
"CamemBERT
	",return_dict
"CamemBERT
	",labels
"CamemBERT
	",config
"CamemBERT
	",input_ids
"CamemBERT
	",attention_mask
"CamemBERT
	",token_type_ids
"CamemBERT
	",position_ids
"CamemBERT
	",head_mask
"CamemBERT
	",inputs_embeds
"CamemBERT
	",output_attentions
"CamemBERT
	",output_hidden_states
"CamemBERT
	",return_dict
"CamemBERT
	",labels
"CamemBERT
	",config
"CamemBERT
	",input_ids
"CamemBERT
	",attention_mask
"CamemBERT
	",token_type_ids
"CamemBERT
	",position_ids
"CamemBERT
	",head_mask
"CamemBERT
	",inputs_embeds
"CamemBERT
	",output_attentions
"CamemBERT
	",output_hidden_states
"CamemBERT
	",return_dict
"CamemBERT
	",start_positions
"CamemBERT
	",end_positions
"CamemBERT
	",config
"CamemBERT
	",input_ids
"CamemBERT
	",attention_mask
"CamemBERT
	",token_type_ids
"CamemBERT
	",position_ids
"CamemBERT
	",head_mask
"CamemBERT
	",inputs_embeds
"CamemBERT
	",output_attentions
"CamemBERT
	",output_hidden_states
"CamemBERT
	",return_dict
"CamemBERT
	",training
"CamemBERT
	",encoder_hidden_states
"CamemBERT
	",encoder_attention_mask
"CamemBERT
	",past_key_values
"CamemBERT
	",use_cache
"CamemBERT
	",config
"CamemBERT
	",input_ids
"CamemBERT
	",attention_mask
"CamemBERT
	",token_type_ids
"CamemBERT
	",position_ids
"CamemBERT
	",head_mask
"CamemBERT
	",inputs_embeds
"CamemBERT
	",output_attentions
"CamemBERT
	",output_hidden_states
"CamemBERT
	",return_dict
"CamemBERT
	",training
"CamemBERT
	",encoder_hidden_states
"CamemBERT
	",encoder_attention_mask
"CamemBERT
	",past_key_values
"CamemBERT
	",use_cache
"CamemBERT
	",labels
"CamemBERT
	",config
"CamemBERT
	",input_ids
"CamemBERT
	",attention_mask
"CamemBERT
	",token_type_ids
"CamemBERT
	",position_ids
"CamemBERT
	",head_mask
"CamemBERT
	",inputs_embeds
"CamemBERT
	",output_attentions
"CamemBERT
	",output_hidden_states
"CamemBERT
	",return_dict
"CamemBERT
	",training
"CamemBERT
	",labels
"CamemBERT
	",config
"CamemBERT
	",input_ids
"CamemBERT
	",attention_mask
"CamemBERT
	",token_type_ids
"CamemBERT
	",position_ids
"CamemBERT
	",head_mask
"CamemBERT
	",inputs_embeds
"CamemBERT
	",output_attentions
"CamemBERT
	",output_hidden_states
"CamemBERT
	",return_dict
"CamemBERT
	",training
"CamemBERT
	",labels
"CamemBERT
	",config
"CamemBERT
	",input_ids
"CamemBERT
	",attention_mask
"CamemBERT
	",token_type_ids
"CamemBERT
	",position_ids
"CamemBERT
	",head_mask
"CamemBERT
	",inputs_embeds
"CamemBERT
	",output_attentions
"CamemBERT
	",output_hidden_states
"CamemBERT
	",return_dict
"CamemBERT
	",training
"CamemBERT
	",labels
"CamemBERT
	",config
"CamemBERT
	",input_ids
"CamemBERT
	",attention_mask
"CamemBERT
	",token_type_ids
"CamemBERT
	",position_ids
"CamemBERT
	",head_mask
"CamemBERT
	",inputs_embeds
"CamemBERT
	",output_attentions
"CamemBERT
	",output_hidden_states
"CamemBERT
	",return_dict
"CamemBERT
	",training
"CamemBERT
	",labels
"CamemBERT
	",config
"CamemBERT
	",input_ids
"CamemBERT
	",attention_mask
"CamemBERT
	",token_type_ids
"CamemBERT
	",position_ids
"CamemBERT
	",head_mask
"CamemBERT
	",inputs_embeds
"CamemBERT
	",output_attentions
"CamemBERT
	",output_hidden_states
"CamemBERT
	",return_dict
"CamemBERT
	",training
"CamemBERT
	",start_positions
"CamemBERT
	",end_positions
"ByT5
	",eos_token
"ByT5
	",unk_token
"ByT5
	",pad_token
"ByT5
	",extra_ids
"ByT5
	",additional_special_tokens
"ByT5
	",token_ids_0
"ByT5
	",token_ids_1
"ByT5
	",token_ids_0
"ByT5
	",token_ids_1
"ByT5
	",token_ids_0
"ByT5
	",token_ids_1
"ByT5
	",already_has_special_tokens
"BLOOM
	",vocab_size
"BLOOM
	",hidden_size
"BLOOM
	",n_layer
"BLOOM
	",n_head
"BLOOM
	",layer_norm_epsilon
"BLOOM
	",initializer_range
"BLOOM
	",apply_residual_connection_post_layernorm
"BLOOM
	",hidden_dropout
"BLOOM
	",attention_dropout
"BLOOM
	",use_cache
"BLOOM
	",pretraining_tp
"BLOOM
	",slow_but_exact
"BLOOM
	",config
"BLOOM
	",input_ids
"BLOOM
	",past_key_values
"BLOOM
	",attention_mask
"BLOOM
	",head_mask
"BLOOM
	",inputs_embeds
"BLOOM
	",use_cache
"BLOOM
	",output_attentions
"BLOOM
	",output_hidden_states
"BLOOM
	",return_dict
"BLOOM
	",vocab_file
"BLOOM
	",merges_file
"BLOOM
	",errors
"BLOOM
	",unk_token
"BLOOM
	",bos_token
"BLOOM
	",eos_token
"BLOOM
	",add_prefix_space
"BLOOM
	",trim_offsets
"BLOOM
	",config
"BLOOM
	",input_ids
"BLOOM
	",past_key_values
"BLOOM
	",attention_mask
"BLOOM
	",head_mask
"BLOOM
	",inputs_embeds
"BLOOM
	",use_cache
"BLOOM
	",output_attentions
"BLOOM
	",output_hidden_states
"BLOOM
	",return_dict
"BLOOM
	",labels
"BLOOM
	",are shifted
"BLOOM
	",config
"BLOOM
	",input_ids
"BLOOM
	",past_key_values
"BLOOM
	",attention_mask
"BLOOM
	",head_mask
"BLOOM
	",inputs_embeds
"BLOOM
	",use_cache
"BLOOM
	",output_attentions
"BLOOM
	",output_hidden_states
"BLOOM
	",return_dict
"BLOOM
	",labels
"BLOOM
	",config
"BLOOM
	",input_ids
"BLOOM
	",past_key_values
"BLOOM
	",attention_mask
"BLOOM
	",head_mask
"BLOOM
	",inputs_embeds
"BLOOM
	",use_cache
"BLOOM
	",output_attentions
"BLOOM
	",output_hidden_states
"BLOOM
	",return_dict
"BLOOM
	",labels
"BLOOM
	",config
"BLOOM
	",input_ids
"BLOOM
	",past_key_values
"BLOOM
	",attention_mask
"BLOOM
	",head_mask
"BLOOM
	",inputs_embeds
"BLOOM
	",use_cache
"BLOOM
	",output_attentions
"BLOOM
	",output_hidden_states
"BLOOM
	",return_dict
"BLOOM
	",start_positions
"BLOOM
	",end_positions
"Blenderbot Small
	",vocab_size
"Blenderbot Small
	",d_model
"Blenderbot Small
	",encoder_layers
"Blenderbot Small
	",decoder_layers
"Blenderbot Small
	",encoder_attention_heads
"Blenderbot Small
	",decoder_attention_heads
"Blenderbot Small
	",decoder_ffn_dim
"Blenderbot Small
	",encoder_ffn_dim
"Blenderbot Small
	",activation_function
"Blenderbot Small
	",dropout
"Blenderbot Small
	",attention_dropout
"Blenderbot Small
	",activation_dropout
"Blenderbot Small
	",classifier_dropout
"Blenderbot Small
	",max_position_embeddings
"Blenderbot Small
	",init_std
"Blenderbot Small
	",encoder_layerdrop
"Blenderbot Small
	",decoder_layerdrop
"Blenderbot Small
	",scale_embedding
"Blenderbot Small
	",use_cache
"Blenderbot Small
	",forced_eos_token_id
"Blenderbot Small
	",vocab_file
"Blenderbot Small
	",merges_file
"Blenderbot Small
	",bos_token
"Blenderbot Small
	",eos_token
"Blenderbot Small
	",unk_token
"Blenderbot Small
	",pad_token
"Blenderbot Small
	",token_ids_0
"Blenderbot Small
	",token_ids_1
"Blenderbot Small
	",token_ids_0
"Blenderbot Small
	",token_ids_1
"Blenderbot Small
	",already_has_special_tokens
"Blenderbot Small
	",token_ids_0
"Blenderbot Small
	",token_ids_1
"Blenderbot Small
	",vocab_file
"Blenderbot Small
	",token_ids_0
"Blenderbot Small
	",token_ids_1
"Blenderbot Small
	",config
"Blenderbot Small
	",input_ids
"Blenderbot Small
	",attention_mask
"Blenderbot Small
	",decoder_input_ids
"Blenderbot Small
	",decoder_attention_mask
"Blenderbot Small
	",head_mask
"Blenderbot Small
	",decoder_head_mask
"Blenderbot Small
	",cross_attn_head_mask
"Blenderbot Small
	",encoder_outputs
"Blenderbot Small
	",past_key_values
"Blenderbot Small
	",decoder_inputs_embeds
"Blenderbot Small
	",use_cache
"Blenderbot Small
	",output_attentions
"Blenderbot Small
	",output_hidden_states
"Blenderbot Small
	",return_dict
"Blenderbot Small
	",config
"Blenderbot Small
	",input_ids
"Blenderbot Small
	",attention_mask
"Blenderbot Small
	",decoder_input_ids
"Blenderbot Small
	",decoder_attention_mask
"Blenderbot Small
	",head_mask
"Blenderbot Small
	",decoder_head_mask
"Blenderbot Small
	",cross_attn_head_mask
"Blenderbot Small
	",encoder_outputs
"Blenderbot Small
	",past_key_values
"Blenderbot Small
	",decoder_inputs_embeds
"Blenderbot Small
	",use_cache
"Blenderbot Small
	",output_attentions
"Blenderbot Small
	",output_hidden_states
"Blenderbot Small
	",return_dict
"Blenderbot Small
	",labels
"Blenderbot Small
	",input_ids
"Blenderbot Small
	",attention_mask
"Blenderbot Small
	",encoder_hidden_states
"Blenderbot Small
	",encoder_attention_mask
"Blenderbot Small
	",head_mask
"Blenderbot Small
	",cross_attn_head_mask
"Blenderbot Small
	",past_key_values
"Blenderbot Small
	",labels
"Blenderbot Small
	",use_cache
"Blenderbot Small
	",output_attentions
"Blenderbot Small
	",output_hidden_states
"Blenderbot Small
	",return_dict
"Blenderbot Small
	",config
"Blenderbot Small
	",input_ids
"Blenderbot Small
	",attention_mask
"Blenderbot Small
	",decoder_input_ids
"Blenderbot Small
	",decoder_attention_mask
"Blenderbot Small
	",decoder_position_ids
"Blenderbot Small
	",head_mask
"Blenderbot Small
	",decoder_head_mask
"Blenderbot Small
	",cross_attn_head_mask
"Blenderbot Small
	",encoder_outputs
"Blenderbot Small
	",past_key_values
"Blenderbot Small
	",use_cache
"Blenderbot Small
	",output_attentions
"Blenderbot Small
	",output_hidden_states
"Blenderbot Small
	",return_dict
"Blenderbot Small
	",training
"Blenderbot Small
	",config
"Blenderbot Small
	",input_ids
"Blenderbot Small
	",attention_mask
"Blenderbot Small
	",decoder_input_ids
"Blenderbot Small
	",decoder_attention_mask
"Blenderbot Small
	",decoder_position_ids
"Blenderbot Small
	",head_mask
"Blenderbot Small
	",decoder_head_mask
"Blenderbot Small
	",cross_attn_head_mask
"Blenderbot Small
	",encoder_outputs
"Blenderbot Small
	",past_key_values
"Blenderbot Small
	",use_cache
"Blenderbot Small
	",output_attentions
"Blenderbot Small
	",output_hidden_states
"Blenderbot Small
	",return_dict
"Blenderbot Small
	",training
"Blenderbot Small
	",labels
"Blenderbot Small
	",config
"Blenderbot Small
	",dtype
"Blenderbot Small
	",input_ids
"Blenderbot Small
	",attention_mask
"Blenderbot Small
	",position_ids
"Blenderbot Small
	",output_attentions
"Blenderbot Small
	",output_hidden_states
"Blenderbot Small
	",return_dict
"Blenderbot Small
	",decoder_input_ids
"Blenderbot Small
	",encoder_outputs
"Blenderbot Small
	",encoder_attention_mask
"Blenderbot Small
	",decoder_attention_mask
"Blenderbot Small
	",decoder_position_ids
"Blenderbot Small
	",past_key_values
"Blenderbot Small
	",output_attentions
"Blenderbot Small
	",output_hidden_states
"Blenderbot Small
	",return_dict
"Blenderbot Small
	",config
"Blenderbot Small
	",dtype
"Blenderbot Small
	",input_ids
"Blenderbot Small
	",attention_mask
"Blenderbot Small
	",decoder_input_ids
"Blenderbot Small
	",decoder_attention_mask
"Blenderbot Small
	",position_ids
"Blenderbot Small
	",decoder_position_ids
"Blenderbot Small
	",output_attentions
"Blenderbot Small
	",output_hidden_states
"Blenderbot Small
	",return_dict
"Blenderbot Small
	",input_ids
"Blenderbot Small
	",attention_mask
"Blenderbot Small
	",position_ids
"Blenderbot Small
	",output_attentions
"Blenderbot Small
	",output_hidden_states
"Blenderbot Small
	",return_dict
"Blenderbot Small
	",decoder_input_ids
"Blenderbot Small
	",encoder_outputs
"Blenderbot Small
	",encoder_attention_mask
"Blenderbot Small
	",decoder_attention_mask
"Blenderbot Small
	",decoder_position_ids
"Blenderbot Small
	",past_key_values
"Blenderbot Small
	",output_attentions
"Blenderbot Small
	",output_hidden_states
"Blenderbot Small
	",return_dict
"Blenderbot
	",vocab_size
"Blenderbot
	",d_model
"Blenderbot
	",encoder_layers
"Blenderbot
	",decoder_layers
"Blenderbot
	",encoder_attention_heads
"Blenderbot
	",decoder_attention_heads
"Blenderbot
	",decoder_ffn_dim
"Blenderbot
	",encoder_ffn_dim
"Blenderbot
	",activation_function
"Blenderbot
	",dropout
"Blenderbot
	",attention_dropout
"Blenderbot
	",activation_dropout
"Blenderbot
	",classifier_dropout
"Blenderbot
	",max_position_embeddings
"Blenderbot
	",init_std
"Blenderbot
	",encoder_layerdrop
"Blenderbot
	",decoder_layerdrop
"Blenderbot
	",scale_embedding
"Blenderbot
	",use_cache
"Blenderbot
	",forced_eos_token_id
"Blenderbot
	",vocab_file
"Blenderbot
	",merges_file
"Blenderbot
	",errors
"Blenderbot
	",bos_token
"Blenderbot
	",eos_token
"Blenderbot
	",sep_token
"Blenderbot
	",cls_token
"Blenderbot
	",unk_token
"Blenderbot
	",pad_token
"Blenderbot
	",mask_token
"Blenderbot
	",add_prefix_space
"Blenderbot
	",token_ids_0
"Blenderbot
	",token_ids_1
"Blenderbot
	",vocab_file
"Blenderbot
	",merges_file
"Blenderbot
	",errors
"Blenderbot
	",bos_token
"Blenderbot
	",eos_token
"Blenderbot
	",sep_token
"Blenderbot
	",cls_token
"Blenderbot
	",unk_token
"Blenderbot
	",pad_token
"Blenderbot
	",mask_token
"Blenderbot
	",add_prefix_space
"Blenderbot
	",trim_offsets
"Blenderbot
	",token_ids_0
"Blenderbot
	",token_ids_1
"Blenderbot
	",config
"Blenderbot
	",input_ids
"Blenderbot
	",attention_mask
"Blenderbot
	",decoder_input_ids
"Blenderbot
	",decoder_attention_mask
"Blenderbot
	",head_mask
"Blenderbot
	",decoder_head_mask
"Blenderbot
	",cross_attn_head_mask
"Blenderbot
	",encoder_outputs
"Blenderbot
	",past_key_values
"Blenderbot
	",decoder_inputs_embeds
"Blenderbot
	",use_cache
"Blenderbot
	",output_attentions
"Blenderbot
	",output_hidden_states
"Blenderbot
	",return_dict
"Blenderbot
	",config
"Blenderbot
	",input_ids
"Blenderbot
	",attention_mask
"Blenderbot
	",decoder_input_ids
"Blenderbot
	",decoder_attention_mask
"Blenderbot
	",head_mask
"Blenderbot
	",decoder_head_mask
"Blenderbot
	",cross_attn_head_mask
"Blenderbot
	",encoder_outputs
"Blenderbot
	",past_key_values
"Blenderbot
	",decoder_inputs_embeds
"Blenderbot
	",use_cache
"Blenderbot
	",output_attentions
"Blenderbot
	",output_hidden_states
"Blenderbot
	",return_dict
"Blenderbot
	",labels
"Blenderbot
	",input_ids
"Blenderbot
	",attention_mask
"Blenderbot
	",encoder_hidden_states
"Blenderbot
	",encoder_attention_mask
"Blenderbot
	",head_mask
"Blenderbot
	",cross_attn_head_mask
"Blenderbot
	",past_key_values
"Blenderbot
	",labels
"Blenderbot
	",use_cache
"Blenderbot
	",output_attentions
"Blenderbot
	",output_hidden_states
"Blenderbot
	",return_dict
"Blenderbot
	",config
"Blenderbot
	",input_ids
"Blenderbot
	",attention_mask
"Blenderbot
	",decoder_input_ids
"Blenderbot
	",decoder_attention_mask
"Blenderbot
	",decoder_position_ids
"Blenderbot
	",head_mask
"Blenderbot
	",decoder_head_mask
"Blenderbot
	",cross_attn_head_mask
"Blenderbot
	",encoder_outputs
"Blenderbot
	",past_key_values
"Blenderbot
	",use_cache
"Blenderbot
	",output_attentions
"Blenderbot
	",output_hidden_states
"Blenderbot
	",return_dict
"Blenderbot
	",training
"Blenderbot
	",config
"Blenderbot
	",input_ids
"Blenderbot
	",attention_mask
"Blenderbot
	",decoder_input_ids
"Blenderbot
	",decoder_attention_mask
"Blenderbot
	",decoder_position_ids
"Blenderbot
	",head_mask
"Blenderbot
	",decoder_head_mask
"Blenderbot
	",cross_attn_head_mask
"Blenderbot
	",encoder_outputs
"Blenderbot
	",past_key_values
"Blenderbot
	",use_cache
"Blenderbot
	",output_attentions
"Blenderbot
	",output_hidden_states
"Blenderbot
	",return_dict
"Blenderbot
	",training
"Blenderbot
	",labels
"Blenderbot
	",config
"Blenderbot
	",input_ids
"Blenderbot
	",attention_mask
"Blenderbot
	",decoder_input_ids
"Blenderbot
	",decoder_attention_mask
"Blenderbot
	",position_ids
"Blenderbot
	",decoder_position_ids
"Blenderbot
	",output_attentions
"Blenderbot
	",output_hidden_states
"Blenderbot
	",return_dict
"Blenderbot
	",input_ids
"Blenderbot
	",attention_mask
"Blenderbot
	",position_ids
"Blenderbot
	",output_attentions
"Blenderbot
	",output_hidden_states
"Blenderbot
	",return_dict
"Blenderbot
	",decoder_input_ids
"Blenderbot
	",encoder_outputs
"Blenderbot
	",encoder_attention_mask
"Blenderbot
	",decoder_attention_mask
"Blenderbot
	",decoder_position_ids
"Blenderbot
	",past_key_values
"Blenderbot
	",output_attentions
"Blenderbot
	",output_hidden_states
"Blenderbot
	",return_dict
"Blenderbot
	",config
"Blenderbot
	",input_ids
"Blenderbot
	",attention_mask
"Blenderbot
	",decoder_input_ids
"Blenderbot
	",decoder_attention_mask
"Blenderbot
	",position_ids
"Blenderbot
	",decoder_position_ids
"Blenderbot
	",output_attentions
"Blenderbot
	",output_hidden_states
"Blenderbot
	",return_dict
"Blenderbot
	",input_ids
"Blenderbot
	",attention_mask
"Blenderbot
	",position_ids
"Blenderbot
	",output_attentions
"Blenderbot
	",output_hidden_states
"Blenderbot
	",return_dict
"Blenderbot
	",decoder_input_ids
"Blenderbot
	",encoder_outputs
"Blenderbot
	",encoder_attention_mask
"Blenderbot
	",decoder_attention_mask
"Blenderbot
	",decoder_position_ids
"Blenderbot
	",past_key_values
"Blenderbot
	",output_attentions
"Blenderbot
	",output_hidden_states
"Blenderbot
	",return_dict
"BigBirdPegasus
	",vocab_size
"BigBirdPegasus
	",d_model
"BigBirdPegasus
	",encoder_layers
"BigBirdPegasus
	",decoder_layers
"BigBirdPegasus
	",encoder_attention_heads
"BigBirdPegasus
	",decoder_attention_heads
"BigBirdPegasus
	",decoder_ffn_dim
"BigBirdPegasus
	",encoder_ffn_dim
"BigBirdPegasus
	",activation_function
"BigBirdPegasus
	",dropout
"BigBirdPegasus
	",attention_dropout
"BigBirdPegasus
	",activation_dropout
"BigBirdPegasus
	",classifier_dropout
"BigBirdPegasus
	",max_position_embeddings
"BigBirdPegasus
	",init_std
"BigBirdPegasus
	",encoder_layerdrop
"BigBirdPegasus
	",decoder_layerdrop
"BigBirdPegasus
	",use_cache
"BigBirdPegasus
	",attention_type
"BigBirdPegasus
	",use_bias
"BigBirdPegasus
	",block_size
"BigBirdPegasus
	",num_random_blocks
"BigBirdPegasus
	",scale_embeddings
"BigBirdPegasus
	",config
"BigBirdPegasus
	",input_ids
"BigBirdPegasus
	",attention_mask
"BigBirdPegasus
	",decoder_input_ids
"BigBirdPegasus
	",decoder_attention_mask
"BigBirdPegasus
	",decoder_head_mask
"BigBirdPegasus
	",encoder_outputs
"BigBirdPegasus
	",past_key_values
"BigBirdPegasus
	",decoder_inputs_embeds
"BigBirdPegasus
	",use_cache
"BigBirdPegasus
	",output_attentions
"BigBirdPegasus
	",output_hidden_states
"BigBirdPegasus
	",return_dict
"BigBirdPegasus
	",config
"BigBirdPegasus
	",input_ids
"BigBirdPegasus
	",attention_mask
"BigBirdPegasus
	",decoder_input_ids
"BigBirdPegasus
	",decoder_attention_mask
"BigBirdPegasus
	",decoder_head_mask
"BigBirdPegasus
	",encoder_outputs
"BigBirdPegasus
	",past_key_values
"BigBirdPegasus
	",decoder_inputs_embeds
"BigBirdPegasus
	",use_cache
"BigBirdPegasus
	",output_attentions
"BigBirdPegasus
	",output_hidden_states
"BigBirdPegasus
	",return_dict
"BigBirdPegasus
	",labels
"BigBirdPegasus
	",config
"BigBirdPegasus
	",input_ids
"BigBirdPegasus
	",attention_mask
"BigBirdPegasus
	",decoder_input_ids
"BigBirdPegasus
	",decoder_attention_mask
"BigBirdPegasus
	",decoder_head_mask
"BigBirdPegasus
	",encoder_outputs
"BigBirdPegasus
	",past_key_values
"BigBirdPegasus
	",decoder_inputs_embeds
"BigBirdPegasus
	",use_cache
"BigBirdPegasus
	",output_attentions
"BigBirdPegasus
	",output_hidden_states
"BigBirdPegasus
	",return_dict
"BigBirdPegasus
	",labels
"BigBirdPegasus
	",config
"BigBirdPegasus
	",input_ids
"BigBirdPegasus
	",attention_mask
"BigBirdPegasus
	",decoder_input_ids
"BigBirdPegasus
	",decoder_attention_mask
"BigBirdPegasus
	",decoder_head_mask
"BigBirdPegasus
	",encoder_outputs
"BigBirdPegasus
	",past_key_values
"BigBirdPegasus
	",decoder_inputs_embeds
"BigBirdPegasus
	",use_cache
"BigBirdPegasus
	",output_attentions
"BigBirdPegasus
	",output_hidden_states
"BigBirdPegasus
	",return_dict
"BigBirdPegasus
	",start_positions
"BigBirdPegasus
	",end_positions
"BigBirdPegasus
	",input_ids
"BigBirdPegasus
	",attention_mask
"BigBirdPegasus
	",encoder_hidden_states
"BigBirdPegasus
	",encoder_attention_mask
"BigBirdPegasus
	",head_mask
"BigBirdPegasus
	",cross_attn_head_mask
"BigBirdPegasus
	",past_key_values
"BigBirdPegasus
	",labels
"BigBirdPegasus
	",use_cache
"BigBirdPegasus
	",output_attentions
"BigBirdPegasus
	",output_hidden_states
"BigBirdPegasus
	",return_dict
"BigBird
	",vocab_size
"BigBird
	",hidden_size
"BigBird
	",num_hidden_layers
"BigBird
	",num_attention_heads
"BigBird
	",intermediate_size
"BigBird
	",hidden_act
"BigBird
	",hidden_dropout_prob
"BigBird
	",attention_probs_dropout_prob
"BigBird
	",max_position_embeddings
"BigBird
	",type_vocab_size
"BigBird
	",initializer_range
"BigBird
	",layer_norm_eps
"BigBird
	",use_cache
"BigBird
	",attention_type
"BigBird
	",use_bias
"BigBird
	",rescale_embeddings
"BigBird
	",block_size
"BigBird
	",num_random_blocks
"BigBird
	",classifier_dropout
"BigBird
	",vocab_file
"BigBird
	",eos_token
"BigBird
	",bos_token
"BigBird
	",unk_token
"BigBird
	",pad_token
"BigBird
	",sep_token
"BigBird
	",cls_token
"BigBird
	",mask_token
"BigBird
	",sp_model_kwargs
"BigBird
	",token_ids_0
"BigBird
	",token_ids_1
"BigBird
	",token_ids_0
"BigBird
	",token_ids_1
"BigBird
	",already_has_special_tokens
"BigBird
	",token_ids_0
"BigBird
	",token_ids_1
"BigBird
	",vocab_file
"BigBird
	",bos_token
"BigBird
	",eos_token
"BigBird
	",unk_token
"BigBird
	",sep_token
"BigBird
	",pad_token
"BigBird
	",cls_token
"BigBird
	",mask_token
"BigBird
	",token_ids_0
"BigBird
	",token_ids_1
"BigBird
	",token_ids_0
"BigBird
	",token_ids_1
"BigBird
	",token_ids_0
"BigBird
	",token_ids_1
"BigBird
	",already_has_special_tokens
"BigBird
	",loss
"BigBird
	",prediction_logits
"BigBird
	",seq_relationship_logits
"BigBird
	",hidden_states
"BigBird
	",attentions
"BigBird
	",config
"BigBird
	",input_ids
"BigBird
	",attention_mask
"BigBird
	",token_type_ids
"BigBird
	",position_ids
"BigBird
	",head_mask
"BigBird
	",inputs_embeds
"BigBird
	",output_attentions
"BigBird
	",output_hidden_states
"BigBird
	",return_dict
"BigBird
	",encoder_hidden_states
"BigBird
	",encoder_attention_mask
"BigBird
	",past_key_values
"BigBird
	",use_cache
"BigBird
	",input_ids
"BigBird
	",attention_mask
"BigBird
	",token_type_ids
"BigBird
	",position_ids
"BigBird
	",head_mask
"BigBird
	",inputs_embeds
"BigBird
	",output_attentions
"BigBird
	",output_hidden_states
"BigBird
	",return_dict
"BigBird
	",labels
"BigBird
	",next_sentence_label
"BigBird
	",kwargs
"BigBird
	",config
"BigBird
	",input_ids
"BigBird
	",attention_mask
"BigBird
	",token_type_ids
"BigBird
	",position_ids
"BigBird
	",head_mask
"BigBird
	",inputs_embeds
"BigBird
	",output_attentions
"BigBird
	",output_hidden_states
"BigBird
	",return_dict
"BigBird
	",encoder_hidden_states
"BigBird
	",encoder_attention_mask
"BigBird
	",past_key_values
"BigBird
	",labels
"BigBird
	",use_cache
"BigBird
	",config
"BigBird
	",input_ids
"BigBird
	",attention_mask
"BigBird
	",token_type_ids
"BigBird
	",position_ids
"BigBird
	",head_mask
"BigBird
	",inputs_embeds
"BigBird
	",output_attentions
"BigBird
	",output_hidden_states
"BigBird
	",return_dict
"BigBird
	",labels
"BigBird
	",config
"BigBird
	",input_ids
"BigBird
	",attention_mask
"BigBird
	",token_type_ids
"BigBird
	",position_ids
"BigBird
	",head_mask
"BigBird
	",inputs_embeds
"BigBird
	",output_attentions
"BigBird
	",output_hidden_states
"BigBird
	",return_dict
"BigBird
	",labels
"BigBird
	",config
"BigBird
	",input_ids
"BigBird
	",attention_mask
"BigBird
	",token_type_ids
"BigBird
	",position_ids
"BigBird
	",head_mask
"BigBird
	",inputs_embeds
"BigBird
	",output_attentions
"BigBird
	",output_hidden_states
"BigBird
	",return_dict
"BigBird
	",labels
"BigBird
	",config
"BigBird
	",input_ids
"BigBird
	",attention_mask
"BigBird
	",token_type_ids
"BigBird
	",position_ids
"BigBird
	",head_mask
"BigBird
	",inputs_embeds
"BigBird
	",output_attentions
"BigBird
	",output_hidden_states
"BigBird
	",return_dict
"BigBird
	",labels
"BigBird
	",config
"BigBird
	",input_ids
"BigBird
	",attention_mask
"BigBird
	",token_type_ids
"BigBird
	",position_ids
"BigBird
	",head_mask
"BigBird
	",inputs_embeds
"BigBird
	",output_attentions
"BigBird
	",output_hidden_states
"BigBird
	",return_dict
"BigBird
	",start_positions
"BigBird
	",end_positions
"BigBird
	",config
"BigBird
	",dtype
"BigBird
	",input_ids
"BigBird
	",attention_mask
"BigBird
	",token_type_ids
"BigBird
	",position_ids
"BigBird
	",head_mask
"BigBird
	",return_dict
"BigBird
	",config
"BigBird
	",dtype
"BigBird
	",input_ids
"BigBird
	",attention_mask
"BigBird
	",token_type_ids
"BigBird
	",position_ids
"BigBird
	",head_mask
"BigBird
	",return_dict
"BigBird
	",config
"BigBird
	",dtype
"BigBird
	",input_ids
"BigBird
	",attention_mask
"BigBird
	",token_type_ids
"BigBird
	",position_ids
"BigBird
	",head_mask
"BigBird
	",return_dict
"BigBird
	",config
"BigBird
	",dtype
"BigBird
	",input_ids
"BigBird
	",attention_mask
"BigBird
	",token_type_ids
"BigBird
	",position_ids
"BigBird
	",head_mask
"BigBird
	",return_dict
"BigBird
	",config
"BigBird
	",dtype
"BigBird
	",input_ids
"BigBird
	",attention_mask
"BigBird
	",token_type_ids
"BigBird
	",position_ids
"BigBird
	",head_mask
"BigBird
	",return_dict
"BigBird
	",config
"BigBird
	",dtype
"BigBird
	",input_ids
"BigBird
	",attention_mask
"BigBird
	",token_type_ids
"BigBird
	",position_ids
"BigBird
	",head_mask
"BigBird
	",return_dict
"BigBird
	",config
"BigBird
	",dtype
"BigBird
	",input_ids
"BigBird
	",attention_mask
"BigBird
	",token_type_ids
"BigBird
	",position_ids
"BigBird
	",head_mask
"BigBird
	",return_dict
"BigBird
	",config
"BigBird
	",dtype
"BigBird
	",input_ids
"BigBird
	",attention_mask
"BigBird
	",token_type_ids
"BigBird
	",position_ids
"BigBird
	",head_mask
"BigBird
	",return_dict
"BERTweet
	",vocab_file
"BERTweet
	",merges_file
"BERTweet
	",normalization
"BERTweet
	",bos_token
"BERTweet
	",eos_token
"BERTweet
	",sep_token
"BERTweet
	",cls_token
"BERTweet
	",unk_token
"BERTweet
	",pad_token
"BERTweet
	",mask_token
"BERTweet
	",token_ids_0
"BERTweet
	",token_ids_1
"BERTweet
	",token_ids_0
"BERTweet
	",token_ids_1
"BERTweet
	",token_ids_0
"BERTweet
	",token_ids_1
"BERTweet
	",already_has_special_tokens
"BertJapanese
	",vocab_file
"BertJapanese
	",do_lower_case
"BertJapanese
	",do_word_tokenize
"BertJapanese
	",do_subword_tokenize
"BertJapanese
	",word_tokenizer_type
"BertJapanese
	",subword_tokenizer_type
"BertJapanese
	",mecab_kwargs
"BertJapanese
	",sudachi_kwargs
"BertJapanese
	",jumanpp_kwargs
"BertGeneration
	",vocab_size
"BertGeneration
	",hidden_size
"BertGeneration
	",num_hidden_layers
"BertGeneration
	",num_attention_heads
"BertGeneration
	",intermediate_size
"BertGeneration
	",hidden_act
"BertGeneration
	",hidden_dropout_prob
"BertGeneration
	",attention_probs_dropout_prob
"BertGeneration
	",max_position_embeddings
"BertGeneration
	",initializer_range
"BertGeneration
	",layer_norm_eps
"BertGeneration
	",position_embedding_type
"BertGeneration
	",use_cache
"BertGeneration
	",vocab_file
"BertGeneration
	",eos_token
"BertGeneration
	",bos_token
"BertGeneration
	",unk_token
"BertGeneration
	",pad_token
"BertGeneration
	",sp_model_kwargs
"BertGeneration
	",config
"BertGeneration
	",input_ids
"BertGeneration
	",attention_mask
"BertGeneration
	",position_ids
"BertGeneration
	",head_mask
"BertGeneration
	",inputs_embeds
"BertGeneration
	",output_attentions
"BertGeneration
	",output_hidden_states
"BertGeneration
	",return_dict
"BertGeneration
	",encoder_hidden_states
"BertGeneration
	",encoder_attention_mask
"BertGeneration
	",past_key_values
"BertGeneration
	",use_cache
"BertGeneration
	",config
"BertGeneration
	",input_ids
"BertGeneration
	",attention_mask
"BertGeneration
	",position_ids
"BertGeneration
	",head_mask
"BertGeneration
	",inputs_embeds
"BertGeneration
	",output_attentions
"BertGeneration
	",output_hidden_states
"BertGeneration
	",return_dict
"BertGeneration
	",encoder_hidden_states
"BertGeneration
	",encoder_attention_mask
"BertGeneration
	",labels
"BertGeneration
	",past_key_values
"BertGeneration
	",use_cache
"BERT
	",vocab_size
"BERT
	",hidden_size
"BERT
	",num_hidden_layers
"BERT
	",num_attention_heads
"BERT
	",intermediate_size
"BERT
	",hidden_act
"BERT
	",hidden_dropout_prob
"BERT
	",attention_probs_dropout_prob
"BERT
	",max_position_embeddings
"BERT
	",type_vocab_size
"BERT
	",initializer_range
"BERT
	",layer_norm_eps
"BERT
	",position_embedding_type
"BERT
	",use_cache
"BERT
	",classifier_dropout
"BERT
	",vocab_file
"BERT
	",do_lower_case
"BERT
	",do_basic_tokenize
"BERT
	",never_split
"BERT
	",unk_token
"BERT
	",sep_token
"BERT
	",pad_token
"BERT
	",cls_token
"BERT
	",mask_token
"BERT
	",tokenize_chinese_chars
"BERT
	",strip_accents
"BERT
	",token_ids_0
"BERT
	",token_ids_1
"BERT
	",token_ids_0
"BERT
	",token_ids_1
"BERT
	",already_has_special_tokens
"BERT
	",token_ids_0
"BERT
	",token_ids_1
"BERT
	",vocab_file
"BERT
	",do_lower_case
"BERT
	",unk_token
"BERT
	",sep_token
"BERT
	",pad_token
"BERT
	",cls_token
"BERT
	",mask_token
"BERT
	",clean_text
"BERT
	",tokenize_chinese_chars
"BERT
	",strip_accents
"BERT
	",wordpieces_prefix
"BERT
	",token_ids_0
"BERT
	",token_ids_1
"BERT
	",token_ids_0
"BERT
	",token_ids_1
"BERT
	",vocab_list
"BERT
	",do_lower_case
"BERT
	",cls_token_id
"BERT
	",sep_token_id
"BERT
	",pad_token_id
"BERT
	",padding
"BERT
	",truncation
"BERT
	",max_length
"BERT
	",pad_to_multiple_of
"BERT
	",return_token_type_ids
"BERT
	",return_attention_mask
"BERT
	",pretrained_model_name_or_path
"BERT
	",tokenizer
"BERT
	",loss
"BERT
	",prediction_logits
"BERT
	",seq_relationship_logits
"BERT
	",hidden_states
"BERT
	",attentions
"BERT
	",prediction_logits
"BERT
	",seq_relationship_logits
"BERT
	",hidden_states
"BERT
	",attentions
"BERT
	",prediction_logits
"BERT
	",seq_relationship_logits
"BERT
	",hidden_states
"BERT
	",attentions
"BERT
	",config
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",inputs_embeds
"BERT
	",output_attentions
"BERT
	",output_hidden_states
"BERT
	",return_dict
"BERT
	",encoder_hidden_states
"BERT
	",encoder_attention_mask
"BERT
	",past_key_values
"BERT
	",use_cache
"BERT
	",config
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",inputs_embeds
"BERT
	",output_attentions
"BERT
	",output_hidden_states
"BERT
	",return_dict
"BERT
	",config
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",inputs_embeds
"BERT
	",output_attentions
"BERT
	",output_hidden_states
"BERT
	",return_dict
"BERT
	",encoder_hidden_states
"BERT
	",encoder_attention_mask
"BERT
	",labels
"BERT
	",past_key_values
"BERT
	",use_cache
"BERT
	",config
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",inputs_embeds
"BERT
	",output_attentions
"BERT
	",output_hidden_states
"BERT
	",return_dict
"BERT
	",labels
"BERT
	",config
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",inputs_embeds
"BERT
	",output_attentions
"BERT
	",output_hidden_states
"BERT
	",return_dict
"BERT
	",labels
"BERT
	",config
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",inputs_embeds
"BERT
	",output_attentions
"BERT
	",output_hidden_states
"BERT
	",return_dict
"BERT
	",labels
"BERT
	",config
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",inputs_embeds
"BERT
	",output_attentions
"BERT
	",output_hidden_states
"BERT
	",return_dict
"BERT
	",labels
"BERT
	",config
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",inputs_embeds
"BERT
	",output_attentions
"BERT
	",output_hidden_states
"BERT
	",return_dict
"BERT
	",labels
"BERT
	",config
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",inputs_embeds
"BERT
	",output_attentions
"BERT
	",output_hidden_states
"BERT
	",return_dict
"BERT
	",start_positions
"BERT
	",end_positions
"BERT
	",config
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",inputs_embeds
"BERT
	",output_attentions
"BERT
	",output_hidden_states
"BERT
	",return_dict
"BERT
	",training
"BERT
	",encoder_hidden_states
"BERT
	",encoder_attention_mask
"BERT
	",past_key_values
"BERT
	",use_cache
"BERT
	",config
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",inputs_embeds
"BERT
	",output_attentions
"BERT
	",output_hidden_states
"BERT
	",return_dict
"BERT
	",training
"BERT
	",labels
"BERT
	",next_sentence_label
"BERT
	",kwargs
"BERT
	",config
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",inputs_embeds
"BERT
	",output_attentions
"BERT
	",output_hidden_states
"BERT
	",return_dict
"BERT
	",training
"BERT
	",labels
"BERT
	",config
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",inputs_embeds
"BERT
	",output_attentions
"BERT
	",output_hidden_states
"BERT
	",return_dict
"BERT
	",training
"BERT
	",config
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",inputs_embeds
"BERT
	",output_attentions
"BERT
	",output_hidden_states
"BERT
	",return_dict
"BERT
	",training
"BERT
	",labels
"BERT
	",config
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",inputs_embeds
"BERT
	",output_attentions
"BERT
	",output_hidden_states
"BERT
	",return_dict
"BERT
	",training
"BERT
	",labels
"BERT
	",config
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",inputs_embeds
"BERT
	",output_attentions
"BERT
	",output_hidden_states
"BERT
	",return_dict
"BERT
	",training
"BERT
	",labels
"BERT
	",config
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",inputs_embeds
"BERT
	",output_attentions
"BERT
	",output_hidden_states
"BERT
	",return_dict
"BERT
	",training
"BERT
	",start_positions
"BERT
	",end_positions
"BERT
	",config
"BERT
	",dtype
"BERT
	",dtype
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",return_dict
"BERT
	",config
"BERT
	",dtype
"BERT
	",dtype
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",return_dict
"BERT
	",config
"BERT
	",dtype
"BERT
	",dtype
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",return_dict
"BERT
	",config
"BERT
	",dtype
"BERT
	",dtype
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",return_dict
"BERT
	",config
"BERT
	",dtype
"BERT
	",dtype
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",return_dict
"BERT
	",config
"BERT
	",dtype
"BERT
	",dtype
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",return_dict
"BERT
	",config
"BERT
	",dtype
"BERT
	",dtype
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",return_dict
"BERT
	",config
"BERT
	",dtype
"BERT
	",dtype
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",return_dict
"BERT
	",config
"BERT
	",dtype
"BERT
	",dtype
"BERT
	",input_ids
"BERT
	",attention_mask
"BERT
	",token_type_ids
"BERT
	",position_ids
"BERT
	",head_mask
"BERT
	",return_dict
"BARTpho
	",vocab_file
"BARTpho
	",monolingual_vocab_file
"BARTpho
	",bos_token
"BARTpho
	",eos_token
"BARTpho
	",sep_token
"BARTpho
	",cls_token
"BARTpho
	",unk_token
"BARTpho
	",pad_token
"BARTpho
	",mask_token
"BARTpho
	",additional_special_tokens
"BARTpho
	",sp_model_kwargs
"BARTpho
	",sp_model
"BARTpho
	",token_ids_0
"BARTpho
	",token_ids_1
"BARTpho
	",token_ids_0
"BARTpho
	",token_ids_1
"BARTpho
	",token_ids_0
"BARTpho
	",token_ids_1
"BARTpho
	",already_has_special_tokens
"BARThez
	",vocab_file
"BARThez
	",bos_token
"BARThez
	",eos_token
"BARThez
	",sep_token
"BARThez
	",cls_token
"BARThez
	",unk_token
"BARThez
	",pad_token
"BARThez
	",mask_token
"BARThez
	",additional_special_tokens
"BARThez
	",sp_model_kwargs
"BARThez
	",sp_model
"BARThez
	",token_ids_0
"BARThez
	",token_ids_1
"BARThez
	",token_ids_0
"BARThez
	",token_ids_1
"BARThez
	",token_ids_0
"BARThez
	",token_ids_1
"BARThez
	",already_has_special_tokens
"BARThez
	",vocab_file
"BARThez
	",bos_token
"BARThez
	",eos_token
"BARThez
	",sep_token
"BARThez
	",cls_token
"BARThez
	",unk_token
"BARThez
	",pad_token
"BARThez
	",mask_token
"BARThez
	",additional_special_tokens
"BARThez
	",token_ids_0
"BARThez
	",token_ids_1
"BARThez
	",token_ids_0
"BARThez
	",token_ids_1
"BART
	",vocab_size
"BART
	",d_model
"BART
	",encoder_layers
"BART
	",decoder_layers
"BART
	",encoder_attention_heads
"BART
	",decoder_attention_heads
"BART
	",decoder_ffn_dim
"BART
	",encoder_ffn_dim
"BART
	",activation_function
"BART
	",dropout
"BART
	",attention_dropout
"BART
	",activation_dropout
"BART
	",classifier_dropout
"BART
	",max_position_embeddings
"BART
	",init_std
"BART
	",encoder_layerdrop
"BART
	",decoder_layerdrop
"BART
	",scale_embedding
"BART
	",use_cache
"BART
	",num_labels
"BART
	",forced_eos_token_id
"BART
	",vocab_file
"BART
	",merges_file
"BART
	",errors
"BART
	",bos_token
"BART
	",eos_token
"BART
	",sep_token
"BART
	",cls_token
"BART
	",unk_token
"BART
	",pad_token
"BART
	",mask_token
"BART
	",add_prefix_space
"BART
	",token_ids_0
"BART
	",token_ids_1
"BART
	",token_ids_0
"BART
	",token_ids_1
"BART
	",token_ids_0
"BART
	",token_ids_1
"BART
	",already_has_special_tokens
"BART
	",vocab_file
"BART
	",merges_file
"BART
	",errors
"BART
	",bos_token
"BART
	",eos_token
"BART
	",sep_token
"BART
	",cls_token
"BART
	",unk_token
"BART
	",pad_token
"BART
	",mask_token
"BART
	",add_prefix_space
"BART
	",trim_offsets
"BART
	",token_ids_0
"BART
	",token_ids_1
"BART
	",config
"BART
	",input_ids
"BART
	",attention_mask
"BART
	",decoder_input_ids
"BART
	",decoder_attention_mask
"BART
	",head_mask
"BART
	",decoder_head_mask
"BART
	",cross_attn_head_mask
"BART
	",encoder_outputs
"BART
	",past_key_values
"BART
	",decoder_inputs_embeds
"BART
	",use_cache
"BART
	",output_attentions
"BART
	",output_hidden_states
"BART
	",return_dict
"BART
	",config
"BART
	",input_ids
"BART
	",attention_mask
"BART
	",decoder_input_ids
"BART
	",decoder_attention_mask
"BART
	",head_mask
"BART
	",decoder_head_mask
"BART
	",cross_attn_head_mask
"BART
	",encoder_outputs
"BART
	",past_key_values
"BART
	",decoder_inputs_embeds
"BART
	",use_cache
"BART
	",output_attentions
"BART
	",output_hidden_states
"BART
	",return_dict
"BART
	",labels
"BART
	",config
"BART
	",input_ids
"BART
	",attention_mask
"BART
	",decoder_input_ids
"BART
	",decoder_attention_mask
"BART
	",head_mask
"BART
	",decoder_head_mask
"BART
	",cross_attn_head_mask
"BART
	",encoder_outputs
"BART
	",past_key_values
"BART
	",decoder_inputs_embeds
"BART
	",use_cache
"BART
	",output_attentions
"BART
	",output_hidden_states
"BART
	",return_dict
"BART
	",labels
"BART
	",config
"BART
	",input_ids
"BART
	",attention_mask
"BART
	",decoder_input_ids
"BART
	",decoder_attention_mask
"BART
	",head_mask
"BART
	",decoder_head_mask
"BART
	",cross_attn_head_mask
"BART
	",encoder_outputs
"BART
	",past_key_values
"BART
	",decoder_inputs_embeds
"BART
	",use_cache
"BART
	",output_attentions
"BART
	",output_hidden_states
"BART
	",return_dict
"BART
	",start_positions
"BART
	",end_positions
"BART
	",config
"BART
	",input_ids
"BART
	",attention_mask
"BART
	",encoder_hidden_states
"BART
	",encoder_attention_mask
"BART
	",head_mask
"BART
	",cross_attn_head_mask
"BART
	",past_key_values
"BART
	",labels
"BART
	",use_cache
"BART
	",output_attentions
"BART
	",output_hidden_states
"BART
	",return_dict
"BART
	",config
"BART
	",input_ids
"BART
	",attention_mask
"BART
	",decoder_input_ids
"BART
	",decoder_attention_mask
"BART
	",decoder_position_ids
"BART
	",head_mask
"BART
	",decoder_head_mask
"BART
	",cross_attn_head_mask
"BART
	",encoder_outputs
"BART
	",past_key_values
"BART
	",use_cache
"BART
	",output_attentions
"BART
	",output_hidden_states
"BART
	",return_dict
"BART
	",training
"BART
	",config
"BART
	",input_ids
"BART
	",attention_mask
"BART
	",decoder_input_ids
"BART
	",decoder_attention_mask
"BART
	",decoder_position_ids
"BART
	",head_mask
"BART
	",decoder_head_mask
"BART
	",cross_attn_head_mask
"BART
	",encoder_outputs
"BART
	",past_key_values
"BART
	",use_cache
"BART
	",output_attentions
"BART
	",output_hidden_states
"BART
	",return_dict
"BART
	",training
"BART
	",labels
"BART
	",config
"BART
	",dtype
"BART
	",input_ids
"BART
	",attention_mask
"BART
	",decoder_input_ids
"BART
	",decoder_attention_mask
"BART
	",position_ids
"BART
	",decoder_position_ids
"BART
	",output_attentions
"BART
	",output_hidden_states
"BART
	",return_dict
"BART
	",input_ids
"BART
	",attention_mask
"BART
	",position_ids
"BART
	",output_attentions
"BART
	",output_hidden_states
"BART
	",return_dict
"BART
	",decoder_input_ids
"BART
	",encoder_outputs
"BART
	",encoder_attention_mask
"BART
	",decoder_attention_mask
"BART
	",decoder_position_ids
"BART
	",past_key_values
"BART
	",output_attentions
"BART
	",output_hidden_states
"BART
	",return_dict
"BART
	",config
"BART
	",dtype
"BART
	",input_ids
"BART
	",attention_mask
"BART
	",decoder_input_ids
"BART
	",decoder_attention_mask
"BART
	",position_ids
"BART
	",decoder_position_ids
"BART
	",output_attentions
"BART
	",output_hidden_states
"BART
	",return_dict
"BART
	",input_ids
"BART
	",attention_mask
"BART
	",position_ids
"BART
	",output_attentions
"BART
	",output_hidden_states
"BART
	",return_dict
"BART
	",decoder_input_ids
"BART
	",encoder_outputs
"BART
	",encoder_attention_mask
"BART
	",decoder_attention_mask
"BART
	",decoder_position_ids
"BART
	",past_key_values
"BART
	",output_attentions
"BART
	",output_hidden_states
"BART
	",return_dict
"BART
	",config
"BART
	",dtype
"BART
	",input_ids
"BART
	",attention_mask
"BART
	",decoder_input_ids
"BART
	",decoder_attention_mask
"BART
	",position_ids
"BART
	",decoder_position_ids
"BART
	",output_attentions
"BART
	",output_hidden_states
"BART
	",return_dict
"BART
	",input_ids
"BART
	",attention_mask
"BART
	",position_ids
"BART
	",output_attentions
"BART
	",output_hidden_states
"BART
	",return_dict
"BART
	",decoder_input_ids
"BART
	",encoder_outputs
"BART
	",encoder_attention_mask
"BART
	",decoder_attention_mask
"BART
	",decoder_position_ids
"BART
	",past_key_values
"BART
	",output_attentions
"BART
	",output_hidden_states
"BART
	",return_dict
"BART
	",config
"BART
	",dtype
"BART
	",input_ids
"BART
	",attention_mask
"BART
	",decoder_input_ids
"BART
	",decoder_attention_mask
"BART
	",position_ids
"BART
	",decoder_position_ids
"BART
	",output_attentions
"BART
	",output_hidden_states
"BART
	",return_dict
"BART
	",input_ids
"BART
	",attention_mask
"BART
	",position_ids
"BART
	",output_attentions
"BART
	",output_hidden_states
"BART
	",return_dict
"BART
	",decoder_input_ids
"BART
	",encoder_outputs
"BART
	",encoder_attention_mask
"BART
	",decoder_attention_mask
"BART
	",decoder_position_ids
"BART
	",past_key_values
"BART
	",output_attentions
"BART
	",output_hidden_states
"BART
	",return_dict
"BART
	",config
"BART
	",dtype
"BART
	",decoder_input_ids
"BART
	",encoder_outputs
"BART
	",encoder_attention_mask
"BART
	",decoder_attention_mask
"BART
	",decoder_position_ids
"BART
	",past_key_values
"BART
	",output_attentions
"BART
	",output_hidden_states
"BART
	",return_dict
