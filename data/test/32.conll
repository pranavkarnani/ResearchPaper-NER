Proceedings O
of O
the O
12th O
Workshop O
on O
Computational O
Approaches O
to O
Subjectivity, O
Sentiment O
& O
Social O
Media O
Analysis O
, O
pages O
304 O
- O
314 O
May O
26, O
2022 O
c O
2022 O
Association O
for O
Computational O
Linguistics O
Polite B-TaskName
Task-oriented I-TaskName
Dialog I-TaskName
Agents: I-TaskName
To O
Generate O
or O
to O
Rewrite? O
Diogo O
Silva, O
David O
Semedo, O
João O
Magalhães O
NOV O
A O
LINCS O
- O
Universidade O
NOV O
A O
de O
Lisboa O
Lisbon, O
Portugal O
dmgc.silva@campus.fct.unl.pt O
,{df.semedo, O
jmag}@fct.unl.pt O
Abstract O
For O
task-oriented B-TaskName
dialog I-TaskName
agents, I-TaskName
the O
tone O
of O
voice O
mediates O
user-agent O
interactions, O
play- O
ing O
a O
central O
role O
in O
the O
ﬂow O
of O
a O
conversa- O
tion. O
Distinct O
from O
domain-agnostic O
politeness O
constructs, O
in O
speciﬁc O
domains O
such O
as O
online O
stores, O
booking O
platforms, O
and O
others, O
agents O
need O
to O
be O
capable O
of O
adopting O
highly O
speciﬁc O
vocabulary, O
with O
signiﬁcant O
impact O
on O
lexical O
and O
grammatical O
aspects O
of O
utterances. O
Then, O
the O
challenge O
is O
on O
improving O
utterances’ O
po- O
liteness O
while O
preserving O
the O
actual O
content, O
an O
utterly O
central O
requirement O
to O
achieve O
the O
task O
goal. O
In O
this O
paper, O
we O
conduct O
a O
novel O
assess- O
ment O
of O
politeness O
strategies O
for O
task-oriented B-TaskName
dialog I-TaskName
agents I-TaskName
under O
a O
transfer O
learning O
sce- O
nario. O
We O
extend O
existing O
generative O
and O
rewriting O
politeness O
approaches, O
towards O
over- O
coming O
domain-shifting O
issues, O
and O
enabling O
the O
transfer O
of O
politeness O
patterns O
to O
a O
novel O
domain. O
Both O
automatic O
and O
human O
evalua- O
tion O
is O
conducted O
on O
customer-store O
interac- O
tions, O
over O
the O
fashion O
domain, O
from O
which O
contribute O
with O
insightful O
and O
experimentally O
supported O
lessons O
regarding O
the O
improvement O
of O
politeness O
in O
task-speciﬁc O
dialog O
agents. O
1 O
Introduction O
In O
a O
conversational O
scenario, O
the O
tone O
of O
voice O
used O
by O
interlocutors O
is O
a O
key O
aspect O
towards O
achieving O
fruitful, O
engaging, O
and O
natural O
user-agent O
interac- O
tions O
(Brown O
et O
al., O
1987; O
Niu O
and O
Bansal, O
2018). O
This O
is O
deeply O
rooted O
in O
the O
fact O
that O
discoursing O
in O
a O
polite O
manner, O
is O
a O
social O
trait O
of O
human O
conversa- O
tions, O
that O
when O
left O
unattended O
by O
dialog O
agents, O
can O
lead O
to O
an O
immediate O
perception O
of O
artiﬁcial O
discourse O
and O
lack O
of O
intelligent O
behavior, O
which O
in O
turn O
leads O
to O
poor O
engagement. O
Task-oriented O
dialog O
agents O
require O
simultane- O
ously O
keeping O
the O
user O
engaged O
while O
achieving O
the O
task O
goal, O
whether O
it O
is O
selling O
a O
product, O
booking O
a O
restaurant O
or O
simply O
providing O
assistance. O
This O
re- O
quires O
informative O
and O
correct O
answers, O
embedding O
Figure O
1: O
Politeness O
can O
be O
introduced O
either O
by O
incor- O
porating O
it O
in O
the O
generation O
step O
or O
as O
a O
rewritting O
step. O
In O
this O
example O
the O
politeness O
strategy O
adopted O
is O
the O
use O
of O
a O
positive O
lexicon O
. O
domain-speciﬁc O
language, O
while O
keeping O
a O
polite O
tone O
of O
voice O
. O
Being O
able O
to O
accomplish O
this, O
has O
an O
impact O
that O
extrapolates O
isolated O
conversations. O
For O
example, O
in O
the O
fashion O
world, O
the O
tone O
and O
the O
way O
the O
customer O
is O
addressed O
are O
strongly O
linked O
to O
the O
brand O
culture O
(Sousa O
et O
al., O
2021) O
(e.g. O
more O
eloquent O
vs. O
more O
casual O
and O
youthful O
discourse). O
While O
politeness O
is O
a O
deeply O
seeded O
cultural O
con- O
cept O
and O
difﬁcult O
to O
fully O
generalize O
(Meier, O
1995), O
it O
has O
been O
recently O
approached O
from O
a O
computa- O
tional O
perspective O
(Danescu-Niculescu-Mizil O
et O
al., O
2013; O
Niu O
and O
Bansal, O
2018; O
Madaan O
et O
al., O
2020) O
under O
the O
framework O
of O
(Brown O
et O
al., O
1987), O
which O
divides O
politeness O
strategies O
in O
a) O
negative O
polite- O
ness O
- O
where O
polite O
discourse O
is O
achieved O
by O
ex- O
pressing O
restraint, O
thus O
avoiding O
being O
direct O
- O
and304b) O
positive O
politeness O
- O
where O
an O
explicit O
attempt O
of O
expressing O
solidarity, O
optimism O
and O
gratitude O
is O
made. O
Danescu-Niculescu-Mizil O
et O
al. O
(2013) O
took O
a O
pioneering O
approach O
and O
proposed O
to O
approxi- O
mate O
these O
strategies O
by O
creating O
a O
human O
anno- O
tated O
politeness O
corpora, O
and O
training O
a O
classiﬁer O
to O
capture O
general O
linguistic O
patterns O
of O
both O
negative O
and O
positive O
politeness. O
Recent O
works O
leverage O
on O
such O
classiﬁer O
to O
develop O
either O
generative O
(Niu O
and O
Bansal, O
2018; O
Firdaus O
et O
al., O
2020) O
or O
rewriting- O
based O
(Madaan O
et O
al., O
2020; O
Fu O
et O
al., O
2020) O
ap- O
proaches. O
Figure O
1 O
contrasts O
these O
approaches, O
with O
respect O
to O
politeness O
strategies. O
While O
these O
have O
been O
applied O
to O
generic O
and O
domain-agnostic O
sce- O
narios, O
it O
remains O
unclear O
how O
well O
such O
principles O
transfer O
to O
task-speciﬁc O
domains. O
In O
this O
work, O
we O
assess O
under O
a O
transfer-learning O
scenario, O
the O
applicability O
of O
both O
generative O
and O
rewriting O
politeness O
approaches O
to O
a O
novel O
domain. O
Speciﬁcally, O
we O
use O
the O
challenging O
fashion O
do- O
main O
as O
a O
use O
case, O
given O
its O
vocabulary O
complexity O
and O
highly O
speciﬁc-nature1. O
Namely, O
we O
propose O
to O
overcome O
the O
lack O
of O
labeled O
data O
by O
extending O
state-of-the-art O
generative O
(Niu O
and O
Bansal, O
2018) O
and O
rewriting O
(Madaan O
et O
al., O
2020) O
approaches, O
re- O
spectively, O
towards O
allowing O
each O
of O
them O
to O
over- O
come O
the O
domain-shift, O
and O
transferring O
linguistic O
politeness O
constructs O
to O
a O
novel O
(fashion) O
domain. O
This O
is O
one O
of O
the O
ﬁrst O
works O
to O
study O
politeness O
approaches O
for O
task-oriented O
dialog O
agents, O
con- O
tributing O
with: O
•An O
adaptation O
of O
generative O
and O
rewriting O
po- O
liteness O
approaches O
(section O
3), O
enabling O
trans- O
fer O
learning O
for O
speciﬁc O
domains. O
•Comprehensive O
experiments O
(section O
5), O
lead- O
ing O
to O
valuable O
insights O
regarding O
how O
po- O
liteness O
approaches O
deal O
with O
the O
content- O
preservation O
vs. O
politeness O
improvement O
trade-off, O
in O
task-oriented O
dialog O
agents. O
•A O
user-centered O
study O
that O
supports O
and O
con- O
ﬁrms O
the O
conclusions O
of O
the O
automatic O
evalua- O
tion O
(section O
5). O
•Explored O
politeness O
on O
a O
novel O
domain, O
con- O
versational O
assistants O
on O
the O
fashion O
do- O
main O
(Saha O
et O
al., O
2018), O
exposing O
the O
oppor- O
tunities O
for O
improving O
politeness. O
1The O
established O
politeness O
classiﬁer O
of O
Danescu- O
Niculescu-Mizil O
et O
al. O
(2013) O
lacks O
≈15k O
terms O
from O
the O
considered O
fashion O
dialog O
corpus.2 O
Related O
work O
The O
importance O
of O
politeness O
in O
social O
interac- O
tions O
and O
its O
impact O
in O
the O
projected O
self-image O
during O
social O
interactions O
has O
been O
studied O
for O
decades O
(Brown O
et O
al., O
1978, O
1987). O
These O
concepts O
were O
later O
reviewed O
and O
reﬁned O
(Watts, O
2019) O
with O
new O
work O
(Bargiela-Chiappini, O
2003) O
proposing O
the O
label O
of O
’polite O
behavior’ O
to O
separate O
it O
from O
the O
theoretical O
and O
cultural O
baggage O
of O
the O
term O
face- O
work. O
More O
recently, O
Danescu-Niculescu-Mizil O
et O
al. O
(2013) O
introduced O
a O
labeled O
dataset O
(Stanford B-DatasetName
Politeness I-DatasetName
Corpus), I-DatasetName
along O
with O
a O
politeness O
clas- O
siﬁer O
to O
enable O
further O
research O
as O
an O
NLP O
task. O
Additionally, O
they O
look O
into O
how O
politeness O
relates O
to O
the O
speaker’s O
status O
and O
power O
within O
their O
com- O
munity. O
Later O
work O
(Aubakirova O
and O
Bansal, O
2016) O
introduced O
a O
new O
politeness O
classiﬁer O
and O
several O
visualization O
techniques O
to O
gain O
further O
insight O
into O
linguistic O
markers O
of O
politeness. O
These O
visualiza- O
tion O
techniques O
reveal O
novel O
politeness O
strategies O
not O
considered O
originally, O
namely O
how O
punctuation O
affected O
politeness O
scores. O
The O
introduced O
polite- O
ness O
classiﬁer O
uses O
a O
CNN B-MethodName
and O
does O
not O
use O
po- O
liteness O
strategies O
as O
features O
while O
having O
higher O
accuracy. O
Politeness O
as O
an O
NLP O
task O
has O
seen O
recent O
in- O
terest. O
Niu O
and O
Bansal O
(2018) O
uses O
the O
Stanford B-DatasetName
Politeness I-DatasetName
Corpus I-DatasetName
to O
investigate O
politeness O
genera- O
tion O
models. O
Politeness O
generation O
here O
is O
treated O
as O
part O
of O
the O
answer O
generation O
task O
with O
mod- O
els O
producing O
answers O
already O
in O
their O
polite O
form, O
using O
Reinforcement O
Learning O
and O
a O
novel O
polite- O
ness O
classiﬁer. O
A O
Multilingual O
approach O
is O
taken O
in O
(Firdaus O
et O
al., O
2020) O
where O
courteous O
responses O
are O
generated O
in O
a O
customer O
care O
scenario. O
Madaan O
et O
al. O
(2020) O
sees O
politeness O
as O
a O
style O
transfer O
task O
where O
politeness O
is O
introduced O
onto O
an O
utterance O
by O
rewriting O
it. O
This O
work O
uses O
a O
politeness O
classiﬁer O
to O
label O
the O
Enron O
corpus O
(Klimt O
and O
Yang, O
2004), O
and O
applies O
a O
transformer-based O
(Vaswani O
et O
al., O
2017) O
style O
transfer O
pipeline O
to O
the O
utterance, O
using O
a O
tagger O
and O
generator O
approach. O
In O
a O
similar O
vein, O
in O
(Golchha O
et O
al., O
2019) O
the O
authors O
transform O
neu- O
tral O
customer O
service O
replies O
into O
courteous O
ones. O
Hence, O
we O
follow O
a O
similar O
line O
of O
work O
and O
propose O
to O
enrich O
fashion O
dialog O
agents O
with O
polite- O
ness. O
Saha O
et O
al. O
(2018) O
introduced O
a O
large-scale O
multimodal B-DatasetName
fashion I-DatasetName
dialog I-DatasetName
dataset I-DatasetName
(MMD) I-DatasetName
built O
semi-automatically, O
using O
ﬁeld O
experts, O
accompa- O
nied O
by O
two O
RNN O
(Cho O
et O
al., O
2014) O
models O
capable O
of O
emulating O
the O
system O
responses O
in O
a O
multimodal305scenario. O
Due O
to O
its O
domain, O
it O
carries O
mainly O
neu- O
tral O
and O
polite O
dialog. O
To O
the O
best O
of O
our O
knowledge, O
there O
is O
no O
task-oriented O
conversational O
dataset O
to O
study O
politeness O
and O
we O
propose O
to O
ﬁll O
this O
research O
gap. O
3 O
Task-Speciﬁc O
Polite O
Dialog O
Agents O
We O
consider O
two O
distinct O
methods O
of O
producing O
politeness O
and O
evaluate O
how O
each O
deals O
with O
do- O
main O
changes: O
polite O
answer O
generation O
andpo- O
liteness O
rewriting O
. O
We O
adapt O
each O
model O
to O
allow O
it O
to O
use O
transfer O
learning, O
in O
particular, O
transfer O
po- O
liteness O
patterns O
to O
a O
different O
domain, O
the O
fashion O
domain. O
3.1 O
Politeness O
through O
Utterance O
Generation O
Politeness O
can O
be O
improved O
in O
a O
generative O
manner, O
where O
an O
answer O
generation O
model O
learns O
to O
do O
so, O
by O
merging O
answer O
generation O
and O
politeness O
generation O
in O
the O
same O
task O
. O
This O
type O
of O
approach O
makes O
the O
work O
of O
the O
decoder O
two-fold: O
it O
needs O
to O
be O
able O
to O
accurately O
understand O
the O
context O
and O
produce O
an O
accurate O
answer, O
but O
it O
also O
needs O
to O
improve O
the O
politeness O
of O
the O
produced O
answer. O
We O
adopted O
the O
Polite-RL B-MethodName
generative O
ap- O
proach O
(Niu O
and O
Bansal, O
2018) O
based O
on O
a O
Seq2Seq B-MethodName
model O
that O
receives O
the O
conversation O
history O
to O
pro- O
duce O
a O
polite O
answer. O
The O
model O
is O
trained O
with O
Reinforcement O
Learning O
that O
leverages O
a O
Polite- O
ness O
Classiﬁer O
(we O
will O
refer O
to O
as O
Classiﬁer) O
to O
estimate O
the O
politeness O
of O
a O
sampled O
answer. O
Polite- B-MethodName
RL I-MethodName
uses O
the O
politeness O
score O
of O
a O
sampled O
utter- O
ance O
as O
a O
measure O
of O
politeness O
that O
acts O
as O
the O
Reinforcement O
Learning O
component O
of O
the O
loss O
function O
(see O
appendix O
A.4), O
to O
guide O
the O
gener- O
ation O
towards O
a O
more O
polite O
output. O
We O
focused O
on O
improving O
the O
used O
embeddings O
to O
include O
a O
novel O
lexicon, O
given O
that O
the O
fashion O
domain O
(Saha O
et O
al., O
2018) O
differs O
signiﬁcantly O
from O
the O
train- O
ing O
data O
(Danescu-Niculescu-Mizil O
et O
al., O
2013), O
making O
out-of-vocabulary O
situations O
a O
major O
issue. O
Originally, O
this O
model O
uses O
embeddings O
initialized O
using O
a O
Word2Vec B-MethodName
model O
trained O
on O
the O
Google B-DatasetName
News I-DatasetName
dataset O
(Mikolov O
et O
al., O
2013). O
Despite O
its O
vocabulary O
size, O
the O
dataset’s O
vocabulary O
can O
still O
leave O
out O
a O
signiﬁcant O
portion O
of O
the O
terms O
used O
in O
the O
fashion-speciﬁc O
datasets O
(mainly O
clothes’ O
names O
and O
attributes), O
due O
to O
its O
highly O
speciﬁc O
domain O
(Saha O
et O
al., O
2018). O
Looking O
at O
Table O
7, O
we O
observe O
that O
politeness O
can O
be O
applied O
in O
several O
different O
ways, O
makingit O
important O
to O
take O
into O
account O
the O
utterance O
as O
a O
whole O
to O
better O
understand O
how O
phrase O
struc- O
tures O
affect O
its O
tone. O
In O
the O
Polite-RL B-MethodName
(Niu O
and O
Bansal, O
2018) O
model, O
these O
strategies O
are O
intro- O
duced O
implicitly O
by O
the O
politeness O
Classiﬁer O
as O
the O
Seq2Seq B-MethodName
model O
is O
not O
explicitly O
trained O
on O
po- O
liteness O
data. O
With O
this O
in O
mind, O
to O
improve O
the O
adaptability O
of O
this O
implementation O
and O
reduce O
the O
impact O
of O
this O
separation O
in O
the O
vocabulary, O
we O
introduce O
a O
new O
set O
of O
embeddings O
that O
accounts O
for O
the O
additional O
tokens O
from O
the O
novel O
domain O
dataset. O
These O
embeddings O
were O
obtained O
by O
train- O
ing O
a O
Word2Vec B-MethodName
(Mikolov O
et O
al., O
2013) O
model O
on O
a O
concatenation O
of O
the O
MMD B-DatasetName
(Saha O
et O
al., O
2018) O
- O
a O
conversational O
dataset O
on O
the O
fashion O
domain O
(see O
section O
4.1) O
- O
and O
the O
original O
Politeness O
cor- O
pus. O
We O
will O
refer O
to O
these O
embeddings O
as O
Domain- O
Extended O
embeddings O
(DE). O
3.2 O
Politeness O
through O
Utterance O
Rewriting O
Politeness O
rewriting O
separates O
the O
task O
of O
politeness O
generation O
from O
answer O
generation O
. O
This O
enables O
tackling O
politeness O
individually, O
and O
avoid O
its O
de- O
pendence O
on O
the O
answer O
generation O
task. O
For O
this O
approach, O
we O
adopt O
Tag-and- O
Generate O
(Madaan O
et O
al., O
2020), O
which O
is O
composed O
of O
two O
main O
components: O
Tagger O
and O
Generator. O
The O
Tagger O
is O
responsible O
for O
extracting O
style O
makers O
from O
the O
utterance O
and O
adding O
a O
[TAG] O
token O
where O
new O
markers O
should O
be O
introduced. O
The O
style O
markers O
are O
deﬁned O
using O
a O
TF-IDF-based B-MethodName
approach O
that O
compares O
the O
relevance O
of O
an O
n-gram O
on O
the O
polite O
and O
rude O
subset O
of O
data. O
The O
Generator O
takes O
the O
tagged O
utterance O
and O
replaces O
the O
[TAG] O
token O
with O
polite O
style O
markers. O
This O
approach O
follows O
the O
assumption O
that O
the O
extracted O
style O
markers O
are O
good O
markers O
for O
politeness, O
meaning O
that O
if O
the O
model O
is O
dealing O
with O
a O
poor O
set O
of O
style O
markers O
then O
the O
results O
can O
be O
destructive O
and O
nonsensical. O
Models O
such O
as O
this, O
apply O
politeness O
strategies O
in O
an O
explicit O
manner, O
Table O
7. O
The O
Generator O
learns O
the O
best O
way O
to O
add O
each O
politeness O
strat- O
egy O
onto O
a O
given O
utterance, O
by O
observing O
how O
each O
style O
marker O
is O
used O
throughout O
the O
training O
data. O
For O
honoriﬁcs, O
ideally, O
the O
model O
learns O
to O
place O
them O
immediately O
before O
surnames. O
With O
the O
Tagger O
architecture O
in O
mind, O
we O
fo- O
cused O
on O
using O
Transfer O
Learning O
to O
better O
adapt O
the O
model O
to O
the O
fashion O
domain. O
For O
the O
rewriting O
part, O
we O
hypothesize O
that O
using O
the O
style O
markers306previously O
learned O
on O
the O
original O
dataset O
(Enron) O
will O
lead O
to O
improved O
politeness O
scores. O
To O
deal O
with O
the O
out-of-the-domain-vocabulary O
problem, O
we O
propose O
to O
curate O
the O
extracted O
style O
markers, O
by O
excluding O
domain-speciﬁc O
words O
and O
terms O
from O
being O
classiﬁed O
as O
style O
markers, O
thus O
leading O
to O
more O
representative O
style O
markers. O
To O
assess O
how O
this O
affects O
generation O
quality, O
we O
deﬁne O
four O
train- O
ing O
setups: O
•RW-Enron: B-DatasetName
Original O
model O
trained O
on O
the O
Enron O
dataset O
(Klimt O
and O
Yang, O
2004). O
•RW-Fashion: B-DatasetName
Model O
trained O
on O
the O
fashion- O
domain O
dataset, O
using O
polite O
and O
rude O
utter- O
ances, O
i.e. O
utterances O
with O
a O
politeness B-MetricName
score I-MetricName
above O
0.9 B-MetricValue
and O
between O
0.5-0.6 B-MetricValue
respectively. O
•RW-Fashion-Clean: B-DatasetName
Similar O
to O
the O
previous O
model, O
but O
we O
force O
the O
model O
to O
ignore O
style O
markers O
associated O
to O
product O
nouns. O
For O
ex- O
ample, O
"scarf" O
and O
"trousers", O
shouldn’t O
be O
counted O
as O
a O
style O
marker O
of O
politeness. O
•RW-Mixed: O
This O
model O
learns O
the O
style O
markers O
on O
the O
original O
domain O
(Enron) O
and O
is O
trained O
on O
the O
fashion O
dataset. O
This O
way O
the O
model O
circumvents O
the O
noisy O
style O
markers O
extracted O
from O
the O
fashion O
data. O
Effectively O
transferring O
knowledge O
learned O
on O
politeness O
annotated O
data O
to O
the O
fashion O
domain. O
4 O
Experimental O
Setup O
4.1 O
Datasets O
and O
Protocols O
In O
our O
experiments, O
3 O
datasets O
were O
considered: O
Stanford B-MethodName
Politeness I-MethodName
Corpus I-MethodName
(SPC) I-MethodName
- O
This O
is O
the O
dataset O
used O
for O
politeness O
conditioning, O
by O
train- O
ing O
the O
Politeness O
proxy O
classiﬁer O
(Niu O
and O
Bansal, O
2018). O
This O
corpus O
is O
composed O
of O
requests O
(Wikipedia O
and O
Stack O
Exchange) O
annotated O
by O
5 O
humans. O
We O
follow O
(Niu O
and O
Bansal, O
2018) O
and O
use O
the O
original O
data O
splits. O
Enron O
- O
Collection O
of O
emails O
exchanged O
in O
the O
En- O
ron O
company O
(Klimt O
and O
Yang, O
2004) O
- O
originally O
used O
to O
train O
the O
Tag-and-Generate O
model O
(Madaan O
et O
al., O
2020) O
- O
that O
we O
adopt O
as O
the O
original O
domain, O
in O
a O
domain-transfer O
scenario. O
We O
consider O
an O
au- O
tomatically O
annotated O
subset O
of O
Enron, O
with O
212k O
polite O
and O
51k O
rude O
utterances O
for O
training, O
27k O
po- O
lite O
and O
5.8k O
rude O
for O
validation, O
and O
26k O
polite O
and O
5.8k O
rude O
utterances O
for O
testing.MMD B-DatasetName
- O
This O
dataset O
comprises O
multi-turn O
dialogs O
for O
the O
fashion O
domain O
(Saha O
et O
al., O
2018), O
which O
we O
use O
as O
the O
target O
domain. O
We O
ﬁrst O
create O
the O
MMD-R O
subset, O
comprised O
by O
system O
utterances O
that O
correspond O
to O
product(s) O
recommendations(s) O
to O
expose O
the O
model O
to O
domain-speciﬁc O
product O
lexicon, O
resulting O
in O
380k/81k/81k O
utterances O
for O
training/validation/testing. O
A O
second O
subset O
is O
cre- O
ated, O
MMD-A O
, O
comprising O
all O
neutral2andpolite O
system O
utterances O
with O
more O
than O
5 O
tokens, O
result- O
ing O
in O
453k/116k/116k O
utterances. O
The O
MMD-A O
subset O
generalizes O
MMD-R O
to O
include O
utterances O
from O
multiple O
dialog O
intents. O
Please O
kindly O
refer O
to O
Appendix O
A.2 O
for O
more O
details O
regarding O
each O
dataset O
(annotation O
protocol, O
splits, O
and O
others). O
4.2 O
Metrics O
For O
evaluation, O
we O
will O
focus O
mainly O
on O
two O
as- O
pects O
of O
the O
generated O
utterances: O
a) O
Politeness O
Im- O
provement O
andb) O
Content O
Preservation O
. O
With O
a), O
we O
focus O
on O
understanding O
if O
each O
resulting O
utterance O
is O
in O
fact O
more O
polite O
than O
the O
original O
one. O
For O
this, O
to O
automatically O
quantify O
polite- O
ness, O
we O
follow O
(Niu O
and O
Bansal, O
2018) O
and O
com- O
pute O
the O
average B-MetricName
Politeness I-MetricName
Score I-MetricName
( O
Pol.) O
using O
its O
politeness O
classiﬁer, O
where O
1.0 B-MetricValue
is O
polite, O
0.5 B-MetricValue
neu- O
tral O
and O
0.0 B-MetricValue
is O
rude. O
In O
b), O
we O
focus O
on O
under- O
standing O
whether O
or O
not O
the O
model O
can O
preserve O
the O
original O
content. O
Thus, O
we O
follow O
previous O
work O
(Niu O
and O
Bansal, O
2018; O
Madaan O
et O
al., O
2020) O
and O
evaluate O
the O
results O
using O
BLEU B-MetricName
(B)(Papineni O
et O
al., O
2002), O
ROUGE B-MetricName
(R)(Lin, O
2004), O
and O
ME- O
TEOR B-MetricName
(M)(Denkowski O
and O
Lavie, O
2011). O
Given O
the O
subjective O
nature O
of O
the O
task, O
we O
complement O
our O
evaluation O
with O
human O
evaluation. O
4.3 O
Model O
Variants O
and O
Implementation O
For O
evaluation, O
we O
refer O
to O
politeness O
answer O
gener- O
ation O
variants O
as O
Gen O
and O
rewriting O
variants O
as O
RW. O
ForGen, O
we O
use O
the O
original O
embeddings. O
The O
gen- O
erative O
approach O
with O
domain O
extented O
embeddings O
(section O
3.1) O
is O
referred O
as O
Gen+DE O
. O
For O
rewriting, O
the O
4 O
proposed O
variants O
(section O
3.2) O
are O
referred O
as O
RW-Enron O
,RW-Fashion O
,RW-Fashion-C O
(lean) O
andRW-Mixed O
. O
Regarding O
models O
implementation, O
for O
RW O
vari- O
ants O
we O
use O
the O
original O
hyper-parameters, O
and O
both O
components O
are O
trained O
using O
a O
4-layer O
4- O
2Due O
to O
its O
nature, O
the O
number O
of O
rude O
utterances O
in O
MMD O
is O
minimal, O
leading O
to O
a O
high O
imbalance.307Models O
head O
transformer O
block O
and O
512-dimensional B-HyperparameterValue
em- B-HyperparameterName
beddings, I-HyperparameterName
for O
5 B-HyperparameterValue
epochs. B-HyperparameterName
For O
Polite-RL O
we O
also O
use O
the O
original O
hyper-parameters, O
but O
we O
tuned O
the O
batch B-HyperparameterName
sizeband I-HyperparameterName
theβparameter, O
the O
weight O
of O
the O
politeness O
component O
of O
the O
computed O
loss. O
Refer O
to O
Appendix O
A.4 O
for O
model O
tuning O
details. O
5 O
Results O
and O
Discussion O
5.1 O
Politeness O
Generation O
or O
Rewriting? O
Automatic-Evaluation. O
We O
start O
by O
comparing O
how O
the O
adapted O
generative O
(section O
3.1) O
and O
rewrit- O
ing O
(section O
3.2) O
politeness O
approaches O
perform O
on O
the O
fashion O
domain, O
in O
terms O
of O
politeness O
and O
con- O
tent O
preservation. O
The O
Gen O
and O
RW O
models O
were O
evaluated O
on O
the O
MMD-R B-DatasetName
andMMD-A B-DatasetName
datasets, O
respectively. O
Table O
1 O
shows O
the O
evaluation O
results O
for O
both O
models O
and O
their O
variants. O
From O
these O
re- O
sults, O
it O
is O
evident O
that O
rewriting O
variations O
(RW) O
outperform O
the O
generation-based O
ones O
(Gen) O
across O
all O
metrics, O
due O
to O
their O
need O
to O
attend O
to O
two O
tasks. O
For O
content O
preservation, O
the O
results O
from O
Gen O
are O
consistently O
behind O
its O
RW O
counterparts, O
with O
all O
variations O
of O
the O
RW O
model O
outperforming O
the O
generation-based O
models. O
Regarding O
politeness, O
the O
scores O
paint O
a O
similar O
picture O
with O
Gen O
models O
trailing O
behind O
and O
only O
reaching O
near O
when O
con- O
tent O
preservation O
is O
signiﬁcantly O
neglected O
(higher O
βvalue, O
the O
weight O
given O
to O
politeness O
in O
Polite- O
RL). O
Despite O
this, O
all O
models O
are O
able O
to O
post O
the O
politeness O
score O
on O
the O
polite O
spectrum O
(Pol. O
> O
0.5), O
according O
to O
the O
politeness O
classiﬁer. O
Human-Evaluation. O
Automatic O
metrics O
offer O
a O
quick O
and O
reproducible O
way O
of O
evaluating O
work, O
however, O
they O
lack O
the O
depth O
needed O
to O
accurately O
evaluate O
subjective O
topics O
like O
politeness O
our O
previous O
automatic O
analysis O
of O
the O
proposed O
changes O
to O
the O
RW O
setup, O
we O
ran O
a O
crowdsourcing O
experiment O
to O
assess O
the O
tone O
and O
grammar3of O
gen- O
erated O
utterances. O
For O
this, O
we O
randomly O
sample O
100 O
utterances O
from O
the O
MMD-A O
test O
set O
and O
then O
collect O
the O
generated O
utterance O
for O
each O
of O
the O
RW O
variations O
and O
Gen+DE. O
For O
each O
utterance, O
3 O
an- O
notators O
were O
asked O
to O
rate O
its O
tone O
on O
a O
scale O
of O
1 O
to O
3 O
(1=Rude, O
2=Neutral, O
3=Polite). O
For O
gram- O
mar, O
annotators O
were O
asked O
to O
give O
a O
binary O
rating, O
whether O
the O
utterance O
was O
grammatically O
correct O
or O
not O
(0=No, O
1=Yes). O
Annotators O
were O
provided O
an O
example O
utterance O
for O
each O
possible O
value. O
We O
ob- O
tained≈82% O
agreement O
on O
grammar O
and O
≈77% O
for O
politeness. O
The O
results O
are O
show O
in O
Table O
2. O
For O
a O
given O
utterance, O
the O
agreement O
was O
the O
measure O
of O
how O
many O
annotators O
labeled O
it O
the O
same. O
Regarding O
politeness, O
the O
Gen+DE O
model O
scored O
lower O
than O
the O
Reference, O
whereas O
all O
RW O
setups O
matched O
or O
improved O
on O
it. O
In O
particular, O
only O
RW- O
Fashion O
failed O
to O
improve O
and O
both O
RW-Fashion-C O
and O
RW O
were O
able O
to O
outscore O
the O
reference. O
When O
looking O
into O
rating O
distribution, O
we O
noted O
that O
of O
the O
1800 O
annotations, O
only O
in O
28 O
occasions O
did O
an O
annotator O
consider O
the O
utterance O
rude, O
and O
never O
2 O
annotators O
agreed O
that O
an O
utterance O
was O
rude, O
showing O
that O
all O
models O
are O
able O
to O
keep O
the O
text O
neutral. O
For O
grammar, O
none O
of O
the O
models O
were O
able O
to O
score O
higher O
than O
the O
reference, O
and O
Gen+DE O
was O
rated O
signiﬁcantly O
lower. O
From O
the O
ratings, O
we O
note O
that O
there O
is O
a O
signif- O
icant O
gap O
between O
Generative O
and O
Rewriting O
ap- O
proaches, O
similar O
to O
the O
automatic O
evaluation. O
Ad- O
ditionally, O
Gen+DE O
underperforming O
with O
respect O
to O
the O
reference O
shows O
that O
generally, O
the O
model O
was O
not O
able O
to O
improve O
on O
the O
utterances’ O
tone O
of- O
ten O
leading O
to O
incoherent O
generations. O
On O
another O
note, O
the O
performance O
of O
the O
RW-Fashion-C O
shows O
3We O
included O
grammar O
to O
understand O
if O
the O
models O
were O
reducing O
the O
quality O
of O
the O
re-written O
utterances.308that O
style O
marker O
curation O
can O
be O
the O
way O
forward O
for O
rewriting O
approaches. O
5.2 O
Style O
Marker O
Domain O
Transfer O
In O
the O
previous O
section, O
we O
observed O
that O
politeness O
rewriting O
is O
the O
top-performing O
approach O
to O
im- O
prove O
the O
politeness O
of O
task-oriented O
dialog O
agents. O
In O
this O
section, O
we O
perform O
a O
ﬁner-grain O
evalua- O
tion O
of O
the O
rewriting O
model O
variants, O
i.e. O
the O
style O
marker-based O
model O
( O
RW), O
under O
a O
domain O
trans- O
fer O
setting. O
As O
this O
corresponds O
to O
an O
utterance O
rewriting O
task, O
we O
look O
for O
high O
content O
preserva- O
tion O
paired O
with O
high O
politeness O
score. O
To O
perform O
this O
experiment, O
we O
use O
the O
MMD-A B-DatasetName
subset, O
comprising O
diverse O
system O
utterances O
(rec- O
ommendation, O
answering O
product O
questions, O
etc.). O
Then, O
we O
follow O
Madaan O
et O
al. O
(2020) O
and O
use O
the O
politeness O
classiﬁer O
to O
split O
the O
subset O
into O
10 O
buckets, O
corresponding O
to O
a O
10-bin O
histogram O
over O
politeness O
scores. O
Table O
1 O
also O
depicts O
the O
results, O
where O
we O
com- O
pare O
the O
four O
RW O
model O
variations O
on O
the O
MMD- B-DatasetName
Atest I-DatasetName
set. O
We O
observe O
that O
for O
content O
preserva- O
tion, O
top O
performance O
is O
achieved O
by O
the O
RW-Mixed O
model, O
across O
all O
three O
content O
metrics. O
Addition- O
ally, O
we O
note O
that O
the O
RW-Fashion-C B-DatasetName
model O
is O
a O
step O
up O
on O
RW-Fashion, B-DatasetName
showing O
that O
excluding O
domain- O
speciﬁc O
words O
from O
the O
style O
attribute O
list O
helps O
pre- O
serve O
content. O
However, O
for O
the O
RW-Enron O
model, O
which O
is O
restricted O
to O
the O
original O
domain, O
the O
re- O
sults O
were O
signiﬁcantly O
lower. O
Regarding O
Politeness O
scores, O
the O
RW-Enron O
model O
outperforms O
all O
the O
others O
speciﬁcally O
trained O
on O
MMD-A B-DatasetName
data. O
The O
Mixed O
model O
also O
performed O
better O
than O
its O
RW-Fashion B-DatasetName
and O
RW-Fashion-C B-DatasetName
counterparts. O
The O
success O
of O
RW- O
Enron O
in O
politeness O
score O
and O
RW-Mixed B-DatasetName
in O
content O
preservation O
shows O
that O
leveraging O
out-of-domain O
style O
markers O
yields O
positive O
results O
for O
neutral O
do- O
mains, O
where O
it O
is O
difﬁcult O
to O
extract O
style O
markers. O
This O
also O
shows O
how O
models O
can O
vary O
in O
the O
way O
they O
add O
style O
markers. O
While O
RW-Enron B-DatasetName
does O
several O
and O
signiﬁcant O
changes, O
thus O
having O
lower O
content O
preservation O
scores, O
RW-Mixed B-DatasetName
does O
less O
but O
more O
informed O
and O
in-domain O
additions. O
5.2.1 O
Utterance O
Tone O
and O
Length O
Impact O
To O
identify O
the O
impact O
of O
utterance O
tone O
(rude O
or O
neutral) O
and O
utterance O
size O
on O
the O
models’ O
perfor- O
mance, O
we O
prepared O
a O
set O
of O
distinct O
scenarios O
cov- O
ering O
the O
different O
aspects O
of O
utterances’ O
tone O
and O
length. O
We O
ﬁx O
utterances O
tone O
to O
neutral O
. O
to O
the O
following O
reasons: O
Utterance O
tone O
- O
It O
is O
important O
to O
gauge O
models’ O
ability O
to O
adapt O
to O
different O
levels O
of O
polite- O
ness. O
Namely, O
the O
difﬁculty O
of O
improving O
from O
rude O
to O
polite O
differs O
from O
neutral O
to O
po- O
lite. O
Additionally, O
models O
are O
trained O
on O
the O
neutral O
politeness O
bucket O
of O
data(to O
perform O
style O
transfer O
to O
polite O
tone), O
which O
may O
bias O
their O
performance O
towards O
a O
particular O
tone. O
Utterance O
Length O
- O
During O
the O
initial O
experi- O
ments, O
we O
observed O
that O
the O
models O
tended O
to O
leave O
longer O
utterances O
untouched, O
and O
we O
wanted O
to O
measure O
the O
extent O
of O
that O
behavior O
for O
different O
utterance O
sizes. O
To O
assess O
these O
two O
aspects, O
we O
evaluated O
our O
proposed O
four O
RW O
model O
variations, O
under O
a O
set O
of O
scenarios O
obtained O
by O
systematically O
varying O
the O
length O
and O
tone O
utterance O
properties, O
resulting O
in O
the O
following O
5 O
scenarios: O
Long O
(L) O
- O
Comprises O
of O
neutral4long O
utterances O
from O
the O
MMD-A O
test O
set. O
These O
correspond O
to O
recommendation O
of O
products O
thus O
being O
very O
rich O
in O
fashion-speciﬁc O
terms. O
We O
obtained O
88 O
utterances. O
Short O
& O
Rude O
(SR) O
- O
Short O
utterances O
obtained O
from O
the O
MMD-A O
test O
set. O
This O
corresponds O
to O
utterances O
belonging O
to O
the O
P_0 O
or O
P_1 O
buckets, O
i.e. O
utterances O
deemed O
rude, O
with O
less O
than O
17 O
tokens. O
In O
total, O
we O
obtain O
134 O
utterances. O
Short O
& O
Neutral O
(SN) O
- O
Same O
strategy O
as O
SRbut O
utterances O
are O
picked O
from O
the O
P_5 O
bucket O
instead O
- O
halfway O
of O
the O
politeness O
scale, O
meaning O
that O
ut- O
terances O
are O
deemed O
as O
neutral O
. O
In O
total O
we O
obtain O
2.5k O
utterances. O
Similar O
to O
SRbut O
with O
utterances O
length O
between O
16 O
and O
32 O
tokens, O
total- O
ing O
138 O
utterances. O
Medium O
& O
Neutral O
(MN) O
- O
Similar O
to O
SNbut O
with O
utterances O
length O
between O
16 O
and O
32 O
tokens, O
result- O
ing O
in O
a O
total O
of O
2.2k O
utterances. O
Table O
3 O
shows O
the O
results O
of O
each O
model O
over O
neutral O
utterances, O
but O
of O
varying O
lengths. O
The O
RW-Fashion-C O
model O
achieved O
the O
highest O
content O
preservation O
scores O
on O
the O
short O
and O
medium O
ut- O
terance O
scenarios. O
It O
is O
interesting O
to O
point O
that O
in O
all O
scenarios, O
models O
trained O
on O
MMD-A B-DatasetName
(all O
ex- O
cept O
RW-Enron), O
showed O
the O
same O
pattern: O
they O
make O
more O
changes O
in O
shorter O
utterances O
and O
less O
in O
longer O
ones, O
producing O
very O
few O
changes O
or O
even O
leaving O
utterances O
unaltered O
in O
the O
latter O
case. O
The O
RW-Enron O
model O
showed O
the O
opposite O
trend, O
mak- O
ing O
signiﬁcant O
changes O
in O
longer O
utterances. O
With O
respect O
to O
style O
changes O
(Table O
4 O
and O
Ta- O
ble O
5), O
for O
every O
model, O
there O
was O
a O
clear O
difference O
between O
neutral O
scenarios O
(SN O
and O
MN) O
and O
theirrude O
counterparts O
(SR O
and O
MR). O
On O
average, O
the O
rude O
scenarios O
scored O
7% O
lower O
on O
content O
preser- O
vation O
metrics O
than O
the O
neutral O
tests. O
This O
result O
should O
not O
lead O
to O
the O
conclusion O
that O
models O
per- O
form O
better O
on O
neutral O
data. O
Actually, O
after O
inspect- O
ing O
the O
results, O
we O
observed O
that O
models O
obtained O
higher O
scores O
in O
neutral O
utterances O
because O
they O
are O
less O
capable O
of O
identifying O
what O
needs O
to O
be O
replaced O
or O
added O
to O
improve O
politeness. O
This O
is O
supported O
by O
the O
politeness O
variation, O
shown O
in O
Ta- O
ble O
5. O
Here O
we O
observe O
that O
all O
models O
produce O
a O
higher O
improvement O
in O
rude O
utterances, O
but O
the O
difference O
in O
the O
relative O
improvement O
on O
neutral O
ut- O
terances O
is O
small, O
meaning O
that O
the O
utterance O
would O
still O
fall O
on O
the O
rude O
split. O
Regarding O
Politeness O
scores, O
the O
models O
trained O
on O
the O
MMD-A B-DatasetName
(Fashion O
,Fashion-C O
andMixed O
) O
show O
signiﬁcant O
improvement O
on O
the O
Enron O
test. O
However, O
after O
a O
second O
inspection O
of O
the O
generated O
utterances, O
it O
was O
evident O
that O
the O
Politeness O
score O
increase O
did O
not O
translate O
to O
tone O
improvements O
given O
the O
generation O
being O
of O
low O
quality. O
Namely, O
models O
simply O
add O
MMD-A B-DatasetName
excerpts O
with O
no O
ap- O
parent O
criteria. O
Overall, O
these O
models O
perform O
better O
in O
short O
rude O
utterances. O
When O
dealing O
with O
neutral O
text, O
they O
tend O
to O
produce O
a O
lesser O
amount O
of O
changes O
meaning O
that O
for O
such O
models O
to O
be O
applied O
as O
part O
of O
a O
pipeline O
of O
a O
task-oriented O
dialog O
agent, O
it O
is O
im- O
portant O
to O
perform O
ﬁne-tuning, O
towards O
overcoming O
domain O
shift O
issues. O
We O
also O
observed O
that, O
based O
on O
common O
politeness O
strategies O
(see O
section O
A.1), O
most O
of O
the O
politeness O
strategies O
employed O
were O
Gratitude O
and O
Positive O
Lexicon, O
as O
is O
common O
in O
a O
costumer-store O
interaction, O
on O
the O
fashion O
domain. O
5.2.2 O
Qualitative O
Analysis O
of O
Style O
Markers O
In O
this O
section, O
we O
conduct O
a O
qualitative O
evaluation O
over O
a O
set O
of O
three O
utterances, O
in O
order O
to O
further O
pinpoint O
each O
rewriting O
variant’s O
characteristics. O
Table O
6 O
illustrates O
2 O
sample O
output O
utterances, O
and O
the O
resulting O
output O
of O
each O
RW O
variant. O
For O
the O
ﬁrst O
example, O
we O
have O
a O
polite-sounding O
utter- O
ance O
where O
the O
ideal O
behavior O
would O
be O
to O
leave O
the O
utterance O
untouched, O
given O
that O
it O
is O
already O
in O
a O
very O
polite O
form. O
For O
this O
case, O
the O
RW-Mixed O
model O
produced O
a O
slightly O
improved O
form, O
making O
the O
utterance O
less O
generic O
and O
more O
fashion-related. O
The O
utterance O
generated O
by O
RW-Enron O
and O
RW- O
Fashion-C O
could O
have O
been O
a O
successful O
case O
had O
the O
correct O
semantics O
been O
applied O
to O
the O
added O
text. O
In O
the O
second O
example, O
we O
see O
mixed O
results.310Hi, O
please O
tell O
me O
what O
I O
can O
help O
you O
with? O
RW-Enron O
Hi, O
please O
tell O
me O
what O
I O
can O
help O
you O
get O
together O
with? O
RW-Fashion O
Hi, O
please O
tell O
me O
what O
I O
can O
help O
you O
with? O
please O
note O
RW-Fashion-C O
Hi, O
please O
tell O
me O
what O
I O
can O
help O
you O
show O
with? O
RW-Mixed O
Hi, O
please O
tell O
me O
what O
I O
can O
help O
ﬁt O
you O
with? O
Hello, O
what O
I O
can O
help O
you O
with O
today? O
RW-Enron O
Hello, O
what O
I O
can O
help O
you O
get O
together O
with O
today? O
RW-Fashion O
Hello, O
what O
I O
can O
help O
you O
move O
with O
today? O
RW-Fashion-C O
Hello, O
what O
I O
can O
help O
you O
get O
ready O
for O
today? O
RW-Mixed O
He O
can O
go O
well O
withrit O
, O
what O
I O
can O
help O
ﬁt O
ﬁt O
you O
with O
today? O
Great. O
I O
think O
that’s O
a O
great O
choice. O
RW-Enron O
Great. O
I O
think O
that’s O
could O
be O
a O
great O
choice. O
RW-Fashion O
Great. O
I O
do O
not O
think O
i O
have O
a O
great O
choice O
but O
would O
you O
like O
something O
in O
other O
types O
. O
RW-Fashion-C B-DatasetName
Great. O
I O
think O
that’s O
a O
great O
choice. O
RW-Mixed O
Great. O
I O
think O
that’s O
a O
great O
choice O
thank O
you O
for O
shopping O
with O
us. O
Table O
6: O
Politeness O
rewriting O
output O
utterances O
analysis. O
Changes O
made O
by O
the O
model O
are O
highlighted O
with O
red O
, O
meaning O
a O
negative O
change O
(Grammar O
error O
or O
Rude O
tone) O
occurred, O
yellow O
for O
neutral O
changes, O
and O
green O
for O
positive O
changes. O
lighter O
green O
indicates O
a O
positive O
change O
but O
less O
impactful O
than O
a O
darker O
green O
one. O
Both O
the O
RW-Enron O
and O
RW-Fashion-C O
models O
were O
able O
to O
improve O
on O
the O
utterance’s O
sentiment O
by O
adding O
in-domain O
knowledge. O
The O
RW-Mixed O
model O
produced O
a O
bad O
generation, O
adding O
dupli- O
cated O
words O
and O
low-quality O
excerpts. O
Overall, O
under O
the O
correct O
circumstances, O
we O
see O
that O
most O
of O
the O
models O
can O
successfully O
improve O
politeness. O
The O
RW-Fashion O
makes O
mostly O
low- O
quality O
additions, O
showing O
that O
there O
is O
a O
need O
for O
style O
marker O
curation. O
We O
also O
observed O
that O
the O
models O
are O
often O
more O
successful O
when O
improving O
on O
an O
already O
polite O
utterance O
rather O
than O
when O
dealing O
with O
neutral O
utterances. O
We O
believe O
this O
behavior O
is O
a O
product O
of O
the O
model O
architecture O
that O
looks O
for O
style O
markers O
to O
replace O
and O
said O
style O
markers O
are O
not O
present O
in O
neutral-sounding O
text. O
6 O
Conclusion O
In O
this O
work, O
we O
address O
the O
research O
gap O
regard- O
ing O
the O
development O
of O
polite B-TaskName
task-oriented I-TaskName
dialog I-TaskName
agents. I-TaskName
We O
demonstrate O
that O
while O
politeness O
lan- O
guage O
constructs O
tend O
not O
to O
be O
domain-speciﬁc, O
their O
application O
is, O
requiring O
politeness O
approaches O
to O
cope O
with O
domain-speciﬁc O
vocabulary. O
Particu- O
larly, O
we O
show O
that O
when O
improving O
politeness O
in O
task-speciﬁc O
utterances, O
rewriting O
approaches O
con-sistently O
deliver O
better O
results, O
given O
that O
generative O
alternatives O
need O
to O
attend O
to O
two O
tasks. O
In O
summary, O
the O
key O
takeaways O
are: O
•Politeness O
through O
rewriting O
results O
in O
the O
most O
robust O
approach, O
providing O
a O
good O
bal- O
ance O
between O
delivering O
polite O
utterances O
and O
preserving O
content. O
•Politeness O
answer O
generation O
is O
less O
stable. O
By O
deﬁnition, O
generation O
and O
politeness O
improve- O
ment O
need O
to O
be O
addressed O
jointly, O
which O
is O
too O
ambitious O
in O
a O
domain-transfer O
setting. O
•Bringing O
politeness O
to O
task-oriented O
dialog O
agents, O
characterized O
by O
operating O
over O
highly O
speciﬁc O
domains, O
is O
achievable O
with O
the O
pro- O
posed O
model O
domain O
adaptations. O
As O
future O
work, O
we O
plan O
to O
extend O
our O
work O
and O
research O
methods O
that O
select O
the O
best O
politeness O
strategies O
while O
accounting O
for O
the O
speciﬁcity O
of O
distinct O
conversation O
phases O
(e.g. O
greeting O
vs. O
prod- O
uct O
description O
utterances). O
Appendix O
A.1 O
Politeness O
Strategies O
Table O
7 O
shows O
some O
of O
the O
Politeness O
Strategies O
that O
can O
be O
identiﬁed O
when O
dealing O
with O
polite O
dialog. O
A.2 O
Dataset O
details O
Stanford B-DatasetName
Politeness I-DatasetName
Corpus I-DatasetName
(SPC) I-DatasetName
- O
Dataset O
used O
for O
politeness O
conditioning, O
by O
training O
the O
Politeness O
proxy O
classiﬁer O
(Niu O
and O
Bansal, O
2018). O
This O
corpus O
is O
composed O
of O
requests O
made O
by O
editors O
in O
Wikipedia O
and O
by O
requests O
made O
on O
Sack O
Ex- O
change, O
all O
of O
which O
have O
been O
annotated O
by O
5 O
humans. O
For O
Wikipedia O
and O
Stack O
Exchange O
requests, O
4,353 O
out O
of O
35,661 O
and O
6,603 O
out O
of O
373,519 O
were O
annotated, O
respectively. O
Re- O
quest O
scores O
were O
z-score O
normalized O
and O
averaged. O
We O
used O
the O
data O
splits O
used O
originally O
with O
Polite-RL B-MethodName
(Niu O
and O
Bansal, O
2018), O
so O
we O
only O
considered O
the O
top O
and O
bottom O
25% O
utter- O
ances O
for O
polite O
and O
rude O
respectively. O
3808 O
utterances O
were O
used O
for O
training O
and O
1056 O
for O
testing. O
Enron O
- O
This O
dataset O
is O
a O
collection O
of O
emails O
exchanged O
in O
the O
Enron O
company O
(Klimt O
and O
Yang, O
2004), O
that O
was O
origi- O
nally O
used O
to O
train O
the O
Tag-and-Generate O
model O
(Madaan O
et O
al., O
2020). O
We O
consider O
the O
subset O
of O
the O
Enron O
dataset O
that O
the O
authors O
automatically O
annotated O
using O
the O
Politeness O
Classi- O
ﬁer O
(Niu O
and O
Bansal, O
2018). O
This O
dataset O
is O
used O
in O
our O
work O
to O
establish O
an O
initial O
domain O
for O
a O
task-oriented O
dialog O
agent. O
For O
training, O
212k O
polite O
and O
51k O
rude O
sentences O
are O
consid- O
ered, O
for O
validation O
27k O
polite O
and O
5.8k O
rude, O
and O
for O
testing O
26k O
polite O
and O
5.8k O
rude O
utterances. O
Multimodal O
Dialogs O
Dataset O
(MMD) O
- O
MMD O
(Saha O
et O
al., O
2018) O
comprises O
multi-turn O
multimodal O
dialogs O
for O
the O
fash- O
ion O
domain. O
MMD B-DatasetName
is O
used O
as O
use-case O
for O
a O
second O
do- O
main O
task-oriented O
dialog O
agent, O
where O
we O
deﬁne O
two O
dis- O
tinct O
(but O
overlapping) O
subsets: O
MMD-R B-DatasetName
andMMD-A B-DatasetName
. O
In O
MMD-R B-DatasetName
, O
based O
on O
the O
provided O
intent O
annotations, O
we O
only O
keep O
system O
utterances O
corresponding O
to O
product(s) O
recom- O
mendation(s), O
resulting O
in O
380k/81k/81k O
utterances O
for O
train- O
ing/validation/testing. O
The O
goal O
of O
this O
ﬁrst O
subset O
is O
to O
exposeModel O
Name O
( O
b,β) O
BLEU O
Politeness O
Reference(96, O
2.0) O
66.30 O
64.47 O
Model O
1(32, O
2.0) O
49.64 O
72.40 O
Model O
2 O
(128, O
2.0) O
63.60 O
60.24 O
Model O
3 O
(96, O
5.0) O
33.56 O
75.21 O
Model O
4 O
(96, O
10.0) O
29.41 O
78.77 O
Table O
8: O
Experimental O
results O
of O
the O
4 O
tested O
scenarios O
vs O
a O
reference O
model. O
From O
now O
on, O
we O
scale O
up O
the O
politeness O
scores O
into O
a O
0 O
to O
100 O
scale. O
the O
model O
to O
the O
domain-speciﬁc O
product O
lexicon O
of O
the O
fash- O
ion O
domain. O
Namely, O
these O
utterances O
comprise O
scenarios O
in O
which O
the O
system O
recommends O
and O
describes O
one O
or O
more O
products O
to O
the O
user. O
In O
MMD-A O
we O
keep O
all O
neutral O
and O
polite O
system O
utterances, O
with O
more O
than O
5 O
tokens, O
totaling O
39k/10k/10k O
and O
414k/96k/96k, O
neutral O
and O
polite O
utterances, O
respectively, O
for O
training/validation/testing. O
Here O
we O
consid- O
ered O
a O
style O
change O
from O
neutral O
to O
polite, O
rather O
than O
rude O
to O
polite, O
since O
the O
number O
of O
rude O
utterances O
is O
minimal O
( O
2.5k). O
A.3 O
MMD O
Sample O
dialog O
A O
sample O
dialog O
from O
the O
MMD O
(Saha O
et O
al., O
2018) O
dataset O
can O
be O
found O
in O
Figure O
2. O
A.4 O
Polite-RL B-MethodName
Model O
tuning O
For O
the O
model O
parameter O
tuning, O
the O
two O
parameters, B-HyperparameterName
βand I-HyperparameterName
batch B-HyperparameterName
size I-HyperparameterName
(b), O
were O
tested O
separately, O
and, O
for O
each O
parameter, O
we O
tested O
2 O
variations O
of O
their O
values. O
To O
measure O
the O
impact O
on O
the O
results, O
we O
use O
BLEU B-MetricName
and O
the O
politeness B-MetricName
score I-MetricName
on O
the O
test O
set. O
As O
for O
baselines, O
we O
use O
a O
version O
of O
the O
model O
trained O
on O
the O
MMD O
data O
with O
the O
default O
values O
for O
each O
parameter. O
L=LML+βLRL O
(1) O
For O
the O
batch B-HyperparameterName
size I-HyperparameterName
(whose O
default O
value O
was O
96), B-HyperparameterValue
we O
tested O
the O
model O
with O
sizes B-HyperparameterName
128 B-HyperparameterValue
and O
32, B-HyperparameterValue
these O
values O
were O
picked O
to O
understand O
the O
model’s O
behavior O
with O
an O
increase O
and O
de- O
crease O
of O
the O
value. O
The O
βis O
an O
hyperparameter O
that O
dictates O
the O
weight O
given O
to O
the O
politeness O
reward O
component O
of O
the O
model’s O
loss O
function, O
as O
shown O
in O
Equation O
1 O
where O
LMLis O
the O
maximum B-HyperparameterValue
likelihood I-HyperparameterValue
loss B-HyperparameterName
and O
LRLis O
the O
politeness B-HyperparameterValue
reward I-HyperparameterValue
loss. B-HyperparameterName
For O
this O
parameter, O
we O
followed O
a O
different O
direction O
and O
tested O
with O
values O
5 O
and O
10, O
both O
signiﬁcantly O
bigger O
than O
the O
default O
value O
of O
2. O
This O
was O
done O
to O
understand O
the O
impact O
of O
the O
parameter O
in O
the O
politeness O
of O
the O
generated O
text O
and O
how O
it O
impacted O
generation O
quality. O
This O
is O
an O
important O
factor O
given O
that, O
for O
conversational O
agents, O
it O
is O
important O
to O
gener- O
ate O
polite O
text O
but O
also O
retain O
high-quality O
question O
answering O
capabilities. O
The O
results, O
shown O
in O
Table O
8, O
are O
using O
the O
Classiﬁer O
with O
custom O
embeddings. O
These O
results O
show O
that O
altering O
both O
parameters O
can O
lead O
to O
a O
noticeable O
change O
in O
the O
model’s O
performance. O
Looking O
at O
the O
BLEU B-MetricName
scores, O
none O
of O
the O
tested O
variations O
beat O
the O
base O
model, O
with O
only O
Model O
2 O
coming O
close. O
For O
the O
two O
models O
where O
we O
changed O
the O
beta O
value, O
Model O
3 O
and O
Model O
4, O
the O
BLEU B-MetricName
score O
took O
a O
nosedive, O
which O
was O
expected O
since O
by O
increasing O
the O
βwe O
are O
changing O
the O
initial O
balance O
in O
the O
loss O
function O
making O
it O
highly O
favor O
polite O
generation O
over O
accurate O
question O
answering. O
When O
looking O
at O
the O
inference O
results O
from O
both O
models, O
we O
see O
signiﬁcant O
text O
degeneration O
on O
a O
large O
portion O
of O
the O
test O
sentences, O
with O
the O
same O
pattern O
repeating: O
the O
ﬁrst O
dozen O
or O
so O
tokens O
are O
correctly O
predicted O
followed O
by O
a O
dozen O
or313Figure O
2: O
A O
sample O
dialog O
from O
the O
MMD B-DatasetName
dataset. O
Source: O
Saha O
et O
al. O
(2018) O
more O
repetitions O
of O
the O
same O
token, O
a O
token O
favored O
by O
the O
politeness O
classiﬁer. O
Still O
considering O
the O
BLEU B-MetricName
scores, O
Model O
1 O
presented O
some O
surprising O
results O
as O
we O
were O
not O
expecting O
text O
degeneration O
to O
also O
occur O
in O
this O
scenario, O
but O
it O
did, O
albeit O
not O
as O
accentuated O
as O
in O
the O
later O
2 O
models. O
When O
taking O
into O
account O
the O
politeness O
scores, O
we O
see O
that O
increasing O
the O
beta O
value O
clearly O
improves O
politeness O
gen- O
eration, O
or O
so O
it O
would O
seem, O
as O
mentioned O
before O
all O
of O
the O
models O
that O
beat O
the O
reference O
in O
politeness O
generation O
did O
it O
by O
starting O
to O
generate O
the O
same O
token O
repeatedly O
mid-sentence. O
These O
results O
showed O
us O
that O
when O
trying O
to O
encourage O
po- O
liteness O
generation, O
we O
cannot O
solely O
rely O
on O
token O
probability O
distributions, O
semantics O
need O
to O
be O
taken O
into O
account O
or, O
at O
least, O
vocabulary O
diversity O
at O
the O
classiﬁer O
level, O
since O
any O
other O
way O
the O
model O
is O
not O
punished O
by O
simply O
outputting O
the O
classiﬁer’s O
favorite O
word, O
’belt’ O
in O
some O
cases O
and O
’republic’ O
in O
others. O
This O
means O
that, O
using O
the O
Polite-RL, B-MethodName
the O
best O
balance O
that O
can O
be O
achieved O
results O
is O
a O
compromise O
in O
generation O
quality O
while O
not O
making O
the O
used O
tone O
polite. O
For O
conver- O
sational O
agents, O
this O
is O
important O
as O
the O
question O
answering O
quality O
needs O
to O
remain O
high O
throughout O
the O
conversation.314 O