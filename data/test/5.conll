Findings O
of O
the O
Association O
for O
Computational O
Linguistics: O
NAACL O
2022 O
, O
pages O
2727 O
- O
2745 O
July O
10-15, O
2022 O
©2022 O
Association O
for O
Computational O
Linguistics O
Cross-Domain B-TaskName
Classification I-TaskName
of I-TaskName
Moral I-TaskName
Values I-TaskName
Enrico O
Liscio, O
Alin O
E. O
Dondera, O
Andrei O
Gead O
˘au, O
Catholijn O
M. O
Jonker, O
and O
Pradeep O
K. O
Murukannaiah O
Delft O
University O
of O
Technology, O
the O
Netherlands O
{E.Liscio,C.M.Jonker,P.K.Murukannaiah}@tudelft.nl O
{A.E.Dondera,A.Geadau}@student.tudelft.nl O
Abstract O
Moral O
values O
influence O
how O
we O
interpret O
and O
act O
upon O
the O
information O
we O
receive. O
Identifying O
human O
moral O
values O
is O
essential O
for O
artificially O
intelligent O
agents O
to O
co-exist O
with O
humans. O
Re- O
cent O
progress O
in O
natural O
language O
processing O
allows O
the O
identification O
of O
moral O
values O
in O
textual O
discourse. O
However, O
domain-specific O
moral O
rhetoric O
poses O
challenges O
for O
transferring O
knowledge O
from O
one O
domain O
to O
another. O
We O
provide O
the O
first O
extensive O
investigation O
on O
the O
effects O
of O
cross-domain B-TaskName
classification I-TaskName
of I-TaskName
moral I-TaskName
values I-TaskName
from O
text. O
We O
compare O
a O
state-of- O
the-art O
deep O
learning O
model O
(BERT) B-MethodName
in O
seven O
domains O
and O
four O
cross-domain O
settings. O
We O
show O
that O
a O
value O
classifier O
can O
generalize O
and O
transfer O
knowledge O
to O
novel O
domains, O
but O
it O
can O
introduce O
catastrophic O
forgetting. O
We O
also O
high- O
light O
the O
typical O
classification O
errors O
in O
cross- B-TaskName
domain I-TaskName
value I-TaskName
classification I-TaskName
and O
compare O
the O
model O
predictions O
to O
the O
annotators O
agreement. O
Our O
results O
provide O
insights O
to O
computer O
and O
social O
scientists O
that O
seek O
to O
identify O
moral O
rhetoric O
specific O
to O
a O
domain O
of O
discourse. O
1 O
Introduction O
Morality O
helps O
humans O
discern O
right O
from O
wrong. O
Pluralist O
moral O
philosophers O
argue O
that O
human O
morality O
can O
be O
represented, O
understood, O
and O
ex- O
plained O
by O
a O
finite O
number O
of O
irreducible O
basic O
elements, O
referred O
to O
as O
moral O
values O
(Graham O
et O
al., O
2013). O
The O
difference O
in O
our O
preferences O
over O
moral O
values O
explains O
how O
and O
why O
we O
think O
differently. O
For O
instance, O
both O
conservatives O
and O
liberals O
may O
agree O
that O
individual O
welfare O
is O
impor- O
tant. O
However, O
a O
conservative, O
who O
cherishes O
the O
values O
of O
freedom O
and O
independence, O
may O
believe O
that O
taxes O
should O
be O
decreased O
to O
attain O
more O
indi- O
vidual O
welfare. O
In O
contrast, O
a O
liberal, O
who O
cherishes O
the O
values O
of O
community O
and O
care, O
may O
believe O
that O
taxes O
should O
be O
increased O
to O
obtain O
welfare O
(Graham O
et O
al., O
2009).It O
is O
crucial O
to O
understand O
human O
morality O
to O
de- O
velop O
beneficial O
AI O
(Russell O
et O
al., O
2015; O
Soares O
and O
Fallenstein, O
2017). O
To O
operate O
among O
humans, O
arti- O
ficial O
agents O
must O
be O
able O
to O
comprehend O
and O
recog- O
nize O
the O
moral O
values O
that O
drive O
the O
differences O
in O
human O
behavior O
(Akata O
et O
al., O
2020; O
Gabriel, O
2020). O
The O
ability O
to O
understand O
moral O
rhetoric O
can O
be O
in- O
strumental O
for, O
e.g., O
facilitating O
human-agent O
trust O
(Chhogyal O
et O
al., O
2019; O
Mehrotra O
et O
al., O
2021) O
and O
engineering O
value-aligned O
socio-technical O
systems O
(Ajmeri O
et O
al., O
2020; O
Murukannaiah O
et O
al., O
2020; O
Serramia O
et O
al., O
2021; O
Montes O
and O
Sierra, O
2021). O
There O
are O
survey O
instruments O
to O
estimate O
individ- O
ual O
value O
profiles O
(Schwartz, O
2012; O
Graham O
et O
al., O
2013). O
However, O
reasoning O
about O
moral O
values O
is O
challenging O
for O
humans O
(Le O
Dantec O
et O
al., O
2009; O
Pommeranz O
et O
al., O
2012). O
Further, O
in O
practical O
appli- O
cations, O
e.g., O
to O
conduct O
meaningful O
conversations O
(Tigunova O
et O
al., O
2019) O
or O
to O
identify O
online O
trends O
(Mooijman O
et O
al., O
2018), O
artificial O
agents O
should O
be O
able O
to O
understand O
moral O
rhetoric O
on O
the O
fly. O
The O
growing O
capabilities O
of O
natural O
language O
processing O
(NLP) O
enable O
the O
estimation O
of O
moral O
rhetoric O
from O
textual O
discourse O
(Hoover O
et O
al., O
2020; O
Araque O
et O
al., O
2020; O
Alshomary O
et O
al., O
2022; O
Kiesel O
et O
al., O
2022). O
Specifically, O
a O
value O
classifier O
can O
be O
used O
to O
identify O
the O
moral O
values O
underlying O
a O
piece O
of O
text O
on O
the O
fly. O
For O
instance, O
Mooijman O
et O
al. O
(2018) O
show O
that O
detecting O
moral O
values O
from O
tweets O
can O
predict O
violent O
protests. O
Existing O
value O
classifiers O
are O
evaluated O
on O
a O
spe- O
cific O
dataset, O
without O
re-training O
or O
testing O
the O
clas- O
sifier O
on O
a O
different O
dataset. O
This O
shows O
the O
ability O
of O
the O
classifier O
to O
predict O
values O
from O
text, O
but O
not O
the O
ability O
to O
transfer O
the O
learned O
knowledge O
across O
datasets. O
A O
critical O
aspect O
of O
moral O
values O
is O
that O
they O
are O
intrinsically O
linked O
to O
the O
domain O
under O
discussion O
(Pommeranz O
et O
al., O
2012; O
Liscio O
et O
al., O
2021, O
2022). O
Moral O
value O
expressions O
may O
take O
different O
forms O
in O
different O
domains. O
For O
example, O
in O
the O
driving O
domain, O
the O
value O
of O
safety O
concerns2727speed O
limits O
and O
seat O
belts, O
but O
in O
the O
COVID-19 O
domain, O
safety O
concerns O
social O
distancing O
and O
face O
masks. O
Further, O
a O
word O
(broadly, O
language) O
may O
trigger O
different O
moral O
rhetoric O
in O
different O
domains. O
For O
example, O
in O
a O
libertarian O
blog, O
the O
word O
‘taxes’ O
may O
be O
linked O
to O
the O
authority O
value, O
but O
in O
a O
social- O
ist O
blog O
it O
may O
be O
linked O
to O
the O
community O
value. O
Thus, O
it O
is O
crucial O
for O
a O
value O
classifier O
to O
recognize O
domain-specific O
connotations O
of O
moral O
rhetoric. O
Collecting O
and O
annotating O
a O
sufficient O
amount O
of O
training O
examples O
in O
each O
domain O
is O
expensive O
and O
time O
consuming. O
To O
reduce O
the O
need O
for O
new O
an- O
notated O
examples, O
we O
can O
pretrain O
classifiers O
with O
similar O
available O
annotated O
data O
and O
transfer O
the O
acquired O
knowledge O
to O
a O
novel O
task—a O
practice O
known O
as O
transfer O
learning O
(Ruder, O
2019). O
De- O
spite O
the O
benefits, O
transfer O
learning O
poses O
well- O
known O
challenges, O
including: O
(1) O
generalizability O
: O
how O
well O
does O
a O
classifier O
perform O
on O
novel O
data? O
(2)transferability O
: O
how O
well O
is O
knowledge O
trans- O
ferred O
from O
one O
domain O
to O
another? O
and O
(3) O
catas- O
trophic O
forgetting O
: O
to O
what O
extent O
is O
knowledge O
of O
a O
previous O
domain O
lost O
after O
training O
in O
a O
new O
domain? O
These O
challenges O
are O
crucial O
for O
value B-TaskName
classification I-TaskName
because O
of O
its O
domain-specific O
nature. O
We O
perform O
the O
first O
comprehensive O
cross- O
domain O
evaluation O
of O
a O
value O
classifier. O
We O
em- O
ploy O
the O
Moral B-DatasetName
Foundation I-DatasetName
Twitter I-DatasetName
Corpus I-DatasetName
(Hoover O
et O
al., O
2020), O
consisting O
of O
seven O
datasets O
spanning O
different O
socio-political O
areas, O
annotated O
with O
the O
value O
taxonomy O
of O
the O
Moral O
Foundation O
Theory O
(Graham O
et O
al., O
2013). O
Treating O
each O
dataset O
as O
a O
domain, O
we O
train O
a O
deep O
learning O
model, O
BERT B-MethodName
(Devlin O
et O
al., O
2019), O
in O
four O
training O
settings O
to O
evaluate O
the O
value O
classifier’s O
generalizability, O
trans- O
ferability, O
and O
catastrophic O
forgetting. O
Our O
experiments O
show O
that O
(1) O
a O
value O
classifier O
can O
generalize O
to O
novel O
domains, O
especially O
when O
trained O
on O
a O
variety O
of O
domains; O
(2) O
initializing O
a O
classifier O
with O
examples O
from O
different O
domains O
im- O
proves O
performance O
in O
novel O
domains O
even O
when O
little O
training O
data O
is O
available O
in O
the O
novel O
domains; O
(3) O
catastrophic O
forgetting O
occurs O
even O
when O
train- O
ing O
on O
a O
small O
portion O
of O
data O
from O
the O
novel O
do- O
main, O
and O
its O
impact O
must O
be O
considered O
when O
train- O
ing O
on O
a O
novel O
domain; O
and O
(4) O
in O
the O
large O
majority O
of O
cases, O
in O
all O
considered O
training O
settings, O
at O
least O
one O
annotator O
agrees O
with O
the O
model O
predictions. O
Our O
investigation O
is O
significant O
because O
moral O
rhetoric O
is O
seldom O
explicit O
in O
language, O
but O
often O
lies O
in O
subtle O
domain-dependent O
cues. O
Understand-ing O
whether O
a O
classifier O
can O
recognize O
and O
transfer O
such O
hidden O
patterns O
across O
domains O
is O
instrumen- O
tal O
for O
the O
practical O
use. O
By O
unveiling O
the O
successes O
and O
mistakes O
of O
value O
classifiers O
in O
cross-domain O
settings, O
we O
hope O
to O
inspire O
researchers O
and O
practi- O
tioners O
to O
employ O
value B-TaskName
classification I-TaskName
responsibly. O
2 O
Background O
and O
Data O
We O
introduce O
the O
Moral B-DatasetName
Foundation I-DatasetName
Theory I-DatasetName
(MFT) I-DatasetName
(Graham O
et O
al., O
2013) O
and O
the O
Moral B-DatasetName
Foundation I-DatasetName
Twitter I-DatasetName
Corpus I-DatasetName
(MFTC) I-DatasetName
(Hoover O
et O
al., O
2020) O
used O
in O
our O
experiments. O
The O
MFT B-DatasetName
is O
a O
well-established O
theory O
of O
moral O
values O
developed O
by O
social O
and O
cultural O
psycholo- O
gists. O
It O
argues O
that O
human O
morality O
is O
composed O
of O
a O
finite O
set O
of O
innate O
moral O
foundations, O
similar O
to O
how O
the O
five O
taste O
receptors O
(for O
sweet, O
sour, O
salt, O
bitter, O
and O
umami) O
combine O
to O
yield O
the O
tastes O
we O
experience. O
The O
MFT B-DatasetName
includes O
five O
foundations, O
each O
composed O
of O
a O
vice–virtue O
duality, O
resulting O
in O
the O
10 O
moral O
values O
shown O
in O
Table O
1. O
The O
MFTC B-DatasetName
is O
composed O
of O
35,108 O
tweets, O
di- O
vided O
into O
seven O
datasets, O
each O
corresponding O
to O
a O
topic: O
All B-DatasetName
Lives I-DatasetName
Matter I-DatasetName
( I-DatasetName
ALM I-DatasetName
), I-DatasetName
Baltimore I-DatasetName
protests I-DatasetName
(BLT I-DatasetName
), I-DatasetName
Black I-DatasetName
Lives I-DatasetName
Matter I-DatasetName
( I-DatasetName
BLM I-DatasetName
), I-DatasetName
hate I-DatasetName
speech I-DatasetName
and I-DatasetName
offensive I-DatasetName
language I-DatasetName
( I-DatasetName
DA I-DatasetName
V I-DatasetName
) I-DatasetName
(Davidson O
et O
al., O
2017), O
2016 B-DatasetName
presidential I-DatasetName
election I-DatasetName
( I-DatasetName
ELE I-DatasetName
), I-DatasetName
MeToo I-DatasetName
move- I-DatasetName
ment I-DatasetName
( I-DatasetName
MT), I-DatasetName
and I-DatasetName
hurricane I-DatasetName
Sandy I-DatasetName
( I-DatasetName
SND I-DatasetName
). I-DatasetName
These O
datasets O
from O
complex O
and O
diverse O
socio-political O
issues O
allow O
us O
to O
evaluate O
the O
transferability O
by O
treating O
each O
dataset O
as O
belonging O
to O
a O
domain. O
The O
tweets O
were O
annotated O
by O
multiple O
annota- O
tors O
with O
the O
MFT B-DatasetName
taxonomy. O
Hoover O
et O
al. O
(2020) O
provide O
additional O
details O
on O
the O
annotation O
pro- O
cess. O
They O
recognize O
that O
the O
vice O
and O
the O
virtue O
constituting O
one O
moral O
foundation O
are O
expressed O
differently O
in O
natural O
language. O
For O
example, O
an O
ut-2728terance O
describing O
a O
care O
concern O
(e.g., O
taking O
care O
of O
one’s O
offspring) O
does O
not O
necessarily O
also O
con- O
tain O
harm O
expressions. O
For O
this O
reason, O
each O
tweet O
was O
annotated O
with O
all O
10 O
individual O
moral O
values O
plus O
an O
additional O
nonmoral O
label, O
resulting O
in O
11 O
possible O
labels O
per O
tweet. O
Due O
to O
the O
subjective O
nature O
of O
moral O
values, O
different O
annotators O
may O
label O
the O
same O
tweet O
differently. O
For O
this O
reason, O
Hoover O
et O
al. O
(2020) O
apply O
a O
majority O
vote O
to O
select O
the O
definitive O
label(s) O
of O
each O
tweet. O
Tweets O
with O
no O
majority O
label O
are O
labeled O
as O
nonmoral. O
Table O
2 O
shows O
three O
examples O
of O
annotated O
tweets. O
Table O
3 O
shows O
the O
distribution O
of O
labels. O
The O
MeanIR O
is O
a O
measure O
of O
imbalance O
in O
a O
dataset O
(Charte O
et O
al., O
2015). O
MeanIR O
is O
the O
mean O
of O
IR O
lfor O
each O
label O
l, O
where O
IR O
lis O
the O
ratio O
of O
the O
number O
of O
instances O
having O
the O
majority O
(i.e., O
nonmoral) O
label O
and O
the O
number O
of O
instances O
having O
label O
l. O
The O
degree O
of O
imbalance O
varies O
largely O
across O
datasets, O
which O
is O
realistic O
since O
different O
domains O
are O
likely O
to O
have O
different O
distributions O
of O
moral O
content. O
Experimental O
Setup O
Predicting O
moral O
values O
is O
a O
multi-label O
classifica- O
tion O
problem. O
Given O
a O
set O
of O
textual O
documents, O
T, O
and O
a O
set O
of O
moral O
value O
labels, O
L= O
(l1, O
l2, O
. O
. O
. O
, O
l O
n),we O
wish O
to O
learn O
a O
mapping O
C:T O
∝⇕⊣√∫⊔≀→ O
P O
(L). O
Each O
element O
in O
P(L)is O
a O
binary O
vector, O
y= O
(y1, O
y2, O
. O
. O
. O
, O
y O
n), O
where O
yi= O
1if O
the O
corresponding O
text O
is O
labeled O
with O
li. O
The O
mapping O
Cis O
learned O
via O
BERT B-MethodName
(Devlin O
et O
al., O
2019), O
a O
language O
representa- O
tion O
model O
based O
on O
the O
Transformer O
architecture O
(Vaswani O
et O
al., O
2017). O
We O
choose O
BERT B-MethodName
as O
it O
rep- O
resents O
the O
state-of-the-art O
for O
several O
NLP O
tasks, O
including O
value B-TaskName
classification I-TaskName
(Kobbe O
et O
al., O
2020; O
Alshomary O
et O
al., O
2022; O
Kiesel O
et O
al., O
2022). O
We O
provide O
additional O
details, O
including O
hyperparam- O
eters, O
in O
the O
Appendix. O
The O
code O
is O
available O
on O
GitHub1. O
3.1 O
Cross-Domain O
Evaluation O
To O
perform O
cross-domain O
evaluation, O
we O
partition O
the O
MFTC B-DatasetName
datasets O
into O
Tsource O
andTtarget O
. O
We O
treatTsource O
as O
available O
data O
and O
Ttarget O
as O
an O
in- O
coming O
dataset O
from O
a O
novel O
domain. O
In O
our O
exper- O
iments, O
Ttarget O
is O
always O
composed O
of O
one O
MFTC B-DatasetName
dataset. O
We O
experiment O
with O
Tsource O
composed O
of O
one, O
three, O
and O
six O
datasets. O
We O
present O
the O
re- O
sults O
for O
the O
setting O
with O
six O
datasets O
as O
Tsource O
in O
Section O
4 O
and O
the O
other O
settings O
in O
the O
Appendix. O
For O
each O
partition, O
we O
train O
a O
value O
classifier, O
C, O
in O
each O
of O
the O
four O
scenarios O
shown O
in O
Fig- O
ure O
1. O
These O
scenarios O
differ O
in O
how O
the O
classifier O
is O
trained. O
(1) O
In O
the O
source O
scenario, O
Tsource O
is O
the O
training O
set. O
(2) O
In O
the O
target O
scenario, O
Ttarget O
is O
the O
training O
set. O
(3) O
In O
the O
finetune O
scenario, O
the O
classifier O
is O
first O
trained O
on O
Tsource O
and O
then O
contin- O
ued O
to O
train O
(i.e., O
finetuned) O
on O
Ttarget O
. O
(4) O
In O
the O
allscenario, O
the O
training O
set O
includes O
both O
Tsource O
andTtarget O
. O
Tsour O
cesourceTsour O
ce O
TtargetC(sou O
rce,target)train O
eval O
Ttargettarget O
Tsour O
ce O
Ttargettrain O
eval O
Tsour O
ce O
Ttargetfinetune O
Tsour O
ce O
Ttargetevaltrain O
finetune O
Tsour O
ce O
+ O
TtargetallTsour O
ce O
Ttargettrain O
evalC(sou O
rce,source O
) O
C(finetune, O
source O
)C(target, O
target)C(target, O
source O
) O
C(all, O
target)C(all, O
source O
)C(finetune, O
target)C O
CCC O
https://github.com/adondera/ O
transferability-of-values2729In O
each O
scenario, O
the O
classifier O
is O
evaluated O
on O
bothTsource O
andTtarget O
, O
resulting O
in O
eight O
settings O
(combinations O
of O
training O
scenario O
and O
evaluation O
set) O
as O
shown O
in O
Figure O
1. O
For O
example, O
C(source, O
target O
)indicates O
that O
Cis O
trained O
in O
the O
source O
scenario O
(i.e., O
on O
Tsource O
) O
and O
evaluated O
on O
Ttarget O
. O
As O
we O
have O
seven O
partitions O
and O
four O
scenarios, O
we O
train O
28 O
unique O
models. O
We O
evaluate O
the O
models O
on O
both O
Tsource O
andTtarget O
, O
covering O
56 O
settings. O
3.2 O
Comparisons O
Our O
experimental O
setting O
(partitioning, O
training O
sce- O
narios, O
and O
evaluation O
settings) O
enables O
a O
compre- O
hensive O
cross-domain O
evaluation O
of O
the O
value O
clas- O
sifiers O
as O
described O
below. O
Baseline O
C(source, O
source O
)and O
C(target, O
target O
)show O
the O
performances O
of O
a O
value O
classi- O
fier O
on O
the O
training O
domain, O
when O
no O
cross-domain O
training O
is O
performed. O
Topline O
C(all, O
source O
)andC(all, O
target O
)repre- O
sent O
the O
ideal O
scenario, O
where O
all O
data O
is O
simultane- O
ously O
available O
for O
training. O
Generalizability O
C(source, O
target O
) O
and O
C(target, O
source O
)reflect O
the O
ability O
of O
a O
value O
classifier O
to O
generalize O
to O
a O
new O
domain. O
Transferability O
Comparing O
C(finetune, O
target O
) O
andC(target, O
target O
)shows O
whether O
the O
knowl- O
edge O
learned O
by O
pretraining O
on O
Tsource O
(finetune O
scenario) O
has O
an O
advantage O
over O
the O
absence O
of O
pre- O
training O
( O
target O
scenario). O
Catastrophic O
Forgetting O
Comparing O
C(finetune, O
source O
)andC(source, O
source O
) O
shows O
the O
extent O
to O
which O
the O
knowledge O
learned O
by O
training O
on O
Tsource O
is O
lost O
when O
finetuned O
on O
Ttarget O
. O
3.3 O
Metrics O
Since O
the O
imbalance O
in O
our O
datasets O
varies O
greatly, O
we O
report O
both O
the O
micro B-MetricName
F1-score I-MetricName
and O
the O
macro B-MetricName
F1-score I-MetricName
in O
each O
setting. O
The O
micro B-MetricName
F1-score, I-MetricName
m, B-MetricName
is O
the O
weighted O
(by O
class O
size) O
mean O
of O
the O
per- O
label O
F1-scores. B-MetricName
The O
macro B-MetricName
F1-score, I-MetricName
M, B-MetricName
is O
the O
unweighted O
mean O
of O
the O
per-label O
F1-scores. B-MetricName
When O
training O
and O
testing O
on O
the O
same O
set, O
we O
use O
10-fold O
cross-validation O
with O
fixed O
splits O
into O
training O
and O
test O
data, O
and O
report O
the O
average B-MetricName
F1- I-MetricName
scores I-MetricName
over O
the O
10 O
runs. O
For O
consistency, O
when O
testing O
on O
a O
set O
different O
from O
the O
training O
set, O
we O
test O
on O
10 O
splits O
of O
the O
set O
(i.e., O
ultimately O
on O
the O
whole O
set) O
and O
report O
average B-MetricName
F1-scores.4 I-MetricName
Results O
and O
Discussion O
We O
evaluate O
the O
performance O
of O
the O
model O
in O
four O
training O
scenarios O
( O
source O
,target O
,finetune O
,all). O
Table O
4 O
reports O
the O
micro O
and O
macro O
F1-scores B-MetricName
of O
the O
eight O
evaluation O
settings. O
The O
columns O
indicate O
the O
dataset O
used O
as O
Ttarget O
(e.g., O
in O
the O
BLT B-DatasetName
column, O
BLT B-DatasetName
is O
Ttarget O
and O
the O
remaining O
six O
datasets O
com- O
poseTsource O
). O
The O
final O
column O
reports O
the O
average B-MetricName
F1-scores I-MetricName
over O
the O
seven O
datasets. O
We O
also O
report O
the O
results O
of O
the O
majority O
classifier O
which O
labels O
all O
tweets O
as O
nonmoral O
(the O
majority O
class O
in O
all O
datasets), O
for O
both O
Tsource O
andTtarget O
. O
We O
perform O
Wilcoxon’s O
ranksum O
test O
(Hollander O
and O
Wolfe, O
1999) O
to O
evaluate O
whether O
two O
results O
significantly O
differ O
or O
not. O
In O
each O
column O
(and O
in O
the O
top-half O
or O
the O
bottom-half), O
we O
choose O
the O
setting O
with O
the O
highest O
F1-score B-MetricName
and O
perform O
a O
pair-wise O
comparison O
with O
each O
of O
the O
other O
set- O
tings O
in O
that O
(half) O
column. O
We O
highlight, O
in O
bold, O
the O
best O
result O
and O
the O
results O
that O
are O
not O
signifi- O
cantly O
different O
( O
p O
> O
0.05) O
from O
the O
best. O
4.1 O
General O
Trends O
Before O
cross-domain O
analysis, O
we O
observe O
some O
general O
trends. O
First, O
the O
topline O
training O
scenario O
(all) O
leads O
to O
the O
best O
results O
when O
evaluating O
on O
bothTsource O
andTtarget O
(Table O
4). O
However, O
all O
is O
the O
ideal O
scenario. O
In O
the O
top O
half O
of O
the O
ta- O
ble,C(source, O
source O
)has O
comparable O
results O
to O
C(all, O
source O
), O
which O
is O
to O
be O
expected, O
since O
the O
two O
models O
are O
trained O
on O
similar O
data O
(six O
out O
of O
seven O
datasets O
in O
the O
source O
scenario, O
all O
seven O
in O
the O
allscenario). O
Analogously, O
in O
the O
bottom O
half O
of O
the O
table, O
the O
C(finetune, O
target O
)setting O
leads O
to O
results O
comparable O
to O
C(all, O
target O
). O
We O
analyze O
this O
result O
further O
in O
Section O
4.3. O
Second, O
the O
results O
are O
rather O
consistent O
across O
datasets O
when O
evaluating O
on O
Tsource O
(top O
half O
of O
Table O
4), O
but O
have O
large O
differences O
when O
evalu- O
ating O
on O
Ttarget O
(bottom O
half O
of O
Table O
4). O
These O
differences O
can O
be O
attributed O
to O
BLT B-DatasetName
and O
DA B-DatasetName
V I-DatasetName
, O
two O
highly-imbalanced O
datasets O
(Table O
3). O
The O
class O
im- O
balance O
also O
justifies O
the O
large O
difference O
between O
micro B-MetricName
and I-MetricName
macro I-MetricName
F1-scores I-MetricName
for O
these O
two O
datasets. O
4.2 O
Generalizability O
To O
evaluate O
generalizability, O
we O
analyze O
the O
results O
for O
the O
C(source, O
target O
)andC(target, O
source O
) O
settings. O
In O
C(source, O
target O
),Tsource O
includes O
six O
datasets O
and O
Ttarget O
includes O
one O
dataset. O
In O
contrast, O
in O
C(target, O
source O
),Tsource O
includes O
one O
dataset O
and O
Ttarget O
includes O
six O
datasets. O
Thus, O
C(target, O
source O
)is O
a O
more O
challenging O
setting O
for O
generalization O
than O
C(source, O
target O
). O
First, O
we O
observe O
that O
the O
model O
achieves O
better O
average B-MetricName
F1-scores I-MetricName
in O
the O
C(source, O
target O
)setting O
than O
the O
majority O
( O
target O
) O
baseline. O
This O
indicates O
that O
the O
moral O
rhetoric O
learned O
on O
a O
varied O
array O
of O
domains O
is O
generalizable O
to O
a O
novel O
domain O
to O
some O
extent, O
in O
spite O
of O
the O
domain-specific O
na- O
ture O
of O
moral O
values. O
However, O
the O
performances O
inC(source, O
target O
)are O
not O
on O
par O
with O
the O
best O
results O
on O
Ttarget O
, O
as O
we O
discuss O
in O
Section O
4.3. O
Second, O
we O
observe O
that O
the O
model O
achieves O
bet- O
ter O
average B-MetricName
F1-scores I-MetricName
in O
the O
C(target, O
source O
)set- O
ting O
than O
the O
majority O
( O
source O
) O
baseline, O
despite O
the O
more O
challenging O
setting. O
However, O
the O
re- O
sults O
are O
just O
marginally O
better O
than O
the O
majority O
(source O
) O
baseline, O
showing O
the O
difficulty O
in O
gener- O
alizing O
from O
one O
to O
multiple O
domains. O
Finally, O
in O
both O
cases, O
when O
we O
look O
at O
the O
results O
for O
individual O
datasets, O
the O
generalizability O
result O
does O
not O
hold O
for O
BLT B-DatasetName
and O
DA B-DatasetName
V I-DatasetName
, O
which O
highlights O
the O
challenge O
of O
generalizing O
to O
domains O
with O
a O
skewed O
distribution O
of O
moral O
values. O
4.3 O
Transferability O
Recall O
that, O
in O
the O
target O
scenario, O
a O
model O
is O
only O
trained O
on O
Ttarget O
, O
but O
in O
the O
finetune O
sce- O
nario, O
the O
model O
is O
first O
trained O
on O
Tsource O
and O
then O
finetuned O
on O
Ttarget O
. O
Thus, O
to O
evaluate O
transfer- O
ability, O
we O
compare O
the O
C(finetune, O
target O
)and O
C(target, O
target O
)settings. O
From O
the O
average B-MetricName
F1-scores I-MetricName
in O
Table O
4, O
we O
ob- O
serve O
that O
C(finetune, O
target O
)performs O
better O
than O
or O
on O
par O
with O
C(target, O
target O
)—precisely, O
similar O
mand O
8% O
increase O
of O
M. O
Thus, O
the O
bene-fits O
of O
finetuning O
are O
larger O
for O
the O
macro O
than O
the O
micro B-MetricName
F1-scores. I-MetricName
This O
suggests O
that O
pretraining O
on O
Tsource O
, O
which O
contains O
a O
more O
varied O
distribution O
of O
labels O
than O
Ttarget O
, O
improves O
the O
prediction O
of O
the O
minority O
labels O
in O
Ttarget O
. O
To O
transfer O
knowledge O
from O
Tsource O
toTtarget O
, O
typically, O
we O
need O
some O
labeled O
data O
in O
Ttarget O
. O
For O
the O
results O
in O
Table O
4, O
we O
used O
90% O
of O
Ttarget O
for O
training, O
and O
the O
leftover O
10% O
for O
evaluating O
at O
each O
fold. O
However, O
in O
practice, O
such O
a O
large O
amount O
of O
training O
data O
may O
not O
be O
available O
in O
the O
target O
do- O
main. O
Thus, O
we O
perform O
an O
additional O
experiment O
to O
compare O
C(target, O
target O
)andC(finetune, O
target O
), O
when O
trained O
or O
finetuned, O
respectively, O
on O
a O
smaller O
portion O
of O
Ttarget O
(10%, O
25%, O
and O
50%) O
and O
tested O
on O
a O
fixed, O
randomly O
selected, O
10% O
of O
Ttarget O
. O
Figure O
2 O
shows O
this O
comparison. O
We O
re- O
port O
the O
average O
results O
of O
10-fold O
cross-validations O
performed O
on O
each O
of O
the O
seven O
datasets. O
We O
make O
an O
important O
observation O
from O
Fig- O
ure O
2. O
The O
finetuning O
paradigm O
does O
not O
require O
a O
large O
portion O
of O
Ttarget O
to O
perform O
well O
in O
the O
target O
domain. O
In O
contrast, O
the O
performance O
of O
C(target, O
target O
)increases O
(but O
does O
not O
surpass2731C(finetune, O
target O
)) O
as O
training O
data O
from O
Ttarget O
increases. O
Indeed, O
C(finetune, O
target O
)with O
10% O
ofTtarget O
performs O
on O
par O
with O
C(target, O
target O
) O
trained O
on O
90% O
of O
Ttarget O
. O
This O
result O
shows O
that O
transferring O
the O
knowledge O
of O
values O
from O
source O
domains O
to O
a O
target O
domain O
is O
valuable O
especially O
when O
the O
target O
domain O
has O
little O
training O
data. O
4.4 O
Catastrophic O
Forgetting O
Recall O
that, O
in O
the O
source O
scenario, O
a O
model O
is O
only O
trained O
on O
Tsource O
, O
but O
in O
the O
finetune O
scenario, O
the O
model O
is O
first O
trained O
on O
Tsource O
and O
then O
fine- O
tuned O
on O
Ttarget O
. O
Thus, O
comparing O
C(finetune, O
source O
)andC(source, O
source O
)provides O
insight O
on O
the O
extent O
to O
which O
a O
model O
forgot O
about O
Tsource O
because O
of O
finetuning O
on O
Ttarget O
. O
We O
observe O
that O
the O
model O
suffers O
from O
catas- O
trophic O
forgetting O
since O
finetuning O
on O
Ttarget O
re- O
duces O
the O
performance O
on O
Tsource O
. O
The O
forgetting O
is O
most O
evident O
when O
finetuning O
on O
unbalanced O
datasets O
such O
as O
DA B-DatasetName
V I-DatasetName
than O
balanced O
datasets O
such O
as O
BLM. B-DatasetName
In O
fact, O
C(finetune, O
source O
)leads O
to O
only O
slightly O
worse O
results O
than O
C(source, O
source O
) O
in O
BLM B-DatasetName
(decrease O
of O
2% O
in O
mand O
7% O
in O
M), O
with O
the O
difference O
being O
largest O
in O
DA B-DatasetName
V I-DatasetName
(decrease O
of O
15% O
in O
mand O
25% O
in O
M). O
Figure O
2 O
shows O
that O
the O
finetuning O
paradigm O
en- O
sures O
good O
performances O
on O
Ttarget O
even O
when O
the O
model O
is O
trained O
on O
a O
small O
portion O
of O
Ttarget O
. O
Next, O
we O
evaluate O
catastrophic O
forgetting O
in O
the O
same O
setting, O
comparing O
C(source, O
source O
)and O
C(finetune, O
source O
)when O
the O
model O
is O
trained O
with O
increasing O
portions O
of O
Ttarget O
(10%, O
25%, O
and O
50%) O
as O
shown O
in O
Figure O
3. O
Figure O
3 O
indicates O
that O
catastrophic O
forgetting O
worsens O
as O
the O
model O
is O
trained O
with O
a O
larger O
por- O
tion O
of O
Ttarget O
.C(finetune, O
source O
)trained O
with O
10% O
of O
Ttarget O
leads O
to O
a O
decrease O
of O
4% O
in O
m O
and O
7% O
in O
Mcompared O
to O
C(source, O
source O
)(ev- O
ident O
by O
comparing O
the O
source O
flat O
blue O
line O
to O
thefirst O
red O
finetune O
square O
in O
Figure O
3). O
Further, O
C(finetune, O
target O
)trained O
with O
10% O
of O
Ttarget O
leads O
to O
an O
increase O
of O
7% O
in O
mand O
6% O
in O
M O
compared O
to O
C(source, O
target O
)(evident O
by O
com- O
paring O
the O
average O
C(source, O
target O
)in O
Table O
4 O
to O
the O
first O
red O
finetune O
square O
in O
Figure O
2). O
These O
results O
show O
the O
tradeoff O
between O
the O
advantage O
of O
transfer O
learning O
and O
the O
impact O
of O
forgetting, O
even O
when O
finetuning O
with O
a O
small O
portion O
of O
Ttarget O
. O
4.5 O
Misclassification O
Errors O
We O
reported O
F1-scores B-MetricName
to O
provide O
an O
overview O
of O
the O
model O
performance O
in O
different O
training O
set- O
tings. O
Next, O
we O
investigate O
the O
behavior O
of O
the O
model O
through O
the O
lens O
of O
the O
MFT. B-DatasetName
We O
inspect O
(1) O
the O
confusion O
between O
morally O
loaded O
and O
non- O
moral O
tweets, O
and, O
(2) O
the O
mistakes O
among O
and O
within O
moral O
foundations O
since O
moral O
foundations O
are O
differentially O
manifested O
in O
language O
(Kennedy O
et O
al., O
2021). O
We O
highlight O
the O
following O
four O
types O
of O
misclassification O
errors O
(which O
add O
up O
to O
100%): O
Error O
I O
A O
tweet O
labeled O
with O
one O
(or O
more) O
values O
is O
classified O
(by O
the O
model) O
as O
nonmoral. O
Error O
II O
A O
tweet O
labeled O
as O
nonmoral O
is O
classified O
with O
one O
(or O
more) O
values. O
Error O
III O
A O
tweet O
labeled O
with O
a O
value O
is O
classified O
with O
values O
from O
other O
foundations. O
Error O
IV O
A O
tweet O
labeled O
as O
a O
vice/virtue O
is O
clas- O
sified O
as O
the O
opposite O
virtue/vice O
of O
the O
foundation. O
Table O
5 O
shows O
the O
distribution O
of O
errors, O
averaged O
over O
the O
seven O
datasets. O
Table O
5: O
Distribution O
of O
errors O
per O
setting O
(in O
percentage) O
Setting O
Err. O
I O
Err. O
II O
Err. O
III O
Err. O
IV O
C(source, O
source O
) O
25.8 O
34.3 O
36.3 O
3.5 O
C(target, O
source O
) O
41.8 O
24.4 O
32.0 O
1.8 O
C(finetune, O
source O
)38.7 O
27.5 O
31.3 O
2.5 O
C(all, O
source O
) O
25.9 O
34.3 O
36.3 O
3.4 O
C(source, O
target O
) O
34.7 O
32.3 O
30.2 O
2.8 O
C(target, O
target O
) O
31.5 O
27.6 O
38.5 O
2.4 O
C(finetune, O
target O
)36.0 O
28.6 O
32.6 O
2.8 O
C(all, O
target O
) O
30.8 O
33.0 O
33.1 O
3.1 O
Generalizability O
InC(target, O
source O
), O
Error O
I O
occurs O
largely O
more O
often O
than O
the O
other O
errors, O
indicating O
that, O
when O
generalizing O
from O
one O
to O
sev- O
eral O
domains, O
labeling O
value-laden O
tweets O
as O
non- O
moral O
is O
the O
most O
common O
mistake. O
In O
contrast, O
inC(source, O
target O
), O
when O
generalizing O
from O
sev- O
eral O
to O
one O
domain, O
Error O
I O
is O
less O
prominent, O
in- O
dicating O
that O
the O
model O
attempts O
to O
classify O
moral O
rhetoric O
in O
the O
novel O
domain.2732Transferability O
Error O
III O
is O
more O
prevalent O
inC(target, O
target O
)thanC(finetune, O
target O
). O
Thus, O
the O
confusion O
among O
moral O
values O
reduces O
when O
a O
model O
is O
pretrained O
on O
the O
source O
domain. O
Catastrophic O
Forgetting O
Error O
I O
occurs O
largely O
more O
often O
in O
C(finetune, O
source O
)than O
C(source, O
source O
), O
indicating O
that O
the O
major O
type O
of O
catastrophic O
forgetting O
is O
missing O
moral O
rhetoric O
in O
the O
source O
dataset. O
Finally, O
Error O
IV O
occurs O
seldom, O
suggesting O
that O
the O
models O
generally O
learn O
to O
not O
confuse O
between O
virtues O
and O
vices O
of O
the O
same O
moral O
foundation. O
4.6 O
Annotators O
Agreement O
We O
analyze O
the O
correspondence O
between O
the O
model O
predictions O
and O
the O
annotators O
agreement. O
Each O
tweet O
in O
the O
MFTC B-DatasetName
was O
annotated O
by O
at O
least O
three O
and O
at O
most O
eight O
different O
annotators O
(Hoover O
et O
al., O
2020, O
Table O
1). O
More O
than O
99% O
of O
the O
tweets O
were O
annotated O
by O
three O
to O
five O
annotators O
and O
84% O
by O
three O
or O
four O
annotators. O
As O
described O
in O
Section O
2, O
the O
majority O
agreement O
was O
selected O
for O
training O
and O
evaluation—that O
is, O
only O
values O
annotated O
by O
at O
least O
50% O
of O
the O
annotators O
were O
retained O
as O
correct O
labels. O
However, O
given O
the O
subjectivity O
in O
value O
annotation, O
values O
labeled O
by O
a O
minority O
of O
annotators O
ought O
to O
be O
considered O
too. O
Tables O
6 O
and O
7 O
show O
the O
percentage O
of O
annota- O
tors O
that O
agree O
with O
the O
model O
predictions O
consid- O
ered O
as O
errors O
and O
accurate, O
respectively, O
averaged O
over O
the O
seven O
datasets. O
The O
columns O
indicate O
the O
percentage O
of O
annotators O
agreeing O
with O
the O
model O
prediction. O
For O
instance, O
if O
one O
out O
of O
the O
four O
work- O
ers O
who O
annotated O
a O
tweet O
agrees O
with O
the O
model O
prediction, O
we O
record O
a O
25% O
agreement. O
Table O
6: O
Distribution O
(in O
percentage) O
of O
classification O
errors O
and O
annotators O
agreement O
percentage O
Setting O
0(0,25] O
(25,34] O
(34,50) O
C(source, O
source O
) O
26.1 O
22.3 O
45.0 O
6.6 O
C(target, O
source O
) O
49.5 O
18.0 O
28.5 O
3.9 O
C(finetune, O
source O
)38.5 O
20.2 O
36.1 O
5.2 O
C(all, O
source O
) O
26.3 O
22.2 O
45.0 O
6.5 O
C(source, O
target O
) O
40.2 O
23.2 O
30.4 O
6.2 O
C(target, O
target O
) O
19.7 O
30.7 O
40.6 O
8.9 O
C(finetune, O
target O
)21.2 O
30.5 O
39.9 O
8.4 O
C(all, O
target O
) O
25.6 O
27.5 O
39.0 O
7.9 O
First, O
we O
analyze O
the O
classification O
errors O
in O
Table O
6. O
We O
observe O
that O
the O
sum O
of O
the O
last O
three O
columns O
is O
always O
larger O
than O
50%. O
This O
indicates O
that, O
in O
all O
settings, O
more O
than O
half O
ofTable O
7: O
Distribution O
(in O
percentage) O
of O
correct O
predic- O
tions O
and O
annotators O
agreement O
percentage O
Setting O
[50,66) O
[66,75) O
[75,100)100 O
C(source, O
source O
) O
16.9 O
24.4 O
20.9 O
37.7 O
C(target, O
source O
) O
16.8 O
20.0 O
20.2 O
43.1 O
C(finetune, O
source O
)17.0 O
22.7 O
20.9 O
39.4 O
C(all, O
source O
) O
17.0 O
24.5 O
20.9 O
37.7 O
C(source, O
target O
) O
15.0 O
27.5 O
18.5 O
39.0 O
C(target, O
target O
) O
15.0 O
27.7 O
18.8 O
38.5 O
C(finetune, O
target O
)15.8 O
28.5 O
18.7 O
37.0 O
C(all, O
target O
) O
15.7 O
28.4 O
18.8 O
37.2 O
the O
model O
classification O
errors O
are O
not O
severe O
in O
that O
at O
least O
one O
human O
annotator O
agrees O
with O
the O
model O
prediction. O
Then, O
we O
notice O
that O
the O
settings O
with O
the O
highest O
incidence O
of O
‘bad’ O
classification O
errors O
(i.e., O
where O
no O
annotators O
agree O
with O
the O
model O
prediction) O
are O
those O
employed O
to O
evaluate O
generalizability O
( O
C(target, O
source O
)andC(source, O
target O
)) O
and O
catastrophic O
forgetting O
( O
C(finetune, O
source O
)). O
These O
results O
are O
explained O
by O
the O
harder O
challenge O
represented O
in O
these O
settings O
(refer O
to O
Sec- O
tions O
4.2 O
and O
4.4 O
for O
a O
more O
in-depth O
discussion). O
Finally, O
we O
observe O
that O
there O
is O
a O
small O
percentage O
of O
errors O
with O
agreement O
between O
34% O
and O
50%. O
For O
the O
agreement O
to O
be O
in O
this O
range, O
a O
tweet O
must O
have O
been O
annotated O
by O
at O
least O
5 O
annotators. O
How- O
ever, O
84% O
of O
the O
tweets O
in O
the O
MFTC B-DatasetName
have O
been O
annotated O
by O
four O
annotators O
or O
less, O
thus O
resulting O
in O
a O
smaller O
agreement O
in O
the O
last O
column. O
Second, O
we O
analyze O
the O
correct O
predictions O
in O
Table O
7. O
We O
notice, O
in O
all O
settings, O
a O
high O
correspon- O
dence O
between O
100% O
agreement O
among O
annotators O
and O
correct O
model O
predictions—that O
is, O
tweets O
an- O
notated O
with O
consistent O
agreement O
reliably O
lead O
to O
correct O
predictions. O
Further, O
we O
observe O
that O
the O
distributions O
of O
agreement O
and O
correct O
predictions O
are O
consistent O
across O
different O
settings. O
5 O
Related O
Work O
We O
review O
closely O
related O
works O
on O
value O
estima- O
tion O
from O
text, O
and O
on O
cross-domain B-TaskName
classification I-TaskName
in O
NLP O
subfields O
relevant O
to O
value B-TaskName
classification. I-TaskName
5.1 O
Value O
Estimation O
from O
Text O
Value O
estimation O
has O
been O
addressed O
from O
both O
unsupervised O
and O
supervised O
approaches. O
Unsuper- O
vised O
methods O
exploit O
value O
lexicons O
to O
identify O
val- O
ues O
in O
text. O
Value O
lexicons O
are O
generated O
manually O
(Graham O
et O
al., O
2009), O
via O
semi-automated O
methods O
(Wilson O
et O
al., O
2018; O
Rezapour O
et O
al., O
2019; O
Araque2733et O
al., O
2020; O
Hopp O
et O
al., O
2021), O
or O
expanded O
from O
an O
initial O
seed O
via O
NLP O
techniques O
(Ponizovskiy O
et O
al., O
2020; O
Araque O
et O
al., O
2021). O
Value O
lexicons O
are O
used O
to O
identify O
values O
in O
text O
through O
word O
count O
software O
(Pennebaker O
et O
al., O
2001) O
or O
similar- O
ity O
in O
embedding O
space O
(Garten O
et O
al., O
2018; O
Shen O
et O
al., O
2019; O
Bahgat O
et O
al., O
2020). O
However, O
adapt- O
ing O
a O
lexicon O
to O
a O
novel O
domain O
is O
a O
significant O
additional O
effort O
as O
it O
requires O
identifying O
words O
that O
are O
relevant O
and O
removing O
words O
that O
are O
not O
relevant O
in O
the O
novel O
domain. O
Supervised O
methods O
employ O
the O
classification O
paradigm O
(Lin O
et O
al., O
2018; O
Mooijman O
et O
al., O
2018; O
Hoover O
et O
al., O
2020; O
Alshomary O
et O
al., O
2022; O
Kiesel O
et O
al., O
2022). O
A O
textual O
dataset O
is O
annotated O
with O
val- O
ues O
belonging O
to O
a O
value O
taxonomy, O
and O
the O
labels O
are O
used O
to O
train O
a O
supervised O
model. O
This O
approach O
is O
akin O
to O
the O
one O
we O
use O
in O
this O
paper. O
However, O
in O
the O
reviewed O
literature, O
no O
emphasis O
is O
put O
on O
the O
effect O
of O
cross-domain O
training. O
Further, O
several O
of O
the O
works O
mentioned O
above O
(Lin O
et O
al., O
2018; O
Mooi- O
jman O
et O
al., O
2018; O
Hoover O
et O
al., O
2020) O
use O
binary O
classification O
to O
independently O
predict O
the O
presence O
of O
a O
value O
in O
text. O
That O
is, O
given O
Nvalues, O
Nclas- O
sifiers O
are O
employed O
(one O
per O
value). O
However, O
it O
has O
been O
shown O
that O
modeling O
relationships O
among O
values O
(and O
additional O
contextualizing O
information O
such O
as O
actors) O
helps O
improve O
downstream O
perfor- O
mances O
(Johnson O
and O
Goldwasser, O
2018; O
Roy O
et O
al., O
2021). O
Thus, O
we O
train O
a O
multi-label O
value O
classifier, O
similarly O
to O
Alshomary O
et O
al. O
(2022) O
and O
Kiesel O
et O
al. O
(2022). O
Furthermore, O
our O
objective O
is O
not O
to O
compare O
binary O
and O
multi-label O
value O
classifica- O
tion O
but O
to O
evaluate O
the O
cross-domain O
capabilities O
(generalizability, O
transferability, O
and O
catastrophic O
forgetting) O
of O
a O
multi-label O
value O
classifier. O
5.2 O
Datasets O
with O
Moral O
Content O
The O
recent O
success O
of O
NLP O
models O
has O
sparked O
a O
surge O
of O
research O
in O
constructs O
akin O
to O
moral O
values, O
e.g., O
moral O
norms, O
ethical O
judgments, O
and O
social O
biases. O
Researchers O
have O
collected O
large O
datasets O
annotated O
with O
the O
related O
implicit O
components O
of O
human O
language O
similar O
to O
the O
MFTC O
(Section O
2). O
Forbes O
et O
al. O
(2020) O
introduced O
SOCIAL O
-CHEM O
- O
101, O
a O
corpus O
of O
almost O
300,000 O
rules-of-thumb O
aimed O
at O
learning O
social O
and O
moral O
norms. O
Sap O
et O
al. O
(2020) O
collected O
the O
Social O
Bias O
Inference O
Corpus O
with O
the O
intent O
of O
modeling O
the O
way O
in O
which O
people O
project O
social O
biases O
onto O
each O
others. O
Hendrycks O
et O
al. O
(2021) O
proposed O
the O
ETHICS O
dataset O
to O
as-sess O
basic O
knowledge O
of O
ethics O
through O
well-studied O
theories O
of O
normative O
ethics O
(such O
as O
deontology O
and O
utilitarianism). O
Lourie O
et O
al. O
(2021) O
introduced O
SCRUPLES O
, O
a O
dataset O
composed O
of O
625,000 O
ethi- O
cal O
judgments O
over O
32,000 O
real-life O
anecdotes. O
Fi- O
nally, O
Emelin O
et O
al. O
(2021) O
presented O
Moral O
Stories O
, O
a O
crowd-sourced O
collection O
of O
contextualized O
nar- O
ratives O
with O
the O
intent O
of O
investigating O
grounded, O
goal-oriented O
social O
reasoning. O
These O
datasets O
offer O
an O
unprecedented O
opportu- O
nity O
for O
studying O
the O
social O
and O
moral O
aspects O
of O
language. O
In O
our O
research O
we O
employ O
the O
MFTC B-DatasetName
as O
the O
same O
moral O
value O
theory O
is O
used O
to O
anno- O
tate O
data O
in O
seven O
different O
domains, O
allowing O
for O
a O
direct O
cross-domain O
comparison. O
5.3 O
Cross-Domain O
NLP O
Classification O
Cross-domain B-TaskName
classification I-TaskName
is O
gaining O
attention O
(Aji O
et O
al., O
2020; O
Nguyen O
et O
al., O
2021; O
Rongali O
et O
al., O
2021; O
Bornea O
et O
al., O
2021; O
Markov O
and O
Daelemans, O
2021). O
Ruder O
(2019) O
provides O
an O
overview O
of O
the O
basic O
terminology, O
including O
generalizability, O
trans- O
ferability, O
and O
catastrophic O
forgetting. O
Cross-domain B-TaskName
classification I-TaskName
has O
been O
investi- O
gated O
in O
NLP O
tasks O
such O
as O
sentiment O
analysis O
(Al- O
Moslmi O
et O
al., O
2017; O
Qu O
et O
al., O
2019; O
Du O
et O
al., O
2020), O
fake O
news O
detection O
(Fung O
et O
al., O
2021; O
Silva O
et O
al., O
2021; O
Yuan O
et O
al., O
2021), O
and O
argu- O
ment O
mining O
(Al-Khatib O
et O
al., O
2016; O
Daxenberger O
et O
al., O
2017; O
Thorn O
Jakobsen O
et O
al., O
2021). O
These O
tasks O
are O
similar O
to O
value B-TaskName
classification I-TaskName
in O
that O
they O
aim O
to O
classify O
high-level O
constructs O
(such O
as O
sen- O
timents O
and O
arguments). O
However, O
value O
classi- O
fication O
stands O
out O
for O
its O
multi-label O
and O
domain- O
specific O
nature. O
Also, O
cross-domain B-TaskName
classification I-TaskName
is O
particularly O
important O
for O
values O
because O
reasoning O
about O
values O
(Pommeranz O
et O
al., O
2012) O
and O
generat- O
ing O
value-annotated O
datasets O
is O
very O
difficult. O
6 O
Conclusions O
and O
Directions O
We O
perform O
a O
comprehensive O
cross-domain O
eval- O
uation O
of O
a O
multi-label O
value O
classifier, O
by O
com- O
paring O
a O
deep O
learning O
model O
(BERT) B-MethodName
in O
seven O
domains O
with O
four O
cross-domain O
training O
scenar- O
ios. O
Our O
aim O
is O
to O
support O
practical O
applications O
of O
moral O
rhetoric O
classification, O
e.g., O
the O
detection O
of O
radicalism O
through O
the O
study O
of O
moral O
homogene- O
ity O
(Atari O
et O
al., O
2021), O
the O
prediction O
of O
violent O
protests O
(Mooijman O
et O
al., O
2018), O
the O
identification O
of O
moral O
concerns O
of O
citizens O
(Mouter O
et O
al., O
2021; O
Siebert O
et O
al., O
2022), O
and O
the O
extraction O
of O
moral2734rhetoric O
supporting O
both O
stances O
and O
arguments O
(Draws O
et O
al., O
2022; O
van O
der O
Meer O
et O
al., O
2022). O
Our O
findings O
inform O
both O
computer O
scientists O
and O
social O
scientists O
on O
training O
value O
classifiers. O
However, O
we O
do O
not O
provide O
a O
fixed O
recipe O
since O
the O
right O
model O
and O
approach O
depend O
on O
the O
time, O
resources, O
and O
data O
available. O
We O
show O
that O
a O
value O
classifier O
generally O
exhibits O
the O
ability O
to O
classify O
moral O
values O
across O
domains. O
However, O
the O
results O
are O
highly O
dependent O
on O
the O
distribution O
of O
moral O
rhetoric O
in O
a O
domain. O
Our O
experiments O
support O
the O
following O
key O
find- O
ings. O
First, O
a O
value O
classifier O
can O
generalize O
to O
novel O
domains, O
especially O
when O
trained O
on O
mul- O
tiple O
domains. O
However, O
its O
performance O
on O
the O
novel O
domain O
improves O
even O
when O
trained O
with O
a O
small O
portion O
of O
data O
from O
the O
novel O
domain. O
Sec- O
ond, O
pretraining O
a O
value O
classifier O
with O
data O
from O
different O
domains O
has O
three O
benefits O
when O
finetun- O
ing O
the O
classifier. O
It O
yields O
(1) O
better O
performances O
on O
the O
novel O
domain O
than O
other O
settings, O
(2) O
good O
performances O
even O
when O
little O
training O
data O
is O
avail- O
able O
in O
the O
novel O
domain, O
and O
(3) O
smaller O
confu- O
sion O
among O
moral O
values, O
especially O
among O
those O
less O
frequent O
in O
the O
novel O
domain. O
Third, O
finetun- O
ing O
on O
a O
novel O
domain O
causes O
catastrophic O
forget- O
ting O
of O
the O
domain O
it O
was O
pretrained O
with, O
even O
when O
finetuning O
on O
a O
small O
portion O
of O
data O
from O
the O
novel O
domain. O
Thus, O
the O
tradeoff O
between O
benefits O
of O
transferability O
and O
adverse O
effects O
of O
forgetting O
must O
be O
considered O
in O
choosing O
the O
extent O
of O
fine- O
tuning. O
Finally, O
despite O
the O
challenging O
nature O
of O
cross-domain B-TaskName
value I-TaskName
classification, I-TaskName
the O
majority O
of O
classification O
errors O
are O
not O
severe O
in O
that, O
in O
all O
evaluation O
settings, O
at O
least O
one O
annotator O
agrees O
with O
the O
model O
prediction. O
Our O
investigation O
opens O
avenues O
for O
additional O
experiments O
with O
advanced O
methods O
to O
improve O
transfer O
learning O
(Howard O
and O
Ruder, O
2018; O
Jiang O
et O
al., O
2020; O
Nguyen O
et O
al., O
2021) O
and O
mitigate O
catas- O
trophic O
forgetting O
(Kirkpatrick O
et O
al., O
2017; O
Li O
and O
Hoiem, O
2018; O
Thompson O
et O
al., O
2019). O
Further, O
based O
on O
the O
analysis O
of O
classification O
errors, O
we O
suggest O
incorporating O
the O
annotators O
(dis-) O
agree- O
ment O
into O
the O
training O
of O
the O
model, O
e.g., O
by O
employ- O
ing O
the O
full O
distributions O
of O
annotations, O
as O
opposed O
to O
the O
current O
majority O
approach O
(Uma O
et O
al., O
2021). O
7 O
Ethical O
Considerations O
We O
discuss O
three O
ethical O
considerations O
relevant O
to O
our O
work. O
First, O
the O
MFTC B-DatasetName
is O
composed O
of O
mono-lingual O
tweets O
about O
US-centric O
topics. O
Whether O
or O
not O
our O
conclusions O
hold O
for O
results O
across O
different O
languages O
and O
cultures O
is O
yet O
to O
be O
evaluated. O
This O
limitation O
may O
cause O
the O
perpetuation O
of O
Western O
biases O
and O
values O
(Mehrabi O
et O
al., O
2021). O
How- O
ever, O
we O
believe O
that O
our O
experimental O
setup O
offers O
a O
systematic O
approach O
to O
studying O
such O
cultural O
influences O
when O
pertinent O
data O
is O
available. O
Second, O
the O
MFTC B-DatasetName
has O
low O
annotator O
agreement O
(Hoover O
et O
al., O
2020, O
Table O
6), O
potentially O
caused O
by O
the O
subjectivity O
and O
complexity O
of O
annotating O
values. O
Selecting O
the O
majority O
label O
as O
golden O
label O
may O
perpetuate O
the O
‘tyranny’ O
of O
the O
majority, O
which O
is O
especially O
dangerous O
when O
dealing O
with O
values. O
We O
expose O
the O
impact O
of O
the O
annotator O
agreement O
in O
Section O
4.6 O
and O
identify O
an O
avenue O
for O
addressing O
it O
as O
a O
future O
direction O
in O
Section O
6. O
Finally, O
the O
importance O
of O
understanding O
moral O
values O
has O
been O
recognized O
by O
computer O
scientists O
(Russell O
et O
al., O
2015) O
and O
designers O
(Friedman O
et O
al., O
2008). O
However, O
we O
recognize O
that O
value O
classifi- O
cation O
can O
be O
misused, O
especially, O
when O
sensitive O
attributes O
such O
as O
gender O
and O
race O
are O
attached O
to O
the O
data. O
For O
instance, O
authorities O
could O
use O
it O
to O
automatically O
identify O
and O
suppress O
liberal O
minori- O
ties O
in O
non-liberal O
countries. O
Additional O
research O
is O
necessary O
for O
addressing O
such O
problems, O
e.g., O
by O
devising O
techniques O
that O
mitigate O
bias O
and O
unfair- O
ness O
by O
design O
(Kleinberg O
et O
al., O
2018; O
Dinan O
et O
al., O
2020; O
Vargas O
and O
Cotterell, O
2020). O
Acknowledgments O
This O
research O
was O
(partially) O
funded O
by O
the O
Hybrid O
Intelligence O
Center, O
a O
10-year O
programme O
funded O
by O
the O
Dutch O
Ministry O
of O
Education, O
Culture O
and O
Science O
through O
the O
Netherlands O
Organisation O
for O
Scientific O
Research. O
Furthermore, O
we O
thank O
Flo- O
rentin O
Arsene O
for O
his O
contribution O
in O
previous O
itera- O
tions O
of O
the O
project. O
Experimental O
Details O
As O
we O
train O
deep O
learning O
models, O
reproducibil- O
ity O
is O
an O
issue O
due O
to O
the O
inherent O
randomness O
of O
the O
training O
procedure. O
Nevertheless, O
we O
seek O
to O
provide O
all O
possible O
tools O
for O
reproducing O
our O
ex- O
perimental O
results. O
To O
do O
so, O
we O
attach O
our O
code O
and O
the O
complete O
set O
of O
results. O
Furthermore, O
the O
following O
sections O
describe O
our O
data O
preprocessing, O
the O
hyperparameters, O
the O
computing O
infrastructure, O
and O
the O
random O
seeds O
used O
in O
our O
experiments. O
A.1 O
Data O
Preprocessing O
We O
choose O
to O
use O
the O
datasets O
as O
they O
are, O
despite O
their O
imbalanced O
label O
distribution O
(Table O
3), O
since O
such O
imbalance O
is O
representative O
of O
realistic O
appli- O
cations. O
We O
preprocess O
the O
tweets O
by O
removing O
URLs, O
emails, O
usernames O
and O
mentions. O
Next, O
we O
employ O
the O
Ekphrasis O
package2to O
correct O
common O
spelling O
mistakes O
and O
unpack O
contractions. O
Finally, O
emojis O
are O
transformed O
into O
their O
respective O
words O
using O
the O
Python O
Emoji O
package3. O
A.2 O
Hyperparameters O
To O
select O
the O
hyperparameters, O
we O
trained O
and O
eval- O
uated O
the O
model O
on O
the O
entire O
MFTC B-DatasetName
corpus O
with O
10-fold O
cross-validation. O
Table O
A1 O
shows O
the O
hy- O
perparameters O
that O
were O
compared O
in O
this O
setting, O
highlighting O
in O
bold O
the O
best O
performing O
option O
that O
we O
then O
used O
in O
the O
experiments O
described O
in O
the O
paper. O
If O
a O
parameter O
is O
not O
present O
in O
the O
table, O
the O
default O
value O
supplied O
by O
the O
framework O
was O
used. O
Table O
A1: O
Hyperparameters O
tested O
and O
selected O
Hyperparameters O
Options O
Model O
name O
bert-base-uncased O
Number O
of O
parameters O
110M O
Max O
sequence O
length O
64 O
Epochs O
2, O
3, O
5 O
Batch O
size O
16, O
32, O
64 O
Dropout O
0.05, O
0.1, O
0.02 O
Optimizer O
AdamW O
Learning O
Rate O
5*10-5 O
Loss O
function O
Binary O
Cross O
Entropy O
A.3 O
Computing O
Infrastructure O
The O
following O
are O
the O
main O
libraries O
and O
computing O
environment O
used O
in O
our O
experiments. O
• O
PyTorch: O
1.8.1 O
2https://github.com/cbaziotis/ O
ekphrasis O
3https://pypi.org/project/emoji/• O
TensorFlow: O
2.5.0 O
• O
FastText: O
0.8.22 O
• O
Hugginface’s O
Transformers: O
4.6.0 O
• O
NVIDIA O
GeForce O
RTX O
2080 O
Ti O
GPU O
• O
CUDA: O
11.2 O
• O
cuDNN: O
8.1.1.33 O
Refer O
to O
the O
code O
base O
for O
a O
detailed O
list O
of O
the O
libraries O
we O
used, O
and O
their O
versions. O
The O
following O
list O
details O
the O
amount O
of O
GPU O
hours O
spent O
for O
obtaining O
our O
results: O
• O
Tables O
4, O
B1, O
and O
B2: O
44 O
hours O
• O
Figures O
2 O
and O
3: O
33 O
hours O
• O
Tables O
B3, O
B4, O
and O
B5: O
24 O
hours O
• O
Table O
B7: O
26 O
hours O
The O
error O
analysis O
(Tables O
5, O
6, O
and O
7) O
did O
not O
re- O
quire O
additional O
GPU O
time. O
A.4 O
Random O
Seeds O
In O
our O
experiments, O
we O
ensured O
that O
the O
same O
train- O
test O
splits O
are O
used O
across O
different O
runs O
of O
each O
experiment. O
Further, O
to O
control O
for O
randomness, O
we O
fixed O
the O
random O
seeds O
in O
the O
following O
libraries: O
• O
Python O
( O
random.seed O
); O
• O
NumPy O
( O
numpy.random.seed O
); O
• O
PyTorch O
( O
torch.manual_seed O
); O
• O
Tensorflow O
(tensorflow.random.set_seed O
). O
A.5 O
Artifacts O
Usage O
We O
have O
mainly O
used O
two O
artifacts O
in O
this O
research: O
the O
MFTC B-DatasetName
and O
BERT. B-MethodName
The O
MFTC B-DatasetName
was O
collected O
with O
the O
intent O
of O
fa- O
cilitating O
NLP O
research O
on O
moral O
values O
(Hoover O
et O
al., O
2020). O
It O
can O
be O
downloaded4and O
used O
under O
the O
Creative O
Commons O
Attribution O
4.0 O
license. O
BERT B-MethodName
(Devlin O
et O
al., O
2019) O
was O
created O
with O
the O
intent O
of O
performing, O
among O
others, O
text O
classifica- O
tion. O
Thus, O
we O
are O
using O
it O
as O
originally O
intended, O
under O
its O
Apache O
2.0 O
distribution O
license5. O
4https://osf.io/k5n7y/ O
5https://github.com/google-research/ O
bert/blob/master/LICENSE2740B O
Extended O
Results O
In O
this O
Appendix O
we O
extend O
the O
results O
presented O
in O
the O
paper. O
The O
following O
results O
are O
not O
crucial O
for O
supporting O
our O
conclusions. O
Nevertheless, O
they O
provide O
additional O
details O
on O
our O
experiments. O
B.1 O
Model O
Comparison O
We O
have O
presented O
the O
results O
of O
the O
transferability O
analysis O
with O
the O
BERT B-MethodName
model. O
In O
order O
to O
eval- O
uate O
whether O
our O
conclusions O
generalize O
to O
other O
model O
architectures, O
we O
repeat O
the O
experiment O
con- O
ducted O
in O
the O
paper O
(see O
Sections O
3 O
and O
4) O
with O
the O
following O
two O
additional O
models: O
•Long B-MethodName
Short I-MethodName
Term I-MethodName
Memory I-MethodName
( I-MethodName
LSTM I-MethodName
), I-MethodName
a O
cate- O
gory O
of O
Recurrent B-MethodName
Neural I-MethodName
Networks I-MethodName
(RNN). I-MethodName
We O
choose O
LSTM B-MethodName
as O
a O
baseline O
model O
since O
it O
is O
commonly O
used O
in O
moral O
value O
classifica- O
tion O
(Lin O
et O
al., O
2018; O
Mooijman O
et O
al., O
2018; O
Rezapour O
et O
al., O
2019; O
Hoover O
et O
al., O
2020). O
•fastText B-MethodName
, O
a O
machine O
learning O
approach O
that O
learns O
character-level O
information, O
in O
contrast O
to O
the O
whole O
word O
representations O
LSTM B-MethodName
em- O
ploys. O
This O
flexibility O
makes O
fastText B-MethodName
a O
good O
candidate O
for O
transfer O
learning. O
Further, O
we O
choose O
fastText O
as O
it O
attains O
performances O
on O
par O
with O
state-of-the-art O
deep O
learning O
meth- O
ods, O
but O
is O
considerably O
faster. O
Tables O
B1 O
and O
B2 O
present O
the O
results O
of O
the O
trans- O
ferability O
analysis, O
performed O
and O
presented O
analo- O
gously O
to O
Table O
4, O
for O
LSTM, B-MethodName
fastText, B-MethodName
and O
BERT. B-MethodName
We O
observe O
that O
BERT B-MethodName
outperforms O
fastText B-MethodName
and O
LSTM B-MethodName
in O
most O
settings. O
This O
is O
not O
surprising, O
since O
BERT B-MethodName
is O
state-of-the-art O
for O
text O
classifica- O
tion. O
Both O
BERT B-MethodName
and O
fastText B-MethodName
outperform O
LSTM, B-MethodName
the O
model O
extensively O
used O
for O
predicting O
moral O
values. O
Further, O
we O
notice O
that O
the O
general O
trends O
observed O
in O
Section O
4.1 O
hold O
for O
all O
three O
models. O
Generalizability O
All O
three O
models O
achieve O
better O
average O
F1-scores B-MetricName
in O
the O
C(source, O
target O
)setting O
than O
the O
majority O
( O
target O
) O
baseline. O
However, O
com- O
pared O
to O
the O
majority O
( O
source O
) O
baseline, O
C(target, O
source O
)performs O
worse O
with O
LSTM, B-MethodName
comparably O
with O
fastText, B-MethodName
and O
much O
better O
with O
BERT. B-MethodName
This O
suggests O
that O
a O
contextualized O
representation, O
as O
in O
BERT, B-MethodName
is O
necessary O
for O
value B-TaskName
classification I-TaskName
in O
novel O
domains, O
especially O
for O
the O
novel O
domains O
with O
a O
large O
moral O
vocabulary O
as O
is O
the O
case O
in O
C(target, O
source O
).Transferability O
From O
the O
average O
F1-scores O
in O
Ta- O
ble O
B2, O
we O
observe O
that O
C(finetune, O
target O
)per- O
forms O
better O
than O
or O
on O
par O
with O
C(target, O
target O
) O
across O
all O
three O
models. O
The O
benefits O
of O
finetuning O
are O
most O
evident O
for O
LSTM B-MethodName
(7% B-MetricValue
increase O
in O
the O
average O
mand B-MetricName
17% B-MetricValue
increase O
in O
M). B-MetricName
The O
benefits O
can O
also O
be O
observed O
for O
fastText B-MethodName
(similar O
mand O
8% B-MetricValue
increase O
of O
M) B-MetricName
and O
BERT B-MethodName
(similar O
mand B-MetricName
8% B-MetricValue
increase O
of O
M), B-MetricName
but O
to O
a O
lesser O
degree O
than O
LSTM. B-MethodName
Catastrophic O
Forgetting O
We O
observe O
that O
all O
three O
models O
suffer O
from O
catastrophic O
forgetting O
since O
finetuning O
on O
Ttarget O
reduces O
the O
performance O
onTsource O
. O
As O
mentioned O
in O
the O
paper, O
the O
degree O
of O
catastrophic O
forgetting O
is O
most O
evident O
when O
fine- O
tuning O
on O
unbalanced O
datasets O
such O
as O
DA B-DatasetName
V I-DatasetName
than O
balanced O
datasets O
such O
as O
BLM. O
B.1.1 O
Training O
Time O
In O
some O
applications, O
e.g., O
estimating O
value O
trends O
on O
Twitter, O
value O
classifiers O
need O
to O
be O
re-trained O
frequently O
since O
the O
trends O
can O
shift O
fast. O
Similarly, O
to O
employ O
techniques O
such O
as O
active O
learning O
for O
value O
annotation O
requires O
training O
a O
classifier O
at O
every O
iteration O
to O
prompt O
for O
new O
labels. O
In O
such O
cases, O
training O
time O
is O
an O
important O
factor O
for O
se- O
lecting O
an O
approach O
and O
model. O
Figure O
B1 O
shows O
the O
average O
training O
time O
in O
logarithmic O
scale, O
for O
different O
models O
and O
scenarios O
(Appendix O
A.3 O
de- O
scribes O
our O
computing O
infrastructure). O
Two O
considerations O
are O
evident. O
First, O
fastText B-MethodName
trains O
significantly O
faster O
than O
the O
other O
two O
models. O
Second, O
for O
all O
three O
models, O
the O
training O
time O
is O
approximately O
proportional O
to O
the O
amount O
of O
data O
in O
the O
training O
set—the O
target O
andfinetune O
sce- O
narios O
employ O
a O
similar O
amount O
of O
data, O
which O
is O
roughly O
six O
times O
smaller O
than O
in O
the O
source O
and O
allscenarios. O
Composition O
of O
Tsource O
In O
Section O
3.1, O
we O
mention O
that O
in O
our O
experiments O
Ttarget O
is O
always O
composed O
of O
one O
dataset O
of O
the O
MFTC, B-DatasetName
while O
we O
test O
with O
Tsource O
being O
composed O
of O
one, O
three, O
or O
six O
datasets. O
In O
the O
main O
paper O
we O
present O
the O
results O
where O
Tsource O
is O
composed O
of O
six O
datasets. O
Here, O
we O
present O
the O
results O
where O
it O
is O
composed O
of O
one O
or O
three O
datasets, O
using O
BERT.B.2.1 B-MethodName
One O
Dataset O
as O
Tsource O
Not O
all O
the O
settings O
described O
in O
Section O
3.1 O
can O
be O
meaningfully O
replicated O
when O
Tsource O
is O
com- O
posed O
of O
just O
one O
dataset. O
For O
instance, O
C(source, O
source O
)andC(target, O
target O
)would O
coincide, O
as O
well O
as O
C(source, O
target O
)andC(target, O
source O
). O
Thus, O
in O
Tables O
B3, O
B4, O
and O
B5 O
we O
present O
the O
re- O
sults O
along O
the O
lines O
of O
generalizability, O
transferabil- O
ity, O
and O
catastrophic O
forgetting, O
respectively. O
When O
possible, O
we O
compare O
the O
results O
to O
the O
results O
pre- O
sented O
in O
the O
paper O
(where O
Tsource O
is O
composed O
of O
six O
datasets). O
As O
in O
the O
paper, O
we O
highlight O
in O
bold O
the O
best O
result O
and O
the O
results O
that O
are O
not O
signifi- O
cantly O
different O
from O
it. O
Generalizability O
To O
evaluate O
generalizability O
(Ta- O
ble O
B3), O
the O
model O
is O
trained O
on O
Tsource O
and O
evalu- O
ated O
on O
Ttarget O
, O
akin O
to O
the O
C(source, O
target O
)set- O
ting O
described O
in O
the O
paper. O
Thus, O
at O
the O
end O
of O
the O
table, O
we O
append O
the O
results O
of O
C(source, O
target O
) O
from O
Table O
4 O
(where O
Tsource O
is O
composed O
of O
six O
datasets). O
First, O
we O
notice O
that O
the O
results O
are O
gener- O
ally O
better O
when O
Tsource O
is O
composed O
of O
six O
datasets. O
Further, O
there O
is O
no O
dataset O
that O
stands O
out O
as O
clearly O
better O
than O
the O
other O
six O
in O
generalizability. O
Transferability O
To O
evaluate O
transferability O
(Ta- O
ble O
B4), O
the O
model O
is O
trained O
on O
Tsource O
, O
retrained O
onTtarget O
, O
and O
evaluated O
on O
Ttarget O
, O
akin O
to O
theC(finetune, O
target O
)setting O
described O
in O
the O
pa- O
per. O
Thus, O
at O
the O
end O
of O
the O
table, O
we O
append O
the O
re- O
sults O
of O
C(finetune, O
target O
)from O
Table O
4 O
(where O
Tsource O
is O
composed O
of O
six O
datasets). O
First, O
we O
no- O
tice O
that O
the O
results O
are O
generally O
better O
or O
on O
par O
to O
the O
results O
where O
Tsource O
is O
composed O
of O
six O
datasets. O
Further, O
there O
is O
no O
dataset O
that O
stands O
out O
as O
clearly O
better O
than O
the O
other O
six O
in O
transferability. O
These O
two O
aspects O
suggest O
that O
a O
combination O
of O
the O
six O
datasets O
as O
Tsource O
consistently O
leads O
to O
better O
transferability O
results. O
Catastrophic O
Forgetting O
To O
evaluate O
catas- O
trophic O
forgetting O
(Table O
B5), O
the O
model O
is O
trained O
onTsource O
, O
retrained O
on O
Ttarget O
, O
and O
evaluated O
on O
Tsource O
, O
akin O
to O
the O
C(finetune, O
source O
)setting O
described O
in O
the O
paper. O
However, O
we O
cannot O
compare O
the O
results O
with O
the O
C(finetune, O
source O
)2743setting, O
as O
the O
evaluation O
sets O
differ O
(one O
dataset O
in O
Table O
B5, O
six O
datasets O
in O
C(finetune, O
source O
)in O
Table O
4). O
However, O
we O
compare O
to O
the O
case O
where O
the O
model O
is O
only O
trained O
on O
Tsource O
. O
Differently O
from O
the O
previous O
tables, O
the O
evaluation O
sets O
(i.e., O
Tsource O
) O
are O
consistent O
in O
every O
row, O
not O
in O
every O
column. O
Thus, O
we O
highlight O
the O
best O
results O
per O
row. O
It O
is O
evident O
that O
catastrophic O
forgetting O
happens O
even O
when O
Tsource O
is O
composed O
of O
one O
dataset. O
Further, O
there O
is O
no O
dataset O
that O
stands O
out O
as O
better O
than O
the O
other O
six O
in O
mitigating O
forgetting. O
B.2.2 O
Three O
Datasets O
as O
Tsource O
When O
employing O
three O
datasets O
as O
Tsource O
, O
the O
set- O
tings O
described O
in O
Section O
3.1 O
can O
be O
meaningfully O
reproduced. O
However, O
the O
selection O
of O
the O
three O
datasets O
(out O
of O
the O
six O
available O
at O
each O
experi- O
ment) O
that O
compose O
Tsource O
is O
not O
trivial. O
Experi- O
menting O
with O
all O
possible O
combinations O
would O
re- O
sult O
in6! O
3!(6−3)!= O
20 O
experiments O
per O
setting. O
In O
order O
to O
simplify O
the O
experiments, O
we O
decide O
to O
test O
with O
only O
one O
combination O
of O
three O
datasets, O
selected O
as O
the O
best O
performing O
combination O
from O
the O
experiments O
in O
Section O
B.2.1. O
We O
average O
the O
results O
of O
Tables O
B3, O
B4, O
and O
B5, O
and O
for O
each O
dataset O
used O
as O
Ttarget O
, O
we O
select O
the O
three O
datasets O
that O
led O
to O
the O
best O
average O
performance. O
Due O
to O
the O
class O
imbalance O
of O
all O
datasets, O
one O
of O
the O
biggest O
challenges O
is O
to O
achieve O
good O
performances O
across O
all O
values. O
Thus, O
we O
decide O
to O
consider O
only O
the O
average O
macro B-MetricName
F1-scores. I-MetricName
We O
report O
the O
best O
result- O
ing O
datasets O
in O
Table O
B6—for O
each O
dataset O
that O
we O
use O
asTtarget O
in O
the O
following O
experiments, O
we O
use O
the O
indicated O
three O
datasets O
as O
Tsource O
. O
Table O
B7 O
reports O
the O
complete O
cross-domain O
eval- O
uation O
results, O
analogously O
to O
Table O
4. O
For O
further O
comparison, O
we O
add O
the O
results O
from O
Table O
4 O
(where O
Tsource O
is O
composed O
of O
six O
datasets). O
The O
results O
in O
the O
bottom O
half O
of O
the O
table O
can O
be O
directly O
com- O
pared, O
as O
in O
each O
column O
the O
model O
is O
evaluated O
on O
the O
same O
test O
set. O
However, O
the O
results O
on O
the O
top O
half O
cannot O
be O
directly O
compared, O
as O
the O
modelis O
evaluated O
on O
different O
test O
sets O
(three O
and O
six O
datasets, O
respectively). O
It O
is O
evident O
that O
the O
results O
are O
consistent O
with O
the O
results O
presented O
in O
the O
main O
paper. O
In O
the O
top O
half O
of O
the O
table, O
the O
best O
performing O
settings O
are O
C(source, O
source O
)andC(all, O
source O
), O
both O
when O
Tsource O
is O
composed O
of O
three O
and O
six O
datasets. O
In O
the O
bottom O
half, O
where O
the O
results O
can O
be O
directly O
compared, O
we O
notice O
that O
the O
best O
performing O
set- O
tings O
are O
consistent, O
and O
lead O
to O
comparable O
results. O
We O
conclude O
that O
selecting O
the O
three O
best O
per- O
forming O
datasets O
as O
Tsource O
has O
neither O
advantage O
nor O
disadvantage O
over O
selecting O
all O
six O
datasets. O
However, O
selecting O
all O
six O
allows O
for O
a O
consistent O
evaluation, O
where O
all O
MFTC B-DatasetName
datasets O
are O
used O
in O
all O
evaluation O
settings, O
thus O
avoiding O
the O
arbitrary O
choice O
of O
datasets O
to O
be O
used O
as O
Tsource O
that O
we O
described O
at O
the O
beginning O
of O
this O
section. O