In O
Proceedings O
of O
the O
Thirteenth O
Conference O
on O
Compu- O
tational O
Natural O
Language O
Learning O
(CoNLL-2009) O
, O
pages O
147–155. O
Zilong O
Wang, O
Yiheng O
Xu, O
Lei O
Cui, O
Jingbo O
Shang, O
and O
Furu O
Wei. O
2021. O
Layoutreader: O
Pre-training O
of O
text O
and O
layout O
for O
reading O
order O
detection. O
Ralph O
Weischedel, O
Martha O
Palmer, O
Mitchell O
Marcus, O
Ed- O
uard O
Hovy, O
Sameer O
Pradhan, O
Lance O
Ramshaw, O
Nian- O
wen O
Xue, O
Ann O
Taylor, O
Jeff O
Kaufman, O
Michelle O
Fran- O
chini, O
et O
al. O
2013. O
Ontonotes O
release O
5.0 O
ldc2013t19. O
Linguistic O
Data O
Consortium, O
Philadelphia, O
PA O
, O
23. O
Thomas O
Wolf, O
Lysandre O
Debut, O
Victor O
Sanh, O
Julien O
Chaumond, O
Clement O
Delangue, O
Anthony O
Moi, O
Pier- O
ric O
Cistac, O
Tim O
Rault, O
Rémi O
Louf, O
Morgan O
Funtowicz, O
et O
al. O
2019. O
Huggingface’s O
transformers: O
State-of- O
the-art O
natural O
language O
processing. O
arXiv O
preprint O
arXiv:1910.03771 O
. O
Yang O
Xu, O
Yiheng O
Xu, O
Tengchao O
Lv, O
Lei O
Cui, O
Furu O
Wei, O
Guoxin O
Wang, O
Yijuan O
Lu, O
Dinei O
Florencio, O
Cha O
Zhang, O
Wanxiang O
Che, O
Min O
Zhang, O
and O
Lidong O
Zhou. O
2021a. O
Layoutlmv2: O
Multi-modal O
pre-training O
for O
visually-rich O
document O
understanding. O
In O
Proceed- O
ings O
of O
the O
59th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
(ACL) O
2021 O
.4183Yiheng O
Xu, O
Minghao O
Li, O
Lei O
Cui, O
Shaohan O
Huang, O
Furu O
Wei, O
and O
Ming O
Zhou. O
2020. O
Layoutlm: O
Pre-training O
of O
text O
and O
layout O
for O
document O
image O
understanding. O
InProceedings O
of O
the O
26th O
ACM O
SIGKDD O
Interna- O
tional O
Conference O
on O
Knowledge O
Discovery O
& O
Data O
Mining O
, O
pages O
1192–1200. O
Yiheng O
Xu, O
Tengchao O
Lv, O
Lei O
Cui, O
Guoxin O
Wang, O
Yi- O
juan O
Lu, O
Dinei O
Florencio, O
Cha O
Zhang, O
and O
Furu O
Wei. O
2021b. O
Layoutxlm: O
Multimodal O
pre-training O
for O
mul- O
tilingual O
visually-rich O
document O
understanding. O
Findings O
of O
the O
Association O
for O
Computational O
Linguistics: O
ACL O
2022 O
, O
pages O
4194 O
- O
4204 O
May O
22-27, O
2022 O
c O
2022 O
Association O
for O
Computational O
Linguistics O
What O
is O
wrong O
with O
you?: O
Leveraging O
User O
Sentiment O
for O
Automatic B-TaskName
Dialog I-TaskName
Evaluation I-TaskName
Sarik O
Ghazarian1Behnam O
Hedayatnia2Alexandros O
Papangelis2 O
Yang O
Liu2Dilek O
Hakkani-Tur2 O
1University O
of O
Southern O
California O
/ O
Information O
Sciences O
Institute O
2Amazon O
Alexa O
AI O
sarik@isi.edu O
{behnam,papangea,yangliud,hakkanit}@amazon.com O
Abstract O
Accurate O
automatic O
evaluation O
metrics O
for O
open-domain O
dialogs O
are O
in O
high O
demand. O
Existing O
model-based O
metrics O
for O
system O
re- O
sponse O
evaluation O
are O
trained O
on O
human O
anno- O
tated O
data, O
which O
is O
cumbersome O
to O
collect. O
In O
this O
work, O
we O
propose O
to O
use O
information O
that O
can O
be O
automatically O
extracted O
from O
the O
next O
user O
utterance, O
such O
as O
its O
sentiment O
or O
whether O
the O
user O
explicitly O
ends O
the O
conversation, O
as O
a O
proxy O
to O
measure O
the O
quality O
of O
the O
previous O
system O
response. O
This O
allows O
us O
to O
train O
on O
a O
massive O
set O
of O
dialogs O
with O
weak O
supervision, O
without O
requiring O
manual O
system O
turn O
quality O
annotations. O
Experiments O
show O
that O
our O
model O
is O
comparable O
to O
models O
trained O
on O
human O
an- O
notated O
data. O
Furthermore, O
our O
model O
gener- O
alizes O
across O
both O
spoken O
and O
written O
open- O
domain O
dialog O
corpora O
collected O
from O
real O
and O
paid O
users. O
1 O
Introduction O
Relying O
on O
human O
evaluation O
to O
determine O
the O
qual- O
ity O
of O
open-domain O
dialog O
systems O
is O
not O
an O
efﬁ- O
cient O
approach O
in O
terms O
of O
time O
and O
cost. O
Automatic B-TaskName
evaluation I-TaskName
can O
be O
a O
good O
replacement O
for O
human O
an- O
notations O
and O
can O
increase O
the O
pace O
of O
open-domain O
dialog O
system O
development. O
However, O
standard O
word-overlap O
metrics O
(BLEU, B-MetricName
ROUGE, B-MetricName
Perplexity) B-MetricName
do O
not O
correlate O
well O
with O
human O
judgements O
of O
open-domain O
dialog O
systems O
(Deriu O
et O
al., O
2020; O
Liu O
et O
al., O
2016) O
because O
of O
the O
diverse O
set O
of O
out- O
puts O
that O
can O
be O
relevant O
given O
a O
dialog O
context. O
A O
solution O
for O
better O
automatic O
evaluation O
meth- O
ods O
is O
to O
train O
reference-free O
evaluators O
that O
learn O
how O
to O
assess O
the O
generated O
responses O
given O
dia- O
log O
contexts O
from O
different O
aspects O
such O
as O
rele- O
vancy O
(Tao O
et O
al., O
2018; O
Ghazarian O
et O
al., O
2019; O
Lan O
et O
al., O
2020), O
engagement O
(Ghazarian O
et O
al., O
2020), O
ﬂuency O
(Zhang O
et O
al., O
2021b; O
Pang O
et O
al., O
2020), O
Work O
done O
while O
Sarik O
Ghazarian O
was O
an O
intern O
at O
Ama- O
zon O
Alexa O
AIcontradiction O
(Pang O
et O
al., O
2020; O
Nie O
et O
al., O
2021) O
amongst O
others. O
It O
is O
also O
important O
to O
get O
some O
holistic O
evaluation O
at O
the O
dialog O
level O
in O
order O
to O
assess O
the O
dialogs O
as O
a O
whole O
(Zhang O
et O
al., O
2021a; O
Li O
et O
al., O
2021; O
Mehri O
and O
Eskenazi, O
2020; O
Finch O
et O
al., O
2021). O
Recently, O
Mehri O
and O
Eskenazi O
(2020); O
Eskenazi O
et O
al. O
(2019) O
have O
shown O
the O
effectiveness O
of O
look- O
ing O
into O
the O
next O
user O
utterance O
as O
a O
proxy O
to O
measure O
the O
quality O
of O
the O
chatbot’s O
generated O
re- O
sponses. O
See O
and O
Manning O
(2021) O
have O
shown O
that O
predicting O
next O
user O
satisfaction O
helps O
to O
se- O
lect O
more O
relevant O
system O
utterances. O
Inspired O
by O
works O
in O
this O
area, O
we O
propose O
to O
automatically O
extract O
features O
from O
the O
next O
user O
utterance, O
such O
as O
sentiment, O
to O
use O
as O
a O
proxy O
to O
evaluate O
sys- O
tem O
responses. O
The O
advantage O
of O
our O
method O
is O
that O
we O
do O
not O
need O
to O
train O
on O
data O
with O
human O
annotations O
for O
turn O
level O
quality, O
and O
instead O
can O
rely O
on O
available O
large O
datasets O
with O
automatically O
extracted O
annotations. O
Most O
existing O
automatic O
evaluators O
focus O
purely O
on O
open-domain O
text-based O
dialog O
systems. O
In O
addi- O
tion O
to O
textual O
interactions, O
we O
perform O
experiments O
on O
voice-based O
interactions O
that O
were O
collected O
via O
paid O
and O
real O
users. O
Furthermore, O
we O
compute O
cor- O
relations O
with O
a O
real O
user’s O
own O
(referred O
to O
as O
ﬁrst O
party, O
1P) O
rating O
when O
available, O
in O
addition O
to O
an- O
notations O
by O
third O
party O
(3P) O
annotators. O
Our O
con- O
tributions O
include: O
1.training O
an O
automatic O
evaluator O
on O
the O
senti- O
ment O
of O
the O
next O
user O
utterance O
in O
a O
weakly O
su- O
pervised O
fashion O
to O
evaluate O
system O
responses, O
2.outperforming O
existing O
automatic O
evaluation O
metrics O
on O
both O
text O
and O
voice-based O
open- O
domain O
dialog O
datasets, O
3.a O
turn-level O
annotated O
open-domain O
text-based O
dialog O
dataset O
that O
we O
will O
release.1 O
1We O
cannot O
release O
our O
voice-based O
interactions O
due O
to O
privacy O
concerns O
that O
will O
be O
discussed O
in O
the O
paper.4194Figure O
1: O
Training/Inference O
for O
turn O
quality O
estima- O
tion. O
The O
dotted O
arrows O
show O
how O
qi, O
which O
repre- O
sents O
the O
system O
turn O
quality O
for O
system O
response O
ri, O
is O
constructed O
for O
training. O
For O
our O
regression O
model O
indicated O
by O
the O
red O
arrow, O
si+1(user O
sentiment) O
and O
ei+1(user O
stop) O
are O
summed O
together O
to O
create O
qi. O
For O
our O
classiﬁcation O
model O
indicated O
by O
the O
blue O
arrow, O
qi O
is O
equal O
to O
ti. O
In O
the O
example O
dialog, O
the O
user O
expresses O
negative O
sentiment O
in O
ui+1. O
The O
sentiment O
score O
-1.97 O
is O
used O
as O
the O
reference O
label O
qi, O
indicating O
the O
quality O
of O
response O
ri. O
2 O
Methods O
for O
Automatic O
Evaluation O
For O
turn O
quality O
estimation, O
the O
task O
is O
deﬁned O
as O
follows: O
given O
a O
dialog O
context O
and O
a O
system O
re- O
sponse O
in O
the O
last O
turn, O
D= O
[u1,r1. O
. O
.ui,ri] O
(where O
uiandriare O
the O
user O
utterance O
and O
system O
response O
respectively O
for O
the O
ithturn O
in O
a O
dialog), O
determine O
ifriis O
an O
appropriate O
response. O
qiindicates O
the O
quality O
of O
response O
riand O
will O
be O
used O
as O
our O
ref- O
erence O
label O
when O
training O
the O
model. O
Figure O
1 O
shows O
our O
model O
architecture. O
We O
train O
a O
BERT- B-MethodName
base I-MethodName
(Devlin O
et O
al., O
2019) O
model O
that O
encodes O
the O
dialog O
context O
and O
the O
latest O
system O
response. O
We O
use O
the O
pooled O
representation O
output O
by O
the O
BERT B-MethodName
model O
and O
pass O
it O
through O
a O
linear O
layer O
to O
deter- O
mine O
the O
quality O
of O
the O
response. O
Depending O
on O
the O
reference O
label O
used O
to O
train O
this O
model, O
we O
adopt O
a O
classiﬁcation O
or O
regression O
setup, O
described O
below. O
•Classiﬁcation O
model O
trained O
using O
turn O
level O
annotations. O
When O
annotations O
for O
sys- O
tem O
responses O
are O
available O
in O
our O
training O
data O
(a O
binary O
label O
tias O
shown O
in O
Figure O
1 O
for O
response O
ri, O
indicating O
if O
the O
system O
response O
is O
appropriate), O
we O
train O
a O
classiﬁcation O
modelusing O
such O
reference O
labels. O
•Regression O
model O
trained O
using O
next O
user O
sentiment. O
Obtaining O
turn O
level O
annotations O
for O
dialogs O
is O
costly. O
In O
this O
work, O
we O
ex- O
plore O
using O
weak O
supervision O
to O
approximate O
response O
quality. O
Eskenazi O
et O
al. O
(2019) O
stated O
that O
given O
a O
system O
response, O
the O
follow O
up O
user’s O
utterance O
should O
be O
used O
to O
evaluate O
the O
quality O
of O
the O
system O
response O
as O
it O
increased O
agreement O
amongst O
human O
annotators. O
Mo- O
tivated O
by O
this, O
we O
propose O
to O
use O
the O
senti- O
ment O
of O
the O
next O
user O
utterance O
as O
a O
proxy O
to O
estimate O
the O
quality O
of O
the O
previous O
system O
response. O
In O
Figure O
1, O
si+1is O
the O
sentiment O
score O
for O
the O
next O
user O
utterance O
ui+1. O
Note O
that O
this O
information O
is O
automatically O
gener- O
ated O
from O
the O
user O
utterance, O
and O
thus O
allows O
us O
to O
leverage O
data O
without O
a O
turn O
level O
anno- O
tation. O
Since O
such O
sentiment O
scores O
are O
often O
continuous, O
we O
use O
a O
regression O
model O
for O
these O
target O
labels. O
•Next O
user O
stop O
signal. O
We O
also O
examine O
if O
the O
next O
user O
utterance O
stops O
a O
dialog O
( O
ei+1in O
Figure O
1). O
ei+1is O
0 O
if O
the O
user O
stops O
the O
dialog O
and O
1 O
if O
they O
continue O
the O
dialog. O
We O
use O
this O
as O
an O
additional O
signal O
by O
summing O
it O
with O
the O
sentiment O
information O
above O
as O
target O
labels O
for O
model O
training. O
For O
dialog O
level O
evaluation, O
we O
follow O
previ- O
ous O
work O
and O
use O
mean O
aggregation O
techniques O
to O
estimate O
dialog O
level O
ratings O
from O
turn O
level O
scores O
(Lowe O
et O
al., O
2017; O
Ghazarian O
et O
al., O
2019, O
2020; O
Lan O
et O
al., O
2020; O
Yeh O
et O
al., O
2021). O
In O
our O
experiments, O
we O
show O
how O
aggregated O
turn O
level O
quality O
and O
user O
sentiment O
scores O
correlate O
with O
dialog O
level O
ratings. O
3 O
Dialog O
Datasets O
As O
described O
earlier, O
most O
previous O
work O
in O
au- O
tomatic O
evaluation O
focuses O
on O
text-based O
open- O
domain O
dialog O
systems O
(Yeh O
et O
al., O
2021; O
Lan O
et O
al., O
2020; O
Sinha O
et O
al., O
2020; O
Huang O
et O
al., O
2020; O
Ghazarian O
et O
al., O
2020). O
Additionally O
most O
dialog O
datasets O
are O
collected O
via O
crowdworkers. O
While O
we O
also O
evaluate O
on O
written O
(text-based) O
dialogs, O
the O
primary O
dataset O
in O
our O
work O
consists O
of O
spoken O
(voice-based) O
interactions O
between O
a O
dialog O
system O
and O
a O
real O
user. O
3.1 O
Open O
Domain O
Dialog O
System O
We O
ﬁrst O
describe O
the O
open-domain O
dialog O
system O
used O
for O
our O
spoken O
dialog O
data O
collection. O
The4195Dialog O
SplitNumber O
of O
Interactions O
(Train/Dev/Test)Avg. O
Number O
of O
Turns O
(Train/Dev/Test)3P O
turn O
quality O
3P O
rating O
1P O
rating O
PUI O
-/-/87 O
- O
/ O
- O
/ O
14.5 O
X O
X O
RUI-1P O
6215 O
/ O
690 O
/ O
- O
10.3 O
/ O
10.8 O
/ O
- O
X O
RUI-3P O
500 O
/ O
55 O
/ O
132 O
11.1 O
/ O
10.7 O
/ O
14.3 O
X O
X O
X O
ConTurE O
- O
/ O
- O
/ O
119 O
- O
/ O
- O
/ O
8.95 O
X O
X O
Table O
1: O
Dataset O
Statistics O
for O
Spoken O
and O
Written O
dialog O
datasets. O
RUI O
(Real O
User O
Interactions) O
Figure O
2: O
Architecture O
of O
our O
open-domain O
dialog O
system. O
NER O
= O
Named O
Entity O
Recognition, O
DA O
= O
Dialog O
Act O
architecture O
of O
our O
dialog O
system O
is O
shown O
in O
Fig- O
ure O
2. O
Every O
user O
utterance O
in O
the O
dialog O
is O
sent O
into O
an O
ASR O
system O
whose O
output O
goes O
through O
a O
series O
of O
NLU O
modules O
that O
classiﬁes O
topics, O
dialog O
acts, O
sentiment, O
extracts O
entities, O
and O
detects O
if O
the O
user O
utterance O
is O
offensive. O
Our O
system O
then O
calls O
multiple O
response O
generators O
(called O
responders) O
for O
the O
given O
dialog O
context O
and O
logs O
all O
the O
gener- O
ated O
response O
candidates O
within O
the O
State O
Manager. O
The O
ﬁnal O
response O
is O
selected O
based O
on O
a O
rule-based O
ranking O
strategy, O
and O
then O
sent O
to O
the O
TTS O
module O
whose O
output O
is O
presented O
to O
the O
user. O
For O
popular O
topics O
in O
open O
domain O
dialogs, O
such O
as O
movies, O
music, O
recent O
news, O
we O
develop O
template-based O
responders O
(highlighted O
in O
green O
in O
Figure O
2) O
for O
the O
given O
dialog O
state. O
An O
exam- O
ple O
state O
and O
response O
for O
the O
movie O
domain O
is: O
when O
the O
user O
turn O
mentions O
a O
movie O
name O
(based O
on O
the O
NER O
result), O
we O
respond O
with O
information O
about O
the O
actor, O
the O
rating, O
or O
the O
plot O
of O
this O
certain O
movie. O
In O
addition O
to O
topic-speciﬁc O
template-based O
responders, O
our O
system O
includes O
other O
template- O
based O
responders O
for O
some O
special O
dialog O
contexts, O
such O
as O
greetings, O
topic O
switches, O
etc. O
For O
every O
user O
turn, O
we O
also O
apply O
a O
neural O
network-based O
response O
generation O
(NRG) O
model O
to O
produce O
a O
response, O
highlighted O
in O
purple O
in O
Figure O
2. O
Our O
NRG O
Responder O
is O
a O
GPT2-XL B-MethodName
(Rad- O
ford O
et O
al., O
2019) O
based O
model O
trained O
on O
real O
user- O
system O
interactions O
described O
in O
Section O
3.2. O
The O
rule-based O
response O
ranker O
uses O
predeﬁned O
logic O
and O
selects O
a O
template-based O
responder O
whenit O
is O
available O
and O
the O
user O
topic O
matches O
that O
re- O
sponder, O
otherwise O
it O
uses O
the O
NRG O
response O
as O
a O
fall O
back. O
In O
our O
system O
since O
we O
have O
just O
a O
few O
template-based O
responders, O
the O
system O
uses O
NRG O
responses O
most O
of O
the O
time. O
3.2 O
Spoken O
Dialogs O
We O
deploy O
the O
dialog O
system O
described O
above O
within O
the O
Alexa O
Prize O
Socialbot O
framework O
(Ram O
et O
al., O
2018) O
to O
interact O
with O
real O
users. O
A O
user O
initi- O
ates O
an O
interaction O
with O
our O
dialog O
system O
and O
con- O
sents O
to O
have O
their O
data O
collected. O
A O
turn O
within O
an O
interaction O
is O
speciﬁed O
as O
a O
user O
utterance-system O
response O
pair. O
These O
interactions O
end O
when O
the O
user O
requests O
to O
stop O
the O
conversation. O
At O
the O
end O
of O
each O
interaction, O
users O
are O
given O
the O
opportunity O
to O
leave O
a O
rating O
in O
the O
range O
of O
1 O
to O
5. O
We O
deﬁne O
these O
ratings O
as O
1P O
rating O
as O
they O
come O
from O
the O
same O
users O
who O
interacted O
with O
the O
conversational O
agent. O
We O
denote O
this O
dataset O
as O
Real O
User O
Inter- O
actions O
(RUI)2. O
Our O
data O
consists O
of O
approximately O
100k O
interactions O
and O
5 O
million O
turns. O
This O
dataset O
is O
used O
to O
train O
our O
NRG O
Responder O
mentioned O
in O
the O
previous O
section. O
We O
discuss O
its O
training O
details O
in O
the O
Appendix. O
Not O
every O
user O
leaves O
a O
rating; O
therefore, O
we O
take O
a O
sample O
of O
interactions O
from O
RUI O
that O
contain O
user O
ratings O
and O
denote O
this O
dataset O
as O
RUI-1P O
. O
In O
addition O
to O
real O
user O
interactions, O
we O
form O
a O
dataset O
of O
interactions O
from O
paid O
users O
who O
were O
2All O
interactions O
are O
in O
English.4196instructed O
to O
speak O
to O
the O
same O
dialog O
system. O
We O
denote O
these O
interactions O
as O
paid O
user O
interactions O
PUI2. O
The O
difference O
between O
paid O
and O
real O
users O
is O
that O
the O
former O
are O
internal O
workers O
who O
are O
recruited O
to O
rigorously O
test O
and O
probe O
the O
dialog O
system O
and O
as O
a O
result O
are O
much O
more O
proactive O
in O
the O
dialogs O
as O
opposed O
to O
real O
users O
who O
are O
known O
to O
be O
less O
proactive O
in O
these O
social O
conver- O
sations O
(Juraska O
et O
al., O
2021; O
Finch O
et O
al., O
2020). O
These O
internal O
workers O
are O
considered O
paid O
as O
their O
primary O
job O
consists O
of O
assisting O
with O
data O
collec- O
tion. O
Real O
users, O
however, O
are O
consenting O
to O
a O
dia- O
log O
with O
our O
dialog O
system O
but O
are O
not O
being O
paid. O
To O
obtain O
turn O
quality O
labels, O
we O
annotate O
a O
sub- O
set O
of O
RUI-1P O
at O
the O
turn O
level. O
Given O
a O
complete O
interaction, O
an O
experienced O
annotator O
was O
asked O
to O
annotate O
each O
system O
response O
either O
as O
1 O
or O
0, O
where O
1 O
indicates O
the O
response O
is O
appropriate O
and O
vice O
versa O
for O
0. O
Additionally, O
we O
ask O
annotators O
to O
leave O
a O
dialog O
level O
rating O
in O
the O
range O
of O
1 O
to O
5. O
We O
deﬁne O
this O
turn O
and O
dialog O
level O
annotations O
as O
3P O
turn O
quality O
and3P O
ratings O
respectively, O
since O
they O
came O
from O
annotators O
who O
rated O
other O
users’ O
inter- O
actions. O
We O
denote O
this O
annotated O
data O
as O
RUI-3P O
. O
An O
example O
of O
a O
turn O
level O
annotation O
is O
shown O
in O
the O
Appendix. O
We O
also O
perform O
the O
same O
annota- O
tion O
on O
the O
PUI O
data. O
Table O
1 O
shows O
the O
statistics O
for O
each O
of O
these O
collections O
and O
available O
annota- O
tions O
for O
each O
dataset.3 O
To O
obtain O
sentiment O
labels, O
we O
leverage O
the O
BiL- B-MethodName
STM I-MethodName
sentiment I-MethodName
model O
from O
(Kim O
et O
al., O
2020), O
which O
was O
trained O
on O
spoken O
dialog O
data O
and O
auto- O
matically O
tag O
user O
utterances O
with O
sentiment. O
The O
model O
takes O
in O
both O
audio O
and O
textual O
features O
and O
outputs O
a O
real-valued O
valence O
score O
on O
a O
scale O
from O
- O
3 O
to O
3, O
which O
measures O
the O
degree O
of O
the O
utterance’s O
positivity/negativity. O
3.3 O
Written B-DatasetName
Dialogs I-DatasetName
We O
sample O
a O
set O
of O
dialogs O
released O
from O
the O
In- O
teractive O
Evaluation O
of O
Dialog O
track O
(Gunasekara O
et O
al., O
2020) O
to O
be O
annotated O
for O
turn O
quality. O
These O
dialogs O
were O
collected O
from O
invited O
participants O
conversing O
with O
knowledge-grounded O
response O
generation O
models O
through O
textual O
exchanges, O
and O
have O
been O
publicly O
released4. O
The O
original O
au- O
thors O
of O
this O
dataset O
asked O
Amazon O
Mechanical O
Turk O
(AMT) O
workers O
to O
rate O
2200 O
interactions O
on O
multiple O
dialog O
level O
dimensions, O
such O
as O
coher- O
3We O
cannot O
release O
this O
data O
publicly O
as O
it O
is O
real O
user O
data. O
4https://github.com/exe1023/DialEvalMetricsent, O
informative, O
overall. O
The O
full O
list O
of O
dialog O
level O
annotation O
dimensions O
is O
included O
in O
the O
Ap- O
pendix. O
However, O
these O
dialogs O
do O
not O
have O
turn O
level O
annotations. O
In O
order O
to O
evaluate O
our O
models O
at O
the O
turn O
level, O
we O
sample B-HyperparameterName
119 B-HyperparameterValue
dialogs O
with O
an O
average B-HyperparameterName
length I-HyperparameterName
of O
8 B-HyperparameterValue
turns. O
For O
each O
turn, O
we O
ask O
three O
AMT O
workers O
to O
rate O
whether O
they O
dislike, O
somewhat O
like O
or O
like O
the O
Chatbot’s O
response O
with O
a O
score O
of O
either O
0, O
1, O
or O
2 O
respectively. O
To O
help O
workers O
judge O
response O
quality, O
we O
ask O
them O
to O
look O
at O
how O
relevant O
and O
interesting O
a O
response O
is. O
We O
use O
majority O
voting O
to O
determine O
the O
ﬁnal O
score. O
In O
the O
case O
of O
ties O
we O
use O
a O
score O
from O
an O
internal O
author. O
The O
Krippendorff’s B-MetricName
alpha I-MetricName
score O
is O
0.31 B-MetricValue
rep- O
resenting O
fair O
agreement O
between O
annotators. O
We O
denote O
these O
assessments O
as O
3P O
turn O
quality O
since O
the O
AMT O
workers O
are O
rating O
other O
workers’ O
dialogs. O
We O
denote O
this O
dataset O
as O
Conversational O
Turns O
Evaluation O
(ConTurE) O
and O
publicly O
release O
it.5 O
4 O
Results O
and O
Discussions O
We O
compare O
our O
method O
with O
a O
suite O
of O
open O
source O
models O
from O
(Yeh O
et O
al., O
2021)4including O
RUBER, O
BERT-RUBER, O
PONE, O
PredictiveEngagement O
and O
FED O
(Tao O
et O
al., O
2018; O
Ghazarian O
et O
al., O
2019; O
Lan O
et O
al., O
2020; O
Ghazarian O
et O
al., O
2020; O
Mehri O
and O
Es- O
kenazi, O
2020). O
Table O
2 O
shows O
the O
automatic O
turn O
level O
quality O
estimation, O
measured O
using O
both O
Pearson B-MetricName
and O
Spear- B-MetricName
man I-MetricName
correlation I-MetricName
against O
turn O
level O
annotations O
on O
three O
datasets O
for O
different O
methods. O
On O
the O
spo- O
ken O
dialog O
testsets( O
RUI-3P O
andPUI) O
the O
baseline O
models O
perform O
poorly. O
In O
contrast, O
our O
Classi- O
ﬁcation(3P) O
model O
trained O
using O
3P O
turn O
quality O
achieves O
the O
highest O
correlation O
(0.29/0.28) O
on O
RUI- O
3P. O
This O
can O
be O
partly O
explained O
by O
the O
matched O
training O
and O
testing O
setup. O
We O
observe O
promising O
results O
for O
the O
Reg O
(Sentiment O
+ O
User O
Stop) O
model O
which O
was O
trained O
with O
next O
user O
sentiment O
infor- O
mation O
combined O
with O
stop O
signal O
which O
achieves O
the O
highest O
correlation O
on O
the O
PUI O
test O
set O
and O
a O
correlation O
of O
(0.22/0.23) O
on O
RUI-3P O
. O
This O
demon- O
strates O
the O
effectiveness O
of O
weak O
supervision. O
We O
compare O
different O
training O
sizes O
RUI-1P O
(40%) O
ver- O
susRUI-1P O
and O
show O
the O
expected O
beneﬁt O
of O
more O
data O
for O
model O
training. O
We O
also O
see O
that O
our O
mod- O
els O
outperform O
the O
baseline O
models O
on O
the O
Con- O
TurE O
testset. O
It O
is O
important O
to O
note O
that O
all O
the O
baseline O
models O
have O
been O
designed O
and O
evaluated O
5We O
release O
the O
ConTurE O
dataset O
at O
https://github. O
com/alexa/conture4197Training O
For O
our O
method, O
reference O
labels O
used O
for O
Classiﬁcation O
or O
Reg O
(Regression) O
models O
are O
presented. O
using O
written O
dialogs, O
and O
though O
our O
models O
were O
ﬁne-tuned O
only O
on O
spoken O
dialog, O
they O
are O
able O
to O
generalize O
to O
a O
different O
modality. O
FED O
has O
been O
shown O
to O
be O
a O
good O
dialog-level O
evaluator O
(Yeh O
et O
al., O
2021). O
However O
we O
see O
in O
Table O
2 O
that O
FED O
achieves O
low O
performance O
for O
turn-level O
evaluation. O
This O
matches O
the O
conclusion O
in O
(Mehri O
and O
Eske- O
nazi, O
2020) O
who O
point O
out O
that O
FED O
captures O
the O
dialog-level O
qualities O
from O
its O
training O
data O
Reddit O
better O
than O
turn-level O
qualities. O
Table O
3 O
shows O
the O
correlation O
results O
of O
the O
ag- O
gregated O
turn O
level O
scores O
with O
3P O
ratings O
and1P O
ratings O
on O
the O
spoken O
dataset. O
From O
the O
ﬁrst O
row, O
we O
can O
see O
that O
there O
is O
a O
moderate O
positive O
correla- O
tion O
between O
the O
aggregated O
mean O
of O
3P O
turn O
qual- O
ityand3P O
ratings O
(0.50 O
/ O
0.46), O
but O
see O
a O
very O
low O
positive O
correlation O
with O
1P O
ratings O
(0.16 O
/ O
0.12). O
This O
may O
be O
due O
to O
the O
fact O
that O
Likert O
scale O
ratings O
can O
have O
lower O
inter-annotator O
agreement O
(Belz O
and O
Kow, O
2010). O
Additionally, O
the O
3P O
annotators O
had O
access O
to O
the O
whole O
interaction O
and O
could O
re-read O
the O
context. O
This O
is O
in O
contrast O
to O
1P O
users O
who O
may O
forget O
what O
happened O
earlier O
in O
the O
interaction O
as O
it O
is O
spoken. O
Another O
reason O
is O
that O
3P O
annotators O
only O
read O
the O
transcript O
of O
the O
dialog O
for O
turn O
or O
dialog O
evaluation, O
and O
may O
miss O
the O
tones O
in O
utter- O
ances O
that O
may O
affect O
1P O
user O
ratings. O
When O
using O
the O
user O
sentiment O
scores, O
we O
can O
see O
through O
mean O
aggregation O
it O
has O
positive O
correlation O
with O
both O
3P O
ratings O
(0.48/0.46) O
and O
1P O
ratings O
(0.38/0.37). O
The O
higher O
correlation O
of O
user O
sentiment O
(as O
opposed O
to3P O
turn O
quality O
) O
with O
1P O
rating O
is O
partly O
because O
of O
the O
different O
signals O
used O
in O
3P O
annotation O
as O
discussed O
above. O
These O
results O
suggest O
sentiment O
can O
be O
used O
to O
estimate O
dialog O
level O
ratings, O
as O
done O
in O
previous O
work O
such O
as O
(Kim O
et O
al., O
2020). O
Overall, O
we O
see O
that O
the O
next O
user O
utterance O
sen- O
timent O
serves O
as O
a O
reasonable O
proxy O
to O
the O
quality O
of O
the O
previous O
system O
response, O
hence O
when O
thereis O
not O
much O
data O
with O
turn O
level O
quality O
annotation, O
we O
can O
train O
models O
using O
weak O
supervision O
com- O
ing O
from O
the O
next O
user O
utterance. O
In O
this O
study, O
we O
use O
the O
sentiment O
scores O
obtained O
from O
user O
utter- O
ances O
in O
speech O
based O
dialogs, O
therefore, O
acoustic O
features O
were O
used O
to O
obtain O
such O
sentiment O
infor- O
mation. O
Since O
speech O
based O
sentiment O
or O
emotion O
recognition O
has O
been O
widely O
studied, O
it O
does O
not O
require O
much O
additional O
annotation O
to O
train O
the O
sen- O
timent O
model O
for O
user O
utterances, O
and O
thus O
we O
can O
rely O
on O
existing O
models. O
We O
also O
explored O
using O
sentiment O
just O
based O
on O
text, O
but O
observed O
some O
issues O
in O
our O
preliminary O
study. O
For O
example, O
when O
users O
reply O
with O
a O
‘no’ O
to O
a O
question, O
it O
is O
classi- O
ﬁed O
as O
negative, O
however, O
this O
may O
not O
indicate O
a O
problem O
with O
the O
previous O
system O
response. O
We O
plan O
to O
further O
investigate O
this O
in O
our O
future O
work, O
which O
will O
allow O
us O
to O
better O
utilize O
more O
available O
text O
based O
dialog O
data. O
Example O
outputs O
from O
both O
FED O
and O
our O
model O
are O
shown O
in O
the O
Appendix. O
3P O
Ratings O
1P O
Ratings O
P O
S O
P O
S O
3P O
turn O
quality O
0.50 O
0.46 O
0.16 O
0.12 O
User O
sentiment O
0.48 O
0.46 O
0.38 O
0.37 O
Table O
3: O
Correlation O
between O
turn O
level O
information O
(3P O
turn O
quality O
and O
user O
turn O
sentiment) O
and O
dialog O
level O
rating O
on O
RUI-3P. O
P=Pearson, O
S=Spearman. O
5 O
Conclusion O
In O
this O
work, O
we O
show O
that O
instead O
of O
training O
on O
manually O
annotated O
data O
we O
can O
train O
on O
sentiment O
from O
the O
next O
user O
utterance O
in O
a O
weakly O
supervised O
manner O
to O
evaluate O
system O
responses. O
We O
show O
that O
our O
model O
has O
better O
cross O
domain O
generalization O
and O
performs O
well O
on O
a O
written O
dialog O
dataset. O
In O
our O
future O
work O
we O
will O
investigate O
other O
methods O
beyond O
simple O
aggregation O
for O
dialog O
level O
estima- O
tion O
and O
using O
more O
text O
based O
dialog O
data.41986 O
Ethics O
and O
Broader O
Impact O
Our O
work O
involves O
leveraging O
user O
sentiment O
to O
evaluate O
the O
quality O
of O
system O
responses. O
We O
ac- O
knowledge O
that O
we O
are O
using O
data O
from O
real O
users O
who O
have O
not O
been O
paid O
for O
these O
interactions. O
We O
also O
acknowledge O
there O
may O
be O
biases O
in O
the O
demo- O
graphics O
of O
the O
user O
population. O
We O
conducted O
our O
ConTurE O
annotation O
through O
Amazon O
Mechanical O
Turk. O
We O
pay O
turkers O
$12 O
per O
hour, O
which O
is O
well O
above O
the O
federal O
minimum O
age. O
In O
The O
First O
Workshop O
on O
Evalua- O
tions O
and O
Assessments O
of O
Neural O
Conversation O
Sys- O
tems, O
pages O
15–33. O
Chen O
Zhang, O
Yiming O
Chen, O
Luis O
Fernando O
D’Haro, O
Yan O
Zhang, O
Thomas O
Friedrichs, O
Grandee O
Lee, O
and O
Haizhou O
Li. O
2021a. O
Dynaeval: O
Unifying O
turn O
and O
dialogue O
level O
evaluation. O