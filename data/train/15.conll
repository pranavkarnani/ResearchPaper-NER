-DOCSTART-  O
Proceedings  O
of  O
the  O
Sixth  O
Conference  O
on  O
Machine  O
Translation  O
(WMT)  O
,  O
pages  O
197–204  O
November  O
10–11,  O
2021.  O
©2021  O
Association  O
for  O
Computational  O
Linguistics197NVIDIA  O
NeMo’s  O
Neural  B-TaskName
Machine  I-TaskName
Translation  I-TaskName
Systems  O
for  O
English  O
$  O
German  O
and  O
English  O
$Russian  O
News  O
and  O
Biomedical  O
Tasks  O
at  O
WMT21  O
Sandeep  O
Subramanian,  O
Oleksii  O
Hrinchuk,  O
Virginia  O
Adams,  O
Oleksii  O
Kuchaiev  O
NVIDIA  O
Santa  O
Clara,  O
CA  O
{sandeepsub,  O
ohrinchuk,  O
vadams,  O
okuchaiev}@nvidia.com  O
Abstract  O
This  O
paper  O
provides  O
an  O
overview  O
of  O
NVIDIA  O
NeMo’s  O
neural  B-TaskName
machine  I-TaskName
translation  I-TaskName
systems  O
for  O
the  O
constrained  O
data  O
track  O
of  O
the  O
WMT21  B-DatasetName
News  I-DatasetName
and  I-DatasetName
Biomedical  I-DatasetName
Shared  I-DatasetName
Translation  I-DatasetName
Tasks.  O
Our  O
news  O
task  O
submissions  O
for  O
English  O
$German  O
(En  O
$De)  O
and  O
English  O
$Rus-  O
sian  O
(En  O
$Ru)  O
are  O
built  O
on  O
top  O
of  O
a  O
base-  O
line  O
transformer-based  O
sequence-to-sequence  O
model  O
(Vaswani  O
et  O
al.,  O
2017).  O
Speciﬁcally,  O
we  O
use  O
a  O
combination  O
of  O
1)  O
checkpoint  O
av-  O
eraging  O
2)  O
model  O
scaling  O
3)  O
data  O
augmenta-  O
tion  O
with  O
backtranslation  O
and  O
knowledge  O
dis-  O
tillation  O
from  O
right-to-left  O
factorized  O
models  O
4)  O
ﬁnetuning  O
on  O
test  O
sets  O
from  O
previous  O
years  O
5)  O
model  O
ensembling  O
6)  O
shallow  O
fusion  O
decoding  O
with  O
transformer  O
language  O
models  O
and  O
7)  O
noisy  O
channel  O
re-ranking.  O
Additionally,  O
our  O
biomed-  O
ical  O
task  O
submission  O
for  O
English  O
$Russian  O
uses  O
a  O
biomedically  O
biased  O
vocabulary  O
and  O
is  O
trained  O
from  O
scratch  O
on  O
news  O
task  O
data,  O
medi-  O
cally  O
relevant  O
text  O
curated  O
from  O
the  O
news  O
task  O
dataset,  O
and  O
biomedical  O
data  O
provided  O
by  O
the  O
shared  O
task.  O
Our  O
news  O
system  O
achieves  O
a  O
sacre-  O
BLEU  B-MetricName
score  B-MetricName
of  O
39.5  B-MetricValue
on  O
the  O
WMT’20  O
En  O
!  O
De  O
test  O
set  O
outperforming  O
the  O
best  O
submission  O
from  O
last  O
year’s  O
task  O
of  O
38.8.  O
Our  O
biomedical  O
task  O
Ru  O
!En  O
and  O
En  O
!Ru  O
systems  O
reach  O
BLEU  B-MetricName
scores  I-MetricName
of  O
43.8  B-MetricValue
and  O
40.3  B-MetricValue
respectively  O
on  O
the  O
WMT’20  O
Biomedical  O
Task  O
Test  O
set,  O
outper-  O
forming  O
the  O
previous  O
year’s  O
best  O
submissions.  O
1  O
Introduction  O
We  O
take  O
part  O
in  O
the  O
WMT’21  O
News  O
Shared  O
Task  O
for  O
English  O
$German,  O
English  O
$Russian,  O
and  O
the  O
Biomedical  O
Shared  O
Task  O
for  O
English  O
$Rus-  O
sian.  O
Our  O
systems  O
are  O
implemented  O
in  O
the  O
NVIDIA  O
NeMo1framework  O
(Kuchaiev  O
et  O
al.,  O
2019).  O
They  O
build  O
on  O
baseline  O
sequence-to-sequence  O
trans-  O
former  O
models  O
(Vaswani  O
et  O
al.,  O
2017)  O
in  O
the  O
follow-  O
ing  O
ways:  O
1)  O
Checkpoint  O
averaging,  O
2)  O
Model  O
scal-  O
ing  O
up  O
to  O
1B  O
parameters,  O
3)  O
Data  O
augmentation  O
with  O
1https://github.com/NVIDIA/NeMolarge-scale  O
backtranslation  O
(Edunov  O
et  O
al.,  O
2018)  O
of  O
monolingual  O
Newscrawl  O
data  O
and  O
sequence-level  O
knowledge  O
distillation  O
from  O
a  O
right-to-left  O
factor-  O
ized  O
model  O
(Zhang  O
et  O
al.,  O
2019b),  O
4)  O
Finetuning  O
models  O
on  O
in-domain  O
news  O
data  O
from  O
WMT  B-DatasetName
test  O
sets  O
made  O
available  O
in  O
previous  O
years,  O
5)  O
Ensem-  O
bling  O
models  O
trained  O
on  O
different  O
subsets  O
of  O
the  O
overall  O
data  O
6)  O
Shallow  O
fusion  O
decoding  O
with  O
trans-  O
former  O
language  O
models  O
(Gulcehre  O
et  O
al.,  O
2015)  O
7)  O
Noisy  O
channel  O
re-ranking  O
of  O
beam  O
search  O
candidate  O
hypotheses  O
(Yee  O
et  O
al.,  O
2019).  O
Overall,  O
we  O
ﬁnd  O
each  O
of  O
these  O
components  O
re-  O
sults  O
in  O
a  O
small  O
improvement  O
in  O
BLEU  B-MetricName
scores  O
with  O
backtranslation  O
results  O
being  O
mixed  O
depending  O
on  O
the  O
language  O
direction  O
and  O
whether  O
the  O
test  O
data  O
contains  O
translationese  O
inputs.  O
Using  O
a  O
combina-  O
tion  O
of  O
these  O
techniques,  O
we  O
achieve  O
39.5  O
sacre-  O
BLEU  O
scores  O
on  O
the  O
En  O
!De  O
WMT’20  O
test  O
set,  O
outperforming  O
the  O
best  O
BLEU  O
scores  O
from  O
last  O
year’s  O
competition  O
of  O
38.77.  O
Training  O
our  O
En  O
$Ru  O
biomedical  O
task  O
submis-  O
sion  O
from  O
scratch  O
using  O
a  O
biomedical  O
vocabulary  O
and  O
similar  O
model  O
improvements  O
to  O
those  O
used  O
for  O
our  O
news  O
task  O
submission,  O
we  O
report  O
a  O
sacreBLEU  B-MetricName
score  O
of  O
40.3  B-MetricValue
on  O
En  O
!Ru  O
and  O
43.8  O
on  O
Ru  O
!  O
Enh  O
on  O
the  O
WMT’20  B-DatasetName
Biomedical  I-DatasetName
Shared  I-DatasetName
Task  I-DatasetName
test  O
dataset.  O
This  O
improves  O
over  O
the  O
best  O
submissions  O
from  O
last  O
year’s  O
competition2of  O
39.6  O
and  O
43.3  O
on  O
En!Ru  O
and  O
Ru  O
!En  O
respectively.  O
2  O
Datasets  O
We  O
participated  O
in  O
the  O
constrained  O
data  O
track  O
at  O
this  O
year’s  O
news  O
and  O
biomedical  O
competitions  O
and  O
used  O
all  O
the  O
parallel  O
corpora  O
provided  O
by  O
the  O
WMT  B-DatasetName
Shared  I-DatasetName
Tasks  I-DatasetName
for  O
both  O
En  O
$De  O
and  O
En  O
$Ru.  O
We  O
used  O
the  O
provided  O
English,  O
German,  O
and  O
Russian  O
monolingual  O
Newscrawl  O
data  O
for  O
back-  O
translation  O
and  O
training  O
our  O
autoregressive  O
trans-  O
former  O
language  O
models.  O
We  O
ﬁlter  O
out  O
monolingual  O
2We  O
compare  O
against  O
all  O
En  O
$Ru  O
Biomedical  O
submis-  O
sions,  O
not  O
just  O
the  O
ones  O
marked  O
as  O
the  O
ﬁnal  O
submission.198Newscrawl  O
data  O
only  O
based  O
on  O
minimum  O
and  O
maxi-  O
mum  O
length  O
criteria,  O
but  O
perform  O
more  O
aggressive  O
ﬁltering  O
of  O
our  O
parallel  O
data  O
described  O
in  O
Section  O
2.1.  O
2.1  O
Parallel  B-MethodName
Corpus  I-MethodName
Filtering  I-MethodName
We  O
use  O
a  O
combination  O
of  O
the  O
following  O
data  O
ﬁlter-  O
ing  O
steps  O
for  O
all  O
parallel  O
corpora  O
(including  O
pseudo  O
parallel  O
corpora  O
generated  O
via  O
backtranslation  O
and  O
distillation)  O
except  O
for  O
the  O
Biomedical  O
Shared  O
Task  O
provided  O
data.  O
•Language  O
ID  O
Filtering  O
-  O
We  O
use  O
the  O
fastText  O
(Joulin  O
et  O
al.,  O
2016)  O
language  O
ID  O
classiﬁer3to  O
remove  O
training  O
examples  O
that  O
aren’t  O
in  O
the  O
appropriate  O
language.  O
•Length  O
and  O
Ratio  O
Filtering  O
-  O
We  O
ﬁlter  O
out  O
examples  O
where  O
a  O
sentence  O
in  O
either  O
language  O
is  O
longer  O
than  O
250  O
tokens  O
before  O
BPE  O
tokeniza-  O
tion  O
and  O
where  O
the  O
length  O
ratio  O
between  O
source  O
and  O
target  O
sentences  O
exceeds  O
1.3.  O
•Bicleaner  O
-  O
Bitexts  O
that  O
were  O
assigned  O
a  O
Bi-  O
cleaner  O
(Ramírez-Sánchez  O
et  O
al.,  O
2020)  O
score  O
of  O
<  O
0.6  O
were  O
removed.  O
On  O
the  O
news  O
shared  O
task,  O
we  O
keep  O
60M  O
parallel  O
sentences  O
for  O
En  O
$De  O
and  O
26M  O
sentences  O
for  O
En  O
$Ru  O
after  O
ﬁltering.  O
2.2  O
Biomedical  O
Task  O
Data  O
Our  O
parallel  O
biomedical  O
domain  O
data  O
included  O
a  O
mix  O
of  O
all  O
the  O
En  O
$Ru  O
parallel  O
training  O
data  O
given  O
by  O
shared  O
task  O
organizers  O
and  O
biomedically  O
relevant  O
examples  O
selected  O
from  O
the  O
provided  O
En  O
$Ru  O
news  O
task  O
data.  O
We  O
trained  O
two  O
biomedical  O
domain  O
binary  O
clas-  O
siﬁers,  O
one  O
for  O
English  O
and  O
one  O
for  O
Russian.  O
The  O
classiﬁers  O
were  O
composed  O
of  O
two  O
task-speciﬁc  O
fully  O
connected  O
layers  O
on  O
top  O
of  O
pre-trained  O
BERT  B-MethodName
Base  O
(Devlin  O
et  O
al.,  O
2018)  O
or  O
RuBERT  B-MethodName
Base  O
(Kuratov  O
and  O
Arkhipov,  O
2019)  O
for  O
English  O
and  O
Russian  O
re-  O
spectively.  O
The  O
positive  O
examples  O
were  O
sourced  O
from  O
the  O
WMT’20  B-DatasetName
Biomedical  I-DatasetName
Shared  I-DatasetName
Task  I-DatasetName
train  O
set.  O
The  O
negative  O
examples  O
were  O
randomly  O
sam-  O
pled  O
from  O
the  O
parallel  O
En  O
$Ru  O
news  O
data  O
given  O
for  O
the  O
WMT’21  B-DatasetName
news  I-DatasetName
task.  O
An  O
equal  O
amount  O
of  O
45K  O
examples  O
were  O
used  O
for  O
both  O
the  O
positive  O
and  O
negative  O
classes.  O
3https://fasttext.cc/docs/en/  O
language-identification.htmlWe  O
ran  O
our  O
English  O
biomedical  O
domain  O
classi-  O
ﬁers  O
on  O
the  O
English  O
half  O
of  O
all  O
approximately  O
26M  O
parallel  O
En  O
$Ru  O
WMT’21  O
news  O
training  O
data.  O
We  O
saved  O
all  O
sentences  O
with  O
predicted  O
biomedical  O
domain  O
probabilities  O
over  O
50%,  O
collecting  O
around  O
560k  O
examples.  O
We  O
then  O
ran  O
our  O
Russian  O
classiﬁer  O
on  O
the  O
Russian  O
counterparts  O
to  O
the  O
560k  O
predicted  O
in  O
domain  O
English  O
sentences.  O
We  O
averaged  O
the  O
clas-  O
siﬁer  O
scores  O
from  O
the  O
English  O
and  O
Russian  O
domain  O
classiﬁers  O
and  O
used  O
this  O
average  O
score  O
as  O
our  O
ﬁnal  O
selection  O
criteria.  O
We  O
set  O
a  O
cut-off  O
threshold  O
of  O
.90  O
resulting  O
in  O
208K  O
parallel  O
examples  O
classiﬁed  O
from  O
the  O
news  O
domain  O
data.  O
We  O
combined  O
this  O
with  O
the  O
46k  O
parallel  O
biomedical  O
examples  O
provided  O
for  O
the  O
task,  O
resulting  O
in  O
a  O
total  O
of  O
256,037  O
parallel  O
training  O
examples.  O
2.3  O
Data  O
Pre-processing  O
and  O
Post-processing  O
We  O
normalize  O
punctuation4and  O
tokenize5examples  O
with  O
the  O
Moses  O
toolkit.  O
For  O
En  O
$De,  O
we  O
train  O
a  O
shared  O
BPE  O
tokenizer  O
with  O
a  O
vocab  O
of  O
32k  O
tokens  O
using  O
the  O
YouTokenToMe6library.  O
For  O
En  O
$Ru,  O
we  O
train  O
language-speciﬁc  O
BPE  O
tokenizers  O
with  O
a  O
vocab  O
of  O
16k  O
tokens  O
each.  O
For  O
the  O
En  O
$Ru  O
Biomedical  O
translation  O
task,  O
we  O
learn  O
a  O
separate  O
BPE  O
tokenizer  O
solely  O
on  O
our  O
Biomedical  O
Task  O
Data  O
described  O
in  O
2.2.  O
We  O
use  O
BPE-dropout  B-HyperparameterName
(Provilkov  O
et  O
al.,  O
2019)  O
of  O
0.1  B-HyperparameterValue
for  O
both  O
language  O
pairs  O
and  O
tasks.  O
We  O
post-process  O
En  O
!De  O
model  O
generated  O
translations  O
to  O
replace  O
quotes  O
with  O
their  O
German  O
equivalents  O
-  O
„  O
and  O
“.  O
3  O
System  O
overview  O
Our  O
systems  O
build  O
on  O
the  O
Transformer  B-MethodName
sequence-  O
to-sequence  O
architecture  O
(Vaswani  O
et  O
al.,  O
2017).  O
In  O
the  O
subsequent  O
subsections,  O
we  O
discuss  O
model  B-MethodName
scal-  I-MethodName
ing,  I-MethodName
checkpoint  I-MethodName
averaging,  I-MethodName
data  I-MethodName
augmentation  I-MethodName
with  I-MethodName
backtranslation  I-MethodName
and  I-MethodName
right-to-left  I-MethodName
distillation,  I-MethodName
model  I-MethodName
ﬁnetuning,  I-MethodName
ensembling,  I-MethodName
shallow  I-MethodName
fusion  I-MethodName
decoding  I-MethodName
with  I-MethodName
LMs,  I-MethodName
and  I-MethodName
noisy  I-MethodName
channel  I-MethodName
re-ranking.  I-MethodName
3.1  O
Model  O
Conﬁgurations  O
We  O
experiment  O
with  O
three  O
different  O
model  O
con-  O
ﬁgurations  O
-  O
Large,  O
XLarge,  O
and  O
XXLarge.  O
The  O
Large  O
conﬁguration  O
corresponds  O
to  O
the  O
“Trans-  O
former  O
Large”  O
variant  O
from  O
Vaswani  O
et  O
al.  O
(2017)  O
4https://github.com/moses-smt/  O
mosesdecoder/blob/master/scripts/  O
tokenizer/normalize-punctuation.perl  O
5https://github.com/moses-smt/  O
mosesdecoder/blob/master/scripts/  O
tokenizer/tokenizer.perl  O
6https://github.com/VKCOM/YouTokenToMe199and  O
the  O
XLarge  O
and  O
XXLarge  O
scale  O
that  O
base  O
con-  O
ﬁguration  O
along  O
depth  O
and  O
width.  O
The  O
exact  O
spec-  O
iﬁcations  O
are  O
in  O
Table  O
1.  O
Following  O
Kasai  O
et  O
al.  O
(2020),  O
we  O
keep  O
the  O
number  B-HyperparameterName
decoder  I-HyperparameterName
layers  I-HyperparameterName
ﬁxed  O
at  O
6  B-HyperparameterValue
and  O
scale  O
only  O
the  O
depth  B-HyperparameterName
of  I-HyperparameterName
the  I-HyperparameterName
encoder  I-HyperparameterName
to  O
24  B-HyperparameterValue
layers  O
for  O
the  O
“XLarge”  O
conﬁguration.  O
For  O
stable  O
optimization  O
of  O
deep  O
transformers,  O
we  O
use  O
the  O
“pre-  O
LN”  O
transformer  O
block  O
(Xiong  O
et  O
al.,  O
2020).  O
When  O
scaling  O
to  O
1  O
billion  O
parameters  O
(XXLarge),  O
we  O
only  O
increase  O
hidden  O
and  O
feedforward  O
dimensions  O
of  O
the  O
model.  O
Large  O
XLarge  O
XXLarge  O
Hidden  O
Dim  O
1,024  O
1,024  O
1,536  O
Feedforward  O
Dim  O
4,096  O
4,096  O
6,144  O
Attention  O
Heads  O
16  O
16  O
24  O
Encoder  O
Layers  O
6  O
24  O
24  O
Decoder  O
Layers  O
6  O
6  O
6  O
Pre-LN  O
7  O
3  O
3  O
Parameters  O
240M  O
500M  O
1B  O
Table  O
1:  O
Model  O
Conﬁgurations  O
3.2  O
Checkpoint  O
Averaging  O
Over  O
the  O
course  O
of  O
training,  O
we  O
save  O
the  O
top-k  O
checkpoints  O
that  O
obtain  O
the  O
best  O
sacreBLEU  B-MetricName
scores  O
on  O
a  O
validation  O
set.  O
The  O
ﬁnal  O
model  O
parameters  O
are  O
obtained  O
by  O
averaging  O
the  O
parameters  O
correspond-  O
ing  O
to  O
these  O
checkpoints.  O
avg=1  O
kkX  O
i=1i  O
avgare  O
the  O
model  O
parameters  O
after  O
checkpoint  O
averaging  O
and  O
1:::  O
kare  O
the  O
individual  O
check-  O
points  O
being  O
averaged.  O
Empirically,  O
we  O
didn’t  O
ob-  O
serve  O
a  O
difference  O
between  O
averaging  O
the  O
last  O
k  O
checkpoints  O
versus  O
the  O
top-k  O
checkpoints.  O
The  O
for-  O
mer  O
is  O
however  O
more  O
common  O
and  O
implemented  O
in  O
libraries  O
such  O
as  O
fairseq  O
(Ott  O
et  O
al.,  O
2019).  O
3.3  O
Data  O
Augmentation  O
with  O
Backtranslation  O
&  O
Right-to-left  O
model  O
distillation  O
We  O
follow  O
Edunov  O
et  O
al.  O
(2018)  O
in  O
backtranslating  O
monolingual  O
Newscrawl  O
data  O
with  O
noise  O
introduced  O
via  O
topk  O
sampling  O
(k=500).  O
For  O
En  O
$De,  O
we  O
back-  O
translate  O
~250M  O
sentences  O
and  O
ﬁlter  O
translations  O
based  O
on  O
the  O
process  O
described  O
in  O
Section  O
2.1.  O
We  O
observed  O
fairly  O
signiﬁcant  O
drops  O
in  O
BLEU  O
score  O
when  O
using  O
backtranslated  O
data  O
for  O
En  O
$Ru  O
and  O
did  O
not  O
apply  O
any  O
data  O
augmentation  O
for  O
this  O
lan-  O
guage  O
pair.  O
We  O
use  O
the  O
XLarge  O
model  O
conﬁgurationtrained  O
only  O
on  O
the  O
News  O
Task  O
provided  O
parallel  O
corpus  O
to  O
generate  O
translations.  O
We  O
also  O
train  O
an  O
XLarge  O
model  O
for  O
En  O
!De  O
and  O
De  O
!En  O
on  O
the  O
News  O
Task  O
provided  O
parallel  O
data  O
where  O
the  O
output  O
sequence  O
is  O
factorized  O
from  O
right-to-left.  O
Translations  O
of  O
the  O
training  O
dataset  O
with  O
topk  O
sampling  O
(k=500)  O
using  O
these  O
models  O
are  O
generated  O
and  O
added  O
to  O
the  O
overall  O
training  O
set.  O
When  O
adding  O
only  O
backtranslated  O
text  O
or  O
data  O
generated  O
from  O
right-to-left  O
factorized  O
models,  O
we  O
use  O
a  O
2:1  O
ratio  O
of  O
parallel  O
to  O
pseudo-parallel  O
(model  O
generated)  O
data.  O
When  O
training  O
with  O
a  O
combination  O
of  O
both,  O
we  O
use  O
a  O
6:3:1  O
ratio  O
of  O
parallel,  O
right-to-  O
left  O
generated,  O
and  O
backtranslated  O
data.  O
We  O
skew  O
data  O
sampling  O
in  O
this  O
way  O
since  O
training  O
on  O
right-to-  O
left  O
generated  O
data  O
showed  O
better  O
performance  O
on  O
recent  O
WMT  O
test  O
sets  O
as  O
opposed  O
to  O
backtranslation  O
which  O
did  O
better  O
on  O
old  O
test  O
sets  O
that  O
contained  O
translationese  O
inputs  O
(see  O
Tables  O
2  O
and  O
3).  O
3.4  O
Mixed  O
Domain  O
Training  O
For  O
the  O
biomedical  O
task  O
submission,  O
we  O
experiment  O
with  O
different  O
mixed  O
domain  O
training  O
approaches  O
(Zhang  O
et  O
al.,  O
2019a).  O
We  O
train  O
on  O
the  O
concatenated  O
combination  O
of  O
news  O
task  O
and  O
biomedical  O
task  O
data-  O
up-sampling  O
the  O
proportion  O
of  O
biomedical  O
data  O
to  O
make  O
up  O
30%  O
or  O
50%  O
of  O
the  O
data-parallel  O
exam-  O
ples  O
seen  O
during  O
training.  O
We  O
also  O
train  O
models  O
on  O
concatenated  O
data  O
with  O
no  O
up-sampling  O
and  O
with  O
purely  O
news  O
task  O
data.  O
The  O
base  O
models  O
trained  O
on  O
exclusively  O
news  O
task  O
data  O
still  O
use  O
the  O
biomedical  O
vocabulary  O
tokenizer.  O
3.5  O
Model  O
Finetuning  O
For  O
our  O
news  O
task  O
submission,  O
we  O
ﬁnetuned  O
models  O
on  O
an  O
in-domain  O
parallel  O
corpus  O
consisting  O
of  O
WMT  O
provided  O
test  O
datasets  O
from  O
past  O
years  O
(WMT’08  O
-  O
WMT’19  O
for  O
En  O
$De  O
comprising  O
~32k  O
examples)  O
for  O
both  O
En  O
$De  O
and  O
En  O
$Ru.  O
We  O
ﬁnetuned  O
our  O
biomedical  O
task  O
base  O
models  O
on  O
the  O
250k  O
parallel  O
sentences  O
obtained  O
via  O
the  O
pro-  O
cess  O
described  O
in  O
Section  O
2.2.  O
Models  O
are  O
ﬁnetuned  O
for  O
1-2  O
epochs  O
using  O
a  O
ﬁxed  O
tuned  O
learning  O
rate  O
and  O
the  O
top-k  O
checkpoints  O
on  O
a  O
validation  O
dataset  O
(new-  O
stest2020  O
for  O
the  O
News  O
Shared  O
Task)  O
are  O
averaged.  O
3.6  O
Ensembling  O
Givenkdifferent  O
models  O
for  O
a  O
particular  O
language  O
direction  O
trained  O
with  O
the  O
same  O
tokenizer,  O
we  O
en-  O
semble  O
them  O
at  O
inference  O
by  O
averaging  O
their  O
proba-  O
bility  O
distributions  O
over  O
the  O
next  O
token.200P(ytjy<t;x;1:::  O
k)  O
=1  O
kkX  O
i=1P(ytjy<t;x;i)  O
WhereP(ytjy<t;x)is  O
the  O
probability  O
distribu-  O
tion  O
over  O
the  O
target  O
token  O
ytgiven  O
all  O
previously  O
generated  O
target  O
tokens  O
y<tand  O
the  O
input  O
sequence  O
x.1:::  O
kare  O
thekdifferent  O
models  O
being  O
ensem-  O
bled.  O
Beam  O
search  O
scores  O
are  O
computed  O
using  O
these  O
averaged  O
probabilities  O
at  O
each  O
time  O
step.  O
In  O
practice,  O
we  O
ensemble  O
models  O
trained  O
on  O
different  O
subsets  O
of  O
the  O
available  O
data.  O
For  O
En  O
$De,  O
we  O
ensemble  O
a  O
total  O
of  O
6  O
models  O
trained  O
on  O
different  O
subsets  O
of  O
the  O
data.  O
Example:  O
News  O
Task  O
provided  O
bitext  O
only,  O
the  O
addition  O
of  O
backtranslated  O
and/or  O
data  O
from  O
right-to-left  O
factor-  O
ized  O
models  O
and  O
ﬁnetuned  O
models.  O
For  O
En  O
$Ru,  O
we  O
ensemble  O
a  O
total  O
of  O
3  O
identical  O
XLarge  O
models  O
trained  O
with  O
different  O
random  O
seeds  O
on  O
the  O
main  O
parallel  O
corpus.  O
For  O
the  O
En  O
$Ru  O
biomedical  O
task,  O
we  O
ensem-  O
ble  O
4  O
ﬁnetuned  O
models  O
whose  O
base  O
conﬁgurations  O
were  O
trained  O
with  O
different  O
mixed  O
domain  O
sam-  O
pling  O
ratios.  O
Speciﬁcally,  O
each  O
translation  O
direction  O
includes  O
an  O
ensemble  O
of  O
models  O
initially  O
trained  O
on  O
mixed  O
domain  O
data  O
with  O
50%  O
up-sampling  O
of  O
biomedical  O
data,  O
concatenated  O
biomedical  O
and  O
news  O
data  O
with  O
no  O
up  O
sampling,  O
exclusively  O
news  O
data,  O
and  O
exclusively  O
news  O
data  O
with  O
right-to-left  O
distillation.  O
3.7  O
Shallow  O
Fusion  O
Decoding  O
with  O
Language  O
Models  O
Aside  O
from  O
backtranslation,  O
another  O
way  O
to  O
lever-  O
age  O
large  O
amounts  O
of  O
monolingual  O
data  O
is  O
via  O
train-  O
ing  O
language  O
models.  O
We  O
train  O
language-speciﬁc  O
16-layer  O
transformer  O
language  O
models  O
at  O
the  O
sen-  O
tence  O
level,  O
which  O
is  O
architecturally  O
similar  O
to  O
Rad-  O
ford  O
et  O
al.  O
(2019).  O
They  O
are  O
trained  O
on  O
Newscrawl  B-DatasetName
and  O
use  O
the  O
same  O
tokenizers  O
as  O
our  O
NMT  O
systems.  O
When  O
generating  O
translations,  O
we  O
decode  O
jointly  O
with  O
our  O
NMT  O
system  O
s!tand  O
a  O
target  O
side  O
lan-  O
guage  O
moelt(Gulcehre  O
et  O
al.,  O
2015).  O
The  O
score  O
of  O
a  O
partially  O
decoded  O
sequence  O
on  O
the  O
beam  O
S(y1:::n)  O
of  O
lengthnis  O
given  O
by  O
the  O
following  O
recurrence  O
S(y1:::njx;s!t;t)  O
=S(y1:::n 1jx;s!t;t)  O
+  O
logP(ynjy<n;x;s!t)  O
+sflogP(ynjy<n;t)where  O
the  O
empty  O
sequence  O
has  O
a  O
score  O
of  O
0.  O
We  O
tuned  O
the  O
LM  O
importance  O
coefﬁcient  O
sfon  O
a  O
vali-  O
dation  O
dataset  O
and  O
found  O
a  O
value  O
between  O
0.05  O
-  O
0.1  O
to  O
work  O
well  O
in  O
practice.  O
3.8  O
Noisy  O
Channel  O
Re-ranking  O
We  O
re-rank  O
the  O
beam  O
search  O
candidates  O
produced  O
by  O
our  O
ensemble  O
model  O
generated  O
with  O
or  O
without  O
shallow  O
fusion  O
using  O
a  O
neural  O
noisy  O
channel  O
model  O
(Yee  O
et  O
al.,  O
2019).  O
The  O
noisy  O
channel  O
model  O
com-  O
putes  O
the  O
score  O
of  O
any  O
translation  O
S(yijx)on  O
the  O
beam  O
based  O
on  O
a  O
forward  O
(source-to-target)  O
model,  O
a  O
reverse  O
(target-to-source),  O
and  O
a  O
target  O
language  O
model.  O
The  O
best  O
translation  O
after  O
re-ranking  O
is  O
given  O
by  O
arg  O
max  O
iS(yijx)  O
=  B-DatasetName
logP(yijx;ens  O
s!t)  O
+ncr   O
logP(xjyi;t!s)  O
+  O
logP(yi;t)  O
Forward  O
log  O
probabilities  O
are  O
given  O
by  O
an  O
en-  O
semble  O
of  O
source-to-target  O
models  O
ens  O
s!t.  O
We  O
ex-  O
perimented  O
with  O
using  O
an  O
ensemble  O
of  O
target-to-  O
source  O
translation  O
models  O
to  O
compute  O
logP(xjyi)  O
but  O
didn’t  O
observe  O
any  O
empirical  O
beneﬁts  O
and  O
so  O
all  O
reported  O
results  O
use  O
only  O
a  O
single  O
reverse  O
model  O
t!sfor  O
noisy  O
channel  O
re-ranking.  O
We  O
generate  O
15  O
candidates  O
via  O
beam  O
search  O
and  O
tune  O
ncron  O
a  O
validation  O
dataset  O
and  O
found  O
a  O
value  O
between  O
0.5  O
-  O
0.7  O
to  O
work  O
well  O
in  O
practice.  O
3.9  O
Training  O
&  O
Optimization  O
All  O
En  O
$De  O
models  O
were  O
trained  O
for  O
up  O
to  O
450k  O
updates  O
using  O
the  O
Adam  O
optimizer  O
(Kingma  O
and  O
Ba,  O
2014)  O
with  O
1=  O
0:9;  O
2=  O
0:98and  O
Inverse  O
Square  O
Root  O
Annealing  O
(Vaswani  O
et  O
al.,  O
2017)  O
with  O
30k  O
warm-up  O
steps  O
and  O
a  O
maximum  O
learning  O
rate  O
of  O
4e-4.  O
En  O
$Ru  O
models  O
were  O
trained  O
for  O
up  O
to  O
150k  O
updates  O
with  O
7k  O
warmup  O
steps.  O
We  O
use  O
label  O
smoothing  O
of  O
0.1  O
and  O
a  O
dropout  O
of  O
0.1  O
on  O
intermediate  O
activations  O
including  O
attention  O
scores  O
to  O
regularize  O
our  O
models.  O
The  O
“Large”  O
models  O
were  O
trained  O
on  O
NVIDIA  O
DGX-1  O
machines  O
with  O
8  O
32G  O
V100  O
GPUs.  O
We  O
use  O
a  O
batch  O
size  O
of  O
16k  O
tokens  O
per  O
GPU  O
for  O
an  O
effective  O
batch  O
size  O
of  O
128k  O
tokens.  O
The  O
“XLarge”  O
models  O
were  O
trained  O
on  O
64  O
GPUs  O
split  O
across  O
4  O
NVIDIA  O
DGX-2  O
nodes  O
with  O
16  O
32G  O
V100  O
GPUs  O
each.  O
These  O
models  O
use  O
an  O
effective  O
batch  O
size  O
of  O
256k  O
tokens.  O
Finally,  O
our  O
“XXLarge”  O
models  O
were  O
trained  O
on  O
256  O
GPUs  O
across  O
16  O
DGX-2  O
nodes  O
with  O
an  O
effective  O
batch  O
size  O
of  O
512k  O
tokens.201En!De  O
News  O
Task  O
Model  O
WMT’14  O
WMT’18  O
WMT’19  O
WMT’20  O
Avg  O
(1)  O
Transformer-Large  O
29.9  O
46.6  O
41.1  O
31.5  O
0  B-DatasetName
(2)  O
(1)  O
+  O
Checkpoint  O
Averaging  O
30.7  O
48.3  O
43.5  O
33.5  O
1.4  O
(3)  O
(2)  O
+  O
Transformer-XLarge  O
32.2  O
48.7  O
43.3  O
34.7  O
2.1  O
(4)  O
(3)  O
+  O
Backtranslation  O
34.9  O
49.2  O
40.5  O
34.6  O
2.2  O
(5)  O
(3)  O
+  O
R2L  O
Distllation  O
32.4  O
49.1  O
43.4  O
37.22.9  O
(6)  O
(3)  O
+  O
Backtranslation  O
+  O
R2L  O
Distlla-  O
tion34.3  O
50.1  O
42.9  O
37.43.6  O
(7)  O
(5)  O
+  O
Shallow  O
Fuison  O
Decoding  O
32.8  O
49.0  O
43.4  O
37.63.1  O
(8)  O
(6)  O
+  O
Transformer-XXLarge  O
35.5  O
50.0  O
41.8  O
37.53.6  O
(9)  O
(6)  O
+  O
Finetuning  O
(WMT’08-19)  O
-  O
-  O
-  O
37.6-  O
(10)  O
(8)  O
+  O
(9)  O
+  O
Ensembling  O
34.4  O
50.7  O
44.2  O
38.94.4  O
(11)  O
(10)  O
+  O
Noisy  O
Channel  O
Re-ranking  O
36.0  O
51.6  O
44.3  O
39.55.2  O
Table  O
2:  O
Model  O
ablations  O
for  O
En  O
!De.  O
All  O
reported  O
scores  O
are  O
obtained  O
from  O
sacreBLEU.  O
WMT’20  O
scores  O
with  O
a  O
apply  O
post-processing  O
to  O
replace  O
punctuations  O
as  O
reported  O
in  O
Section  O
2.3.  O
Avg  O
computes  O
the  O
improvement  O
over  O
the  O
Transformer-Large  O
baseline  O
averaged  O
over  O
the  O
4  O
test  O
sets.  O
De!En  O
News  O
Task  O
Model  O
WMT’14  O
WMT’18  O
WMT’19  O
WMT’20  O
Avg  O
(1)  O
Transformer-Large  O
35.5  O
45.0  O
40.5  O
37.5  O
0  O
(2)  O
(1)  O
+  O
Checkpoint  O
Averaging  O
36.5  O
46.1  O
41.6  O
38.3  O
0.7  O
(3)  O
(2)  O
+  O
Transformer-XLarge  O
37.7  O
47.8  O
41.9  O
37.6  O
1.3  O
(4)  O
(3)  O
+  O
Backtranslation  O
40.3  O
50.4  O
40.5  O
37.7  O
2.3  O
(5)  O
(3)  O
+  O
R2L  O
Distllation  O
37.5  O
47.8  O
42.3  O
39.7  O
1.9  O
(6)  O
(3)  O
+  O
Backtranslation  O
+  O
R2L  O
Distllation  O
39.3  O
49.6  O
41.8  O
39.4  O
2.7  O
(7)  O
(6)  O
+  O
Finetuning  O
(WMT’08-19)  O
-  O
-  O
-  O
41.1  O
-  O
(8)  O
(7)  O
+  O
Ensembling  O
39.5  O
49.9  O
43.3  O
41.9  O
3.7  O
(9)  O
(8)  O
+  O
Noisy  O
Channel  O
Re-ranking  O
40.1  O
50.6  O
42.8  O
42.0  O
4.0  O
Table  O
3:  O
Model  O
ablations  O
for  O
De  O
!En.  O
All  O
reported  O
scores  O
are  O
obtained  O
from  O
sacreBLEU.  O
Avg  O
computes  O
the  O
improvement  O
over  O
the  O
Transformer-Large  O
baseline  O
averaged  O
over  O
the  O
4  O
test  O
sets.  O
En!Ru  O
News  O
Task  O
Model  O
WMT’17  O
WMT’18  O
WMT’19  O
WMT’20  O
Avg  O
(1)  O
Transformer-Large  O
35.4  O
30.8  O
32.0  O
22.3  O
0  O
(2)  O
(1)  O
+  O
Transformer-XLarge  O
+  O
Ckpt  O
Avg  O
36.8  O
32.2  O
33.2  O
23.2  O
1.2  O
(3)  O
(2)  O
+  O
Finetuning  O
(WMT’14-16)  O
38.0  O
33.1  O
35.1  O
24.3  O
2.5  O
(4)  O
(3)  O
+  O
Ensemble  O
(x3)  O
38.6  O
33.5  O
35.3  O
24.8  O
2.9  O
(5)  O
(4)  O
+  O
Shallow  O
Fusion  O
38.6  O
33.7  O
35.7  O
24.7  O
3.0  O
(6)  O
Oracle  O
BLEU  O
with  O
beam  O
size  O
4  O
-  O
-  O
39.9  O
-  O
-  O
Table  O
4:  O
Model  O
ablations  O
for  O
En  O
!Ru.  O
All  O
reported  O
scores  O
are  O
obtained  O
from  O
sacreBLEU.  O
Avg  O
computes  O
the  O
improvement  O
over  O
the  O
Transformer-Large  O
baseline  O
averaged  O
over  O
the  O
4  O
test  O
sets.  O
4  O
News  O
Task  O
Submission  O
In  O
this  O
Section,  O
we  O
present  O
results  O
for  O
our  O
News  O
Shared  O
Task  O
submission.  O
Tables  O
2  O
and  O
3  O
contain  O
ablations  O
for  O
En  O
$De  O
and  O
while  O
Tables  O
4  O
and  O
5  O
has  O
ablations  O
for  O
En  O
$Ru.  O
Each  O
of  O
the  O
components  O
we  O
describe  O
improves  O
BLEU  O
scores  O
except  O
for  O
backtranslation  O
and  O
scal-  O
ing  O
our  O
models  O
to  O
1B  O
params.  O
Both  O
show  O
mixedresults  O
on  O
En  O
$De  O
-  O
scores  O
improve  O
signiﬁcantly  O
on  O
WMT’14  O
and  O
WMT’18  O
test  O
sets  O
when  O
adding  O
backtranslated  O
data  O
(possibly  O
because  O
these  O
test  O
sets  O
contain  O
translationese  O
inputs)  O
but  O
hurts  O
or  O
does  O
not  O
improve  O
performance  O
on  O
WMT’19  O
and  O
WMT’20  O
test  O
sets.  O
Our  O
1B  O
parameter  O
model  O
does  O
signiﬁ-  O
cantly  O
better  O
on  O
WMT’14,  O
but  O
worse  O
on  O
WMT’19  O
and  O
is  O
comparable  O
to  O
the  O
500M  O
parameter  O
model  O
on  O
WMT’18  O
and  O
WMT’20.  O
We  O
found  O
optimization202Ru!En  O
News  O
Task  O
Model  O
WMT’17  O
WMT’18  O
WMT’19  O
WMT’20  O
Avg  O
(1)  O
Transformer-Large  O
37.6  O
33.0  O
37.7  O
36.6  O
0  O
(2)  O
(1)  O
+  O
Transformer-XLarge  O
+  O
Ckpt  O
Avg  O
38.7  O
34.3  O
38.2  O
37.2  O
0.9  O
(3)  O
(2)  O
+  O
Finetuning  O
(WMT’14-16)  O
40.7  O
35.4  O
40.5  O
37.1  O
2.2  O
(4)  O
(3)  O
+  O
Ensemble  O
(x3)  O
40.7  O
35.5  O
41  O
37.7  O
2.5  O
(5)  O
(4)  O
+  O
Shallow  O
Fusion  O
40.9  O
35.9  O
40.8  O
37.5  O
2.6  O
(6)  O
Oracle  O
BLEU  O
with  O
beam  O
size  O
4  O
-  O
-  O
46.4  O
-  O
-  O
Table  O
5:  O
Model  O
ablations  O
for  O
Ru  O
!En.  O
All  O
reported  O
scores  O
are  O
obtained  O
from  O
sacreBLEU.  O
Avg  O
computes  O
the  O
improvement  O
over  O
the  O
Transformer-Large  O
baseline  O
averaged  O
over  O
the  O
4  O
test  O
sets.  O
En!Ru  O
Biomedical  O
Task  O
Model  O
WMT’20  O
Bio  O
  O
(1)  O
Transformer-Large  O
News  O
Task  O
Model  O
32.2  O
0  O
(2)  O
Transformer-XLarge  O
News  O
Task  O
Model  O
33.8  O
1.6  O
(3)  O
Transformer-XLarge  O
+  O
Biomed  O
V  O
ocab  O
w/  O
News  O
Data  O
33.9  O
1.7  O
(4)  O
Transformer-XLarge  O
+  O
Biomed  O
V  O
ocab  O
w/  O
News  O
+  O
R2L  O
Distillation  O
Data  O
34.2  O
2.0  O
(5)  O
Transformer-XLarge  O
+  O
Biomed  O
V  O
ocab  O
w/  O
News  O
+  O
30%  O
Biomed  O
Data  O
36.7  O
4.5  O
(6)  O
Transformer-XLarge  O
+  O
Biomed  O
V  O
ocab  O
w/  O
News  O
+  O
50%  O
Biomed  O
Data  O
36.8  O
4.6  O
(7)  O
Transformer-XLarge  O
+  O
Biomed  O
V  O
ocab  O
w/  O
News  O
+  O
Biomed  O
Data  O
37.4  O
5.2  O
(8)  O
(2)  O
+  O
Biomed  O
Data  O
Finetuning  O
37.8  O
5.6  O
(9)  O
(3)  O
+  O
Biomed  O
Data  O
Finetuning  O
38.5  O
6.3  O
(10)  O
(4)  O
+  O
Biomed  O
Data  O
Finetuning  O
38.2  O
6.0  O
(11)  O
(6)  O
+  O
Biomed  O
Data  O
Finetuning  O
37.4  O
5.2  O
(12)  O
(7)  O
+  O
Biomed  O
Data  O
Finetuning  O
38.5  O
6.3  O
(13)  O
(9)  O
(10)  O
(11)  O
(12)  O
Ensemble  O
39.9  O
7.7  O
(14)  O
(13)  O
+  O
Shallow  O
Fusion  O
40.0  O
7.8  O
(15)  O
(13)  O
+  O
Noisy  O
Channel  O
Re-ranking  O
40.3  O
8.1  O
Table  O
6:  O
Model  O
iterations  O
for  O
the  O
Biomedical  O
Shared  O
Task  O
En  O
!Ru.  O
All  O
reported  O
scores  O
are  O
checkpoint  O
averaged  O
and  O
are  O
obtained  O
from  O
sacreBLEU.  O
computes  O
the  O
improvement  O
over  O
the  O
Transformer-Large  O
baseline  O
on  O
the  O
WMT’20  O
Biomedical  O
Shared  O
Task  O
test  O
set.  O
Model  O
15  O
is  O
our  O
selected  O
best  O
submission  O
and  O
model  O
14  O
is  O
our  O
alternate  O
submission.  O
with  O
Adam  O
to  O
be  O
unstable  O
and  O
used  O
AdamW  O
with  O
a  O
weight  O
decay  O
of  O
0.01  O
instead.  O
Our  O
ﬁnal  O
En  O
!  O
De  O
model  O
achieves  O
a  O
BLEU  O
score  O
of  O
39.5  O
on  O
the  O
WMT’20  O
test  O
set,  O
which  O
improves  O
over  O
the  O
sub-  O
mission  O
with  O
the  O
best  O
BLEU  O
score  O
from  O
last  O
year’s  O
competition  O
of  O
38.8.  O
We  O
however  O
do  O
not  O
do  O
as  O
well  O
on  O
De  O
!En,  O
with  O
a  O
ﬁnal  O
BLEU  O
score  O
of  O
42,  O
compared  O
to  O
last  O
year’s  O
best  O
submission  O
of  O
43.8.  O
Backtranslation  O
signiﬁcantly  O
hurt  O
performance  O
in  O
initial  O
experiments  O
on  O
En  O
$Ru  O
so  O
we  O
exclude  O
it  O
from  O
our  O
ensemble.  O
The  O
impact  O
of  O
ensembling,  O
ﬁnetuning,  O
and  O
shallow  O
fusion  O
are  O
fairly  O
similar  O
to  O
En$De.  O
Additionally,  O
we  O
also  O
report  O
an  O
“Oracle  O
BLEU”  O
score  O
in  O
Tables  O
4  O
and  O
5  O
where  O
we  O
compute  O
BLEU  O
scores  O
by  O
cheating  O
and  O
picking  O
the  O
trans-  O
lation  O
on  O
our  O
beam  O
that  O
has  O
the  O
highest  O
sentence  O
BLEU  O
score  O
with  O
respect  O
to  O
the  O
reference.  O
This  O
is  O
a  O
useful  O
indicator  O
of  O
how  O
much  O
there  O
is  O
to  O
gain  O
by  O
re-ranking  O
the  O
beam  O
search  O
candidates.5  O
Biomedical  O
translation  O
task  O
submission  O
We  O
present  O
our  O
Biomedical  O
Shared  O
Task  O
submission  O
in  O
this  O
section.  O
Building  O
on  O
lessons  O
learned  O
from  O
our  O
news  O
task  O
ablation  O
studies,  O
we  O
opted  O
to  O
use  O
the  O
Transformer-XLarge  O
architecture,  O
and  O
average  O
all  O
of  O
the  O
intermediate  O
model  O
checkpoints  O
which  O
helps  O
reduce  O
model  O
variance  O
as  O
a  O
consequence  O
of  O
ﬁnetuning.  O
Tables  O
6  O
and  O
7  O
show  O
our  O
results  O
as  O
we  O
iterated  O
on  O
improving  O
our  O
models.  O
We  O
trained  O
our  O
BPE  O
tokenizer  O
on  O
biomedical  O
data  O
to  O
mitigate  O
character-level  O
segmentation  O
of  O
words  O
unique  O
to  O
the  O
biomedical  O
domain.  O
We  O
found  O
this  O
had  O
a  O
minimal  O
effect  O
on  O
model  O
performance.  O
This  O
could  O
be  O
because  O
the  O
majority  O
of  O
our  O
parallel  O
biomedical  O
data  O
was  O
selected  O
from  O
news  O
task  O
train-  O
ing  O
data,  O
and  O
thus  O
biomedical  O
words  O
were  O
already  O
adequately  O
accounted  O
for  O
by  O
the  O
news  O
task  O
model’s  O
tokenizer.  O
We  O
found  O
that  O
up-sampling  O
in-domain203Ru!En  O
Biomedical  O
Task  O
Model  O
WMT’20  O
Bio  O
  O
(1)  O
Transformer-Large  O
News  O
Task  O
Model  O
38.7  O
0  O
(2)  O
Transformer-XLarge  O
News  O
Task  O
Model  O
39.8  O
1.1  O
(3)  O
Transformer-XLarge  O
+  O
Biomed  O
V  O
ocab  O
w/  O
News  O
Data  O
39.8  O
1.1  O
(4)  O
Transformer-XLarge  O
+  O
Biomed  O
V  O
ocab  O
w/  O
News  O
+  O
R2L  O
Distillation  O
Data  O
39.2  O
0.5  O
(5)  O
Transformer-XLarge  O
+  O
Biomed  O
V  O
ocab  O
w/  O
News  O
+  O
30%  O
Biomed  O
Data  O
37.6  O
-1.1  O
(6)  O
Transformer-XLarge  O
+  O
Biomed  O
V  O
ocab  O
w/  O
News  O
+  O
50%  O
Biomed  O
Data  O
38.4  O
-0.3  O
(7)  O
Transformer-XLarge  O
+  O
Biomed  O
V  O
ocab  O
w/  O
News  O
+  O
Biomed  O
Data  O
41.5  O
2.8  O
(8)  O
(2)  O
+  O
Biomed  O
Data  O
Finetuning  O
42.3  O
3.6  O
(9)  O
(3)  O
+  O
Biomed  O
Data  O
Finetuning  O
42.6  O
3.9  O
(10)  O
(4)  O
+  O
Biomed  O
Data  O
Finetuning  O
41.7  O
3.0  O
(11)  O
(6)  O
+  O
Biomed  O
Data  O
Finetuning  O
39.6  O
0.9  O
(12)  O
(7)  O
+  O
Biomed  O
Data  O
Finetuning  O
41.8  O
3.1  O
(13)  O
(9)  O
(12)  O
Ensemble  O
42.8  O
4.1  O
(14)  O
(9)  O
(10)  O
(11)  O
(12)  O
Ensemble  O
43.8  O
5.1  O
(15)  O
(14)  O
+  O
Shallow  O
Fusion  O
43.7  O
5.0  O
(16)  O
(14)  O
+  O
Noisy  O
Channel  O
Re-ranking  O
42.1  O
3.4  O
Table  O
7:  O
Model  O
iterations  O
for  O
the  O
Biomedical  O
Shared  O
Task  O
Ru  O
!En.  O
All  O
reported  O
scores  O
are  O
checkpoint  O
averaged  O
and  O
are  O
obtained  O
from  O
sacreBLEU.  O
computes  O
the  O
improvement  O
over  O
the  O
Transformer-Large  O
baseline  O
on  O
the  O
WMT’20  O
Biomedical  O
Shared  O
Task  O
test  O
set.  O
Model  O
14  O
is  O
our  O
selected  O
best  O
submission.  O
biomedical  O
data  O
hurt  O
performance  O
compared  O
to  O
con-  O
catenating  O
out-of-domain  O
and  O
in-domain  O
data  O
with  O
no  O
up-sampling.  O
For  O
the  O
En  O
!Ru  O
direction,  O
in-  O
cluding  O
any  O
biomedical  O
domain  O
data  O
during  O
initial  O
model  O
training  O
showed  O
improvements  O
over  O
training  O
on  O
exclusively  O
news  O
task  O
data.  O
Up-sampling  O
in-  O
domain  O
data  O
for  O
the  O
Ru  O
!En  O
direction  O
hurt  O
perfor-  O
mance  O
compared  O
to  O
our  O
news  O
task  O
model  O
baselines.  O
Unsurprisingly,  O
ﬁnetuning  O
base  O
models  O
on  O
biomedical  O
domain  O
data  O
improved  O
BLEU  O
scores  O
for  O
all  O
models.  O
In-domain  O
ﬁnetuning  O
helped  O
mod-  O
els  O
initially  O
trained  O
on  O
news  O
task  O
data  O
overcome  O
performance  O
gaps  O
between  O
themselves  O
and  O
mod-  O
els  O
that  O
had  O
seen  O
a  O
higher  O
amount  O
of  O
biomedical  O
data  O
during  O
training.  O
Neither  O
shallow  O
fusion  O
nor  O
noisy  O
channel  O
re-ranking  O
improved  O
model  O
perfor-  O
mance  O
after  O
ensembling  O
for  O
the  O
Ru  O
!En  O
direction.  O
Both  O
techniques  O
individually  O
improved  O
En  O
!Ru  O
performance  O
but  O
failed  O
to  O
do  O
so  O
in  O
combination.  O
Ensembling  O
our  O
models  O
led  O
to  O
an  O
additional  O
per-  O
formance  O
boost  O
and  O
allowed  O
us  B-DatasetName
to  O
reach  O
our  O
maxi-  O
mum  O
En  O
!Ru  O
BLEU  O
score  O
of  O
40.3  O
and  O
Ru  O
!En  O
BLEU  O
score  O
of  O
43.8.  O
These  O
scores  O
show  O
a  O
0.9  O
and  O
0.5  O
improvement  O
over  O
last  O
year’s  O
best  O
score  O
of  O
39.4  O
and  O
43.3  O
(Bawden  O
et  O
al.,  O
2020)  O
respectively.  O
6  O
Conclusion  O
We  O
present  B-TaskName
Neural  I-TaskName
Machine  I-TaskName
Translation  I-TaskName
Systems  O
for  O
the  O
En  O
$De  O
News  O
Task  O
and  O
En  O
$Ru  O
Newsand  O
Biomedical  O
shared  O
tasks  O
implemented  O
in  O
the  O
NeMo  O
framework  O
(Kuchaiev  O
et  O
al.,  O
2019).  O
Our  O
systems  O
build  O
on  O
the  O
Transformer  O
sequence-to-  O
sequence  O
model  O
to  O
include  O
backtranslated  O
text  O
and  O
data  O
from  O
right-to-left  O
factorized  O
models,  O
ensem-  O
bling,  O
ﬁnetuning,  O
mining  O
biomedically  O
relevant  O
data  O
using  O
domain  O
classiﬁers,  O
shallow  O
fusion  O
with  O
LMs,  O
and  O
noisy  O
channel  O
re-ranking.  O
These  O
achieve  O
competitive  O
performance  O
to  O
submissions  O
from  O
pre-  O
vious  O
years.  O
7  O
Author  O
Contributions  O
Sandeep  O
Subramanian:  O
Sandeep  O
implemented  O
and  O
experimented  O
with  O
model  O
scaling,  O
backtransla-  O
tion,  O
distillation  O
with  O
right-to-left  O
factorized  O
mod-  O
els,  O
model  O
ensembling,  O
and  O
noisy  O
channel  O
re-  O
ranking.  O
He  O
also  O
ran  O
all  O
of  O
the  O
En  O
$De  O
News  O
Shared  O
Task  O
experiments,  O
the  O
right-to-left  O
factor-  O
ized  O
models  O
for  O
the  O
En  O
$Ru  O
Biomedical  O
task,  O
and  O
wrote  O
parts  O
of  O
the  O
paper.  O
Oleksii  O
Hrinchuk:  O
Oleksii  O
H  O
implemented  O
the  O
shallow  O
fusion  O
approach  O
and  O
helped  O
with  O
writing  O
backtranslation  O
scripts.  O
He  O
also  O
ran  O
all  O
of  O
the  O
En  O
$Ru  O
News  O
Shared  O
Task  O
experiments  O
and  O
trained  O
the  O
language  O
models  O
used  O
in  O
the  O
Biomedical  O
exper-  O
iments.  O
Virginia  O
Adams:  O
Virginia  O
implemented  O
and  O
ex-  O
perimented  O
with  O
the  O
warm-start  O
biomegatron  O
en-204coder,  O
biomedical  O
baselines,  O
classiﬁers  O
to  O
extract  O
biomedically  O
relevant  O
monolingual  O
and  O
parallel  O
cor-  O
pora,  O
mixed  O
domain,  O
and  O
ﬁnetuning  O
of  O
News  O
mod-  O
els.  O
She  O
ran  O
all  O
of  O
the  O
En  O
$Ru  O
Biomedical  O
experi-  O
ments.  O
Oleksii  O
Kuchaiev:  O
Oleksii  O
K  O
advised  O
and  O
man-  O
aged  O
the  O
project.  O
8  O
Acknowledgements  O
The  O
authors  O
would  O
like  O
to  O
thank  O
Mike  O
Chrzanowski,  O
Ryan  O
Prenger,  O
Eric  O
Harper,  O
Micha  O
Livne,  O
Abhi-  O
nav  O
Khattar,  O
Anton  O
Peganov,  O
Mohammad  O
Shoeybi,  O
Somshubra  O
Majumdar  O
and  O
Fei  O
Jia  O
for  O
many  O
useful  O
discussions  O
over  O
the  O
course  O
of  O
this  O
project.  O