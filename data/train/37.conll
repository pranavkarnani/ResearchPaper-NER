Proceedings O
of O
the O
2nd O
Workshop O
on O
Cognitive O
Aspects O
of O
the O
Lexicon O
(CogALex O
2010) O
, O
pages O
18–27, O
Beijing, O
August O
2010 O
Textual B-TaskName
Entailment I-TaskName
Recognition I-TaskName
using O
Word O
Overlap, O
Mutual O
Information O
and O
Subpath O
Set O
Yuki O
Muramatsu O
Nagaoka O
University O
of O
Technology O
muramatsu@jnlp.org O
Kunihiro O
Udaka O
Nagaoka O
University O
of O
Technology O
udaka@jnlp.org O
Kazuhide O
Yamamoto O
Nagaoka O
University O
of O
Technology O
yamamoto@jnlp.org O
Abstract O
When O
two O
texts O
have O
an O
inclusion O
relation, O
the O
relationship O
between O
them O
is O
called O
entailment. O
The O
task O
of O
mechanically O
distinguishing O
such O
a O
relation O
is O
called O
recognising B-TaskName
textual I-TaskName
entailment I-TaskName
(RTE), I-TaskName
which O
is O
basically O
a O
kind O
of O
semantic O
analysis. O
A O
variety O
of O
methods O
have O
been O
proposed O
for O
RTE. B-TaskName
However, O
when O
the O
previous O
methods O
were O
combined, O
the O
performances O
were O
not O
clear. O
So, O
we O
utilized O
each O
method O
as O
a O
feature O
of O
machine O
learning, O
in O
order O
to O
combine O
methods. O
We O
have O
dealt O
with O
the O
binary O
classification O
problem O
of O
two O
texts O
exhibiting O
inclusion, O
and O
proposed O
a O
method O
that O
uses O
machine O
learning O
to O
judge O
whether O
the O
two O
texts O
present O
the O
same O
content. O
We O
have O
built O
a O
program O
capable O
to O
perform O
entailment O
judgment O
on O
the O
basis O
of O
word O
overlap, O
i.e. O
the O
matching O
rate O
of O
the O
words O
in O
the O
two O
texts, O
mutual O
information, O
and O
similarity O
of O
the O
respective O
syntax O
trees O
(Subpath O
Set). O
Word O
overlap O
was O
calclated O
by O
utilizing O
BiLingual B-MetricName
Evaluation I-MetricName
Understudy I-MetricName
(BLEU). I-MetricName
Mutual B-MetricName
information I-MetricName
is O
based O
on O
co-occurrence O
frequency, O
and O
the O
Subpath O
Set O
was O
determined O
by O
using O
the O
Japanise O
WordNet. O
A O
Confidence- B-MetricName
Weighted I-MetricName
Score O
of O
68.6% B-MetricValue
was O
obtained O
in O
the O
mutual O
information O
experiment O
on O
RTE. B-TaskName
Mutual O
information O
and O
the O
use O
of O
three O
methods O
of O
SVM B-MethodName
were O
shown O
to O
be O
effective. O
1 O
Introduction O
This O
paper O
can O
help O
solve O
textual O
entailment O
problems. O
Researchers O
of O
natural O
language O
processing O
have O
recently O
become O
interested O
in O
the O
automatic B-TaskName
recognition I-TaskName
of I-TaskName
textual I-TaskName
entailment I-TaskName
(RTE), I-TaskName
which O
is O
the O
task O
of O
mechanically O
distinguishing O
an O
inclusion O
relation. O
Text O
implication O
recognition O
is O
the O
task O
of O
taking O
a O
text O
(T) O
and O
a O
hypothesis O
(H), O
and O
judging O
whether O
one O
(the O
text) O
can O
be O
inferred O
from O
the O
other O
(hypothesis). O
Here O
below O
is O
an O
example O
task. O
In O
case O
of O
entailment, O
we O
call O
the O
relation O
t O
o O
be O
‘true’). O
Example O
1 O
: O
Textual O
entailment O
recognition. O
T: O
Google O
files O
for O
its O
long-awaited O
IPO. O
H: O
Google O
goes O
public. O
Entailment O
Judgment: O
True. O
For O
such O
a O
task, O
large O
applications O
such O
as O
question O
answering, O
information O
extraction, O
summarization O
and O
machine O
translation O
are O
involved. O
A O
large-scale O
evaluation O
workshop O
has O
been O
conducted O
to O
stimulate O
research O
on O
recognition O
of O
entailment O
(Dagan O
et O
al., O
2005). O
These O
authors O
divided O
the O
RTE B-TaskName
methods O
into O
six O
methods. O
We O
focused O
on O
3 O
methods O
of O
them. O
Pérez O
and O
Alfonseca’s O
method O
(Pérez O
and O
Alfonseca, O
2005) O
used O
Word O
Overlap O
. O
This O
method O
is O
assumed O
to O
have O
taken O
place O
when O
words O
or O
sentences O
of O
the O
text O
and O
the O
hypothesis O
are O
similar, O
hence O
the O
relation O
should O
be O
true. O
Pérez O
and O
Alfonseca O
used O
the O
BLEU B-MetricName
algorithm O
to O
calculate O
the O
entailment O
relationship. O
Glickman O
et O
al’s. O
method O
was O
considered O
as O
using O
statistical O
lexical O
relations. O
These O
authors O
assumed O
that O
the O
possibility O
of O
entailment O
were O
high O
when O
the O
co-occurrence O
frequency O
of O
the O
word O
in O
the O
source O
and O
the O
target O
were O
high. O
18While O
this O
may O
be O
correct, O
we O
believe O
nevertheless O
that O
it O
problematic O
not O
to O
consider O
the O
co-occurrence O
of O
the O
hypothesis O
words. O
This O
being O
so, O
we O
proposed O
to O
use O
mutual O
information O
. O
Finally, O
Herrera O
et O
al’s. O
method O
is O
based O
on O
Syntactic O
matching. O
They O
calculated O
the O
degree O
of O
similarity O
of O
the O
syntax O
tree. O
We O
combined O
these O
three O
methods O
using O
machine O
learning O
techniques. O
2 O
Related O
Works O
Dagan O
et O
al. O
(Dagan O
et O
al, O
2005) O
conducted O
research O
in O
2005 O
on O
how O
to O
evaluate O
data O
of O
RTE; B-TaskName
the O
authors O
insisted O
on O
the O
need O
of O
semantic O
analysis. O
As O
a O
first O
step, O
they O
considered O
the O
problem O
of O
textual O
entailment, O
proposing O
how O
to O
build O
evaluation O
data. O
Theu O
also O
organised O
and O
workshop O
on O
this O
topic. O
Their O
evaluation O
data O
are O
problems O
of O
binary O
classification O
of O
the O
texts O
to O
be O
compared. O
They O
used O
a O
sentence O
extracted O
from O
a O
newspaper O
corpus, O
and O
built O
a O
hypothesis O
from O
this O
text O
using O
one O
of O
seven O
methods: O
question O
answering, O
sentence O
comprehension, O
information O
extraction, O
machine O
translation, O
paraphrasing, O
information O
retrieval O
and O
comparable O
documents. O
They O
proposed O
a O
method O
of O
evaluation O
using O
RTE, B-TaskName
and O
they O
introduced O
several O
RTE B-TaskName
methods. O
Odani O
et O
al. O
(Odani O
et O
al, O
2005) O
did O
research O
on O
the O
construction O
of O
evaluation O
data O
in O
Japan, O
mentionning O
that O
there O
was O
a O
problem O
in O
the O
evaluation O
data O
of O
Dagan O
et O
al. O
For O
example, O
they O
stated O
that O
‘The O
evaluation O
data O
that O
he O
constructed O
are O
acting O
some O
factors. O
So O
it O
is O
difficult O
to O
discuss O
the O
problem’. O
Next, O
they O
did O
an O
RTE B-TaskName
evaluation O
data O
using O
Japanese. O
The O
inference O
factors O
for O
judging O
entailment O
judgment O
were O
divided O
into O
five O
categories: O
inclusion, O
lexicon O
(words O
that O
can’t O
be O
declined), O
lexicon O
(declinable O
words), O
syntax O
and O
inference. O
The O
subclassification O
was O
set O
for O
each O
classification, O
and O
Japanese O
RTE B-TaskName
evaluation O
data O
was O
constructed. O
In O
addition, O
a O
dictionary O
and O
Web O
text O
were O
used O
for O
the O
entailment O
judgment. O
The O
authors O
were O
able O
to O
solve O
entailment O
judgment O
with O
words O
or O
phrases O
containing O
synonyms O
and/or O
a O
super-sub O
type O
relation. O
However, O
this O
classification O
lacks O
precision. O
For O
example, O
they O
defined O
the O
term O
‘lexicon O
(words O
that O
cannot O
be O
declined)’ O
as O
‘The O
meaning O
and O
the O
character O
of O
the O
noun O
that O
exists O
in O
text O
are O
data O
from O
which O
information O
on O
the O
truth O
of O
hypothesis O
is O
given’. O
Given O
this O
lack O
of O
clarity, O
we O
considered O
this O
method O
to O
be O
difficult O
to O
reproduce. O
However, O
the O
evaluation O
data O
they O
built O
is O
general O
and O
available O
for O
public O
use. O
Regarding O
the O
research O
using O
the O
evaluation O
data O
of O
such O
RTE, B-TaskName
there O
have O
been O
many O
reports O
in O
the O
workshop. O
For O
example, O
Pérez O
and O
Alfonseca O
(Pérez O
and O
Alfonseca, O
2005) O
assumed O
that O
the O
possibility O
of O
entailment O
was O
high O
when O
the O
text O
matched O
the O
hypothesis. O
The O
concordance O
rate O
of O
the O
text O
and O
the O
hypothesis O
was O
then O
calculated O
for O
judging O
the O
text O
and O
the O
hypothesis O
of O
the O
inclusion O
relation. O
In O
their O
research, O
they O
used O
BiLingual B-MetricName
Evaluation I-MetricName
Understudy I-MetricName
(BLEU) I-MetricName
to O
evaluate O
machine O
translation. O
An O
entailment O
judgment O
of O
‘true’ O
was O
given O
when O
the O
BLEU B-MetricName
score O
was O
above O
than O
a O
given O
threshold O
decided O
in O
advance. O
The O
evaluation O
data O
of O
Dagan O
et O
al. O
was O
used O
in O
the O
experiment, O
and O
its O
accuracy B-MetricName
was O
about O
50%. B-MetricValue
The O
evaluation O
data O
of O
comparable O
document O
types O
were O
the O
results O
with O
the O
highest O
accuracy. O
Hence O
the O
authors O
concluded O
that O
this O
method O
can O
be O
considered O
as O
a O
baseline O
of O
RTE. B-TaskName
We O
dealt O
with O
it O
as O
word O
overlap O
. O
Glickman O
et O
al. O
(Glickman O
et O
al, O
2005) O
conducted O
research O
using O
co-occurring O
words. O
They O
assumed O
that O
the O
entailment O
judgment O
was O
‘true’ O
when O
the O
probability O
of O
co-occurrence O
between O
the O
text O
and O
the O
hypothesis O
was O
high. O
In O
addition, O
the O
content O
word O
of O
the O
text O
with O
the O
highest O
co-occurrence O
probability O
was O
calculated O
from O
the O
content O
word O
of O
all O
of O
the O
hypotheses, O
and O
it O
was O
proposed O
as O
a O
method O
for O
entailment O
judgment. O
A O
Web O
search O
engine O
was O
used O
to O
calculate O
in O
the O
co-occurrence O
probability. O
This O
experiment O
yielded O
an O
accuracy B-MetricName
of O
approximately O
58%, B-MetricValue
while O
the O
evaluation O
data O
of O
comparable O
document O
types O
was O
about O
83%. B-MetricValue
This O
being O
so, O
the O
authors O
concluded O
that O
they O
have O
been O
able O
to O
improve O
the O
results O
with O
the O
help O
of O
other O
deep O
analytical O
tools. O
We O
improved O
this O
method, O
and O
used O
it O
as O
mutual O
information. O
Herrera O
et O
al. O
(Herrera O
et O
al., O
2005) O
focused O
on O
syntactic O
similarity. O
They O
assumed O
that O
the O
entailment O
judgment O
was O
‘true’ O
when O
the O
syntactic O
similarity O
of O
the O
text O
and O
the O
hypothesis O
was O
high. O
In O
addition, O
they O
used O
WordNet B-DatasetName
for O
considering O
identifiable O
expressions. O
The O
results O
19of O
the O
experiment O
yielded O
an O
accuracy B-MetricName
of O
approximately O
57%. B-MetricValue
We O
improved O
this O
method, O
and O
used O
it O
then O
as O
subpath O
set. O
Prodromos O
Malakasiotis O
and O
Ion O
Androutsopoulos O
(Prodromos O
Malakasiotis O
and O
Ion O
Androutsopoulos, O
2007) O
used O
Support B-MethodName
Vector I-MethodName
Machines. I-MethodName
They O
assumed O
that O
the O
entailment O
judgment O
was O
‘true’ O
when O
the O
similarity O
of O
words, O
POS O
tags O
and O
chunk O
tags O
were O
high. O
The O
results O
of O
the O
experiment O
yielded O
an O
accuracy B-MetricName
of O
approximately O
62%. B-MetricValue
However, O
they O
forgot O
to O
combine O
past O
RTE B-TaskName
methods O
as O
feature O
of O
SVM. B-MethodName
The O
authors O
of O
this O
paper O
present O
a O
new O
RTE O
method. O
We O
propose O
to O
combine O
word O
overlap, O
mutual O
information O
and O
subpath O
sets. O
We O
dealt O
with O
SVM B-MethodName
by O
using O
3 O
methods O
equally O
as O
features, O
and O
we O
estimated O
higher O
precision O
than O
when O
using O
individual; O
independent O
methods. O
3 O
Textual O
Entailment O
Evaluation O
Data O
We O
used O
the O
textual O
entailment O
evaluation O
data O
of O
Odani O
et O
al. O
for O
the O
problem O
of O
RTE. B-TaskName
This O
evaluation O
data O
is O
generally O
available O
to O
the O
public O
at O
the O
Kyoto O
University O
1. O
The O
evaluation O
data O
comprises O
the O
inference O
factor, O
subclassification, O
entailment O
judgment, O
text O
and O
hypothesis. O
Table O
1 O
gives O
an O
example. O
The O
inference O
factor O
is O
divided O
into O
five O
categories O
according O
to O
the O
definition O
provided O
by O
Odani O
et O
al.: O
inclusion, O
lexicon O
(indeclinable O
word), O
lexicon O
(declinable O
word), O
syntax O
and O
inference. O
They O
define O
the O
classification O
viewpoint O
of O
each O
inference O
factor O
as O
follows: O
Example O
2: O
Classification O
criteria O
of O
inference O
factors O
•Inclusion: O
The O
text O
almost O
includes O
the O
hypothesis. O
Table O
1: O
RTE O
Evaluation O
data O
of O
Odani O
et O
al. O
1 O
http://www.nlp.kuee.kyoto-u.ac.jp/nl-resource O
• O
Lexicon O
(Indeclinable O
Word): O
Information O
of O
the O
hypothesis O
is O
given O
by O
the O
meaning O
or O
the O
behaviour O
of O
the O
noun O
in O
the O
text. O
• O
Lexicon O
(Declinable O
Word): O
Information O
of O
the O
hypothesis O
is O
given O
by O
the O
meaning O
or O
the O
behaviour O
of O
the O
declinable O
word O
in O
the O
text. O
• O
Syntax: O
The O
text O
and O
the O
hypothesis O
have O
a O
relation O
of O
syntactic O
change. O
•Inference: O
Logical O
form. O
They O
divided O
the O
data O
into O
166 O
subclasses, O
according O
to O
each O
inference O
factor. O
The O
entailment O
judgment O
is O
a O
reliable O
answer O
in O
the O
text O
and O
the O
hypothesis. O
It O
is O
a O
difficult O
problem O
to O
entailment O
judgment O
for O
the O
criteria O
answer. O
Therefore, O
when O
they O
reported O
on O
the O
RTE O
workshop, O
they O
assumed O
the O
following O
classification O
criteria: O
Example O
3: O
Classification O
criteria O
of O
entailment O
determination. O
•◎(T O
alw O
): O
When O
the O
text O
is O
true, O
the O
hypothesis O
is O
always O
true. O
•○(T O
alm O
): O
When O
the O
text O
is O
true, O
the O
hypothesis O
is O
almost O
true. O
•△(F O
may O
): O
When O
the O
text O
is O
true, O
the O
hypothesis O
may O
be O
true. O
•×(F O
alw O
): O
When O
the O
text O
is O
true, O
the O
hypothesis O
is O
false. O
In O
terms O
of O
the O
text O
and O
the O
hypothesis, O
when O
we O
observed O
the O
evaluation O
data, O
the O
evaluation O
data O
accounted O
for O
almost O
every O
sentence O
in O
both O
the O
texts O
and O
the O
hypotheses, O
and O
also O
the O
hypotheses O
were O
shorter O
than O
the O
texts. O
There O
is O
a O
bias O
in O
the O
number O
of O
problems O
evaluated O
by O
the O
inference O
factor O
and O
by O
the O
subclassification. O
The O
number O
of O
evaluation O
data O
open O
to O
the O
public O
now O
stands O
at O
2471. O
Inference O
Factor O
Sub- O
Classification O
Entailment O
Judgment O
Text O
Hypothesis O
Lexicon O
(Indeclinable O
Word) O
Behavior O
◎ O
Toyota O
opened O
a O
luxury O
car O
shop. O
Lexus O
is O
a O
luxury O
car. O
204 O
Proposal O
Method O
Up O
now, O
a O
number O
of O
methods O
have O
been O
proposed O
for O
RTE. O
However, O
when O
the O
previous O
methods O
were O
combined, O
the O
performances O
were O
hard O
to O
judge. O
Hence, O
we O
used O
each O
method O
as O
a O
feature O
of O
machine O
learning, O
and O
combined O
them O
then. O
The O
input O
text O
and O
the O
hypothesis O
were O
considered O
as O
a O
problem O
of O
binary O
classification O
(‘true’ O
or O
‘false’). O
Therefore, O
we O
employed O
support B-MethodName
vector I-MethodName
machines I-MethodName
(Vapnik, O
1998), O
which O
are O
often O
used O
to O
address O
binary O
classification O
problems O
(in O
fact, O
we O
implemented O
our O
system O
with O
Tiny O
SVM). B-MethodName
With O
this O
method O
we O
achieved O
higher O
precision O
than O
with O
individual O
independent O
methods. O
Figure O
1 O
shows O
our O
proposed O
method. O
Figure O
1: O
Our O
Proposed O
Method O
In O
the O
following O
sections, O
we O
will O
describe O
the O
three O
features O
used O
in O
machine O
learning. O
4.1 O
Word O
Overlap O
It O
is O
assumed O
that O
when O
words O
or O
sentences O
of O
the O
text O
and O
the O
hypothesis O
are O
similar, O
the O
relation O
should O
be O
true. O
Pérez O
and O
Alfonseca O
used O
a O
BLEU B-MetricName
algorithm O
to O
calculate O
the O
entailment O
between O
the O
text O
and O
the O
hypothesis. O
BLEU B-MetricName
is O
often O
used O
to O
evaluate O
the O
quality O
of O
machine O
translation. O
Panieni O
et O
al. O
provided O
the O
following O
definition O
of O
BLEU. B-MetricName
In O
particular, O
the O
BLEU B-MetricName
score O
between O
length O
r O
of O
the O
sentence O
B O
and O
length O
c O
of O
the O
sentence O
A O
is O
given O
by O
the O
formulas O
(1) O
and O
(2): O
( O
)1( O
, O
) O
exp( O
log( O
)/ O
) O
(1) O
1 O
{1, O
/ O
} O
(2)n O
i O
iBleu O
A O
B O
BP O
p O
n O
BP O
exp O
max O
r O
c O
== O
= O
− O
∑ O
where O
p O
i O
represents O
the O
matching O
rate O
of O
n-gram. O
The O
n-gram O
of O
this O
method O
was O
calculated O
as O
word O
n-gram. O
We O
assumed O
n O
= O
1 O
and O
used O
the O
public O
domain O
program O
NTCIR7 O
2. O
Here O
is O
an O
example O
of O
the O
calculation. O
Example O
4: O
Calculation O
by O
BLEU. O
T:月は地球の衛星である。 O
(The O
moon O
is O
Earth's O
satellite.) O
H:月は地球の周りにある。 O
(The O
moon O
is O
around O
the O
Earth.) O
BLEU:0.75 O
We O
estimated O
n O
= O
1 O
for O
the O
following O
reasons: O
1. O
The O
reliability O
of O
word O
overlap O
is O
not O
high O
when O
n O
is O
large. O
2. O
The O
calculated O
result O
of O
BLEU B-MetricName
often O
becomes O
0 O
when O
n O
is O
large. O
First, O
we O
will O
explain O
the O
reason O
1 O
mentioned O
above. O
The O
report O
of O
Kasahara O
et O
al. O
(Kasahara O
et O
al., O
2010) O
is O
a O
reproduction O
of O
the O
one O
provided O
by O
Pérez O
et O
al O
(Pérez O
et O
al., O
2005). O
They O
prepared O
an O
original O
RTE O
evaluation O
set O
of O
reading O
comprehension O
type, O
and O
proposed O
a O
new O
RTE O
system O
using O
a O
BLEU B-MetricName
algorithm. O
When O
they O
experimented O
by O
increasing O
the O
maximum O
number O
of O
elements O
n O
of O
word O
n-gram O
from O
1 O
to O
4, O
the O
optimum O
maximum O
number O
of O
elements O
n O
is O
3. O
They O
proposed O
the O
following O
analysis: O
if O
the O
hypothesis O
is O
shorter O
than O
the O
text, O
with O
n O
= O
4, O
then O
the O
frequency O
is O
low O
in O
word O
4-gram. O
However, O
the O
accidental O
coincidence O
of O
the O
word O
4-gram O
significantly O
affected O
BLEU. B-MetricName
When O
n O
is O
large, O
the O
reliability O
of O
the O
word O
overlap O
decreases. O
Next, O
as O
an O
explanation O
of O
reason O
2, O
when O
the O
length O
of O
the O
targeted O
sentence O
is O
short, O
the O
numerical O
result O
of O
BLEU B-MetricName
sometimes O
becomes O
0. O
For O
example, O
the O
number O
of O
agreements O
of O
4- O
gram O
becomes O
0 O
when O
calculating O
with O
n O
= O
4, O
and O
the O
BLEU B-MetricName
value O
sometimes O
becomes O
0. O
2 O
http://www.nlp.mibel.cs.tsukuba.ac.jp/bleu_kit/ O
Word O
Overlap O
Subpath O
Set O
SVM B-MethodName
True O
False O
T:xxxxx O
H:yyyyy O
Mutual O
Information O
Evaluation O
Data O
Score O
Calculation O
Resource O
Processing O
21Such O
calculations O
accounted O
for O
approximately O
69% O
of O
the O
Odani O
et O
al. O
evaluation O
set. O
4.2 O
Mutual O
Information O
Glickman O
et O
al. O
(Glickman O
et O
al. O
2005) O
assumed O
that O
the O
possibility O
of O
entailment O
is O
high O
when O
the O
co-occurrence O
frequency O
of O
the O
word O
in O
the O
text O
and O
the O
hypothesis O
is O
high. O
Therefore, O
they O
proposed O
a O
method O
of O
total O
multiplication, O
by O
searching O
for O
the O
word O
with O
the O
highest O
co- O
occurrence O
frequency O
from O
all O
the O
words O
of O
the O
hypothesis, O
as O
shown O
in O
formulas O
(3) O
and O
(4): O
,( O
1| O
) O
max O
( O
, O
) O
(3) O
( O
, O
) O
(4)u O
h O
V O
t O
u O
v O
vP O
Trh O
t O
lep O
u O
v O
nlep O
u O
v O
n∈ O
∈ O
= O
=∏ O
≈ O
P(Trh O
=1|t) O
expresses O
the O
probability O
of O
entailment O
between O
the O
text O
and O
the O
hypothesis. O
In O
these O
formulas, O
u O
is O
the O
content O
word O
of O
the O
hypothesis O
(noun, O
verb, O
adjective O
or O
unknown O
word); O
v O
the O
content O
word O
of O
the O
text; O
n O
represents O
the O
number O
of O
Web O
search O
hits; O
nu, O
v O
is O
the O
number O
of O
hits O
when O
the O
words O
u O
and O
v O
are O
searched O
on O
the O
Web. O
But, O
when O
the O
content O
word O
of O
the O
text O
is O
low O
frequency, O
the O
numerical O
result O
of O
the O
lep(u, O
v) O
increases O
for O
P(Trh O
=1|t). O
We O
believe O
that O
it O
was O
a O
problem O
not O
to O
take O
into O
account O
the O
co-occurrence O
of O
the O
hypothesis O
words. O
In O
addition, O
their O
method O
to O
handle O
long O
sentences O
and O
reaching O
the O
conclusion O
‘false’ O
is O
problematic. O
This O
is O
why, O
we O
considered O
Rodney O
et O
al’s. O
method O
(Rodney O
et O
al. O
2006) O
and O
proposed O
the O
use O
of O
mutual O
information, O
which O
is O
calculates O
on O
the O
basis O
of O
the O
formulas O
(5) O
and O
(6): O
,1( O
1| O
) O
max O
( O
, O
) O
(5) O
( O
)( O
, O
) O
log O
(6)( O
) O
( O
)u O
h O
V O
t O
u O
v O
u O
v O
P O
Trh O
t O
lep O
u O
v O
p O
n O
lep O
u O
v O
p O
n O
p O
n O
∈ O
∈ O
= O
= O
∏ O
≈− O
⋅u O
u O
is O
the O
number O
of O
the O
content O
words O
of O
the O
hypothesis. O
Hence, O
1/ O
u O
averages O
product O
of O
max O
lep(u,v) O
. O
This O
being O
so O
we O
considered O
that O
this O
model O
can O
do O
entailment O
judgments O
independantly O
of O
the O
length O
of O
the O
hypothesis. O
It O
searches O
for O
the O
word O
of O
the O
text O
considering O
that O
the O
mutual O
information O
reaches O
the O
maximum O
value O
from O
each O
of O
the O
hypothesis O
words. O
When O
P(Trh O
=1|t) O
is O
higher O
than O
an O
arbitrary O
threshold O
value, O
it O
is O
judged O
to O
be O
‘true O
’, O
and O
‘false’ O
in O
the O
opposite O
case. O
Glickman O
assumed O
the O
co-occurrence O
frequency O
to O
be O
the O
number O
of O
Web-search O
hits. O
However, O
we O
estimated O
that O
the O
reliability O
of O
the O
co- O
occurrence O
frequency O
was O
low, O
because O
the O
co- O
occurrence O
of O
the O
Web O
search O
engine O
was O
a O
wide O
window. O
This O
is O
why, O
we O
used O
the O
Japanese O
Web O
N-gram O
3. O
In O
particular, O
we O
used O
7-gram O
data, O
and O
calculated O
the O
co-occurrence O
frequency O
nu, O
v O
, O
frequency O
nu O
and O
nv O
of O
the O
word. O
p(n O
i) O
was O
calculated O
by O
(?) O
the O
frequency O
n O
i O
divided O
the O
number O
of O
all O
words. O
Japanese O
Web O
N-gram O
was O
made O
from O
20,036,793,177 O
sentences, O
including O
255,198,240,937 O
words. O
The O
unique O
number O
of O
7-gram O
is O
570,204,252. O
To O
perform O
morphological O
analysis, O
we O
used O
Mecab O
4, O
for O
example: O
Example O
5: O
Calculation O
by O
mutual O
information. O
T:この部屋はクーラーが効いている。 O
(The O
air O
conditioner O
works O
in O
this O
room.) O
H:涼しい。(It O
is O
cool.) O
Mutual O
Information:10.0 O
( O
) O
( O
) O
( O
),1( O
1| O
) O
max O
( O
, O
)1 O
( O
, O
)u O
V O
t O
P O
Trh O
t O
lep O
u O
v O
p O
n O
lep O
u O
v O
p O
n O
p O
n O
∈ O
∈ O
= O
= O
∏ O
= O
≈ O
⋅涼しいクーラ O
ー(cool,the O
air O
conditioner) O
涼しい(cool) O
クーラ O
ー(the O
air O
conditioner) O
(7) O
-log O
10.0 O
(8) O
This O
method O
actually O
standardises O
the O
result O
by O
dividing O
by O
the O
maximum O
value O
of O
lep(u, O
v) O
. O
As O
a O
result, O
p O
reaches O
the O
value O
1 O
from O
0. O
We O
used O
the O
discounting O
for O
nu, O
n O
v,and O
nu, O
v O
,, O
because O
a O
zero-frequency O
problem O
had O
occurred O
when O
calculating O
the O
frequency. O
There O
are O
some O
methods O
for O
discounting. O
We O
used O
the O
additive O
method O
reported O
by O
Church O
and O
Gale O
(Church O
and O
Gale, O
1991). O
They O
compared O
some O
discounting O
methods O
by O
using O
the O
newspaper O
corpus. O
The O
addition O
method O
is O
shown O
as O
follows. O
( O
) O
1 O
( O
) O
(9)C O
w O
P O
w O
Jglyph817 O
V O
+=+ O
3 O
http://www.gsk.or.jp/catalog/GSK-2007-C/ O
4 O
http://mecab.sourceforge.net/ O
22The O
additive O
method O
assumed O
N O
to O
be O
the O
number O
of O
all O
words O
in O
a O
corpus. O
C(w) O
is O
the O
frequency O
of O
word O
w O
in O
the O
corpus. O
V O
is O
a O
constant O
to O
adjust O
the O
total O
of O
the O
appearance O
probability O
to O
1. O
It O
is O
equal O
to O
the O
unique O
number O
of O
words O
w. O
The O
additive O
method O
is O
very O
simple, O
it O
adds O
a O
constant O
value O
to O
occurrence O
count O
C(w) O
. O
The O
method O
of O
adding O
1 O
to O
the O
occurrence O
count O
is O
called O
Laplace O
method O
also. O
4.3 O
Subpath O
Set O
Herrera O
et O
al. O
(Herrera O
et O
al., O
2005) O
parsed O
the O
hypothesis O
and O
the O
text, O
and O
they O
calculated O
the O
degree O
of O
similarity O
of O
the O
syntax O
tree O
from O
both. O
Our O
method O
also O
deals O
with O
the O
degree O
of O
similarity O
of O
the O
syntax O
tree. O
The O
tree O
kernel O
method O
of O
Collins O
and O
Duffy O
(M. O
Collins O
and O
N. O
Duffy O
, O
2002 O
) O
shows O
the O
degree O
of O
similarity O
of O
the O
syntax O
tree; O
however, O
it O
requires O
much O
time O
to O
calculate O
the O
degree O
of O
similarity. O
Therefore, O
we O
employed O
the O
subpath O
set O
of O
Ichikawa O
et O
al. O
This O
latter O
calculates O
partial O
routes O
from O
the O
root O
to O
the O
leaf O
of O
the O
syntax O
tree O
. O
Our O
method O
assumes O
the O
node O
to O
be O
a O
content O
word O
(noun, O
verb, O
adjective O
or O
unknown O
word) O
in O
the O
syntax O
tree, O
while O
the O
branch O
is O
a O
dependency O
relation. O
For O
parsing O
we O
relied O
on O
Cabocha O
5 O
. O
The O
frequency O
vector O
was O
assumed O
to O
comprise O
a O
number O
of O
partial O
routes, O
similar O
to O
the O
approach O
of O
Ichikawa O
et O
al. O
(Ichikawa O
et O
al., O
2005). O
The O
number O
of O
partial O
routes O
is O
unique. O
However, O
even O
if O
the O
same O
expression O
is O
shown O
for O
the O
word O
with O
a O
different O
surface O
form, O
it O
is O
not O
possible O
to O
recognise O
it O
as O
the O
same O
node. O
Therefore, O
we O
used O
the O
Japanese O
version O
of O
WordNet B-DatasetName
(Bond O
et O
al., O
2009), O
in O
which O
a O
word O
with O
a O
different O
surface O
can O
be O
treated O
as O
the O
same O
expression, O
because O
Japanese O
WordNet B-DatasetName
contains O
synonyms. O
The O
same O
expressions O
of O
our O
method O
were O
hypernym O
words, O
hyponym O
words O
and O
synonym O
words O
in O
Japanese O
Word O
Net, O
because O
RTE B-MethodName
sometimes O
considered O
the O
hierarchical O
dictionary O
of O
the O
hypernym O
and O
the O
hyponym O
word O
to O
be O
the O
same O
expression. O
However, O
our O
hypernym O
and O
hyponym O
words O
were O
assumed O
to O
be O
a O
parent O
and O
a O
child O
node O
of O
the O
object O
word, O
as O
shown O
in O
Figure O
3. O
5 O
http://chasen.org/~taku/software/cabocha/ O
Example O
6: O
Calculation O
by O
subpath O
set. O
T:キャンペーン中なので、ポイントが O
2倍 O
付く。 O
(T:The O
point O
adheres O
by O
the O
twice O
because O
it O
is O
campaigning.) O
H:キャンペーン中なので、ポイントが普段 O
より2倍付く。 O
(H:The O
point O
adheres O
usually O
by O
the O
twice O
because O
it O
is O
campaigning.) O
Subpath:0.86 O
Figure O
2: O
Partial O
route O
chart O
of O
subpath O
set. O
The O
number O
of O
partial O
routes O
is O
7, O
and O
6 O
partial O
routes O
overlap O
in O
T O
and O
H. O
So, O
the O
subpath O
is O
0.86 O
(6/7). O
5 O
Evaluation O
The O
textual O
entailment O
evaluation O
data O
of O
Odani O
et O
al., O
described O
in O
Section O
3, O
was O
used O
in O
the O
experiment. O
The O
entailment O
judgment O
of O
four O
values O
is O
manually O
given O
to O
the O
textual O
entailment O
evaluation O
data. O
In O
our O
experiment O
we O
considered O
‘T O
alw O
’ O
and O
‘T O
alm O
’ O
to O
be O
‘true’ O
and O
‘Fmay O
’ O
and O
‘Falw O
’ O
as O
‘false O
’. O
The O
evaluation O
method O
used O
was O
a O
Confidence- B-MetricName
Weight I-MetricName
Score I-MetricName
(CWS, O
also O
known O
as O
Average B-MetricName
Precision), I-MetricName
proposed O
by O
Dagan O
et O
al.. O
As O
for O
the O
closed O
test, O
the O
threshold O
value O
with O
the O
maximum O
CWS B-MetricName
was O
used. O
1 O
1/ O
1( O
) O
1( O
)k O
i O
All O
i O
i O
k O
Accuracy B-MetricName
Correct O
All O
CWS B-MetricName
r O
precision O
k O
k O
precision O
k O
r O
k≤ O
≤ O
≤ O
≤ O
= O
∑ O
∑(10) O
=・ O
(11) O
= O
(12) O
All O
= O
Number O
of O
all O
evaluation O
data. O
Correct O
= O
Number O
of O
correct O
answer O
data. O
If O
k O
is O
a O
correct O
answer, O
rk O
= O
1. O
If O
k O
is O
an O
incorrect O
answer, O
rk O
= O
0. O
23When O
the O
Entailment O
judgment O
annotated O
in O
evaluation O
data O
matches O
with O
the O
Entailment O
judgment O
of O
our O
method, O
the O
answer O
is O
true. O
The O
threshold O
of O
the O
Closed O
test O
was O
set O
beforehand O
(0 O
≦th O
≦1). O
When O
it O
was O
above O
the O
threshold, O
it O
was O
judged O
“true”. O
When O
it O
was O
higher O
than O
the O
threshold, O
it O
was O
judged O
“false”. O
SVM B-MethodName
was O
used O
to O
calculate O
the O
value O
of O
three O
methods O
(word O
overlap, O
mutual O
information O
and O
subpath O
set) O
as O
the O
features O
for O
learning O
data, O
was O
experimented. O
Open O
test O
was O
experimented O
10-fold O
cross- O
validations. O
9 O
of O
the O
data O
divided O
into O
10 O
were O
utilized O
as O
the O
learning O
data. O
Remaining O
1 O
was O
used O
as O
an O
evaluation O
data. O
It O
looked O
for O
the O
threshold O
that O
CWS B-MetricName
becomes O
the O
maximum O
from O
among O
the O
learning O
data. O
It O
experimented O
on O
the O
threshold O
for O
which O
it O
searched O
by O
the O
learning O
data O
to O
the O
evaluation O
data. O
It O
repeats O
until O
all O
data O
that O
divides O
this O
becomes O
an O
evaluation O
data, O
averaged O
out. O
(Or O
we O
experimented O
Leave-one- O
out O
cross O
validation.) O
Using O
the O
SVM, B-MethodName
experiments O
were O
conducted O
on O
the O
numerical O
results O
of O
Sections O
4.1 O
to O
4.3 O
as O
the O
features. O
The O
textual O
entailment O
evaluation O
data O
numbered O
2472: O
‘T O
alw O
’: O
924, O
‘T O
alm O
’: O
662, O
‘F O
may O
’: O
262 O
and O
‘F O
alw O
’: O
624, O
and O
there O
were O
4356 O
words. O
The O
total O
number O
of O
words O
was O
43421. O
Tables O
2 O
and O
3 O
show O
the O
results O
of O
the O
experiment, O
which O
focused O
respectively O
on O
the O
closed O
and O
open O
tests,. O
When O
the O
‘true’ O
textual O
entailment O
evaluation O
data O
‘T O
alw O
’ O
only O
and O
‘T O
alw O
and O
Talm O
’ O
was O
used, O
mutual O
information O
achieved O
the O
best O
performance. O
When O
the O
true O
data O
‘T O
alm O
’ O
only O
was O
used, O
SVM B-MethodName
achieved O
the O
best O
performance. O
Table O
2: O
Results O
of O
the O
RTE O
experiments O
6 O
Discussion O
In O
this O
section, O
we O
discuss O
the O
relation O
between O
each O
3 O
method O
value O
assumed O
to O
be O
the O
criterion O
of O
judgment O
and O
CWS B-MetricName
in O
the O
closed O
test. O
When O
the O
‘true O
’ O
evaluation O
data O
was O
assumed O
to O
be O
‘Talm O
’ O
only O
in O
the O
open O
test, O
the O
result O
of O
SVM B-MethodName
exceeded O
the O
results O
of O
the O
closed O
test. O
We O
then O
consider O
the O
relation O
between O
SVM B-MethodName
and O
CWS. B-MetricName
6.1 O
Close O
Test O
of O
Ward O
Overlap O
We O
believe O
that O
the O
results O
of O
the O
experiments O
of O
word O
overlap O
were O
more O
effective O
than O
other O
methods, O
because O
they O
achieved O
the O
best O
performance O
excluding O
‘T O
alm O
’ O
and O
‘T O
alw O
and O
T O
alm O
’ O
in O
3 O
methods. O
Figure O
3 O
shows O
the O
relation O
to O
CWS O
when O
BLEU O
value O
changes. O
010 O
20 O
30 O
40 O
50 O
60 O
70 O
80 O
90 O
100 O
0 O
0.2 O
0.4 O
0.6 O
0.8 O
1 O
BLEU O
C O
W O
S[% O
] O
Talw O
Tmay O
Talw O
and O
Tmay O
Figure O
3: O
Results O
of O
the O
closed O
test O
of O
the O
RTE O
experiments O
by O
word O
overlap. O
The O
tendency O
shown O
in O
Figure O
3 O
did O
not O
change O
much O
when O
the O
relation O
between O
the O
threshold O
value O
and O
CWS B-MetricName
was O
observed, O
even O
though O
the O
‘true’ O
evaluation O
data O
was O
changed. O
CWS O
Closed O
Test O
Open O
Test O
Talw O
T O
alm O
Talw O
and O
T O
alm O
Talw O
T O
alm O
Talw O
and O
T O
alm O
Word O
Overlap O
53.0% O
57.9% O
62.1% O
39.0% O
60.2% O
59.3% O
Mutual O
Informaition O
55.9% O
52.9% O
68.6% O
53.4% O
55.6% O
67.4% O
Subpath O
Set O
54.5% O
57.0% O
61.8% O
45.0% O
59.7% O
61.1% O
SVM O
51.4% O
61.2% O
63.5% O
49.9% O
61.9% O
64.1% O
24However, O
the O
entailment O
judgment O
of O
the O
word O
overlap O
method O
becomes O
nearly O
‘false’ O
when O
the O
BLEU O
value O
is O
1 O
(or O
‘true’ O
when O
BLEU B-MetricName
score O
is O
0.) O
Table O
3 O
shows O
the O
entailment O
judgment O
when O
the O
BLEU B-MetricName
value O
is O
0 O
or O
1. O
We O
assumed O
that O
BLEU B-MetricName
value O
that O
CWS B-MetricName
becomes O
the O
maximum O
depends O
on O
the O
ratio O
of O
number O
of O
T O
and O
F O
in O
the O
evaluation O
set. O
However, O
when O
true O
condition O
is O
“T O
alw O
” O
only, O
T O
is O
more O
than O
F O
(T:924,F:886). O
And O
when O
true O
condition O
is O
“T O
alm O
” O
only, O
F O
is O
more O
than O
T O
(T:662,F:886). O
For O
this O
reason, O
The O
possibility O
of O
our O
assumption O
is O
low O
because O
both O
true O
conditions O
are O
BLEU B-MetricName
value O
that O
CWS B-MetricName
becomes O
the O
maximum O
is O
1. O
6.2 O
Close O
Test O
of O
Mutual O
Information O
We O
believe O
that O
the O
results O
of O
the O
experiments O
of O
mutual O
information O
were O
more O
effective O
than O
other O
methods, O
because O
they O
achieved O
the O
best O
performance O
excluding O
‘T O
alm O
’ O
in O
3 O
methods. O
Figure O
4 O
shows O
the O
relation O
to O
CWS B-MetricName
when O
mutual O
information O
value O
changes. O
The O
tendency O
shown O
in O
Figure O
4 O
did O
not O
change O
much O
when O
the O
relation O
between O
mutual O
information O
value O
and O
CWS B-MetricName
was O
observed, O
even O
though O
the O
‘true’ O
evaluation O
data O
was O
changed. O
When O
mutual O
information O
values O
are O
from O
0.2 O
(or O
0.3) O
to O
1, O
CWS B-MetricName
increased. O
However, O
the O
entailment O
judgment O
of O
the O
mutual O
information O
method O
becomes O
almost O
‘true’ O
when O
mutual O
information O
score O
is O
near O
1 O
(or O
‘false’ O
when O
mutual O
information O
score O
value O
is O
near O
0.) O
Our O
results O
showed O
most O
entailment O
judgment O
results O
to O
be O
almost O
‘true’ O
(or O
almost O
‘false’) O
for O
the O
optimal O
threshold O
value O
in O
the O
evaluation O
data. O
Therefore, O
we O
considered O
that O
the O
method O
of O
RTE O
using O
mutual O
information O
should O
be O
reviewed. O
6.3 O
Close O
Test O
of O
Subpath O
Set O
We O
believe O
that O
the O
results O
of O
the O
experiments O
of O
subpath O
set O
were O
not O
better O
than O
other O
methods. O
Figure O
5 O
shows O
the O
relation O
to O
CWS B-MetricName
when O
subpath O
set O
(SS) O
value O
changes. O
The O
tendency O
shown O
in O
Figure O
5 O
changed O
much O
when O
the O
relation O
between O
the O
threshold O
value O
and O
CWS B-MetricName
was O
observed, O
even O
though O
the O
‘true’ O
evaluation O
data O
was O
changed. O
When O
the O
true O
conditions O
are O
“T O
alw O
” O
and O
“T O
alm O
”, O
the O
tendencies O
were O
very O
near. O
Our O
results O
showed O
most O
entailment O
judgment O
results O
to O
be O
almost O
‘true’ O
(or O
almost O
‘false’) O
for O
the O
optimal O
subpath O
set O
value O
in O
the O
evaluation O
data. O
6.4 O
Open O
Test O
of O
SVM B-MethodName
The O
open O
tests O
were O
conducted O
in O
10-fold O
cross- O
validation O
, O
and O
the O
experimental O
result O
is O
their O
average. O
Figure O
6 O
shows O
the O
related O
chart O
10-fold O
cross-validation. O
When O
the O
true O
data O
were O
assumed O
to O
be O
‘T O
alm O
’ O
only, O
the O
maximum O
value O
of O
CWS B-MetricName
was O
70.3%. B-MetricValue
As O
a O
result, O
the O
result O
of O
10–fold O
cross O
validation O
exceeded O
the O
closed O
test. O
Table O
5: O
Entailment O
judgment O
in O
closed O
test O
of O
subpath O
set O
(T=True, O
F=False, O
SS=subpath O
set). O
010 O
20 O
30 O
40 O
50 O
60 O
70 O
80 O
90 O
100 O
1 O
3 O
5 O
7 O
9 O
Fold O
N O
C O
W O
S O
[% O
] O
Talw O
Tmay O
Talw O
and O
Tmay O
Figure O
6: O
Results O
of O
the O
open O
test O
of O
the O
RTE O
experiments O
by O
SVM B-MethodName
. O
When O
the O
true O
data O
was O
assumed O
to O
be O
‘T O
alw O
’ O
only, O
the O
minimum O
value O
of O
CWS B-MetricName
was O
42.7%. B-MetricValue
We O
focused O
on O
the O
difference O
between O
the O
maximum O
and O
minimum O
value O
in O
10-fold O
cross- O
validation. O
When O
the O
true O
answer O
was O
assumed O
to O
be O
‘T O
alm O
’, O
the O
difference O
between O
the O
maximum O
and O
minimum O
value O
is O
the O
greatest O
(15.3 O
points) O
in O
the O
open O
tests, O
and O
‘T O
alw O
and O
Talm O
’ O
was O
the O
lowest O
with O
11.6 O
points. O
We O
believe O
that O
when O
the O
result O
‘T O
alm’ O
was O
‘true’, O
it O
was O
consequently O
more O
unstable O
than O
‘Talw O
and O
T O
alm O
’, O
because O
there O
was O
a O
larger O
amount O
of O
evaluation O
data O
‘T O
alw O
and O
Talm O
’. O
7 O
Conclusion O
We O
built O
a O
Japanese O
textual O
entailment O
recognition O
system O
based O
on O
the O
past O
methods O
of O
RTE. O
We O
considered O
the O
problem O
of O
RTE O
as O
a O
problem O
of O
binary O
classification, O
and O
built O
a O
new O
model O
of O
RTE B-TaskName
for O
machine O
learning. O
We O
proposed O
machine O
learning O
to O
consider O
the O
matching O
rate O
of O
the O
words O
of O
the O
text O
and O
the O
hypothesis, O
using O
mutual O
information O
and O
similarity O
of O
the O
syntax O
tree. O
The O
method O
of O
using O
mutual O
information O
and O
the O
use O
of O
three O
methods O
of O
SVM B-MethodName
tunrned O
out O
to O
be O
effective. O
Moreover, O
we O
will O
propose O
a O
new O
method O
for O
the O
feature O
of O
machine O
learning. O
We O
will O
also O
consider O
to O
expand O
WordNet. O
Shnarch O
et O
al. O
(Shnarch O
et O
al., O
2009) O
researched O
the O
extraction O
from O
Wikipedia O
of O
lexical O
reference O
rules, O
identifying O
references O
to O
term O
meaning O
triggered O
by O
other O
terms. O
They O
evaluated O
their O
lexical O
reference O
relation O
for O
RTE. B-TaskName
They O
improved O
previous O
RTE B-TaskName
methods. O
We O
will O
use O
their O
method O
for O
ours O
in O
order O
to O
expand O
Japanese O
WordNet. O
We O
believe O
that O
this O
can O
help O
us O
improve O
our O
method/results. O