Proceedings O
of O
the O
First O
Workshop O
on O
Natural O
Language O
Processing O
for O
Indigenous O
Languages O
of O
the O
Americas O
, O
pages O
224–233 O
June O
11, O
2021. O
©2021 O
Association O
for O
Computational O
Linguistics224NRC-CNRC O
Machine B-TaskName
Translation I-TaskName
Systems O
for O
the O
2021 O
AmericasNLP O
Shared O
Task O
Rebecca O
Knowles O
andDarlene O
Stewart O
andSamuel O
Larkin O
andPatrick O
Littell O
National O
Research O
Council O
Canada O
{Rebecca.Knowles, O
Darlene.Stewart, O
Samuel.Larkin, O
Patrick.Littell}@nrc-cnrc.gc.ca O
Abstract O
We O
describe O
the O
NRC-CNRC O
systems O
submit- O
ted O
to O
the O
AmericasNLP O
shared O
task O
on O
ma- B-TaskName
chine I-TaskName
translation. I-TaskName
We O
submitted O
systems O
trans- O
lating O
from O
Spanish O
into O
Wixárika, O
Nahuatl, O
Rarámuri, O
and O
Guaraní. O
Our O
best O
neural O
ma- O
chine O
translation O
systems O
used O
multilingual O
pretraining, O
ensembling, O
ﬁnetuning, O
training O
on O
parts O
of O
the O
development O
data, O
and O
subword O
regularization. O
We O
also O
submitted O
translation O
memory O
systems O
as O
a O
strong O
baseline. O
1 O
Introduction O
This O
paper O
describes O
experiments O
on O
translation O
from O
Spanish O
into O
Wixárika, O
Nahuatl, O
Rarámuri, O
and O
Guaraní, O
as O
part O
of O
the O
First O
Workshop O
on O
Nat- O
ural O
Language O
Processing O
(NLP) O
for O
Indigenous O
Languages O
of O
the O
Americas O
(AmericasNLP) O
2021 O
Shared O
Task O
on O
open-ended O
machine O
translation. O
Our O
approach O
to O
this O
task O
was O
to O
explore O
the O
ap- O
plication O
of O
simple, O
known O
methods O
of O
performing O
neural B-TaskName
machine I-TaskName
translation I-TaskName
(NMT) I-TaskName
for O
low-resource O
languages O
to O
a O
subset O
of O
the O
task O
languages. O
Our O
initial O
experiments O
were O
primarily O
focused O
on O
the O
following O
questions: O
(1)How O
well O
does O
multilin- O
gual O
NMT B-TaskName
work O
in O
these O
very O
low O
resource O
set- O
tings? O
(2)Is O
it O
better O
to O
build O
multilingual O
NMT B-TaskName
systems O
using O
only O
closely-related O
languages O
or O
does O
it O
help O
to O
add O
data O
from O
additional O
languages? O
(3)Is O
applying O
subword O
regularization O
helpful? O
As O
we O
progressed O
through O
the O
task, O
it O
raised O
ques- O
tions O
regarding O
domain O
and O
about O
use O
cases O
for O
low-resource O
machine B-TaskName
translation. I-TaskName
The O
approaches O
that O
we O
used O
for O
this O
task O
are O
not O
entirely O
language- O
agnostic; O
they O
might O
be O
more O
appropriately O
charac- O
terized O
as O
“language O
naïve” O
in O
that O
we O
applied O
some O
simple O
language-speciﬁc O
pre- O
and O
post-processing, O
but O
did O
not O
incorporate O
any O
tools O
that O
required O
in- O
depth O
knowledge O
of O
the O
language. O
We O
submitted O
four O
systems, O
including O
ensem- O
bles, O
single O
systems, O
and O
a O
translation O
memory O
baseline. O
Our O
best O
system O
(S.0) O
consisted O
of O
an O
ensemble O
of O
systems O
incorporating O
multilingual O
training O
and O
ﬁnetuning O
(including O
on O
development O
data O
as O
pseudo-in-domain O
data). O
2 O
Data O
and O
Preprocessing O
The O
shared O
task O
provided O
data O
for O
10 O
language O
pairs, O
all O
with O
the O
goal O
of O
translating O
from O
Span- O
ish. O
We O
chose O
to O
start O
with O
Wixárika O
(hch; O
Mager O
et O
al., O
2018), O
Nahuatl O
(nah; O
Gutierrez-Vasques O
et O
al., O
2016), O
and O
Rarámuri O
(tar; O
Brambila, O
1976) O
as O
our O
main O
three O
languages O
of O
interest, O
all O
of O
which O
are O
languages O
in O
the O
Uto-Aztecan O
family O
indige- O
nous O
to O
Mexico. O
We O
added O
Guaraní O
(gn; O
Chiruzzo O
et O
al., O
2020) O
as O
an O
unrelated O
language O
(as O
spo- O
ken O
in O
Paraguay), O
to O
explore O
building O
multilingual O
NMT B-TaskName
systems O
within O
and O
across O
language O
families. O
Ebrahimi O
et O
al. O
(2021) O
describes O
work O
on O
collect- O
ing O
development O
and O
test O
sets O
for O
the O
languages O
in O
the O
shared O
task. O
The O
datasets O
vary O
in O
size, O
di- O
alect O
and O
orthographic O
variation/consistency, O
and O
level O
of O
domain O
match O
to O
the O
development O
and O
test O
data. O
Due O
to O
space O
considerations, O
we O
direct O
read- O
ers O
to O
the O
task O
page O
and O
the O
dataset O
information O
page O
for O
more O
information O
on O
the O
languages O
and O
on O
the O
datasets O
provided O
for O
the O
task.1 O
Given O
the O
size O
of O
the O
data O
(Table O
1), O
additional O
data O
collection O
(particularly O
of O
data O
in O
the O
domain O
of O
interest) O
is O
likely O
one O
of O
the O
most O
effective O
ways O
to O
improve O
machine B-TaskName
translation I-TaskName
quality. O
However, O
1Task O
page: O
http://turing.iimas.unam.mx/ O
americasnlp/ O
, O
Dataset O
descriptions: O
https:// O
github.com/AmericasNLP/americasnlp2021/ O
blob/main/data/information_datasets.pdf225noting O
both O
ethical O
(Lewis O
et O
al., O
2020) O
and O
quality O
(Caswell O
et O
al., O
2021) O
concerns O
when O
it O
comes O
to O
collecting O
or O
using O
data O
for O
Indigenous O
languages O
without O
community O
collaboration, O
we O
limited O
our O
experiments O
to O
data O
provided O
for O
the O
shared O
task. O
2.1 O
Preprocessing O
and O
Postprocessing O
We O
used O
standard O
preprocessing O
scripts O
from O
Moses O
(Koehn O
et O
al., O
2007): O
clean-corpus-n.perl O
(on O
training O
data O
only), O
normalize-punctuation.perl O
, O
and O
tokenizer.perl O
(applied O
to O
all O
text, O
regard- O
less O
of O
whether O
it O
already O
appeared O
tokenized).2 O
The O
only O
language-speciﬁc O
preprocessing O
we O
performed O
was O
to O
replace O
“+” O
with O
an O
alternative O
character O
(reverted O
in O
postprocessing) O
for O
Wixárika O
text O
to O
prevent O
the O
tokenizer O
from O
oversegmenting O
the O
text. O
We O
note O
that O
the O
13a O
tokenizer O
used O
by O
sacrebleu O
(Post, O
2018) O
tokenizes O
“+”, O
meaning O
that O
scores O
that O
incorporate O
word O
n-grams, O
like O
BLEU B-MetricName
(Papineni O
et O
al., O
2002), O
are O
artiﬁcially O
inﬂated O
for O
Wixárika. O
We O
detokenize O
(after O
unBPEing) O
the O
text O
and O
per- O
form O
a O
small O
amount O
of O
language-speciﬁc O
postpro- O
cessing, O
which O
we O
found O
to O
have O
minimal O
effect O
on O
CHRF(Popovi B-MetricName
´c, O
2015) O
and O
some O
effect O
on O
BLEU B-MetricName
on O
development O
data. O
2.2 O
BPE O
and O
BPE-Dropout O
Following O
(Ding O
et O
al., O
2019), O
we O
sweep O
a O
range O
of O
byte-pair O
encoding O
(BPE; O
Sennrich O
et O
al., O
2016) O
vocabulary O
sizes: O
500, O
1000, O
2000, O
4000, O
and O
8000 O
merges O
(we O
do O
not O
go O
beyond O
this, O
because O
of O
spar- O
sity/data O
size O
concerns, O
though O
some O
results O
sug- O
gest O
we O
should O
consider O
larger O
sizes). O
For O
each O
language O
pair O
or O
multilingual O
grouping, O
we O
learned O
a O
BPE O
model O
jointly O
from O
the O
concate- O
nation O
of O
the O
source O
and O
target O
sides O
of O
the O
parallel O
data O
using O
subword-nmt O
(Sennrich O
et O
al., O
2016), O
and O
then O
extracted O
separate O
source- O
and O
target-side O
vocabularies. O
We O
then O
applied O
the O
joint O
BPE O
model, O
ﬁltered O
by O
the O
source O
or O
target O
vocabulary, O
to O
the O
corresponding O
data. O
We O
apply O
BPE-dropout O
(Provilkov O
et O
al., O
2020) O
in O
part O
to O
assist O
with O
data O
sparsity O
and O
in O
part O
be- O
cause O
it O
may O
be O
an O
effective O
way O
of O
handing O
ortho- O
graphic O
variation O
(as O
a O
generalization O
of O
the O
spelling O
errors O
that O
it O
helps O
systems O
become O
more O
robust O
to). O
Usually, O
BPE-dropout O
would O
be O
performed O
dur- O
ing O
training O
as O
mini-batches O
are O
generated, O
but O
we O
2See O
Appendix O
B O
for O
details.opted O
to O
generate O
10 O
BPE-dropout O
versions O
of O
the O
training O
corpus O
using O
a O
dropout B-HyperparameterName
rate O
of O
0.1 B-HyperparameterValue
as O
part O
of O
our O
preprocessing. O
We O
then O
simply O
concatenate O
all O
10 O
alternate O
versions O
to O
form O
the O
training O
corpus. O
3 O
Models O
and O
Experiments O
We O
report O
CHRF(Popovi B-MetricName
´c, O
2015) O
scores O
computed O
withsacrebleu O
(Post, O
2018). O
3.1 O
Models O
We O
trained O
Transformer B-MethodName
(Vaswani O
et O
al., O
2017) O
mod- O
els O
using O
Sockeye-1.18.115 O
(Hieber O
et O
al., O
2018) O
and O
cuda-10.1. O
We O
used O
the O
default O
value O
of O
6 B-HyperparameterValue
en- B-HyperparameterName
coder/decoder I-HyperparameterName
layers, I-HyperparameterName
8 B-HyperparameterValue
attention B-HyperparameterName
heads, I-HyperparameterName
the O
Adam B-HyperparameterName
(Kingma O
and O
Ba, O
2015) O
optimizer, O
label B-HyperparameterName
smoothing I-HyperparameterName
of O
0.1, B-HyperparameterValue
a O
cross-entropy O
loss, O
a O
model B-HyperparameterName
size I-HyperparameterName
of O
512 B-HyperparameterValue
units O
with O
a O
FFN B-HyperparameterName
size O
of O
2048, B-HyperparameterValue
and O
the O
vocabulary O
was O
not O
shared. O
We O
performed O
early B-HyperparameterName
stopping I-HyperparameterName
after O
32 B-HyperparameterValue
checkpoints O
without O
improvement. O
We O
chose O
custom O
checkpoint O
intervals O
of O
approximately O
two O
checkpoints O
per O
epoch. O
We O
optimized O
for O
CHRF B-MetricName
instead O
of O
BLEU B-MetricName
and O
used O
the O
whole O
validation O
set O
during O
validation. O
The O
batch B-HyperparameterName
size I-HyperparameterName
was O
set O
to O
8192 B-HyperparameterValue
tokens, O
and O
the O
maximum O
sequence B-HyperparameterName
length I-HyperparameterName
for O
both O
source O
and O
target O
was O
set O
to O
200 B-HyperparameterValue
tokens. O
We O
did O
not O
use O
weight O
tying, O
but O
we O
set O
gradient B-HyperparameterName
clipping I-HyperparameterName
to O
absolute B-HyperparameterValue
and O
lowered O
the O
initial O
learning B-HyperparameterName
rate I-HyperparameterName
to O
0.0001. B-HyperparameterValue
We O
performed O
preliminary O
experiments O
decreas- O
ing O
the O
number O
of O
encoder B-HyperparameterName
and I-HyperparameterName
decoder I-HyperparameterName
layers I-HyperparameterName
in O
our O
bilingual O
systems O
to O
3 B-HyperparameterValue
each, O
but O
did O
not O
ob- O
serve O
improvements. O
Nevertheless, O
a O
wider O
search O
of O
architecture O
parameters, O
as O
in O
Araabi O
and O
Monz O
(2020), O
could O
yield O
improvements. O
After O
submis- O
sion, O
we O
performed O
some O
additional O
experiments, O
building O
multilingual O
models O
with O
a O
range O
of O
num- B-HyperparameterName
bers I-HyperparameterName
of I-HyperparameterName
decoder I-HyperparameterName
heads I-HyperparameterName
(1, B-HyperparameterValue
2, I-HyperparameterValue
4, I-HyperparameterValue
8), I-HyperparameterValue
ﬁnding O
that O
a O
smaller O
number O
of O
decoder O
heads O
(e.g., O
2) O
may O
be O
a O
promising O
avenue O
to O
explore O
in O
future O
work. O
Other O
approaches O
from O
Araabi O
and O
Monz O
(2020) O
also O
appear O
to O
show O
promise O
in O
our O
preliminary O
post-submission O
experiments, O
including O
a O
4 B-HyperparameterValue
layer B-HyperparameterName
encoder I-HyperparameterName
with O
a O
6 B-HyperparameterValue
layer B-HyperparameterName
decoder I-HyperparameterName
and O
changing O
layer O
normalization O
from O
pre O
to O
post, O
demonstrating O
that O
there O
are O
additional O
ways O
to O
improve O
upon O
our O
sub- O
mitted O
systems. O
3.2 O
MT O
Baselines O
For O
each O
of O
the O
four O
language O
pairs, O
we O
build O
base- O
line O
systems O
translating O
out O
of O
Spanish. O
The O
best O
baseline O
systems O
with O
their O
respective O
BPE O
sizes O
are O
shown O
in O
Table O
2. O
All O
of O
our O
baseline O
CHRF B-MetricName
scores O
are O
higher O
than O
the O
ofﬁcial O
baselines O
released O
during O
the O
shared O
task,3likely O
due O
in O
part O
to O
more O
consistent O
tokenization O
between O
training O
and O
devel- O
opment/test O
(see O
Appendix O
C O
for O
additional O
discus- O
sion O
of O
training O
and O
development/test O
mismatch). O
For O
all O
languages O
except O
Rarámuri, O
adding O
BPE- O
dropout O
improved O
performance. O
3.3 O
Multilingual O
Systems O
Both O
Johnson O
et O
al. O
(2017) O
and O
Rikters O
et O
al. O
(2018) O
train O
multilingual O
systems O
by O
prepending O
a O
special O
token O
at O
the O
start O
of O
the O
source O
sentence O
to O
indicate O
the O
language O
into O
which O
the O
text O
should O
be O
trans- O
lated. O
For O
example, O
the O
token O
“<nah>” O
prepended O
(space-separated) O
to O
a O
Spanish O
source O
sentence O
indi- O
cates O
that O
the O
text O
should O
be O
translated O
into O
Nahuatl. O
To O
train O
such O
a O
model, O
we O
concatenate O
all O
training O
data O
after O
adding O
these O
special O
tokens; O
the O
develop- O
ment O
data O
is O
similarly O
the O
concatenation O
of O
all O
devel- O
opment O
data. O
We O
do O
not O
perform O
any O
upsampling O
or O
downsampling O
to O
even O
out O
the O
distribution O
of O
lan- O
guages O
in O
our O
training O
or O
development O
data O
(rather, O
we O
rely O
on O
language O
ﬁnetuning, O
as O
described O
in O
Section O
3.4 O
to O
improve O
translation O
quality). O
One O
of O
our O
initial O
questions O
was O
whether O
lan- O
guage O
relatedness O
mattered O
for O
building O
mul- O
tilingual O
systems, O
so O
we O
ﬁrst O
built O
a O
three- O
language O
(Wixárika, O
Nahuatl, O
Rarámuri) O
model, O
Multiligual-3 B-MethodName
, O
and O
then O
built O
a O
four-language O
(Guaraní, O
Wixárika, O
Nahuatl, O
Rarámuri) O
model, O
Multilingual-4 B-MethodName
. O
The O
Multilingual-4 B-MethodName
system O
had O
consistently O
higher O
scores O
for O
all O
languages O
than O
the O
Multilingual-3 B-MethodName
system, O
so O
we O
moved O
forward O
with O
experiments O
on O
Multilingual-4. B-MethodName
Adding O
BPE- O
dropout O
to O
Multilingual-4 B-MethodName
appeared O
to O
improve O
performance O
for O
all O
languages, O
but O
in O
the O
case O
of O
Wixárika O
(the O
language O
with O
the O
smallest O
amount O
of O
data), O
it O
was O
nearly O
identical O
to O
the O
baseline. O
Within O
3https://github.com/AmericasNLP/ O
americasnlp2021/tree/main/baseline_ O
systemthe O
scope O
of O
this O
paper, O
we O
do O
not O
experiment O
with O
a O
wider O
range O
of O
languages O
(i.e., O
the O
remaining O
6 O
languages), O
though O
it O
would O
not O
be O
surprising O
to O
ﬁnd O
that O
additional O
language O
resources O
might O
also O
be O
beneﬁcial. O
For O
the O
Multilingual-3 B-MethodName
and O
Multilingual-4 B-MethodName
mod- O
els, O
the O
vocabulary O
is O
trained O
and O
extracted O
from O
the O
respective O
concatenated O
training O
corpus, O
so O
the O
target O
vocabulary O
is O
shared O
by O
all O
target O
languages O
as O
a O
single O
embedding O
matrix. O
Where O
languages O
share O
subwords, O
these O
are O
shared O
in O
the O
vocabulary O
(i.e., O
the O
language-speciﬁc O
tags O
are O
applied O
at O
the O
sentence O
level, O
not O
at O
the O
token O
level). O
The O
conse- O
quence O
of O
this O
is O
that O
each O
particular O
target O
language O
may O
not O
use O
the O
full O
multilingual O
vocabulary; O
we O
expect O
the O
system O
to O
learn O
which O
vocabulary O
items O
to O
associate O
(or O
not O
associate) O
with O
each O
language. O
For O
example, O
with O
a O
vocabulary O
produced O
through O
8k O
merges, O
the O
full O
Multilingual-4 O
target O
side O
train- O
ing O
corpus O
contains O
7431 O
unique O
subwords, O
but O
the O
language-speciﬁc O
subcorpora O
that O
combine O
to O
make O
it O
only O
use O
subsets O
of O
that: O
Guaraní O
training O
data O
contains O
5936 O
unique O
subwords, O
while O
Wixárika O
contains O
only O
1389 O
(the O
overlap O
between O
Guaraní O
and O
Wixárika O
subwords O
is O
1089 O
subwords). O
Table O
3 O
shows O
the O
number O
of O
unique O
subwords O
in O
the O
target O
language O
training O
corpus O
for O
the O
Multilingual-4 B-MethodName
set- O
ting. O
Our O
systems O
are O
free O
to O
generate O
any O
subword O
from O
the O
full O
combined O
vocabulary O
of O
target O
sub- O
words O
since O
there O
is O
no O
explicit O
restriction O
during O
decoding. O
Thus, O
in O
some O
cases, O
our O
multilingual O
systems O
do O
generate O
subwords O
that O
were O
not O
seen O
in O
a O
speciﬁc O
language’s O
training O
data O
vocabulary O
sub-227set; O
while O
some O
of O
these O
could O
result O
in O
translation O
errors, O
a O
preliminary O
qualitative O
analysis O
suggests O
that O
many O
of O
them O
may O
be O
either O
source O
language O
words O
(being O
copied) O
or O
numerical O
tokens, O
both O
of O
which O
point O
to O
potential O
beneﬁts O
of O
having O
used O
the O
larger O
concatenated O
multilingual O
corpus. O
3.4 O
Language O
Finetuning O
We O
can O
then O
ﬁnetune4the O
multilingual O
models O
to O
be O
language-speciﬁc O
models.5The O
intuition O
here O
is O
that O
the O
multilingual O
model O
may O
be O
able O
to O
en- O
code O
useful O
information O
about O
the O
source O
language, O
terms O
that O
should O
be O
copied O
(e.g., O
names/numbers), O
target O
grammar, O
or O
other O
useful O
topics, O
and O
can O
then O
be O
specialized O
for O
a O
speciﬁc O
language, O
while O
still O
retaining O
the O
most O
relevant O
or O
most O
general O
things O
learned O
from O
all O
languages O
trained O
on. O
We O
do O
this O
ﬁnetuning O
based O
on O
continued O
training O
on O
each O
language’s O
training O
data, O
with O
that O
language’s O
development O
data, O
building O
a O
new O
child O
system O
for O
each O
language O
based O
on O
the O
parent O
Multilingual-4 O
system O
(with O
or O
without O
dropout).6When O
we O
do O
this, O
we O
no O
longer O
use O
the O
language-speciﬁc O
tags O
used O
during O
multilingual O
model O
training. O
Language O
ﬁnetuning O
appears O
to O
produce O
im- O
provements, O
with O
some O
performing O
better O
with O
dropout O
and O
some O
better O
without, O
as O
seen O
in O
the O
ﬁnal O
two O
lines O
of O
Table O
2. O
Rarámuri O
appears O
to O
have O
a O
drop O
in O
performance O
after O
language O
ﬁnetun- O
ing O
with O
dropout. O
However, O
all O
Rarámuri O
scores O
are O
extremely O
low; O
it O
is O
likely O
that O
many O
of O
the O
decisions O
we O
make O
on O
Rarámuri O
do O
not O
represent O
real O
improvements O
or O
performance O
drops, O
but O
rather O
noise, O
so O
we O
have O
very O
low O
conﬁdence O
in O
the O
gener- O
alizability O
of O
the O
choices O
(Mathur O
et O
al., O
2020). O
3.5 O
Development O
Finetuning O
Noting O
that O
the O
development O
data O
was O
of O
a O
different O
domain, O
and O
sometimes O
even O
a O
different O
dialect O
or O
orthography O
than O
the O
training O
data, O
we O
followed O
an O
approach O
used O
in O
Knowles O
et O
al. O
(2020): O
we O
divided O
the O
development O
set O
(in O
this O
case O
in O
half), O
performing O
ﬁnetuning O
with O
half O
of O
it O
and O
using O
the O
remainder O
for O
early O
stopping O
(and O
evaluation). O
We O
4In O
our O
tables, O
we O
use O
the O
following O
notation O
to O
indicate O
ﬁnetuning: O
“[parent O
model]; O
[child O
ﬁnetuning]” O
and O
this O
no- O
tation O
stacks, O
such O
that O
“X; O
Y; O
Z” O
indicates O
a O
parent O
model O
X, O
ﬁnetuned O
as O
Y O
, O
and O
then O
subsequently O
ﬁnetuned O
as O
Z. O
5We O
note O
that O
all O
ﬁnetuning O
experiments O
reported O
in O
this O
paper O
used O
BPE-dropout O
unless O
otherwise O
noted. O
6We O
note O
that O
some O
catastrophic O
forgetting O
may O
occur O
dur- O
ing O
this O
process; O
it O
may O
be O
worth O
considering O
modifying O
the O
learning O
rate O
for O
ﬁnetuning, O
but O
we O
leave O
this O
to O
future O
work.acknowledge O
that, O
given O
the O
very O
small O
sizes O
of O
the O
development O
sets, O
minor O
differences O
we O
observe O
are O
likely O
to O
be O
noise O
rather O
than O
true O
improvements O
(or O
true O
drops O
in O
performance); O
while O
we O
made O
choices O
about O
what O
systems O
to O
submit O
based O
on O
those, O
we O
urge O
caution O
in O
generalizing O
these O
results O
or O
drawing O
strong O
conclusions. O
We O
show O
performance O
of O
models O
ﬁnetuned O
on O
the O
ﬁrst O
half O
of O
the O
development O
set O
(performance O
measured O
on O
the O
second O
half O
of O
the O
development O
set), O
both O
with O
and O
without O
ﬁrst O
ﬁnetuning O
for O
lan- O
guage, O
in O
Table O
4. O
We O
also O
compare O
these O
against O
the O
best O
systems O
we O
trained O
without O
training O
on O
development O
data, O
as O
well O
as O
with O
the O
translation O
memory O
approach O
(Section O
4.3). O
4 O
Submitted O
Systems O
4.1 O
Systems O
with O
Dev. O
(S.0, O
S.2, O
and O
S.4) O
We O
submitted O
single O
systems O
(not O
ensembled) O
that O
were O
trained O
using O
the O
ﬁrst O
half O
of O
the O
development O
set O
(labeled O
S.2 O
in O
submission). O
They O
were O
selected O
based O
on O
highest O
scores O
on O
the O
second O
half O
of O
the O
development O
set O
(see O
Table O
4 O
for O
scores O
and O
vocab- O
ulary O
sizes). O
For O
Guaraní, O
Wixárika, O
and O
Nahuatl, O
we O
selected O
systems O
of O
the O
type O
Multi.-4 B-MethodName
+ O
BPE O
Dr.; O
Lang. O
ﬁnetuning; O
1/2 O
Dev. O
ﬁnetuning. O
For O
Rarámuri, O
we O
selected O
a O
system O
with O
only O
1/2 O
dev. O
ﬁnetuning O
(Multi.-4 B-MethodName
+ O
BPE O
Dr.; O
1/2 O
Dev. O
Ft.). O
Our O
best O
systems O
were O
ensembles O
(labeled O
S.0 O
in O
submission) O
of O
the O
systems O
described O
above O
and O
their O
corresponding O
system O
trained O
with O
the O
second O
half O
of O
the O
development O
set. O
For O
Guaraní, O
we O
also O
submitted O
an O
ensemble O
of O
four O
systems; O
the O
two O
Multi.-4 B-MethodName
+ O
BPE O
Dr.; O
Lang. O
ﬁnetuning; O
1/2 O
Dev O
ﬁnetuning O
systems O
and O
the O
two O
Multi.-4 B-MethodName
+ O
BPE O
Dr.; O
1/2 O
Dev O
Ft. O
systems O
(S.4). O
It O
performed O
similarly O
to O
the O
two-system O
ensemble. O
4.2 O
Systems O
without O
Dev. O
(S.1) O
We O
also O
submitted O
systems O
that O
were O
not O
trained O
on O
development O
data. O
For O
these, O
we O
were O
able O
to O
select O
the O
best O
system O
from O
our O
experiments, O
based O
on O
its O
CHRFscore O
on O
the O
full O
development O
set. O
For O
Guaraní O
and O
Nahuatl, O
these O
were O
Multi.4 B-MethodName
+ O
BPE O
Dr.; O
Lang. O
ft. O
systems, O
for O
Rarámuri O
it O
was O
the O
Multi.4 B-MethodName
+ O
BPE O
Dr.; O
Lang. O
ft. O
(no O
dr.) O
system, O
and O
for O
Wixárika O
it O
was O
an O
ensemble O
of O
the O
two. O
4.3 O
Translation O
Memory O
(S.3) O
Noting O
the O
very O
low O
automatic O
metric O
scores O
across O
languages O
and O
without O
target O
language O
expertise O
to O
determine O
if O
the O
output O
is O
ﬂuent O
but O
not O
adequate, O
adequate O
but O
not O
ﬂuent, O
or O
neither O
ﬂuent O
nor O
ade- O
quate, O
we O
decided O
to O
build O
a O
translation O
memory O
submission. O
In O
computer O
aided O
translation O
(CAT), O
a O
“translation O
memory” O
(TM) O
is O
a O
database O
of O
prior O
source-target O
translation O
pairs O
produced O
by O
human O
translators. O
It O
can O
be O
used O
in O
CAT O
as O
follows: O
when O
a O
new O
sentence O
arrives O
to O
be O
translated, O
the O
system O
ﬁnds O
the O
closest O
source-language O
“fuzzy O
match” O
(typically O
a O
proprietary O
measure O
that O
determines O
similarity; O
could O
be O
as O
simple O
as O
Levenshtein O
dis- O
tance) O
and O
returns O
its O
translation O
(possibly O
with O
annotations O
about O
the O
areas O
where O
the O
sentences O
differed) O
to O
the O
translator O
for O
them O
to O
“post-edit” O
(modify O
until O
it O
is O
a O
valid O
translation O
of O
the O
new O
sentence O
to O
be O
translated). O
With O
the O
understanding O
that O
the O
development O
and O
test O
sets O
are O
closer O
to O
one O
another O
in O
terms O
of O
do- O
main O
and O
dialect O
than O
they O
are O
to O
the O
training O
data, O
we O
treat O
the O
development O
set O
as O
a O
TM. O
Following O
Simard O
and O
Fujita O
(2012), O
we O
use O
an O
MT O
evalua- O
tion O
metric O
( O
CHRF) B-MetricName
as O
the O
similarity O
score O
between O
the O
test O
source O
sentences O
and O
the O
TM O
source O
sen- O
tences, O
with O
the O
translation O
of O
the O
closest O
source O
development O
set O
sentence O
as O
the O
output.7 O
We O
validated O
this O
approach O
on O
the O
two O
halves O
of O
the O
development O
set O
(using O
the O
ﬁrst O
half O
as O
a O
TM O
for O
the O
second O
half O
and O
vice O
versa). O
On O
half O
the O
de- O
velopment O
set, O
for O
all O
languages O
except O
for O
Guaraní, O
the O
TM O
outperformed O
the O
system O
trained O
without O
7In O
the O
event O
of O
a O
tie, O
we O
chose O
the O
ﬁrst O
translation.any O
development O
data O
(S.1), O
highlighting O
the O
differ- O
ences O
between O
the O
training O
and O
development/test O
data O
(Table O
4), O
particularly O
striking O
because O
the O
TM O
used O
for O
these O
experiments O
consisted O
of O
only O
half O
the O
development O
set O
( O
<500 O
lines) O
as O
compared O
to O
the O
full O
training O
set.8On O
the O
test O
set, O
only O
the O
Rará- O
muri O
TM O
outperformed O
the O
best O
of O
our O
MT B-TaskName
systems O
built O
without O
training O
on O
development. O
5 O
Results O
Our O
results O
consistently O
placed O
our O
submissions O
as O
the O
second-ranking O
team O
(behind O
Helsinki’s O
top O
2-3 O
submissions) O
in O
the O
with-development-set O
group, O
and O
second O
or O
third O
ranking O
team O
(2nd, O
3rd, O
or O
4th O
submission) O
within O
the O
no-development-set O
cluster O
as O
measured O
by O
CHRF. O
For O
Wixárika O
and O
Rarámuri O
particularly, O
our O
TM O
submission O
proved O
to O
be O
a O
surprisingly O
strong O
baseline. O
We O
note O
that O
CHRFand B-MetricName
BLEU B-MetricName
are O
not O
strictly O
correlated, O
and O
for O
all O
languages, O
scores O
are O
low. O
This O
raises O
questions O
about O
goals, O
metrics, O
and O
use O
cases O
for O
very O
low O
resource O
machine O
transla- O
tion. O
We O
provide O
a O
short O
discussion O
of O
this O
in O
Ap- O
pendix O
A. O
It O
will O
require O
future O
work O
and O
human O
evaluation O
to O
determine O
whether O
such O
systems O
are O
useful O
or O
harmful O
in O
downstream O
tasks. O
Acknowledgements O
We O
thank O
the O
translators O
who O
provided O
their O
exper- O
tise O
and O
time O
to O
make O
this O
work O
possible:9Gio- O
vany O
Martinez O
Sebastián, O
Pedro O
Kapoltitan, O
José O
Antonio O
(Nahuatl), O
Silvino O
González O
de O
la O
Crúz O
(Wixárika), O
Perla O
Alvarez O
Britez O
(Guaraní), O
and O
María O
del O
Cármen O
Sotelo O
Holguín O
(Rarámuri). O
We O
thank O
the O
anonymous O
reviewers O
and O
our O
colleagues O
Michel O
Simard, O
Gabriel O
Bernier-Colborne, O
and O
Chi- O
kiu O
Lo O
for O
their O
comments O
and O
suggestions. O
8See O
Appendix O
C O
for O
additional O
detail O
on O
vocabulary O
cov- O
erage O
between O
training, O
development, O
and O
test O
data. O
9Full O
list O
for O
all O
languages O
available O
here: O
https:// O
github.com/AmericasNLP/americasnlp2021/ O
blob/main/data/information_datasets.pdf O
When O
does O
it O
make O
sense O
to O
build O
MT B-TaskName
systems? O
Our O
recent O
participation O
in O
shared O
tasks O
has O
made O
us O
consider O
scenarios O
and O
use O
cases O
for O
low-resource O
MT, B-TaskName
which O
we O
discuss O
in O
this O
appendix. O
At O
the O
WMT O
2020 O
News O
translation O
task, O
the O
Inuktitut-English O
translation O
task O
was O
arguably O
mid- O
resource O
(over O
a O
million O
lines O
of O
parallel O
legislative O
text), O
with O
the O
Hansard O
(legislative O
assembly) O
por- O
tion O
of O
the O
development O
and O
test O
set O
being O
a O
strong O
domain O
match O
to O
the O
training O
data. O
The O
news O
data O
in O
the O
development O
and O
test O
sets O
represented O
a O
domain O
mismatch. O
In O
the O
supervised O
low-resource O
task O
at O
WMT, O
there O
was O
an O
arguably O
low-resource O
(approximately O
60,000 O
lines O
of O
parallel O
text) O
language O
pair O
of O
German-Upper O
Sorbian. O
However, O
the O
test O
set O
was O
extremely O
well-matched O
to O
the O
training O
data O
(though O
not O
exact O
duplicates), O
resulting O
in O
surpris- O
ingly O
high O
automatic O
metric O
scores O
(BLEU O
scores O
in O
the O
50s O
and O
60s). O
In O
this O
AmericasNLP O
shared O
task, O
we O
observed O
perhaps O
the O
hardest O
scenario O
(outside O
of O
zero-shot): O
low O
resource O
with O
domain/dialect/orthographic O
mis- O
match. O
It O
should O
come O
as O
no O
surprise, O
then, O
that O
we O
observe O
extremely O
low O
automatic O
metric O
scores O
for O
this O
task. O
For O
both O
the O
Inuktitut O
and O
Upper O
Sorbian O
sys- O
tems, O
we O
know O
of O
community O
and/or O
government O
organizations O
that O
may O
be O
interested O
in O
using O
ma- B-TaskName
chine I-TaskName
translation I-TaskName
technology, O
for O
example O
as O
part O
of O
a O
computer O
aided O
translation O
(CAT) O
tool.10Pro- O
vided O
that O
human O
evaluation O
found O
the O
quality O
level O
of O
the O
machine B-TaskName
translation I-TaskName
output O
appropriately O
high O
(no O
human O
evaluation O
was O
performed O
in O
the O
Upper O
Sorbian O
task, O
and O
the O
Inuktitut O
human O
evalu- O
ation O
is O
ongoing), O
there O
appear O
to O
be O
clear O
suitable O
use O
cases O
here, O
such O
as O
as O
part O
of O
a O
human O
trans- O
lation O
workﬂow O
translating O
the O
Hansard O
as O
it O
is O
10For O
example, O
the O
presentation O
of O
the O
Upper O
Sorbian- O
German O
machine O
translation O
tool O
sotra O
(https://soblex. O
de/sotra/ O
) O
encourages O
users O
to O
proofread O
and O
correct O
the O
output O
where O
necessary: O
https://www.powtoon.com/ O
online-presentation/cr2llmDWRR9/produced O
or O
translating O
more O
of O
the O
same O
domain O
Upper O
Sorbian/German O
text. O
It O
is O
less O
clear, O
where O
there O
is O
a O
domain O
mismatch, O
whether O
the O
quality O
is O
anywhere O
near O
high O
enough O
for O
use O
in O
a O
CAT O
setting. O
We O
know O
that O
the O
usefulness O
of O
machine B-TaskName
translation I-TaskName
in O
CAT O
tools O
varies O
by O
translator O
(Koehn O
and O
Ger- O
mann, O
2014); O
some O
ﬁnd O
even O
relatively O
low-quality O
translations O
useful, O
while O
others O
beneﬁt O
only O
from O
very O
high-quality O
translations, O
and O
so O
on. O
There O
are O
also O
potential O
concerns O
that O
MT B-TaskName
may O
inﬂuence O
the O
way O
translators O
choose O
to O
translate O
text. O
But O
what O
about O
this O
low-resource, O
domain O
mis- O
match O
setting? O
While O
human O
evaluation O
would O
be O
the O
real O
test, O
we O
suspect O
that O
the O
output O
quality O
may O
be O
too O
low O
to O
be O
beneﬁcial O
to O
most O
translators. O
As O
a O
brief O
example, O
we O
consider O
the O
CHRFscores B-MetricName
that O
were O
generated O
between O
two O
Spanish O
sentences O
as O
a O
byproduct O
of O
the O
creation O
of O
our O
translation O
mem- O
ory O
submission. O
•Washington O
ha O
perdi O
do O
todos O
los O
partidos. O
(Washington O
has O
lost O
all O
the O
games.) O
• O
Continuaron O
visitan O
do O
todos O
los O
días. O
(They O
continued O
visiting O
every O
day.) O
In O
part O
on O
the O
basis O
of O
the O
10-character O
(spaces O
ignored) O
substring O
“do O
todos O
los” O
(for O
which O
“todos O
los” O
can O
be O
glossed O
as O
“every”, O
but O
the O
string-initial O
“do” O
sufﬁx O
belongs O
to O
two O
different O
verbs, O
one O
of O
which O
is O
in O
its O
past O
participle O
form O
and O
the O
other O
of O
which O
is O
in O
its O
present O
participle O
form), O
these O
sen- O
tences O
have O
a O
score O
of O
0.366 B-MetricValue
CHRF(if B-MetricName
we O
consider O
the O
ﬁrst O
to O
be O
the O
“system” O
output O
and O
the O
second O
to O
be O
the O
“reference”). O
Here O
of O
course O
both O
sentences O
are O
grammati- O
cal, O
but O
they O
are O
clearly O
not O
semantic O
equivalents. O
Nevertheless, O
comparing O
the O
two O
produces O
a O
CHRF B-MetricName
score O
comparable O
to O
the O
the O
highest O
scores O
observed O
in O
this O
task.11We O
argue O
then, O
that O
if O
the O
goal O
is O
CAT, O
then O
it O
may O
be O
better O
to O
consider O
a O
TM-based O
ap- O
proach, O
even O
though O
it O
has O
lower O
scores, O
given O
that O
CAT O
tools O
are O
well-equipped O
to O
handle O
TMs, O
and O
typically O
provide O
some O
sort O
of O
indication O
about O
the O
differences O
between O
the O
sentence O
to O
be O
translated O
and O
its O
fuzzy-match O
from O
the O
TM O
as O
a O
guide O
for O
the O
translator. O
In O
an O
MT-based B-TaskName
approach, O
the O
transla- O
tor O
may O
be O
confronted O
with O
ﬂuent O
text O
that O
is O
not O
semantically O
related O
to O
the O
source, O
ungrammatical O
language, O
or O
types O
of O
other O
problematic O
output. O
11We O
acknowledge O
that O
this O
is O
an O
imperfect O
comparison, O
since O
the O
scores O
in O
this O
task O
are O
of O
course O
not O
on O
Spanish O
output O
and O
thus O
should O
not O
be O
compared O
directly.232If O
the O
goal O
of O
these O
MT B-TaskName
tools O
is O
notCAT, O
but O
rather O
for O
a O
reader O
to O
access O
text O
in O
their O
preferred O
language, O
we O
expect O
that O
neither O
the O
MT B-TaskName
systems O
nor O
the O
TMs O
would O
provide O
the O
kind O
of O
quality O
that O
users O
of O
online O
MT B-TaskName
systems O
have O
come O
to O
expect. O
This O
raises O
questions O
of O
how O
to O
alert O
potential O
users O
to O
the O
potential O
for O
low-quality O
MT. B-TaskName
It O
is O
possible O
that O
there O
may O
be O
other O
use O
cases, O
in O
which O
case O
a O
downstream O
evaluation O
may O
be O
more O
appropriate O
than O
automatic O
metrics. O
B O
Pre- O
and O
Post-processing O
Details O
Training O
corpora O
(but O
not O
development O
or O
test O
corpora) O
were O
processed O
using O
the O
Moses O
clean-corpus-n.perl O
script O
(Koehn O
et O
al., O
2007), O
with O
a O
sentence O
length O
ratio O
of O
15:1 O
and O
minimum O
and O
maximum O
lengths O
of O
1 O
and O
200, O
re- O
spectively. O
All O
corpora O
were O
preprocessed O
with O
thenormalize-punctuation.perl O
script, O
with O
the O
language O
set O
to O
Spanish O
(since O
no O
language- O
speciﬁc O
rules O
are O
available O
for O
the O
other O
languages O
in O
this O
task), O
and O
all O
instances O
of O
U+FEFF O
ZERO O
WIDTH O
NO O
-BREAK O
SPACE O
were O
removed. O
The O
only O
additional O
language-speciﬁc O
preprocessing O
that O
we O
performed O
was O
to O
replace O
“+” O
with O
U+0268 O
LATIN O
SMALL O
LETTER O
I O
WITH O
STROKE O
in O
the O
Wixárika O
text; O
this O
prevents O
the O
text O
from O
being O
overseg- O
mented O
by O
the O
tokenizer, O
and O
is O
reverted O
in O
post- O
processing.12We O
note O
that O
it O
might O
be O
desirable O
to O
perform O
a O
similar O
replacement O
of O
apostrophes O
with O
a O
modiﬁer O
letter O
apostrophe, O
but O
because O
some O
of O
the O
training O
data O
was O
released O
in O
tokenized O
for- O
mat O
we O
were O
not O
conﬁdent O
that O
we O
could O
guarantee O
consistency O
in O
such O
an O
approach.13 O
All O
text O
is O
then O
tokenized O
with O
the O
Moses O
to- O
kenizer O
tokenizer.perl O
, O
with O
aggressive O
hy- O
phen O
splitting, O
language O
set O
to O
Spanish, O
and O
no O
HTML O
escaping.14Note O
that O
we O
apply O
the O
tok- O
enization O
even O
to O
already-tokenized O
training O
data, O
in O
the O
hopes O
of O
making O
the O
different O
datasets O
as O
consistent O
as O
possible. O
Postprocessing O
consists O
of O
unBPEing O
then O
detok- O
enizing O
using O
Moses’ O
detokenizer.perl O
. O
An O
extra O
step O
is O
needed O
for O
Wixárika O
to O
revert O
back O
to O
12Note, O
however, O
that O
the O
13a O
tokenizer O
used O
by O
sacrebleu O
(Post, O
2018) O
tokenizes O
“+”, O
meaning O
that O
BLEU B-MetricName
scores O
and O
other O
scores O
that O
incorporate O
word O
n-grams O
are O
artiﬁcially O
inﬂated O
for O
Wixárika. O
13With O
CHRFas B-MetricName
the O
main O
metric, O
this O
is O
less O
of O
a O
concern O
than O
it O
would O
be O
were O
the O
main O
metric O
BLEU B-MetricName
or O
human O
evalu- O
ation. O
We O
note O
that O
even O
the O
use O
of O
CHRF++, B-MetricName
with O
its O
use O
of O
word O
bigrams, O
would O
make O
this O
a O
concern. O
14tokenizer.perl O
-a O
-l O
es O
-no-escapethe O
“+” O
character. O
We O
also O
perform O
a O
small O
amount O
of O
extra O
language-speciﬁc O
postprocessing, O
which O
has O
limited O
effects O
on O
CHRF(it B-MetricName
primarily O
involves O
tokenization) O
with O
some O
effect O
on O
BLEU. B-MetricName
For O
ex- O
ample, O
for O
Guaraní, O
we O
delete O
spaces O
around O
apos- O
trophes O
and O
replace O
sequences O
of O
three O
periods O
with O
U+2026 O
HORIZONTAL O
ELLIPSIS O
. O
For O
Wixárika, O
we O
add O
a O
space O
after O
the O
“¿” O
and O
“¡” O
characters. O
For O
Nahuatl, O
we O
make O
sure O
that O
“$” O
is O
separated O
from O
alphabetic O
characters O
by O
a O
space. O
For O
Rará- O
muri, O
we O
replace O
three O
periods O
with O
the O
horizontal O
ellipsis, O
convert O
single O
apostrophes O
or O
straight O
quo- O
tation O
marks O
before O
“u” O
or O
“U” O
to O
U+2018 O
LEFT O
SINGLE O
QUOTATION O
MARK B-DatasetName
and O
remove O
the O
space O
between O
it O
and O
the O
letter, O
and O
then O
convert O
any O
re- O
maining O
apostrophes O
or O
single O
straight O
quotes O
to O
U+2019 O
RIGHT O
SINGLE O
QUOTATION O
MARK O
as O
well O
as O
removing O
any O
surrounding O
spaces. O
These O
are O
all O
heuristics O
based O
on O
frequencies O
of O
those O
char- O
acters O
in O
the O
development O
data, O
and O
we O
note O
that O
their O
effect O
on O
BLEU B-MetricName
scores O
and O
CHRFscores B-MetricName
is O
minimal O
(as O
measured O
on O
development O
data). O
C O
Coverage O
The O
Wixárika O
and O
Guaraní O
data O
was O
provided O
un- O
tokenized, O
but O
Nahuatl O
and O
Rarámuri O
datasets O
con- O
tained O
training O
data O
that O
was O
tokenized O
while O
the O
development O
and O
test O
data O
was O
untokenized. O
Here O
we O
brieﬂy O
illustrate O
the O
impact O
of O
the O
mismatch, O
through O
token O
and O
type O
coverage. O
In O
Table O
7, O
we O
show O
what O
percentage O
of O
target O
language O
devel- O
opment O
tokens O
(and O
types) O
were O
also O
observed O
in O
the O
training O
data, O
before O
and O
after O
applying O
tok- O
enization. O
Table O
8 O
shows O
the O
same O
for O
source O
lan- O
guage. O
Table O
9 O
shows O
source O
coverage O
for O
the O
test O
data O
instead O
of O
the O
development O
data. O
Finally, O
Ta- O
ble O
10 O
shows O
what O
percentage O
of O
the O
source O
test O
data O
is O
contained O
in O
the O
development O
set O
. O
Unsurpris- O
ingly, O
coverage O
is O
higher O
across O
the O
board O
for O
Span- O
ish O
(source), O
which O
is O
less O
morphologically O
com- O
plex O
than O
the O
target O
languages. O
Spanish-Rarámuri O
has O
the O
lowest O
coverage O
in O
both O
source O
and O
target. O
Spanish-Nahuatl O
has O
the O
second-highest O
coverage O
on O
the O
source O
side, O
but O
not O
on O
the O
target O
side, O
per- O
haps O
due O
to O
the O
historical O
content O
in O
the O
training O
data O
and/or O
the O
orthographic O
conversions O
applied. O
Spanish-Guaraní O
has O
the O
highest O
coverage O
on O
both O
source O
and O
target. O
Applying O
BPE O
results O
in O
approximately O
100% O
coverage, O
but O
it O
is O
still O
worth O
noting O
the O
low O
full- O
word O
coverage, O
as O
novel O
vocabulary O
may O
be O
hard O
for O
the O
systems O
to O
translate O
or O
to O
generate. O
For O
all O
languages O
except O
Guaraní, O
the O
ﬁrst O
half O
of O
the O
development O
set O
had O
higher O
target O
language O
coverage O
on O
the O
second O
half O
of O
the O
development O
set, O
as O
compared O
to O
training O
target O
language O
cover- O
age O
on O
the O
full O
development O
set O
(or O
second O
half O
of O
the O
development O
set), O
which O
may O
explain O
both O
the O
improved O
performance O
of O
systems O
that O
trained O
on O
development O
data O
and O
the O
quality O
of O
the O
translation O
memory O
system. O