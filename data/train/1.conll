Proceedings O
of O
the O
3rd O
Wordplay: O
When O
Language O
Meets O
Games O
Workshop O
(Wordplay O
2022) O
, O
pages O
59 O
=- O
62 O
July O
14, O
2022 O
©2022 O
Association O
for O
Computational O
Linguistics O
Automatic O
Exploration B-TaskName
of I-TaskName
Textual I-TaskName
Environments I-TaskName
with O
Language-Conditioned B-MethodName
Autotelic I-MethodName
Agents I-MethodName
Laetitia O
Teodorescu O
Inria O
laetitia.teodorescu@inria.frXingdi O
Yuan O
Microsoft O
Research O
eric.yuan@microsoft.com O
Marc-Alexandre O
Côté O
Microsoft O
Research O
macote@microsoft.comPierre-Yves O
Oudeyer O
Inria O
pierre-yves.oudeyer@inria.fr O
This O
extended O
abstract O
discusses O
the O
opportu- O
nities O
and O
challenges O
of O
studying O
intrinsically- B-MethodName
motivated I-MethodName
agents I-MethodName
for O
exploration B-TaskName
in I-TaskName
textual I-TaskName
envi- I-TaskName
ronments. I-TaskName
Humans O
begin O
their O
life O
with O
very O
few O
skills, O
and O
over O
the O
course O
of O
only O
a O
few O
years O
learn O
complex O
motor O
coordination O
and O
locomotion O
capabilities, O
be- O
gin O
mastering O
vocalization O
and O
language, O
and O
form O
a O
rich O
model O
of O
their O
physical O
and O
social O
surround- O
ings. O
One O
of O
the O
main O
drivers O
of O
this O
phenomenal O
knowledge O
acquisition O
is O
intrinsically-motivated O
ex- O
ploration O
(Oudeyer O
and O
Kaplan, O
2007), O
for O
instance O
through O
exploratory O
play O
(Chu O
and O
Schulz, O
"2020;" O
Davidson O
et O
al., O
2022). O
The O
developmental O
perspec- O
tive O
on O
AI O
tries O
to O
emulate O
this O
exploratory O
behavior O
in O
artificial O
agents O
to O
achieve O
mastery O
of O
diverse O
and O
complex O
repertoires O
of O
skills O
(Forestier O
et O
al., O
2017). O
When O
placed O
in O
open-ended O
environments, O
a O
successful O
intrinsically O
motivated O
agent O
will O
ex- O
plore O
the O
space O
of O
interesting O
and O
diverse O
outcomes, O
ignoring O
random O
and O
unachievable O
subspaces O
of O
the O
world, O
reusing O
its O
previously O
acquired O
skills O
as O
stepping O
stones O
(Stanley O
and O
Lehman, O
2015) O
to O
discover O
new O
ones. O
One O
possible O
implementation O
of O
exploration O
in O
RL O
agents O
are O
so-called O
autotelic B-MethodName
agents I-MethodName
(Colas, O
2021), O
that O
is, O
goal-conditioned O
Reinforcement O
Learning O
(RL) O
agents O
operating O
in O
rewardless O
en- O
vironments O
that O
are O
able O
to O
choose O
what O
goal O
to O
pursue. O
In O
this O
case, O
the O
reward O
is O
given O
by O
a O
goal- O
satisfaction O
function O
and O
not O
extrinsically O
by O
the O
environment. O
Goal-conditioned O
policies O
have O
been O
extensively O
studied O
in O
the O
case O
of O
extrinsic O
goals O
(Schaul O
et O
al., O
2015). O
In O
the O
case O
of O
intrinsically O
chosen O
goals, O
the O
goal-selection O
mechanism O
allows O
autotelic B-MethodName
agents I-MethodName
to O
form O
a O
self-curriculum, O
progress- O
ing O
from O
easier O
to O
increasingly O
harder O
goals O
until O
all O
achievable O
skills O
have O
been O
mastered. O
In O
this O
per- O
spective, O
the O
goal O
representation O
is O
of O
paramount O
importance. O
Most O
previous O
works O
(for O
instance O
Andrychowicz O
et O
al. O
(2017)) O
have O
used O
concreteend-state O
representations O
such O
as O
raw O
observations, O
images O
or O
embeddings, O
which O
has O
some O
drawbacks. O
A O
goal O
should O
be O
insensitive O
to O
changes O
in O
the O
envi- O
ronment O
that O
are O
uncontrollable O
(such O
as O
the O
color O
of O
the O
sky), O
to O
avoid O
the O
agent O
targeting O
impossi- O
ble O
goals O
(for O
instance O
changing O
the O
sky O
color), O
or O
to O
provide O
useful O
abstraction O
for O
goal O
achievement O
(such O
as O
considering O
the O
goal O
of O
navigating O
to O
the O
garden O
is O
satisfied O
regardless O
of O
sky O
color). O
Further- O
more, O
the O
agent O
should O
ideally O
be O
able O
to O
combine O
known O
goals O
into O
novel O
ones. O
Goals O
expressed O
as O
language O
(Tam O
et O
al., O
"2022;" O
Colas O
et O
al., O
"2020;" O
Mu O
et O
al., O
2022) O
fulfill O
both O
conditions: O
they O
are O
at O
once O
abstract O
and O
combinatorial O
(Szabó, O
"2020);" O
they O
are O
thus O
a O
prime O
way O
for O
autotelic B-MethodName
agents I-MethodName
to O
self-specify O
goals O
to O
be O
executed O
in O
the O
environment. O
1 O
A O
bridge O
between O
autotelic B-MethodName
agents I-MethodName
and O
text O
environments O
The O
main O
point O
of O
this O
essay O
is O
the O
relevance O
of O
studying O
language O
autotelic B-MethodName
agents I-MethodName
in O
textual O
en- O
vironments O
(Côté O
et O
al., O
"2018;" O
Hausknecht O
et O
al., O
"2020;" O
Wang O
et O
al., O
2022), O
both O
for O
testing O
explo- O
ration O
methods O
in O
a O
context O
that O
is O
at O
once O
simple O
experimentally O
and O
rich O
from O
the O
perspective O
of O
environment O
"interactions;" O
and O
for O
transferring O
the O
skills O
of O
general-purpose O
agents O
trained O
to O
explore O
in O
an O
autonomous O
way O
to O
the O
predefined O
tasks O
of O
textual O
environment O
benchmarks. O
We O
identify O
three O
key O
properties, O
plus O
one O
additional O
benefit, O
of O
text O
worlds: O
1 O
Depth O
of O
learnable O
skills: O
skills O
learnable O
in O
the O
world O
should O
involve O
multiple O
low-level O
ac- O
tions O
and O
be O
nested, O
such O
that O
mastering O
one O
skill O
opens O
up O
the O
possibility O
of O
mastering O
more O
com- O
plex O
skills. O
Interactive O
fiction O
(IF) O
(Hausknecht O
et O
al., O
2020) O
games O
usually O
feature O
an O
entire O
narra- O
tive O
and O
extensive O
maps, O
such O
that O
navigating O
and O
passing O
obstacles O
requires O
many O
successful O
actions O
(and O
subgoals) O
to O
be O
completed. O
While O
the O
origi-59nal O
TextWorld O
levels O
were O
not O
as O
deep O
as O
would O
be O
desirable, O
other O
non-IF O
text O
worlds O
such O
as O
Science- O
World O
feature O
nested O
repertoires O
of O
skills O
(such O
as O
learning O
to O
navigate O
to O
learn O
to O
grow O
plants O
to O
learn O
the O
rules O
of O
Mendelian O
"genomics);" O
2 O
Breadth O
of O
the O
world: O
there O
should O
be O
many O
paths O
to O
explore O
in O
the O
"environment;" O
this O
ensures O
that O
we O
train O
agents O
that O
are O
able O
to O
follow O
a O
wide O
diversity O
of O
possible O
goals, O
instead O
of O
learning O
to O
achieve O
goals O
along O
a O
linear O
path. O
This O
allows O
us O
to O
study O
generally-capable O
agents. O
Some O
IF O
games O
are O
very O
linear, O
having O
a O
clear O
progression O
from O
start O
to O
finish O
(e.g., O
Acorn O
Court, O
"Detective;" O
others O
have O
huge O
maps O
that O
an O
agent O
has O
to O
explore O
before O
it O
can O
progress O
in O
the O
quest O
(e.g., O
Zork, O
Hitchhiker’s O
Guide O
to O
the O
Galaxy). O
Exploration O
heuristics O
are O
a O
part O
of O
some O
successful O
methods O
for O
playing O
IF O
with O
RL O
(Yao O
et O
al., O
2020). O
ScienceWorld O
(Wang O
et O
al., O
2022) O
has O
an O
underlying O
physical O
engine O
allowing O
for O
a O
combinatorial O
explosion O
of O
possibilities O
like O
making O
new O
objects, O
combining O
existing O
objects, O
changing O
states O
of O
matter, O
etc. O
3 O
Niches O
of O
progress O
: O
real-world O
environments O
have O
both O
easy O
skills O
and O
unlearnable O
skills. O
Our O
simulated O
environments O
should O
mimic O
this O
property O
to O
test O
the O
agent’s O
ability O
to O
focus O
only O
on O
highly O
learnable O
parts O
of O
the O
space O
and O
avoid O
spending O
effort O
on O
uncontrollable O
aspects O
of O
the O
environment. O
In O
textual O
environments, O
high O
depth O
implies O
that O
some O
skills O
are O
much O
more O
learnable O
than O
others, O
already O
implementing O
some O
progress O
niches. O
The O
combinatorial O
property O
of O
language O
goals O
allows O
us O
to O
define O
many O
unfeasible O
goals, O
goals O
that O
an O
autotelic B-MethodName
agent I-MethodName
has O
to O
avoid O
spending O
too O
many O
resources O
on. O
4 O
Language O
representation O
for O
goals: O
a O
language-conditioned O
agent O
has O
to O
learn O
to O
ground O
its O
goal O
representation O
in O
its O
environment O
(Harnad, O
"1990;" O
Hill O
et O
al., O
2020), O
to O
know O
when O
a O
given O
ob- O
servation O
or O
sequence O
of O
observations O
satisfies O
a O
given O
goal, O
or O
to O
know O
what O
goals O
were O
achieved O
in O
a O
given O
trajectory. O
This O
grounding O
is O
made O
much O
simpler O
in O
environments O
with O
a O
single O
"modality;" O
relating O
language O
goals O
to O
language O
observations O
is O
simpler O
than O
grounding O
language O
in O
pixels O
or O
im- O
age O
embeddings. O
This O
allows O
us O
to O
study O
language- B-TaskName
based I-TaskName
exploration I-TaskName
in O
a O
simpler O
context.2 O
Drivers O
of O
exploration O
in O
autotelic B-MethodName
agents I-MethodName
We O
identify O
three O
main O
drivers O
of O
exploration O
in O
autotelic B-MethodName
agents. I-MethodName
Environments O
we O
use O
should O
sup- O
port O
exploration O
algorithms O
that O
implement O
these O
"principles;" O
the O
resulting O
agents O
then O
have O
a O
chance O
to O
acquire O
a O
diverse O
set O
of O
skills O
that O
can O
be O
re- O
purposed O
for O
solving O
the O
benchmarks O
proposed O
by O
textual O
environments. O
1 O
Goal O
self-curriculum: O
automatic O
goal O
se- O
lection O
(Portelas O
et O
al., O
2020) O
allows O
the O
agent O
to O
refine O
its O
skills O
on O
the O
edge O
of O
what O
it O
currently O
masters. O
Among O
metrics O
used O
to O
select O
goals O
are O
novelty/surprise B-MetricName
of I-MetricName
a I-MetricName
goal I-MetricName
(Tam O
et O
al., O
"2022;" O
Burda O
et O
al., O
2018), O
intermediate B-MetricName
competence I-MetricName
on I-MetricName
goals I-MetricName
(Campero O
et O
al., O
2020), O
ensemble B-MetricName
disagreement I-MetricName
(Pathak O
et O
al., O
2019), O
or O
(absolute) B-MetricName
learning I-MetricName
progress I-MetricName
(Colas O
et O
al., O
2019). O
Progress O
niches O
in O
textual O
en- O
vironments O
support O
such O
goal O
"curriculum;" O
2 O
Additional O
exploration O
after O
goal O
achieve- O
ment: O
after O
achieving O
a O
given O
goal, O
the O
agent O
con- O
tinue O
to O
run O
for O
a O
time O
to O
push O
the O
boundary O
of O
explored O
space O
(Ecoffet O
et O
al., O
2021). O
The O
depth O
of O
text O
worlds O
makes O
goal O
chaining O
relevant, O
such O
that O
an O
agent O
that O
has O
achieved O
a O
known O
goal O
can O
imagine O
additional O
goals O
to O
pursue. O
Random O
explo- O
ration O
can O
also O
be O
used O
once O
a O
known O
goal O
has O
been O
achieved. O
Agents O
exploring B-TaskName
in I-TaskName
textual I-TaskName
environments I-TaskName
and O
choosing O
uniformly O
among O
the O
set O
of O
valid O
ac- O
tions O
in O
a O
given O
state O
have O
a O
high O
chance O
of O
effecting O
meaningful O
changes O
in O
the O
environment, O
making O
discovery O
of O
new O
skills O
probable. O
This O
property O
is O
relevant O
in O
any O
environment O
with O
high O
depth, O
and O
both O
IF O
and O
ScienceWorld O
fit O
this O
description. O
3 O
Goal O
composition: O
as O
mentioned O
above, O
this O
means O
using O
the O
compositionality O
afforded O
by O
lan- O
guage O
goals O
to O
imagine O
novel O
goals O
in O
the O
envi- O
ronment O
(Colas O
et O
al., O
2020). O
Goal-chaining O
is O
an O
example O
of O
composition, O
but O
language O
offers O
many O
other O
composition O
possibilities, O
such O
as O
recombin- O
ing O
known O
verbs, O
nouns O
and O
attributes O
in O
novel O
ways, O
or O
making O
analogies. O
This O
is O
relevant O
if O
there O
exists O
some O
transfer O
between O
the O
skills O
required O
to O
accomplish O
similar O
goal O
constructions O
(e.g., O
pick- O
ing O
up O
an O
apple O
and O
picking O
up O
a O
carrot O
requires O
very O
similar O
actions O
if O
both O
are O
in O
the O
kitchen). O
This O
is O
at O
least O
partially O
TRUE O
in O
textual O
environments O
where O
objects O
of O
the O
same O
type O
usually O
have O
similar O
affordances.603 O
Challenges O
for O
autotelic B-MethodName
textual I-MethodName
agents I-MethodName
Text O
worlds O
bring O
a O
set O
of O
unique O
challenges O
for O
autotelic B-MethodName
agents, I-MethodName
among O
which O
we O
foresee: O
1.The O
goal O
space O
can O
be O
very O
large. O
An O
agent O
with O
a O
limited O
training O
budget O
needs O
to O
focus O
on O
a O
subset O
of O
the O
goal O
space, O
possibly O
discovering O
only O
a O
fraction O
of O
what O
is O
discoverable O
within O
the O
environment. O
This O
calls O
for O
finer O
goal-sampling O
approaches O
that O
encourage O
the O
agent O
at O
making O
the O
most O
out O
of O
its O
allocated O
time O
to O
explore O
the O
environ- O
ment. O
In O
addition, O
we O
need O
better O
methods O
to O
push O
the O
agent’s O
exploration O
towards O
certain O
parts O
of O
the O
space O
(e.g., O
warm-starting O
the O
replay O
buffer O
with O
existing O
trajectories, O
providing O
linguistic O
common- O
sense O
"knowledge);" O
2.The O
action O
space O
is O
also O
very O
large O
in O
tex- O
tual O
environments, O
making O
exploration O
(especially O
methods O
based O
on O
random O
action O
selection) O
poten- O
tially O
challenging. O
3.Agents O
must O
be O
trajectory-efficient O
for O
a O
given O
"goal;" O
complex O
goals O
might O
be O
seen O
only O
"once;" O
4.Catastrophic O
forgetting O
needs O
to O
be O
alleviated, O
so O
that O
learning O
to O
achieve O
new O
goals O
does O
not O
im- O
pair O
the O
skills O
learned O
"previously;" O
5.Partial O
observability O
means O
that O
agent O
archi- O
tectures O
need O
to O
include O
some O
form O
of O
memory. O
Agents O
trained O
in O
such O
environments O
will O
learn O
a O
form O
of O
language O
use, O
not O
by O
predicting O
the O
most O
likely O
sequence O
of O
words O
from O
a O
large-scale O
dataset O
(Radford O
and O
Narasimhan, O
"2018;" O
Brown O
et O
al., O
2020) O
but O
by O
learning O
to O
use O
it O
pragmatically O
to O
effect O
changes O
in O
the O
environment. O
Of O
course, O
the O
limits O
of O
the O
autotelic B-MethodName
agent’s I-MethodName
world O
will O
mean O
the O
limits O
of O
its O
"language;" O
an O
interesting O
development O
is O
to O
build O
agents O
that O
explore B-TaskName
textual I-TaskName
environments I-TaskName
to O
refine O
external O
linguistic O
knowledge O
provided O
by O
a O
pretrained O
language O
model. O
This O
external O
knowledge O
repository O
can O
be O
seen O
as O
culturally- O
accumulated O
common O
sense, O
a O
perspective O
that O
is O
related O
to O
so-called O
Vygotskian O
AI O
(Colas, O
2021) O
in O
which O
a O
developmental O
agent O
learns O
by O
interacting O
with O
an O
external O
social O
partner O
that O
imparts O
outside O
language O
knowledge O
and O
organizes O
the O
world O
so O
as O
to O
facilitate O
the O
autotelic B-MethodName
agent’s I-MethodName
exploration. O
To O
conclude, O
textual O
environments O
are O
ideal O
testbeds O
for O
autotelic B-MethodName
language-conditioned I-MethodName
agents, I-MethodName
and O
conversely O
such O
agents O
can O
bring O
progress O
on O
text O
world O
benchmarks. O
There O
is O
also O
promise O
in O
the O
interaction O
between O
exploratory O
agents O
and O
large O
language O
models O
encoding O
exterior O
linguis-tic O
knowledge. O
Preliminary O
steps O
have O
been O
taken O
in O
this O
direction O
(Madotto O
et O
al., O
2020) O
but O
the O
full O
breadth O
of O
drivers O
of O
exploration O
we O
identify O
has O
yet O
to O
be O
studied. O
We O
hope O
to O
foster O
discussion, O
define O
concrete O
implementations O
and O
identify O
challenges O
by O
bringing O
together O
the O
developmental O
perspective O
on O
AI O
and O
the O
textual O
environment O
community. O
