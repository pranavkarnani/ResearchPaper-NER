Proceedings O
of O
the O
Second O
Workshop O
on O
Language O
Technology O
for O
Equality, O
Diversity O
and O
Inclusion O
, O
pages O
312 O
- O
316 O
May O
27, O
2022 O
©2022 O
Association O
for O
Computational O
Linguistics O
MUCS@Text-LT-EDI@ACL O
2022: O
Detecting B-TaskName
Sign I-TaskName
of I-TaskName
Depression I-TaskName
from I-TaskName
Social I-TaskName
Media I-TaskName
Text I-TaskName
using O
Supervised O
Learning O
Approach O
Asha O
Hegde1 O
a, O
Sharal O
Coelho1 O
b, O
Ahmad O
Elyas O
Dashti1 O
c,Hosahalli O
Lakshmaiah O
Shashirekha1 O
d O
1Department O
of O
Computer O
Science, O
Mangalore O
University, O
Mangalore, O
India O
{ahegdekasha,bsharalmucs,celyas.dashti808,dhlsrekha}@gmail.com O
Abstract O
Social O
media O
has O
seen O
enormous O
growth O
in O
its O
users O
recently O
and O
knowingly O
or O
unknowingly O
the O
behavior O
of O
a O
person O
will O
be O
reflected O
in O
the O
comments O
she/he O
posts O
on O
social O
media. O
Users O
having O
the O
sign O
of O
depression O
may O
post O
nega- O
tive O
or O
disturbing O
content O
seeking O
the O
attention O
of O
other O
users. O
Hence, O
social O
media O
data O
can O
be O
analysed O
to O
check O
whether O
the O
users’ O
have O
the O
sign O
of O
depression O
and O
help O
them O
to O
get O
through O
the O
situation O
if O
required. O
However, O
as O
analyzing O
the O
increasing O
amount O
of O
social O
me- O
dia O
data O
manually O
in O
laborious O
and O
error-prone, O
automated O
tools O
have O
to O
be O
developed O
for O
the O
same. O
To O
address O
the O
issue O
of O
detecting B-TaskName
the I-TaskName
sign I-TaskName
of I-TaskName
depression I-TaskName
content I-TaskName
on I-TaskName
social I-TaskName
media, I-TaskName
in O
this O
paper, O
we O
- O
team O
MUCS, O
describe O
an O
En- O
semble O
of O
Machine O
Learning O
(ML) O
models O
and O
a O
Transfer O
Learning O
(TL) O
model O
submitted O
to O
"Detecting B-TaskName
Signs I-TaskName
of I-TaskName
Depression I-TaskName
from I-TaskName
Social I-TaskName
Media I-TaskName
Text-LT-EDI@ACL I-TaskName
2022" O
(DepSign- O
LT-EDI@ACL-2022) O
shared O
task O
at O
Associa- O
tion O
for O
Computational O
Linguistics O
(ACL) O
2022. O
Both O
frequency O
and O
text O
based O
features O
are O
used O
to O
train O
an O
Ensemble O
model O
and O
Bidirectional B-MethodName
Encoder I-MethodName
Representations I-MethodName
from I-MethodName
Transformers I-MethodName
(BERT) I-MethodName
fine-tuned O
with O
raw O
text O
is O
used O
to O
train O
the O
TL O
model. O
Among O
the O
two O
models, O
the O
TL O
model O
performed O
better O
with O
a O
macro B-MetricName
av- I-MetricName
eraged I-MetricName
F-score I-MetricName
of O
0.479 B-MetricValue
and O
placed O
18thrank O
in O
the O
shared O
task. O
The O
code O
to O
reproduce O
the O
proposed O
models O
is O
available O
in O
github O
page1. O
1 O
Introduction O
A O
person O
feeling O
unimportant, O
useless, O
or O
unhappy O
may O
be O
a O
sign O
of O
depression. O
Depression O
is O
one O
of O
the O
most O
severe O
mental O
health O
conditions O
which O
may O
be O
unnoticed, O
undiagnosed O
and O
untreated O
in O
many O
cases. O
People O
worldwide O
suffer O
from O
depres- O
sion O
and O
the O
affected O
person O
may O
operate O
poorly O
at O
work, O
studies, O
and O
in O
the O
community. O
Recent O
research O
studies O
have O
shown O
that O
the O
popularity O
of O
1https://github.com/hegdekasha/ O
Detecting-sign-of-depressionsocial B-TaskName
media I-TaskName
networks O
in O
one’s O
life O
is O
increasing O
day O
by O
day. O
People O
are O
using O
social O
media O
to O
share O
their O
thoughts, O
feelings, O
emotions O
and O
sentiments O
(Islam O
et O
al., O
2018). O
Knowingly O
or O
unknowingly O
the O
behavior O
of O
a O
person O
will O
be O
reflected O
in O
the O
comments O
she/he O
posts O
on O
social O
media O
(Sampath O
et O
al., O
2022a; O
Ravikiran O
et O
al., O
2022; O
Chakravarthi O
et O
al., O
2022; O
Bharathi O
et O
al., O
2022; O
Priyadharshini O
et O
al., O
2022). O
Social O
media O
users O
who O
are O
usually O
in O
depression O
try O
to O
seek O
the O
attention O
and O
sympathy O
of O
others O
by O
posting O
negative O
and O
disturbing O
mes- O
sages O
or O
requesting O
help. O
Some O
have O
even O
reached O
to O
the O
extent O
of O
going O
live O
on O
social O
media O
before O
taking O
drastic O
steps O
such O
as O
suicide O
(Chakravarthi, O
2020; O
Chakravarthi O
et O
al., O
2021; O
Chakravarthi O
and O
Muralidaran, O
2021). O
Due O
to O
all O
these O
issues, O
under- O
standing O
mental O
health O
on O
social O
media O
has O
become O
a O
popular O
field O
of O
study O
(Alhuzali O
et O
al., O
2021). O
Studies O
have O
indicated O
that O
the O
analysis B-TaskName
of I-TaskName
the I-TaskName
messages I-TaskName
posted I-TaskName
on I-TaskName
social I-TaskName
media I-TaskName
platforms O
by O
the O
users O
can O
help O
to O
predict O
the O
sign O
of O
depression O
(Chiong O
et O
al., O
2021) O
of O
the O
users O
and O
the O
early O
prediction O
can O
help O
the O
users O
to O
get O
through O
the O
situation. O
Researchers O
are O
exploring O
to O
analyze O
social O
media O
content O
to O
predict O
the O
mental O
health O
of O
users O
in O
order O
to O
lend O
a O
helping O
hand O
to O
the O
needy O
at O
the O
earliest. O
In O
this O
paper, O
we O
- O
team O
MUCS, O
describe O
the O
models O
submitted O
to O
DepSign- O
LT-EDI@ACL O
20222shared O
task O
to O
detect O
signs O
of O
depression O
in O
social O
media O
text O
and O
classify O
them O
into O
into O
three O
categories: O
"not O
depressed", O
"mod- O
erately O
depressed", O
and O
"severely O
depressed". O
Two O
models: O
i) O
An O
ensemble O
of O
ML O
classifiers, O
namely: O
Random B-MethodName
Forest I-MethodName
(RF), I-MethodName
Multinomial B-MethodName
Naive I-MethodName
Bayes I-MethodName
(MNB), I-MethodName
Multi-Layer B-MethodName
Perceptron I-MethodName
(MLP), I-MethodName
and O
Gra- B-MethodName
dient I-MethodName
Boosting I-MethodName
(GB) I-MethodName
with I-MethodName
soft I-MethodName
voting I-MethodName
ii) O
TL O
model O
with O
BERT, B-MethodName
are O
proposed O
to O
classify O
the O
given O
input O
into O
one O
of O
the O
three O
predefined O
categories. O
The O
rest O
of O
the O
article O
is O
structured O
as O
follows: O
A O
review O
of O
relevant O
work O
is O
included O
in O
Section O
2, O
and O
the O
2https://competitions.codalab.org/competitions/36410312methodology O
is O
discussed O
in O
Section O
3. O
Experi- O
ments, O
results, O
and O
error O
analysis O
are O
described O
in O
Section O
4 O
followed O
by O
concluding O
the O
paper O
with O
future O
work O
in O
Section O
5. O
2 O
Literature O
Review O
Researchers O
have O
experimented O
various O
methodolo- O
gies O
to O
build O
systems O
capable O
of O
detecting O
the O
signs O
of O
depression O
in O
social O
media O
content O
and O
a O
few O
of O
the O
relevant O
ones O
are O
described O
below: O
To O
analyze O
suicide O
ideation O
symptoms O
on O
Red- O
dit O
social O
media, O
Tadesse O
et O
al. O
(2020) O
developed O
a O
combined O
Long O
Short O
Term O
Memory O
(LSTM) O
- O
Convolutional O
Neural O
Network O
(CNN) O
model O
based O
on O
Word2Vec O
features O
and O
obtained O
93.8% O
accu- O
racy. O
Haque O
et O
al. O
(2021) O
implemented O
the O
Boruta O
algorithm O
in O
association O
with O
RF O
classifier O
to O
pre- O
dict O
depression O
in O
kids O
and O
teenagers O
aged O
from O
4 O
to O
17. O
Their O
proposed O
model O
was O
evaluated O
on O
Youth O
Minds O
Matter O
(YMM) O
dataset O
and O
their O
model O
pre- O
dicted O
the O
depressed O
classes O
with O
95% O
accuracy. O
To O
identify O
the O
signs O
of O
depression O
in O
Twitter, O
K O
S O
et O
al. O
(2019) O
used O
Word2Vec O
word O
embeddings O
to O
represent O
the O
Tweets O
and O
train O
the O
combination O
of O
the O
LSTM O
and O
CNN O
model O
and O
Support O
Vec- O
tor O
Machine O
(SVM). O
The O
LSTM O
and O
CNN O
model O
combination O
and O
SVM O
model O
obtained O
an O
overall O
weighted O
avg O
F1-scores O
of O
0.97 O
and O
0.85 O
respec- O
tively. O
Zygadło O
et O
al. O
(2021) O
employed O
Naive O
Bayes, O
SVM, O
and O
BERT O
for O
sentiment O
and O
emotion O
recog- O
nition O
in O
English O
and O
Polish O
texts. O
They O
built O
COR- O
TEX3- O
a O
Polish O
version O
of O
the O
dataset O
for O
senti- O
ment O
and O
emotion O
recognition. O
BERT-based O
clas- O
sifier O
achieved O
accuracies O
of O
over O
90% O
and O
around O
80% O
for O
sentiment O
and O
emotion O
classification O
re- O
spectively. O
Hämäläinen O
et O
al. O
(2021) O
have O
created O
a O
dataset O
for O
detecting O
depression O
in O
Thai O
blog O
posts O
and O
tested O
it O
with O
four O
different O
models: O
(i) O
Bidirectional O
LSTM O
(BiLSTM) O
based O
model O
using O
Open-Source O
Neural O
Machine O
Translation O
(Open- O
NMT)4toolkit O
(ii) O
LSTM O
model O
with O
Word2Vec O
features, O
(iii) O
Thai O
BERT5model, O
and O
(iv) O
Multilin- O
gual O
BERT O
model. O
Among O
these O
models, O
the O
Thai O
BERT O
model O
achieved O
the O
highest O
overall O
accuracy O
of O
77.53%. O
Even O
though O
several O
techniques O
have O
been O
de- O
veloped O
to O
detect O
the O
sign O
of O
depression O
in O
social O
3https://github.com/azygadlo/CORTEX O
4https://github.com/OpenNMT/OpenNMT-py O
5https://github.com/ThAIKeras/bertmedia O
text, O
there O
are O
no O
full-fledged O
models O
for O
all O
datasets. O
Further, O
the O
trend O
in O
posting O
comments O
on O
social O
media O
changes O
frequently O
because O
of O
cre- O
ative O
users. O
Hence, O
this O
necessitates O
the O
need O
for O
the O
development O
of O
new O
models O
to O
detect O
the O
sign O
of O
depression O
in O
a O
social O
media O
text. O
3 O
Methodology O
The O
proposed O
methodology O
includes O
two O
distinct O
models O
namely: O
i) O
Ensemble O
of O
ML O
classifiers O
and O
ii) O
TL O
model O
with O
BERT, B-MethodName
for O
detecting O
the O
sign O
of O
depression O
in O
social O
media O
text. O
Description O
of O
the O
two O
models O
are O
given O
below: O
3.1 O
Ensemble O
of O
Machine O
Learning O
Classifiers O
The O
proposed O
Ensemble O
of O
ML O
classifiers O
consists O
of O
Pre-processing, O
Feature O
Extraction O
and O
Model O
Building O
steps O
and O
the O
framework O
of O
the O
proposed O
model O
is O
shown O
in O
Figure O
1. O
Each O
of O
the O
steps O
are O
explained O
below: O
Pre-processing O
- O
Dataset O
is O
pre-processed O
to O
remove O
punctuation, O
digits, O
and O
stopwords, O
as O
they O
do O
not O
contribute O
to O
the O
classification O
task. O
The O
En- O
glish O
stopwords O
list O
available O
at O
Natural O
Language O
Tool O
Kit O
(NLTK) O
library6is O
used O
to O
remove O
stop- O
6https://www.nltk.org313words O
and O
Porter O
Stemmer7is O
used O
to O
reduce O
the O
words O
to O
their O
stems. O
Feature O
Extraction O
- O
As O
the O
given O
dataset O
is O
imbalanced, O
resampling O
is O
carried O
out O
using O
ran- O
domoversampling8technique O
to O
bring O
balance O
in O
the O
dataset. O
Frequency O
based O
features, O
namely: O
TF- O
IDF O
of O
character O
bigrams O
and O
trigrams O
and O
word O
unigrams O
and O
text O
based O
features, O
namely: O
count O
of O
words O
and O
characters O
followed O
by O
the O
count O
of O
adjectives, O
adverbs, O
nouns, O
and O
pronouns O
are O
ex- O
tracted. O
These O
features O
are O
combined O
and O
used O
to O
train O
the O
Ensemble O
of O
ML O
classifiers. O
The O
num- O
ber O
of O
character O
bigrams O
and O
trigrams O
extracted O
amounts O
to O
9,024 O
and O
word O
unigrams O
amounts O
to O
13,169. O
Model O
Building O
- O
ML O
classifiers O
are O
generally O
ensembled O
by O
making O
use O
of O
the O
strength O
of O
one O
classifier O
to O
overcome O
the O
weakness O
of O
another O
clas- O
sifier O
to O
improve O
the O
results. O
RF, B-MethodName
MLP, I-MethodName
MNB, I-MethodName
and O
GB B-MethodName
classifiers O
are O
ensembled O
to O
detect B-TaskName
the I-TaskName
sign I-TaskName
of I-TaskName
depression I-TaskName
in I-TaskName
social I-TaskName
media I-TaskName
text I-TaskName
and O
soft O
voting O
is O
used O
to O
predict O
the O
category O
of O
the O
Test O
set. O
The O
RF B-MethodName
algorithm O
consists O
of O
a O
set O
of O
decision O
trees, O
each O
of O
which O
is O
trained O
with O
a O
random O
subset O
of O
features, O
and O
the O
prediction O
is O
carried O
out O
based O
on O
majority O
voting O
of O
all O
the O
trees O
in O
the O
forest O
(Is- O
lam O
et O
al., O
2019). O
The O
MLP B-MethodName
classifier O
is O
widely O
used O
in O
classification O
as O
they O
are O
simple O
and O
easy O
to O
im- O
plement. O
It O
is O
a O
feed-forward O
neural O
network O
which O
consists O
of O
three O
layers, O
namely: O
input O
layer, O
an O
out- O
put O
layer, O
and O
one O
or O
more O
hidden O
layers O
(Lakhotia O
and O
Bresson, O
2018). O
The O
MNB B-MethodName
model O
is O
a O
popular O
ML O
classifier O
because O
of O
its O
computing O
efficiency O
and O
relatively O
good O
predictive O
performance O
(Har- O
jule O
et O
al., O
2020). O
GB B-MethodName
classifier I-MethodName
will O
benefit O
the O
regularization O
methods O
that O
penalize O
different O
parts O
of O
the O
algorithm O
and O
improve O
the O
overall O
perfor- O
mance O
by O
reducing O
overfitting O
(Stein O
et O
al., O
2019). O
3.2 O
Transfer O
Learning O
model O
with O
BERT B-MethodName
BERT B-MethodName
is O
a O
popular O
language O
representation O
model O
used O
to O
train O
TL O
model O
for O
text O
classification. O
It O
is O
pre-trained O
on O
Wikipedia O
corpus O
with O
2,500 O
million O
words O
of O
unlabelled O
text O
and O
800 O
million O
words O
from O
huggingface O
Book O
Corpus. O
Further, O
it O
is O
a O
bidirectional O
model O
which O
learns O
information O
from O
both O
left O
and O
right O
sides O
of O
the O
context. O
BERT O
accepts O
raw O
text O
for O
fine-tuning O
the O
pre- O
trained O
embeddings. O
The O
model O
provides O
positional O
encoding O
based O
BERT B-MethodName
tokenizer O
followed O
by O
BERT B-MethodName
embeddings O
which O
transforms O
each O
token O
into O
ten- O
sors O
so O
that O
the O
classifiers O
can O
be O
trained O
using O
these O
tensors. O
The O
framework O
of O
the O
proposed O
TL O
model O
is O
shown O
in O
Figure O
2. O
4 O
Experiments O
and O
Results O
Several O
experiments O
were O
conducted O
with O
different O
resampling O
techniques O
and O
various O
combinations O
of O
features O
and O
classifiers O
and O
the O
models O
that O
gave O
good O
performance O
on O
the O
Development O
set O
are O
ap- O
plied O
for O
the O
Test O
set. O
The O
dataset O
provided O
by O
the O
organisers O
to O
detect B-TaskName
the I-TaskName
sign I-TaskName
of I-TaskName
depression I-TaskName
consists O
of O
social B-DatasetName
media I-DatasetName
comments I-DatasetName
in I-DatasetName
English I-DatasetName
(Sampath O
et O
al., O
2022b). O
Table O
1 O
gives O
the O
class-wise O
distri- O
bution O
of O
the O
dataset. O
For O
TL O
model, O
the O
pre-trained O
BERT-base-uncased9model B-MethodName
is O
used O
with O
Classifi- O
cationModel10- O
a O
transformer O
based O
classifier, O
to O
predict O
the O
labels O
for O
the O
given O
Test O
set. O
Table O
2 O
shows O
the O
hyperparameters O
and O
the O
values O
of O
the O
hyperparameters O
used O
to O
implement O
TL O
model. O
The O
proposed O
models O
were O
evaluated O
by O
the O
orga- O
nizers O
of O
the O
shared O
task O
based O
on O
macro B-MetricName
averaged I-MetricName
F-score I-MetricName
and O
the O
results O
are O
shown O
in O
Table O
3. O
En- O
semble O
of O
ML O
classifiers O
model O
achieved O
macro B-MetricName
averaged I-MetricName
F-scores I-MetricName
of O
0.573 B-MetricValue
and O
0.419 B-MetricValue
for O
Develop- O
ment O
(Dev) O
set O
and O
Test O
set O
respectively. O
Further, O
the O
TL O
model O
outperformed O
the O
other O
model O
with O
macro B-MetricName
averaged I-MetricName
F-scores I-MetricName
of O
0.620 B-MetricValue
and O
0.479 B-MetricValue
for O
Dev O
set O
and O
Test O
set O
respectively. O
In O
spite O
of O
re- O
sampling O
the O
data O
using O
random O
over O
sampling O
to O
balance O
the O
dataset, O
the O
results O
are O
still O
low. O
This O
may O
be O
because O
the O
random O
over O
sampling O
tech- O
nique O
duplicates O
features O
from O
the O
minority O
classes O
resulting O
in O
overfitting O
for O
some O
models O
(Yap O
et O
al., O
2014). O
5 O
Conclusion O
and O
Future O
work O
This O
paper O
describes O
the O
models O
submitted O
by O
our O
team O
- O
MUCS O
to O
DepSign-LT-EDI@ACL-2022 O
shared O
task O
to O
detect B-TaskName
signs I-TaskName
of I-TaskName
depression I-TaskName
from I-TaskName
social I-TaskName
media I-TaskName
text I-TaskName
in O
English. O
The O
two O
proposed O
models O
are: O
i) O
Ensemble O
of O
ML O
classifiers O
trained O
with O
the O
combination O
of O
frequency O
and O
text O
based O
features O
and O
ii) O
TL O
model O
with O
BERT. B-MethodName
Resampling O
is O
also O
explored O
to O
handle O
the O
data O
imbalance O
problem. O
The O
TL O
model O
outperformed O
Ensemble O
model O
with O
a O
macro B-MetricName
averaged I-MetricName
F-score I-MetricName
of O
0.479 B-MetricValue
securing O
18th O
rank O
in O
the O
shared O
task. O
Future O
research O
will O
ex- O
plore O
different O
sets O
of O
features O
and O
feature O
selection O
algorithms O
for O
detecting O
sign O
of O
depression O
from O
social O
media O
text. O
