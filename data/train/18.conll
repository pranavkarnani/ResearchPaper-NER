Proceedings  O
of  O
the  O
19th  O
International  O
Conference  O
on  O
Spoken  O
Language  O
Translation  O
(IWSLT  O
2022)  O
,  O
pages  O
286  O
-  O
292  O
May  O
26-27,  O
2022  O
c  O
2022  O
Association  O
for  O
Computational  O
Linguistics  O
NAIST  O
Simultaneous  O
Speech-to-Text  O
Translation  O
System  O
for  O
IWSLT  O
2022  O
Ryo  O
Fukuda†,  O
Yuka  O
Ko†,  O
Yasumasa  O
Kano†,  O
Kosuke  O
Doi†,  O
Hirotaka  O
Tokuyama†,  O
Sakriani  O
Sakti†‡,  O
Katsuhito  O
Sudoh†,  O
Satoshi  O
Nakamura†  O
†Nara  O
Institute  O
of  O
Science  O
and  O
Technology,  O
Japan  O
‡Japan  O
Advanced  O
Institute  O
of  O
Science  O
and  O
Technology,  O
Japan  O
fukuda.ryo.fo3@is.naist.jp  O
Abstract  O
This  O
paper  O
describes  O
NAIST’s  O
simultane-  O
ous  O
speech  B-TaskName
translation  I-TaskName
systems  O
developed  O
for  O
IWSLT  B-DatasetName
2022  I-DatasetName
Evaluation  O
Campaign.  O
We  O
partic-  O
ipated  O
the  O
speech-to-speech  O
track  O
for  O
English-  O
to-German  O
and  O
English-to-Japanese.  O
Our  O
pri-  O
mary  O
submissions  O
were  O
end-to-end  O
systems  O
us-  O
ing  O
adaptive  O
segmentation  O
policies  O
based  O
on  O
Prefix  O
Alignment.  O
1  O
Introduction  O
This  O
paper  O
describes  O
NAIST’s  O
submissions  O
to  O
IWSLT  B-DatasetName
2022  I-DatasetName
(Anastasopoulos  O
et  O
al.,  O
2022)  O
Simul-  O
taneous  O
Speech  O
Translation  O
track.  O
We  O
participated  O
the  O
speech-to-speech  O
track  O
for  O
English-to-German  O
(En-De)  O
and  O
English-to-Japanese  O
(En-Ja)  O
using  O
our  O
end-to-end  O
simultaneous  B-MethodName
machine  I-MethodName
translation  I-MethodName
(SimulMT)  I-MethodName
systems.  O
SimulMT  B-MethodName
based  O
on  O
neural  O
machine  O
translation  O
(NMT)  O
has  O
achieved  O
a  O
large  O
success  O
in  O
recent  O
years.  O
There  O
are  O
two  O
different  O
SimulMT  B-MethodName
approaches  O
de-  O
pending  O
on  O
the  O
policy  O
that  O
determines  O
READ  O
(wait-  O
ing  O
for  O
speech  O
input)  O
and  O
WRITE  O
(writing  O
text  O
out-  O
put)  O
actions:  O
fixed  O
andadaptive  O
.  O
Fixed  O
policies  O
are  O
usually  O
implemented  O
by  O
simple  O
rules  O
(Dalvi  O
et  O
al.,  O
2018;  O
Ma  O
et  O
al.,  O
2019;  O
Fukuda  O
et  O
al.,  O
2021;  O
Sen  O
et  O
al.,  O
2021).  O
They  O
are  O
simple  O
yet  O
often  O
effective,  O
but  O
they  O
sometimes  O
make  O
inappropriate  O
decisions  O
due  O
to  O
large  O
word  O
order  O
differences,  O
pauses,  O
and  O
so  O
on.  O
In  O
contrast,  O
adaptive  O
policies  O
decide  O
READ  O
or  O
WRITE  O
actions  O
flexibly  O
taking  O
current  O
context  O
into  O
account  O
(Zheng  O
et  O
al.,  O
2019a,b,  O
2020;  O
Liu  O
et  O
al.,  O
2021).  O
They  O
can  O
be  O
more  O
effective  O
than  O
fixed  O
policies  O
in  O
end-to-end  O
speech-to-speech  O
SimulMT  O
because  O
it  O
is  O
difficult  O
to  O
define  O
fixed  O
policies  O
for  O
speech  O
input.  O
In  O
our  O
systems,  O
we  O
use  O
Bilingual  O
Prefix  O
Align-  O
ment  O
(Kano  O
et  O
al.,  O
2022),  O
which  O
extracts  O
alignment  O
between  O
bilingual  O
prefix  O
pairs  O
in  O
the  O
training  O
time,  O
for  O
prefix-to-prefix  O
translation  O
in  O
SimulMT.  O
The  O
Bilingual  O
Prefix  O
Alignment  O
is  O
applied  O
to  O
extract  O
Step  O
A  O
brief  O
overview  O
of  O
our  O
prefix-to-prefix  O
trans-  O
lation  O
process  O
(Kano  O
et  O
al.,  O
2022)  O
from  O
English  O
to  O
Japanese.  O
The  O
threshold  B-HyperparameterName
of  I-HyperparameterName
boundary  I-HyperparameterName
probability  I-HyperparameterName
is  O
0.5  B-HyperparameterValue
in  O
this  O
example.  O
Underlined  O
parts  O
are  O
the  O
forced  O
output  O
prefixes.  O
prefix  O
pairs  O
of  O
source  O
language  O
speech  O
and  O
target  O
language  O
translations.  O
We  O
also  O
use  O
the  O
prefix  O
pairs  O
to  O
train  O
a  O
boundary  O
prediction  O
model  O
for  O
an  O
adaptive  O
speech  O
segmentation  O
policy.  O
Our  O
system  O
showed  O
some  O
improvements  O
against  O
wait-  O
kbaselines  O
on  O
the  O
development  O
data,  O
in  O
all  O
the  O
latency  O
regimes  O
in  O
both  O
En-De  O
and  O
En-Ja.  O
2Simultaneous  O
Speech  O
Translation  O
based  O
on  O
Bilingual  O
Prefix  O
Alignment  O
We  O
developed  O
simultaneous  O
speech  B-MethodName
translation  I-MethodName
(SimulST)  I-MethodName
based  O
on  O
offline  O
speech  O
translation  O
(ST).  O
Our  O
SimulST  B-MethodName
system  O
translates  O
an  O
incrementally-  O
growing  O
source  O
language  O
speech  O
prefix  O
into  O
the  O
tar-  O
get  O
language.  O
When  O
the  O
system  O
detects  O
a  O
segment  O
boundary  O
in  O
source  O
language  O
speech,  O
the  O
latest  O
seg-  O
ment  O
is  O
translated  O
taking  O
its  O
input  O
and  O
translation  O
history  O
into  O
account.  O
The  O
ST  O
model  O
is  O
basically  O
the  O
same  O
as  O
an  O
offline  O
one,  O
and  O
we  O
used  O
it  O
to  O
translate  O
an  O
input  O
prefix  O
speech  O
segment  O
from  O
the  O
beginning.  O
However,  O
we  O
constrained  O
the  O
translation  O
prefix  O
by  O
the  O
results  O
in  O
the  O
previous  O
time  O
step.  O
The  O
constraint  O
is  O
implemented  O
by  O
a  O
forced  O
decoding  O
with  O
a  O
given  O
translation  O
prefix.  O
Figure  O
1  O
shows  O
an  O
example  O
of  O
whole  O
translation  O
process,  O
but  O
we  O
input  O
the  O
speech  O
prefixes  O
with  O
fixed  O
number  O
of  O
frames.  O
Please  O
refer286to  O
(Kano  O
et  O
al.,  O
2022)  O
for  O
details  O
of  O
Bilingual  O
Prefix  O
Alignment.  O
For  O
this  O
system,  O
we  O
need  O
an  O
ST  O
model  O
using  O
an  O
ST  O
corpus  O
consisting  O
of  O
source  O
language  O
speech  O
segments  O
and  O
corresponding  O
translations  O
in  O
the  O
tar-  O
get  O
language.  O
We  O
then  O
fine-tune  O
the  O
offline  O
ST  O
model  O
with  O
prefix  O
pairs  O
of  O
source  O
language  O
speech  O
and  O
target  O
language  O
translations  O
obtained  O
using  O
Bilingual  O
Prefix  O
Alignment.  O
We  O
also  O
need  O
a  O
bound-  O
ary  O
predictor  O
to  O
segment  O
source  O
language  O
speech  O
adaptively  O
as  O
SimulMT  O
policies.  O
In  O
this  O
section,  O
we  O
present  O
how  O
to  O
extract  O
prefix  O
pairs  O
(2.1)  O
and  O
build  O
the  O
boundary  O
predictor  O
(2.2).  O
2.1  O
Extracting  O
Prefix  O
Pairs  O
Suppose  O
we  O
already  O
have  O
an  O
offline  O
ST  O
model  O
trained  O
using  O
an  O
ST  O
corpus  O
and  O
are  O
going  O
to  O
ex-  O
tract  O
prefix  O
pairs  O
for  O
a  O
speech  O
segment  O
in  O
the  O
source  O
language  O
(  O
S).  O
First,  O
we  O
extract  O
the  O
speech  O
prefixes  O
withτ,2τ,3τ,  O
...  O
frames.  O
Then,  O
for  O
each  O
speech  O
prefix  O
Sprefix  O
,  O
we  O
translate  O
it  O
into  O
ˆTprefix  O
using  O
the  O
offline  O
ST  O
model.  O
Finally,  O
we  O
compare  O
ˆTprefix  O
with  O
ˆToffline  O
,  O
which  O
is  O
a  O
translation  O
of  O
the  O
entire  O
speech  O
segment.  O
If  O
ˆTprefix  O
appears  O
as  O
a  O
prefix  O
of  O
ˆToffline  O
,  O
we  O
extact  O
(Sprefix  O
,ˆTprefix  O
)as  O
a  O
prefix  O
pair.  O
We  O
apply  O
this  O
process  O
to  O
all  O
the  O
source  O
prefixes.  O
Here,  O
we  O
use  O
a  O
forced  O
decoding  O
with  O
the  O
previously  O
ex-  O
tracted  O
prefix  O
ˆTprefix  O
to  O
obtain  O
latter  O
prefix  O
trans-  O
lations  O
and  O
update  O
ˆToffline  O
to  O
extract  O
consistent  O
prefix  O
translations.  O
We  O
may  O
obtain  O
the  O
same  O
tar-  O
get  O
prefix  O
with  O
different  O
source  O
prefixes  O
within  O
a  O
given  O
speech  O
segment.  O
We  O
just  O
extract  O
the  O
first  O
ap-  O
pearance  O
and  O
ignore  O
the  O
rest  O
with  O
longer  O
speech  O
prefixes  O
in  O
such  O
cases.  O
The  O
procedure  O
above  O
some-  O
times  O
extracts  O
unbalanced  O
prefix  O
pairs,  O
in  O
which  O
a  O
source  O
language  O
prefix  O
does  O
not  O
fully  O
match  O
its  O
tar-  O
get  O
language  O
speech  O
counterpart.  O
Such  O
unbalanced  O
prefix  O
pairs  O
frequently  O
appear  O
between  O
English  O
and  O
Japanese  O
and  O
cause  O
the  O
degradation  O
of  O
the  O
transla-  O
tion  O
performance.  O
We  O
use  O
a  O
simple  O
heuristic  O
rule  O
to  O
filter  O
out  O
them  O
based  O
on  O
the  O
length  O
ratio  O
between  O
source  O
language  O
speech  O
and  O
target  O
language  O
trans-  O
lation.  O
We  O
exclude  O
prefix  O
pairs  O
in  O
which  O
the  O
length  O
ratiolens/len  O
texceeds  O
maxratio  O
,  O
where  O
lensis  O
the  O
length  O
of  O
Sprefix  O
(in  O
the  O
number  O
of  O
frames)  O
andlentis  O
the  O
length  O
of  O
ˆTprefix  O
(in  O
the  O
number  O
of  O
words).  O
2.2  O
Boundary  O
Predictor  O
In  O
inference,  O
the  O
SimulST  O
system  O
incrementally  O
reads  O
source  O
speech  O
and  O
predicts  O
a  O
segment  O
bound-ary  O
in  O
every  O
τframes.  O
To  O
train  O
the  O
boundary  O
predictor,  O
we  O
prepare  O
pairs  O
of  O
a  O
speech  O
prefix  O
and  O
the  O
corresponding  O
binary  O
la-  O
bel  O
sequence  O
extracted  O
from  O
the  O
training  O
data.  O
One  O
source  O
language  O
speech  O
derives  O
many  O
speech  O
pre-  O
fixes  O
in  O
τ,2τ,3τ,  O
...  O
frames.  O
Suppose  O
we  O
extracted  O
2τ-  O
and  O
5τ-frame  O
speech  O
prefixes  O
from  O
the  O
same  O
utterance,  O
for  O
example.  O
We  O
assign  O
a  O
label  O
sequence  O
withτ0s  O
followed  O
τ1s  O
to  O
the  O
2τ-frame  O
prefix,  O
which  O
means  O
we  O
should  O
predict  O
a  O
boundary  O
in  O
the  O
second  O
τframes  O
but  O
not  O
in  O
the  O
first  O
τframes.  O
For  O
the5τ-frame  O
prefix,  O
we  O
assign  O
a  O
label  O
sequence  O
where  O
the  O
second  O
and  O
fifth  O
τ-frame  O
parts  O
are  O
filled  O
with1s  O
and  O
the  O
rest  O
with  O
0s,  O
consistently  O
with  O
the  O
2τ-frame  O
prefix.  O
In  O
addition,  O
we  O
also  O
extracted  O
speech  O
prefixes  O
where  O
the  O
last  O
τ-frame  O
part  O
is  O
not  O
a  O
boundary.  O
For  O
example,  O
the  O
last  O
τ-frame  O
part  O
of  O
the3τ-  O
and  O
4τ-frame  O
speech  O
prefixes  O
is  O
filled  O
with  O
0s  O
in  O
this  O
case.  O
The  O
boundary  O
predictor  O
is  O
trained  O
using  O
weighted  O
cross-entropy  O
loss  O
normalized  O
in  O
inverse  O
proportional  O
to  O
the  O
number  O
of  O
appearances  O
of  O
each  O
label.  O
During  O
inference,  O
the  O
boundary  O
predictor  O
pre-  O
dicts  O
a  O
boundary  O
in  O
every  O
τframes  O
as  O
a  O
binary  O
classification  O
output.  O
The  O
prediction  O
is  O
made  O
on  O
every  O
frames  O
in  O
the  O
τ-frame  O
segment,  O
so  O
we  O
obtain  O
τbinary  O
classification  O
outputs.  O
If  O
the  O
proportion  O
of  O
label  O
1here  O
is  O
larger  O
than  O
or  O
equals  O
to  O
λthre,  O
the  O
predictor  O
makes  O
a  O
decision  O
of  O
boundary  O
,  O
otherwise  O
non-boundary  O
.  O
3  O
Primary  O
System  O
We  O
developed  O
SimulST  B-MethodName
systems  O
for  O
two  O
language  O
pairs:  O
English-to-German  O
(En-De)  O
and  O
English-  O
to-Japanese  O
(En-Ja).  O
We  O
implemented  O
both  O
our  O
systems  O
based  O
on  O
fairseq1(Ott  O
et  O
al.,  O
2019).  O
3.1  O
End-to-end  O
Speech  O
Translation  O
3.1.1  O
Data  O
We  O
used  O
MuST-C  B-DatasetName
v2  I-DatasetName
(Di  O
Gangi  O
et  O
al.,  O
2019),  O
a  O
mul-  O
tilingual  O
ST  O
corpus  O
extracted  O
from  O
TED  O
talks  O
subti-  O
tles.  O
Each  O
dataset  O
consists  O
of  O
triplets  O
of  O
segmented  O
English  O
speech,  O
transcripts,  O
and  O
target  O
language  O
translations.  O
The  O
En-De  O
and  O
En-Ja  O
datasets  O
con-  O
tained  O
about  O
250k  O
and  O
330k  O
segments,  O
respectively.  O
As  O
acoustic  O
features,  O
we  O
used  O
80-dimensional  O
log  O
Mel  O
filter  O
bank  O
(FBANK)  O
with  O
global-level  O
cepstral  O
mean  O
and  O
variance  O
normalization  O
(CMVN)  O
applied.  O
1https://github.com/  O
pytorch/fairseq/commit/  O
acf312418e4718996a103d67bd57516938137a7d287We  O
applied  O
with  O
Byte  O
Pair  O
Encoding  O
(BPE)  O
to  O
split  O
the  O
sentences  O
into  O
subwords  O
using  O
SentencePiece  O
(Kudo  O
and  O
Richardson,  O
2018),  O
with  O
a  O
vocabulary  O
of  O
20,000  O
subwords  O
shared  O
across  O
the  O
source  O
and  O
target  O
languages.  O
3.1.2  O
Model  O
We  O
used  O
the  O
Transformer  O
implementation  O
of  O
fairseq  O
to  O
build  O
the  O
models.  O
We  O
trained  O
the  O
ASR  O
model  O
using  O
the  O
English  O
speech-text  O
pairs  O
and  O
then  O
trained  O
the  O
ST  O
model  O
using  O
the  O
ASR  O
model  O
for  O
the  O
param-  O
eter  O
initialization.  O
The  O
architecture  O
of  O
ASR  O
and  O
ST  O
models  O
were  O
the  O
same.  O
The  O
encoder  O
consisted  O
of  O
a  O
2D-convolution  O
layer  O
that  O
reduces  O
the  O
sequence  O
length  O
to  O
a  O
quarter,  O
and  O
12  O
transformer  O
encoder  O
layers.  O
The  O
decoder  O
consisted  O
of  O
six  O
transformer  O
decoder  O
layers.  O
We  O
set  O
the  O
embedding  O
dimensions  O
and  O
the  O
feed-forward  O
dimensions  O
to  O
256  O
and  O
2,048  O
and  O
used  O
four  O
attention  O
heads  O
for  O
both  O
the  O
encoder  O
and  O
decoder.  O
The  O
model  O
was  O
trained  O
using  O
Adam  B-HyperparameterName
with  O
an  O
initial  O
learning  B-HyperparameterName
rate  I-HyperparameterName
of  O
0.0005  B-HyperparameterValue
with  O
warmup  B-MethodName
updates  I-MethodName
of  O
10,000.  B-HyperparameterValue
In  O
the  O
En-De  O
ASR  O
and  O
ST  O
mod-  O
els  O
and  O
the  O
En-Ja  O
ASR  O
model,  O
we  O
performed  O
the  O
dropout  B-HyperparameterName
probability  I-HyperparameterName
of  O
0.1  B-HyperparameterValue
and  O
set  O
early  B-HyperparameterName
stopping  I-HyperparameterName
patience  I-HyperparameterName
to  O
16.  B-HyperparameterValue
In  O
the  O
En-Ja  O
ST  O
model,  O
we  O
set  O
the  O
dropout  B-HyperparameterName
probability  I-HyperparameterName
of  O
0.2  B-HyperparameterValue
and  O
set  O
early  B-HyperparameterName
stopping  I-HyperparameterName
patience  I-HyperparameterName
to  O
32.  B-HyperparameterValue
The  O
ST  O
model  O
training  O
was  O
in  O
two  O
steps.  O
We  O
first  O
trained  O
the  O
ST  O
model  O
using  O
entire  O
segment  O
pairs  O
from  O
the  O
MuST-C.  B-DatasetName
We  O
then  O
fine-tuned  O
the  O
model  O
using  O
bilingual  O
prefix  O
pairs  O
extracted  O
using  O
Bilingual  O
Prefix  O
Alignment  O
(2.1).  O
3.1.3  O
Evaluation  O
We  O
evaluated  O
the  O
models  O
with  O
BLEU  B-MetricName
and  O
Average  B-MetricName
Lagging  I-MetricName
(AL)  I-MetricName
(Ma  O
et  O
al.,  O
2019)  O
using  O
SimulEval  O
(Ma  O
et  O
al.,  O
2020)  O
on  O
MuST-C  B-DatasetName
v2  I-DatasetName
tst-COMMON.  I-DatasetName
For  O
En-De,  O
we  O
evaluated  O
on  O
the  O
best  O
ST  O
model  O
based  O
on  O
the  O
dev  O
set,  O
and  O
for  O
En-Ja,  O
we  O
evaluated  O
on  O
the  O
checkpoint  O
averaged  O
ST  O
model  O
in  O
last  O
10  O
epochs.  O
Our  O
proposed  O
models  O
were  O
decoded  O
with  O
beam  O
search  O
(beam  O
size=10).  O
3.2  O
Implementation  O
Details  O
of  O
the  O
Proposed  O
Method  O
3.2.1  O
Data  O
Extraction  O
We  O
extracted  O
training  O
data  O
for  O
the  O
ST  O
model  O
and  O
the  O
boundary  O
prediction  O
model  O
by  O
using  O
Bilingual  O
Pre-  O
fix  O
Alignment  O
described  O
in  O
section  O
The  O
main  O
results  O
of  O
our  O
systems  O
on  O
En-De  O
tst-  O
COMMON.  O
†usesT=  O
48  O
frames  O
as  O
an  O
input  O
unit.  O
System  O
BLEU  O
AL  O
2:  O
The  O
main  O
results  O
of  O
our  O
systems  O
on  O
En-Ja  O
tst-  O
COMMON.  O
The  O
FT  O
model  O
was  O
the  O
best  O
model  O
with  O
data  O
filtering  O
approach.  O
3.2.2  O
Boundary  O
Predictor  O
We  O
trained  O
the  O
boundary  O
predictor  O
using  O
the  O
ex-  O
tracted  O
source  O
language  O
speech  O
prefixes.  O
The  O
boundary  O
predictor  O
consisted  O
of  O
a  O
2D-convolution  O
layer  O
reducing  O
the  O
sequence  O
length  O
to  O
τ/4(25  O
frames),  O
a  O
unidirectional  O
LSTM  O
layer,  O
and  O
an  O
output  O
linear  O
layer  O
that  O
gives  O
label  O
probabilities  O
ˆxn∈R2at  O
the  O
n-th  O
frame  O
of  O
the  O
convolution  O
layer.  O
We  O
set  O
the  O
embedding  O
dimensions  O
and  O
the  O
hidden  O
state  O
dimensions  O
of  O
the  O
LSTM  O
layer  O
to  O
256  O
and  O
512.  O
The  O
model  O
was  O
trained  O
using  O
Adam  B-HyperparameterName
with  O
an  O
initial  O
learning  B-HyperparameterName
rate  I-HyperparameterName
of  O
0.0001,  B-HyperparameterValue
warmup  B-HyperparameterName
updates  I-HyperparameterName
of  O
4,000  B-HyperparameterValue
and  O
early  B-HyperparameterName
stopping  I-HyperparameterName
patience  I-HyperparameterName
of  O
8.  B-HyperparameterValue
During  O
inference,  O
we  O
tried  O
several  O
values  O
of  O
voting  O
threshold  O
λthre  O
between  O
0.0  O
to  O
1.0  O
to  O
adjust  O
for  O
latency  O
and  O
BLEU  B-MetricName
tradeoffs.  O
4  O
Experiments  O
We  O
conducted  O
comparative  O
experiments  O
with  O
wait-  O
k(Ma  O
et  O
al.,  O
2019).  O
For  O
baseline  O
wait-  O
k,  O
The  O
evaluation  O
results  O
of  O
boundary  O
predic-  O
tor  O
models  O
on  O
prefix  O
pairs  O
of  O
tst-COMMON  O
dataset  O
inλthre=  O
0.5.  O
Following  O
the  O
default  O
wait-  O
ksetting  O
in  O
fairseq,  O
one  O
unit  O
for  O
kwas  O
set  O
to  O
280  O
frames.  O
For  O
examples,  O
when  O
k=  O
3,  O
after  O
reading  O
3×280frames,  O
the  O
model  O
would  O
WRITE  O
and  O
READ  O
alternately.  O
4.1  O
Main  O
Results  O
1  O
shows  O
the  O
best  O
results  O
of  O
the  O
proposed  O
and  O
baseline  O
2  O
shows  O
the  O
counter-  O
part  O
in  O
En-Ja  O
with  O
low  O
(AL  O
≤2,500),  O
medium  O
(AL  O
≤4,000),  O
and  O
high  O
(AL  O
≤5,000)  O
latency  O
regimes.  O
In  O
both  O
language  O
pairs,  O
our  O
model  O
outperformed  O
the  O
baselines  O
with  O
all  O
the  O
latency  O
regimes.  O
In  O
particular,  O
the  O
proposed  O
method  O
showed  O
a  O
significant  O
improve-  O
ment  O
of  O
more  O
than  O
10  O
points  O
in  O
BLEU  O
in  O
En-De  O
with  O
low  O
latency  O
regime.  O
On  O
the  O
other  O
hand,  O
the  O
improvement  O
for  O
En-Ja  O
was  O
smaller  O
than  O
in  O
En-De.  O
One  O
possible  O
reason  O
was  O
the  O
performance  O
differ-  O
ence  O
of  O
the  O
boundary  O
predictor,  O
which  O
depends  O
on  O
the  O
difference  O
between  O
source  O
and  O
target  O
languages.  O
Table  O
3  O
shows  O
the  O
results  O
of  O
the  O
boundary  O
predic-  O
tor  O
on  O
prefix  O
pairs  O
of  O
tst-COMMON  O
dataset  O
with  O
λthre=  O
0.5.  O
For  O
both  O
language  O
pairs,  O
the  O
accu-  O
racy  O
was  O
under  O
68%,  O
suggesting  O
the  O
difficulty  O
of  O
binary  O
classification  O
at  O
the  O
acoustic  O
frame  O
level.  O
Es-  O
pecially,  O
the  O
recall  O
of  O
En-Ja  O
boundary  O
predictor  O
was  O
extremely  O
low,  O
which  O
means  O
that  O
its  O
output  O
predic-  O
tions  O
were  O
almost  O
shows  O
the  O
counterparts  O
in  O
En-Ja.  O
In  O
En-De,  O
the  O
fine-  O
tuned  O
model  O
worked  O
better  O
than  O
the  O
non  O
fine-tuned  O
model  O
in  O
the  O
range  O
of  O
AL  O
≤4,000.  O
The  O
perfor-  O
mance  O
gap  O
between  O
proposed  O
models  O
and  O
wait-  O
k  O
models  O
in  O
the  O
low  O
latency  O
ranges  O
were  O
larger  O
than  O
0  O
The  O
BLEU  O
and  O
AL  O
results  O
of  O
FT,  O
w/o  O
FT  O
and  O
baseline  O
in  O
En-De.  O
The  O
two  O
FT  O
points  O
in  O
low  O
latency  O
regime  O
(AL  O
≤1000)  O
were  O
evaluated  O
The  O
BLEU  O
and  O
AL  O
results  O
of  O
FT,  O
w/o  O
FT  O
and  O
baseline  O
in  O
En-Ja.  O
The  O
FT  O
model  O
was  O
fine-tuned  O
with  O
non-filtered  O
prefix  O
pairs.  O
those  O
in  O
the  O
high  O
latency  O
ranges.  O
On  O
the  O
other  O
hand,  O
the  O
non-fine-tuned  O
model  O
worked  O
better  O
than  O
the  O
fine-tuned  O
model  O
in  O
the  O
very  O
large  O
latency  O
ranges  O
with  O
AL  O
>4000.  O
Both  O
of  O
them  O
outperformed  O
the  O
baseline  O
wait-  O
kmodels  O
consistently  O
in  O
BLEU.  O
The  O
fine-tuned  O
model  O
achieved  O
higher  O
BLEU  O
scores  O
at  O
the  O
cost  O
of  O
the  O
larger  O
latency,  O
compared  O
to  O
the  O
non-fine-tuned  O
and  O
wait-  O
kmodels.  O
In  O
En-Ja,  O
the  O
scores  O
of  O
the  O
non-fine-tuned  O
model  O
were  O
better  O
than  O
those  O
of  O
wait-  O
kbaselines  O
with  O
all  O
the  O
latency  O
regimes.  O
The  O
performance  O
improve-  O
ments  O
of  O
the  O
non-fine-tuned  O
model  O
against  O
wait-  O
kmodels  O
in  O
the  O
low  O
latency  O
ranges  O
were  O
larger  O
than  O
those  O
in  O
the  O
high  O
latency  O
ranges.  O
However,  O
the  O
scores  O
of  O
the  O
fine-tuned  O
model  O
were  O
worse  O
than  O
those  O
of  O
wait-  O
kmodels  O
and  O
the  O
non-fine-tuned  O
model  O
almost  O
everywhere.  O
It  O
suggests  O
the  O
failure  O
of  O
appropriate  O
fine-tuning  O
in  O
took  O
our  O
order,  O
and  O
then  O
went  O
to  O
the  O
couple  O
in  O
the  O
booth  O
next  O
to  O
us,  O
and  O
she  O
lowered  O
hervoic  O
e  O
...  O
4:  O
The  O
samples  O
size  O
of  O
En-Ja  O
prefix  O
alignment  O
data  O
filtered  O
by  O
maxratio  O
.maxratio  O
indicates  O
ratio  O
between  O
source  O
speech  O
frames  O
size  O
and  O
target  O
hypothesis  O
tokens  O
length.  O
Offline  O
5:  O
The  O
En-Ja  O
FT  O
BLEU  O
results  O
on  O
offline  O
with  O
filtered  O
prefix  O
alignment  O
data.  O
hyp/ref  O
indicates  O
ratio  O
between  O
hypothesis  O
length  O
and  O
reference  O
length.  O
4.2.1  O
Data  O
Filtering  O
for  O
English-Japanese  O
In  O
contrast  O
to  O
En-De,  O
the  O
fine-tuned  O
model  O
was  O
in-  O
ferior  O
to  O
the  O
non-fine-tuned  O
and  O
wait-  O
kmodels  O
in  O
En-Ja.  O
We  O
expected  O
that  O
under-translation  O
would  O
degrade  O
the  O
performance  O
because  O
the  O
fine-tuning  O
used  O
prefix  O
pairs  O
of  O
a  O
long  O
source  O
language  O
speech  O
prefix  O
and  O
a  O
short  O
target  O
language  O
text  O
segment.  O
It  O
would  O
be  O
due  O
to  O
differences  O
in  O
sentence  O
structures  O
between  O
English  O
and  O
Japanese.  O
Since  O
English  O
and  O
German  O
are  O
subject-verb-object  O
(SVO)  O
languages,  O
the  O
English  O
prefix  O
speech  O
frames  O
and  O
the  O
German  O
prefix  O
tokens  O
can  O
be  O
aligned  O
without  O
long-distance  O
reordering.  O
The  O
En-Ja  O
BLEU  O
and  O
AL  O
results  O
of  O
w/o  O
FT  O
models  O
and  O
FT  O
models.  O
The  O
FT  O
models  O
were  O
fine-tuned  O
with  O
filtered  O
prefix  O
alignment  O
data.  O
{SV  O
,  O
SV},  O
{SVO,  O
SVO}.  O
On  O
the  O
other  O
hand,  O
since  O
Japanese  O
is  O
a  O
subject-object-verb  O
(SOV)  O
language,  O
the  O
difference  O
in  O
sentence  O
structures  O
between  O
them  O
causes  O
the  O
difficulty  O
in  O
aligning  O
prefixes.  O
For  O
exam-  O
ple,  O
the  O
prefix  O
pairs  O
of  O
English  O
speech  O
and  O
Japanese  O
text  O
{English  O
prefix  O
frames,  O
Japanese  O
prefix  O
tokens}  O
would  O
consist  O
of  O
{S,  O
S},  O
{SV  O
,  O
S},  O
{SVO,  O
SOV}.  O
Such  O
an  O
unbalanced  O
pair  O
like  O
{SV  O
,  O
S}  O
would  O
make  O
the  O
fine-tuned  O
model  O
prefer  O
inappropriately  O
short  O
outputs.  O
Figure  O
4  O
shows  O
examples  O
of  O
prefix  O
pairs  O
extracted  O
using  O
Bilingual  O
Prefix  O
Alignment  O
to  O
fine-  O
tune  O
the  O
ST  O
model.  O
Bilingual  O
Prefix  O
Alignment  O
ex-  O
tracted  O
unbalanced  O
pairs  O
(Sprefix  O
,ˆTprefix  O
)whose  O
target  O
prefix  O
is  O
too  O
short.  O
For  O
example,  O
a  O
source  O
speech  O
prefix  O
of  O
300  O
frames  O
(about  O
three  O
seconds)  O
is  O
paired  O
with  O
a  O
target  O
prefix  O
of  O
only  O
two  O
subwords,  O
which  O
obviously  O
does  O
not  O
match.  O
We  O
applied  O
simple  O
data  O
filtering  O
described  O
in  O
2.1  O
for  O
En-Ja.  O
Table  O
4  O
shows  O
the  O
prefix  O
alignment  O
dataset  O
with  O
the  O
filtering.  O
The  O
filtering  O
can  O
reduce  O
the  O
unbalanced  O
pairs  O
of  O
data  O
that  O
consists  O
of  O
long  O
source  O
speech  O
frames  O
and  O
short  O
target  O
tokens.  O
It290would  O
alleviate  O
the  O
model  O
to  O
generate  O
too  O
short  O
sequences.  O
Table  O
5  O
shows  O
the  O
results  O
of  O
the  O
fine-  O
tuned  O
model  O
with  O
the  O
filtered  O
prefix  O
pairs.  O
Table  O
5  O
shows  O
the  O
BLEU  O
improvement  O
from  O
no  O
filter  O
set-  O
ting  O
(None)  O
to  O
larger  O
maxratio  O
filter  O
setting  O
with  O
alleviating  O
the  O
gap  O
between  O
hypothesis  O
length  O
and  O
reference  O
length  O
the  O
re-  O
sults  O
of  O
the  O
fine-tuned  O
(FT)  O
models  O
with  O
filtered  O
pre-  O
fix  O
alignment  O
dataset.  O
FT  O
(None)  O
was  O
worse  O
than  O
the  O
non-fine-tuned  O
model  O
in  O
the  O
latency  O
ranges  O
with  O
AL>3500.  O
The  O
scores  O
by  O
the  O
fine-tuned  O
model  O
us-  O
ing  O
filtered  O
data  O
on  O
maxratio  O
=  O
80  O
(filter80)  O
were  O
almost  O
the  O
same  O
as  O
FT  O
(None)  O
model’s.  O
Decreas-  O
ingmaxratio  O
to  O
20  O
significantly  O
improved  O
BLEU  O
scores.  O
It  O
suggests  O
selective  O
use  O
of  O
the  O
fine-tuning  O
data  O
alleviated  O
the  O
under-translation  O
problem  O
for  O
distant  O
language  O
pairs.  O
5  O
Conclusions  O
In  O
this  O
paper,  O
we  O
described  O
our  O
SimulST  O
systems  O
in  O
English-to-German  O
and  O
English-to-Japanese.  O
The  O
proposed  O
method  O
uses  O
prefix  O
alignment  O
data  O
to  O
fine-  O
tune  O
the  O
offline  O
ST  O
model  O
and  O
train  O
boundary  O
pre-  O
dictor  O
that  O
judges  O
when  O
to  O
READ  O
and  O
WRITE.  O
Our  O
models  O
achieved  O
some  O
improvements  O
compared  O
to  O
the  O
wait-  O
kbaselines  O
in  O
every  O
latency  O
regime  O
in  O
both  O
English-to-German  O
and  O
English-to-Japanese.  O
Acknowledgement  O
Part  O
of  O
this  O
work  O
was  O
supported  O
by  O
JSPS  O
KAK-  O
ENHI  O
Grant  O
Number  O
JP21H05054.  O